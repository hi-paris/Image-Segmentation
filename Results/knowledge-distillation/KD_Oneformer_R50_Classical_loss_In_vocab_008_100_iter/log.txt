[07/23 09:08:13] detectron2 INFO: Rank of current process: 0. World size: 2
[07/23 09:08:14] detectron2 INFO: Environment info:
-------------------------------  ---------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]
numpy                            1.24.4
detectron2                       0.6 @/home/ids/gbrison/FC/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    CUDA 12.2
detectron2 arch flags            8.0
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.1+cu121 @/home/ids/gbrison/FC/venv/lib/python3.10/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA L40S (arch=8.9)
Driver version                   545.29.06
CUDA_HOME                        /usr/local/cuda
Pillow                           10.2.0
torchvision                      0.17.1+cu121 @/home/ids/gbrison/FC/venv/lib/python3.10/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[07/23 09:08:14] detectron2 INFO: Command line arguments: Namespace(config_file='/home/ids/gbrison/FC/fc-clip/configs/coco/panoptic-segmentation/fcclip/r50_KD.yaml', resume=False, eval_only=False, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:54928', opts=[])
[07/23 09:08:14] detectron2 INFO: Contents of args.config_file=/home/ids/gbrison/FC/fc-clip/configs/coco/panoptic-segmentation/fcclip/r50_KD.yaml:
[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./fcclip_convnext_large_eval_ade20k_r50.yaml[39m

[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2560[39m

[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m19[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/ids/gbrison/FC/fc-clip/fcclip_cocopan_r50.pth[39m
[38;5;15m  [39m[38;5;204mWEIGHTS_Teacher [39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/tsi/hi-paris/models/oneformer/mapillary_pretrain_250_16_convnext_l_oneformer_cityscapes_90k.pth[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/tsi/hi-paris/FCCLIP_results/All_results/KD_results/KD_Oneformer_R50_Classical_loss_In_vocab_008[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("openvocab_cityscapes_fine_panoptic_train",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("openvocab_cityscapes_fine_panoptic_val",)[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m

[07/23 09:08:14] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mopenvocab_cityscapes_fine_panoptic_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mopenvocab_cityscapes_fine_panoptic_train[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mMINIMUM_INST_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_panoptic_lsj[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;204mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2560[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mCLIP[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFC_CLIP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_MODEL_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRN50[39m
[38;5;15m    [39m[38;5;204mCLIP_PRETRAINED_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mopenai[39m
[38;5;15m    [39m[38;5;204mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mENSEMBLE_ON_VALID_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mGEOMETRIC_ENSEMBLE_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;204mGEOMETRIC_ENSEMBLE_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;204mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;204mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;204mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;204mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m250[39m
[38;5;15m    [39m[38;5;204mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;204mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;204mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;204mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;204mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFCCLIP[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m122.7709383[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.7460125[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m104.09373615[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m68.5005327[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m66.6321579[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m70.32316305[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;204mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;204mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;204mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;204mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFCCLIPHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m19[39m
[38;5;15m    [39m[38;5;204mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;204mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;204mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;204mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;204mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;204mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;204mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;204mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;204mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;204mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;204mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/ids/gbrison/FC/fc-clip/fcclip_cocopan_r50.pth[39m
[38;5;15m  [39m[38;5;204mWEIGHTS_Teacher[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/tsi/hi-paris/models/oneformer/mapillary_pretrain_250_16_convnext_l_oneformer_cityscapes_90k.pth[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/tsi/hi-paris/FCCLIP_results/All_results/KD_results/KD_Oneformer_R50_Classical_loss_In_vocab_008[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m327778[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m355092[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[07/23 09:08:14] detectron2 INFO: Full config saved to /tsi/hi-paris/FCCLIP_results/All_results/KD_results/KD_Oneformer_R50_Classical_loss_In_vocab_008/config.yaml
[07/23 09:08:14] d2.utils.env INFO: Using a generated random seed 18671424
[07/23 09:08:25] d2.engine.defaults INFO: Model:
FCCLIP(
  (backbone): CLIP(
    (clip_model): CLIP(
      (visual): ModifiedResNet(
        (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (layer1): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer2): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer3): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer4): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (attnpool): AttentionPool2d(
          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (c_proj): Linear(in_features=2048, out_features=1024, bias=True)
        )
      )
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ls_1): Identity()
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ls_2): Identity()
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (sem_seg_head): FCCLIPHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(250, 256)
      (query_embed): Embedding(250, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (mask_pooling): MaskPooling()
      (_mask_pooling_proj): Sequential(
        (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
      )
      (class_embed): MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=1024, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 19
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (mask_pooling): MaskPooling()
  (void_embedding): Embedding(1, 1024)
)
[07/23 09:08:25] fcclip.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerPanopticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1333, sample_style='choice'), RandomFlip()]
[07/23 09:08:26] fcclip.data.datasets.register_cityscapes_panoptic INFO: 18 cities found in 'datasets/cityscapes/leftImg8bit/train'.
[07/23 09:08:26] d2.data.build INFO: Using training sampler TrainingSampler
[07/23 09:08:26] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/23 09:08:26] d2.data.common INFO: Serializing 2975 elements to byte tensors and concatenating them all ...
[07/23 09:08:26] d2.data.common INFO: Serialized dataset takes 4.12 MiB
[07/23 09:08:26] d2.data.build INFO: Making batched data loader with batch_size=4
[07/23 09:08:26] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[07/23 09:08:37] d2.engine.defaults INFO: Model:
FCCLIP(
  (backbone): CLIP(
    (clip_model): CLIP(
      (visual): ModifiedResNet(
        (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (layer1): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer2): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer3): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer4): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (attnpool): AttentionPool2d(
          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (c_proj): Linear(in_features=2048, out_features=1024, bias=True)
        )
      )
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ls_1): Identity()
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ls_2): Identity()
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (sem_seg_head): FCCLIPHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(250, 256)
      (query_embed): Embedding(250, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (mask_pooling): MaskPooling()
      (_mask_pooling_proj): Sequential(
        (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
      )
      (class_embed): MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=1024, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 19
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (mask_pooling): MaskPooling()
  (void_embedding): Embedding(1, 1024)
)
[07/23 09:08:37] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/ids/gbrison/FC/fc-clip/fcclip_cocopan_r50.pth ...
[07/23 09:08:37] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/ids/gbrison/FC/fc-clip/fcclip_cocopan_r50.pth ...
[07/23 09:08:37] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (134,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.
[07/23 09:08:37] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.clip_model.ln_final.{bias, weight}[0m
[34mbackbone.clip_model.token_embedding.weight[0m
[34mbackbone.clip_model.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.k_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.positional_embedding[0m
[34mbackbone.clip_model.visual.attnpool.q_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.v_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.conv1.weight[0m
[34mbackbone.clip_model.visual.conv2.weight[0m
[34mbackbone.clip_model.visual.conv3.weight[0m
[34mbackbone.clip_model.visual.layer1.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer1.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer1.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer1.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer1.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer1.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer1.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer1.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer1.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer1.2.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer2.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.2.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.3.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.3.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.3.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.3.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.3.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.3.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer3.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.2.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.3.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.3.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.3.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.3.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.3.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.3.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.4.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.4.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.4.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.4.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.4.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.4.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.5.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.5.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.5.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.5.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.5.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.5.conv3.weight[0m
[34mbackbone.clip_model.visual.layer4.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer4.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer4.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer4.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer4.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer4.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer4.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer4.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer4.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer4.2.conv3.weight[0m
[34mbackbone.clip_model.{logit_scale, positional_embedding, text_projection}[0m
[34mcriterion.empty_weight[0m
[07/23 09:08:37] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/ids/gbrison/FC/fc-clip/fcclip_cocopan_r50.pth ...
[07/23 09:08:37] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/ids/gbrison/FC/fc-clip/fcclip_cocopan_r50.pth ...
[07/23 09:08:37] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (134,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.
[07/23 09:08:37] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.clip_model.ln_final.{bias, weight}[0m
[34mbackbone.clip_model.token_embedding.weight[0m
[34mbackbone.clip_model.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.k_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.positional_embedding[0m
[34mbackbone.clip_model.visual.attnpool.q_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.v_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.conv1.weight[0m
[34mbackbone.clip_model.visual.conv2.weight[0m
[34mbackbone.clip_model.visual.conv3.weight[0m
[34mbackbone.clip_model.visual.layer1.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer1.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer1.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer1.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer1.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer1.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer1.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer1.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer1.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer1.2.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer2.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.2.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.3.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.3.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.3.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.3.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.3.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.3.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer3.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.2.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.3.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.3.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.3.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.3.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.3.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.3.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.4.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.4.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.4.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.4.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.4.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.4.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.5.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.5.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.5.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.5.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.5.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.5.conv3.weight[0m
[34mbackbone.clip_model.visual.layer4.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer4.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer4.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer4.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer4.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer4.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer4.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer4.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer4.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer4.2.conv3.weight[0m
[34mbackbone.clip_model.{logit_scale, positional_embedding, text_projection}[0m
[34mcriterion.empty_weight[0m
[07/23 09:09:05] d2.utils.events INFO:  eta: 0:01:31  iter: 19  total_loss: 67.03  loss_ce: 3.47  loss_mask: 0.2669  loss_dice: 1.49  loss_ce_0: 1.713  loss_mask_0: 0.3113  loss_dice_0: 1.843  loss_ce_1: 1.878  loss_mask_1: 0.3151  loss_dice_1: 1.672  loss_ce_2: 1.795  loss_mask_2: 0.2902  loss_dice_2: 1.604  loss_ce_3: 1.614  loss_mask_3: 0.2844  loss_dice_3: 1.549  loss_ce_4: 1.544  loss_mask_4: 0.2847  loss_dice_4: 1.556  loss_ce_5: 1.577  loss_mask_5: 0.2866  loss_dice_5: 1.542  loss_ce_6: 1.472  loss_mask_6: 0.2815  loss_dice_6: 1.524  loss_ce_7: 1.958  loss_mask_7: 0.2808  loss_dice_7: 1.511  loss_ce_8: 2.615  loss_mask_8: 0.2828  loss_dice_8: 1.51  distillation_loss: 27.59    time: 1.1445  last_time: 1.1519  data_time: 0.1870  last_data_time: 0.0266   lr: 0.0001  max_mem: 20691M
[07/23 09:09:28] d2.utils.events INFO:  eta: 0:01:08  iter: 39  total_loss: 35  loss_ce: 1.935  loss_mask: 0.2384  loss_dice: 1.392  loss_ce_0: 1.166  loss_mask_0: 0.2718  loss_dice_0: 1.643  loss_ce_1: 1.143  loss_mask_1: 0.2654  loss_dice_1: 1.556  loss_ce_2: 1.01  loss_mask_2: 0.2579  loss_dice_2: 1.464  loss_ce_3: 0.9825  loss_mask_3: 0.2532  loss_dice_3: 1.42  loss_ce_4: 0.9775  loss_mask_4: 0.2579  loss_dice_4: 1.413  loss_ce_5: 0.9291  loss_mask_5: 0.2526  loss_dice_5: 1.404  loss_ce_6: 0.9795  loss_mask_6: 0.2483  loss_dice_6: 1.393  loss_ce_7: 1.007  loss_mask_7: 0.2387  loss_dice_7: 1.407  loss_ce_8: 1.09  loss_mask_8: 0.2444  loss_dice_8: 1.408  distillation_loss: 6.631    time: 1.1424  last_time: 1.1360  data_time: 0.0275  last_data_time: 0.0270   lr: 0.0001  max_mem: 20691M
[07/23 09:09:51] d2.utils.events INFO:  eta: 0:00:45  iter: 59  total_loss: 30.76  loss_ce: 1.222  loss_mask: 0.1908  loss_dice: 1.401  loss_ce_0: 0.8442  loss_mask_0: 0.2362  loss_dice_0: 1.631  loss_ce_1: 0.9731  loss_mask_1: 0.2128  loss_dice_1: 1.563  loss_ce_2: 0.8843  loss_mask_2: 0.2025  loss_dice_2: 1.46  loss_ce_3: 0.8245  loss_mask_3: 0.1964  loss_dice_3: 1.427  loss_ce_4: 0.794  loss_mask_4: 0.1945  loss_dice_4: 1.408  loss_ce_5: 0.755  loss_mask_5: 0.1943  loss_dice_5: 1.4  loss_ce_6: 0.7741  loss_mask_6: 0.1939  loss_dice_6: 1.414  loss_ce_7: 0.7496  loss_mask_7: 0.1965  loss_dice_7: 1.413  loss_ce_8: 0.7388  loss_mask_8: 0.1976  loss_dice_8: 1.436  distillation_loss: 4.923    time: 1.1435  last_time: 1.1476  data_time: 0.0288  last_data_time: 0.0324   lr: 0.0001  max_mem: 20691M
[07/23 09:10:15] d2.utils.events INFO:  eta: 0:00:22  iter: 79  total_loss: 29.02  loss_ce: 1.037  loss_mask: 0.2002  loss_dice: 1.379  loss_ce_0: 0.8041  loss_mask_0: 0.2277  loss_dice_0: 1.672  loss_ce_1: 0.905  loss_mask_1: 0.219  loss_dice_1: 1.547  loss_ce_2: 0.8535  loss_mask_2: 0.2071  loss_dice_2: 1.476  loss_ce_3: 0.8  loss_mask_3: 0.2105  loss_dice_3: 1.399  loss_ce_4: 0.7373  loss_mask_4: 0.2067  loss_dice_4: 1.358  loss_ce_5: 0.7375  loss_mask_5: 0.2068  loss_dice_5: 1.372  loss_ce_6: 0.7018  loss_mask_6: 0.2067  loss_dice_6: 1.351  loss_ce_7: 0.7198  loss_mask_7: 0.2053  loss_dice_7: 1.378  loss_ce_8: 0.7527  loss_mask_8: 0.2066  loss_dice_8: 1.368  distillation_loss: 4.705    time: 1.1464  last_time: 1.1531  data_time: 0.0287  last_data_time: 0.0264   lr: 0.0001  max_mem: 21808M
[07/23 09:10:37] fvcore.common.checkpoint INFO: Saving checkpoint to /tsi/hi-paris/FCCLIP_results/All_results/KD_results/KD_Oneformer_R50_Classical_loss_In_vocab_008/model_final.pth
[07/23 09:10:40] d2.utils.events INFO:  eta: 0:00:00  iter: 99  total_loss: 28.19  loss_ce: 0.9896  loss_mask: 0.2128  loss_dice: 1.282  loss_ce_0: 0.727  loss_mask_0: 0.2406  loss_dice_0: 1.559  loss_ce_1: 0.8823  loss_mask_1: 0.2272  loss_dice_1: 1.429  loss_ce_2: 0.8041  loss_mask_2: 0.2192  loss_dice_2: 1.381  loss_ce_3: 0.7272  loss_mask_3: 0.2188  loss_dice_3: 1.321  loss_ce_4: 0.7345  loss_mask_4: 0.2188  loss_dice_4: 1.358  loss_ce_5: 0.6838  loss_mask_5: 0.2182  loss_dice_5: 1.324  loss_ce_6: 0.6422  loss_mask_6: 0.2184  loss_dice_6: 1.299  loss_ce_7: 0.6611  loss_mask_7: 0.2207  loss_dice_7: 1.305  loss_ce_8: 0.6985  loss_mask_8: 0.2201  loss_dice_8: 1.315  distillation_loss: 4.375    time: 1.1455  last_time: 1.1569  data_time: 0.0257  last_data_time: 0.0229   lr: 0.0001  max_mem: 21808M
[07/23 09:10:40] d2.engine.hooks INFO: Overall training speed: 98 iterations in 0:01:52 (1.1455 s / it)
[07/23 09:10:40] d2.engine.hooks INFO: Total training time: 0:01:55 (0:00:02 on hooks)
[07/23 09:10:40] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[07/23 09:10:40] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[07/23 09:10:40] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/23 09:10:40] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[07/23 09:10:40] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[07/23 09:11:50] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evallqmks2al ...
[07/23 09:14:26] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 49.532 | 79.713 | 60.470 |      19       |
| Things | 40.422 | 79.959 | 50.207 |       8       |
| Stuff  | 56.158 | 79.533 | 67.934 |      11       |
[07/23 09:14:26] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.406 | 97.112 | 99.273 |     Stuff     |
| class_8  | 68.710 | 81.661 | 84.141 |     Stuff     |
| class_11 | 86.202 | 87.725 | 98.264 |     Stuff     |
| class_12 | 6.547  | 75.293 | 8.696  |     Stuff     |
| class_13 | 26.958 | 75.434 | 35.737 |     Stuff     |
| class_17 | 29.193 | 62.221 | 46.919 |     Stuff     |
| class_19 | 40.388 | 67.546 | 59.794 |     Stuff     |
| class_20 | 56.633 | 73.212 | 77.354 |     Stuff     |
| class_21 | 87.788 | 88.977 | 98.664 |     Stuff     |
| class_22 | 33.180 | 74.236 | 44.695 |     Stuff     |
| class_23 | 85.728 | 91.450 | 93.743 |     Stuff     |
| class_24 | 51.338 | 77.098 | 66.588 |    Things     |
| class_25 | 20.449 | 75.638 | 27.035 |    Things     |
| class_26 | 64.389 | 82.910 | 77.662 |    Things     |
| class_27 | 45.304 | 88.224 | 51.351 |    Things     |
| class_28 | 54.603 | 90.470 | 60.355 |    Things     |
| class_31 | 15.570 | 80.962 | 19.231 |    Things     |
| class_32 | 34.409 | 73.192 | 47.012 |    Things     |
| class_33 | 37.315 | 71.182 | 52.422 |    Things     |
[07/23 09:14:26] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[07/23 09:14:26] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[07/23 09:14:26] d2.evaluation.testing INFO: copypaste: 49.5321,79.7128,60.4703,40.4221,79.9595,50.2070,56.1576,79.5334,67.9345,96.4058,97.1117,99.2731,68.7104,81.6610,84.1410,86.2020,87.7253,98.2635,6.5472,75.2932,8.6957,26.9576,75.4341,35.7367,29.1933,62.2208,46.9189,40.3883,67.5460,59.7938,56.6328,73.2122,77.3543,87.7880,88.9768,98.6639,33.1800,74.2360,44.6953,85.7280,91.4501,93.7429,51.3376,77.0978,66.5876,20.4491,75.6383,27.0353,64.3891,82.9096,77.6618,45.3042,88.2240,51.3514,54.6033,90.4702,60.3550,15.5695,80.9615,19.2308,34.4091,73.1923,47.0120,37.3152,71.1820,52.4222
