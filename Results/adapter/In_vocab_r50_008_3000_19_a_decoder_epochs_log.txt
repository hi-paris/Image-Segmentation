[10/09 19:36:49] detectron2 INFO: Rank of current process: 0. World size: 1
[10/09 19:36:50] detectron2 INFO: Environment info:
-------------------------------  -------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:47:35) [GCC 12.3.0]
numpy                            1.24.4
detectron2                       0.6 @/home/ids/gbrison/segmentation/segmentation/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    CUDA 12.5
detectron2 arch flags            8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.0+cu121 @/home/ids/gbrison/segmentation/miniconda3/envs/fc/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA L40S (arch=8.9)
Driver version                   560.35.03
CUDA_HOME                        /usr/local/cuda
Pillow                           9.4.0
torchvision                      0.19.0+cu121 @/home/ids/gbrison/segmentation/miniconda3/envs/fc/lib/python3.8/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.10.0
-------------------------------  -------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[10/09 19:36:50] detectron2 INFO: Command line arguments: Namespace(config_file='configs/coco/panoptic-segmentation/fcclip/r50_exp_3000_a_decoder.yaml', dist_url='tcp://127.0.0.1:51163', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[10/09 19:36:50] detectron2 INFO: Contents of args.config_file=configs/coco/panoptic-segmentation/fcclip/r50_exp_3000_a_decoder.yaml:
_BASE_: ./fcclip_convnext_large_eval_ade20k_r50.yaml

INPUT:
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TEST: 2560

MODEL:
  SEM_SEG_HEAD:
    NUM_CLASSES: 19
  WEIGHTS: /tsi/hi-paris/GB/segmentation/models/fcclip_cocopan_r50.pth
OUTPUT_DIR: /tsi/hi-paris/GB/segmentation/results/In_vocab/r50_008_3000_19_a_decoder
DATASETS:
  TRAIN: ("openvocab_cityscapes_fine_panoptic_train",)
  TEST: ("openvocab_cityscapes_fine_panoptic_val",)
SOLVER:
  IMS_PER_BATCH: 8
  MAX_ITER: 3000
TEST:
  EVAL_PERIOD: 3000


[10/09 19:36:50] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - openvocab_cityscapes_fine_panoptic_val
  TRAIN:
  - openvocab_cityscapes_fine_panoptic_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    MINIMUM_INST_AREA: 1
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_panoptic_lsj
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 1024
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: -1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: CLIP
  DEVICE: cuda
  FC_CLIP:
    CLIP_MODEL_NAME: RN50
    CLIP_PRETRAINED_WEIGHTS: openai
    EMBED_DIM: 1024
    ENSEMBLE_ON_VALID_MASK: true
    GEOMETRIC_ENSEMBLE_ALPHA: 0.4
    GEOMETRIC_ENSEMBLE_BETA: 0.8
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 250
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.0
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: true
      SEMANTIC_ON: true
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: FCCLIP
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.32316305
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 1
    - 1
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: basic
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: FCCLIPHead
    NORM: GN
    NUM_CLASSES: 19
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: /tsi/hi-paris/GB/segmentation/models/fcclip_cocopan_r50.pth
OUTPUT_DIR: /tsi/hi-paris/GB/segmentation/results/In_vocab/r50_008_3000_19_a_decoder
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 3000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 3000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[10/09 19:36:50] detectron2 INFO: Full config saved to /tsi/hi-paris/GB/segmentation/results/In_vocab/r50_008_3000_19_a_decoder/config.yaml
[10/09 19:36:50] d2.utils.env INFO: Using a generated random seed 53960134
[10/09 19:36:54] d2.engine.defaults INFO: Model:
FCCLIP(
  (backbone): CLIP(
    (clip_model): CLIP(
      (visual): ModifiedResNet(
        (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (layer1): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer2): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer3): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer4): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (attnpool): AttentionPool2d(
          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (c_proj): Linear(in_features=2048, out_features=1024, bias=True)
        )
      )
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ls_1): Identity()
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ls_2): Identity()
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (sem_seg_head): FCCLIPHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(250, 256)
      (query_embed): Embedding(250, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (mask_pooling): MaskPooling()
      (_mask_pooling_proj): Sequential(
        (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
      )
      (class_embed): MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=1024, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 19
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU()
  (mask_pooling): MaskPooling()
  (decoder_adapter): DecoderAdapter(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (conv2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (norm1): LayerNorm((64, 1, 1), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((256, 1, 1), eps=1e-05, elementwise_affine=True)
    (relu): ReLU()
  )
  (void_embedding): Embedding(1, 1024)
)
[10/09 19:36:54] fcclip.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerPanopticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1333, sample_style='choice'), RandomFlip()]
[10/09 19:36:54] fcclip.data.datasets.register_cityscapes_panoptic INFO: 18 cities found in 'datasets/cityscapes/leftImg8bit/train'.
[10/09 19:36:54] d2.data.build INFO: Using training sampler TrainingSampler
[10/09 19:36:54] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/09 19:36:54] d2.data.common INFO: Serializing 2975 elements to byte tensors and concatenating them all ...
[10/09 19:36:54] d2.data.common INFO: Serialized dataset takes 4.12 MiB
[10/09 19:36:54] d2.data.build INFO: Making batched data loader with batch_size=8
[10/09 19:36:54] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[10/09 19:36:54] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /tsi/hi-paris/GB/segmentation/models/fcclip_cocopan_r50.pth ...
[10/09 19:36:54] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /tsi/hi-paris/GB/segmentation/models/fcclip_cocopan_r50.pth ...
[10/09 19:36:54] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (134,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.
[10/09 19:36:54] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.clip_model.ln_final.{bias, weight}[0m
[34mbackbone.clip_model.token_embedding.weight[0m
[34mbackbone.clip_model.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.k_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.positional_embedding[0m
[34mbackbone.clip_model.visual.attnpool.q_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.v_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.conv1.weight[0m
[34mbackbone.clip_model.visual.conv2.weight[0m
[34mbackbone.clip_model.visual.conv3.weight[0m
[34mbackbone.clip_model.visual.layer1.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer1.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer1.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer1.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer1.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer1.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer1.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer1.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer1.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer1.2.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer2.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.2.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.3.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.3.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.3.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.3.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.3.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.3.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer3.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.2.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.3.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.3.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.3.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.3.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.3.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.3.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.4.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.4.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.4.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.4.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.4.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.4.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.5.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.5.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.5.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.5.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.5.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.5.conv3.weight[0m
[34mbackbone.clip_model.visual.layer4.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer4.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer4.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer4.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer4.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer4.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer4.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer4.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer4.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer4.2.conv3.weight[0m
[34mbackbone.clip_model.{logit_scale, positional_embedding, text_projection}[0m
[34mbn1.{bias, running_mean, running_var, weight}[0m
[34mbn2.{bias, running_mean, running_var, weight}[0m
[34mconv1.{bias, weight}[0m
[34mconv2.{bias, weight}[0m
[34mcriterion.empty_weight[0m
[34mdecoder_adapter.conv1.{bias, weight}[0m
[34mdecoder_adapter.conv2.{bias, weight}[0m
[34mdecoder_adapter.norm1.{bias, weight}[0m
[34mdecoder_adapter.norm2.{bias, weight}[0m
[10/09 19:36:54] d2.engine.train_loop INFO: Starting training from iteration 0
[10/09 19:37:18] d2.utils.events INFO:  eta: 0:53:19  iter: 19  total_loss: 30.89  loss_ce: 1.234  loss_mask: 0.2773  loss_dice: 1.452  loss_ce_0: 1.271  loss_mask_0: 0.3177  loss_dice_0: 1.804  loss_ce_1: 1.391  loss_mask_1: 0.3128  loss_dice_1: 1.657  loss_ce_2: 1.325  loss_mask_2: 0.3058  loss_dice_2: 1.574  loss_ce_3: 1.232  loss_mask_3: 0.2909  loss_dice_3: 1.534  loss_ce_4: 1.207  loss_mask_4: 0.2976  loss_dice_4: 1.48  loss_ce_5: 1.196  loss_mask_5: 0.287  loss_dice_5: 1.495  loss_ce_6: 1.202  loss_mask_6: 0.283  loss_dice_6: 1.48  loss_ce_7: 1.222  loss_mask_7: 0.2808  loss_dice_7: 1.455  loss_ce_8: 1.193  loss_mask_8: 0.2787  loss_dice_8: 1.464    time: 1.0808  last_time: 1.0835  data_time: 0.1060  last_data_time: 0.0698   lr: 0.0001  max_mem: 31328M
[10/09 19:37:41] d2.utils.events INFO:  eta: 0:53:33  iter: 39  total_loss: 25.5  loss_ce: 0.7659  loss_mask: 0.2242  loss_dice: 1.412  loss_ce_0: 0.8216  loss_mask_0: 0.2601  loss_dice_0: 1.74  loss_ce_1: 0.9699  loss_mask_1: 0.2525  loss_dice_1: 1.541  loss_ce_2: 0.9005  loss_mask_2: 0.2341  loss_dice_2: 1.524  loss_ce_3: 0.8482  loss_mask_3: 0.2243  loss_dice_3: 1.462  loss_ce_4: 0.8204  loss_mask_4: 0.2247  loss_dice_4: 1.449  loss_ce_5: 0.7962  loss_mask_5: 0.2269  loss_dice_5: 1.424  loss_ce_6: 0.7801  loss_mask_6: 0.2252  loss_dice_6: 1.418  loss_ce_7: 0.775  loss_mask_7: 0.2237  loss_dice_7: 1.431  loss_ce_8: 0.7988  loss_mask_8: 0.2249  loss_dice_8: 1.453    time: 1.0883  last_time: 1.1063  data_time: 0.0731  last_data_time: 0.0834   lr: 0.0001  max_mem: 31328M
[10/09 19:38:02] d2.utils.events INFO:  eta: 0:52:52  iter: 59  total_loss: 23.63  loss_ce: 0.6984  loss_mask: 0.2215  loss_dice: 1.322  loss_ce_0: 0.7432  loss_mask_0: 0.2626  loss_dice_0: 1.675  loss_ce_1: 0.8852  loss_mask_1: 0.244  loss_dice_1: 1.552  loss_ce_2: 0.8081  loss_mask_2: 0.2288  loss_dice_2: 1.46  loss_ce_3: 0.7265  loss_mask_3: 0.2252  loss_dice_3: 1.387  loss_ce_4: 0.7163  loss_mask_4: 0.2241  loss_dice_4: 1.37  loss_ce_5: 0.6911  loss_mask_5: 0.2202  loss_dice_5: 1.347  loss_ce_6: 0.6709  loss_mask_6: 0.2286  loss_dice_6: 1.351  loss_ce_7: 0.6656  loss_mask_7: 0.2221  loss_dice_7: 1.343  loss_ce_8: 0.6668  loss_mask_8: 0.223  loss_dice_8: 1.332    time: 1.0781  last_time: 1.0406  data_time: 0.0705  last_data_time: 0.0724   lr: 0.0001  max_mem: 31328M
[10/09 19:38:23] d2.utils.events INFO:  eta: 0:52:28  iter: 79  total_loss: 22.66  loss_ce: 0.6516  loss_mask: 0.2145  loss_dice: 1.336  loss_ce_0: 0.6804  loss_mask_0: 0.2526  loss_dice_0: 1.618  loss_ce_1: 0.8257  loss_mask_1: 0.2349  loss_dice_1: 1.537  loss_ce_2: 0.7676  loss_mask_2: 0.2216  loss_dice_2: 1.46  loss_ce_3: 0.7003  loss_mask_3: 0.2201  loss_dice_3: 1.383  loss_ce_4: 0.6992  loss_mask_4: 0.2161  loss_dice_4: 1.42  loss_ce_5: 0.6517  loss_mask_5: 0.2174  loss_dice_5: 1.369  loss_ce_6: 0.6365  loss_mask_6: 0.2156  loss_dice_6: 1.362  loss_ce_7: 0.634  loss_mask_7: 0.2156  loss_dice_7: 1.317  loss_ce_8: 0.6773  loss_mask_8: 0.2145  loss_dice_8: 1.339    time: 1.0790  last_time: 1.0853  data_time: 0.0746  last_data_time: 0.0789   lr: 0.0001  max_mem: 31328M
[10/09 19:38:44] d2.utils.events INFO:  eta: 0:51:50  iter: 99  total_loss: 21.76  loss_ce: 0.5831  loss_mask: 0.2193  loss_dice: 1.283  loss_ce_0: 0.668  loss_mask_0: 0.248  loss_dice_0: 1.529  loss_ce_1: 0.7656  loss_mask_1: 0.2294  loss_dice_1: 1.391  loss_ce_2: 0.6858  loss_mask_2: 0.2184  loss_dice_2: 1.376  loss_ce_3: 0.6419  loss_mask_3: 0.2196  loss_dice_3: 1.347  loss_ce_4: 0.6085  loss_mask_4: 0.2219  loss_dice_4: 1.283  loss_ce_5: 0.5838  loss_mask_5: 0.2168  loss_dice_5: 1.279  loss_ce_6: 0.634  loss_mask_6: 0.2184  loss_dice_6: 1.257  loss_ce_7: 0.6099  loss_mask_7: 0.2218  loss_dice_7: 1.28  loss_ce_8: 0.5819  loss_mask_8: 0.2202  loss_dice_8: 1.258    time: 1.0727  last_time: 1.0501  data_time: 0.0697  last_data_time: 0.0687   lr: 0.0001  max_mem: 31328M
[10/09 19:39:06] d2.utils.events INFO:  eta: 0:51:19  iter: 119  total_loss: 23.63  loss_ce: 0.6453  loss_mask: 0.2187  loss_dice: 1.317  loss_ce_0: 0.7339  loss_mask_0: 0.2479  loss_dice_0: 1.602  loss_ce_1: 0.7917  loss_mask_1: 0.2255  loss_dice_1: 1.479  loss_ce_2: 0.6952  loss_mask_2: 0.2185  loss_dice_2: 1.44  loss_ce_3: 0.6724  loss_mask_3: 0.2239  loss_dice_3: 1.39  loss_ce_4: 0.681  loss_mask_4: 0.2229  loss_dice_4: 1.354  loss_ce_5: 0.6572  loss_mask_5: 0.2184  loss_dice_5: 1.352  loss_ce_6: 0.6603  loss_mask_6: 0.2219  loss_dice_6: 1.31  loss_ce_7: 0.6312  loss_mask_7: 0.2221  loss_dice_7: 1.331  loss_ce_8: 0.6342  loss_mask_8: 0.2162  loss_dice_8: 1.328    time: 1.0699  last_time: 1.1136  data_time: 0.0722  last_data_time: 0.0829   lr: 0.0001  max_mem: 31328M
[10/09 19:39:27] d2.utils.events INFO:  eta: 0:51:00  iter: 139  total_loss: 22.8  loss_ce: 0.6022  loss_mask: 0.2031  loss_dice: 1.363  loss_ce_0: 0.7123  loss_mask_0: 0.2384  loss_dice_0: 1.609  loss_ce_1: 0.8013  loss_mask_1: 0.2214  loss_dice_1: 1.502  loss_ce_2: 0.7388  loss_mask_2: 0.2026  loss_dice_2: 1.466  loss_ce_3: 0.6877  loss_mask_3: 0.2057  loss_dice_3: 1.384  loss_ce_4: 0.6581  loss_mask_4: 0.2083  loss_dice_4: 1.414  loss_ce_5: 0.6435  loss_mask_5: 0.2071  loss_dice_5: 1.368  loss_ce_6: 0.6528  loss_mask_6: 0.2084  loss_dice_6: 1.376  loss_ce_7: 0.6188  loss_mask_7: 0.208  loss_dice_7: 1.382  loss_ce_8: 0.607  loss_mask_8: 0.2025  loss_dice_8: 1.35    time: 1.0704  last_time: 1.1154  data_time: 0.0714  last_data_time: 0.1025   lr: 0.0001  max_mem: 31760M
[10/09 19:39:48] d2.utils.events INFO:  eta: 0:50:36  iter: 159  total_loss: 21.39  loss_ce: 0.5324  loss_mask: 0.2137  loss_dice: 1.252  loss_ce_0: 0.5987  loss_mask_0: 0.239  loss_dice_0: 1.56  loss_ce_1: 0.7355  loss_mask_1: 0.2288  loss_dice_1: 1.395  loss_ce_2: 0.6635  loss_mask_2: 0.2138  loss_dice_2: 1.345  loss_ce_3: 0.6076  loss_mask_3: 0.2154  loss_dice_3: 1.278  loss_ce_4: 0.5633  loss_mask_4: 0.2157  loss_dice_4: 1.306  loss_ce_5: 0.5514  loss_mask_5: 0.2175  loss_dice_5: 1.298  loss_ce_6: 0.5414  loss_mask_6: 0.2163  loss_dice_6: 1.276  loss_ce_7: 0.5217  loss_mask_7: 0.2171  loss_dice_7: 1.274  loss_ce_8: 0.5292  loss_mask_8: 0.2129  loss_dice_8: 1.24    time: 1.0695  last_time: 1.0278  data_time: 0.0684  last_data_time: 0.0781   lr: 0.0001  max_mem: 31760M
[10/09 19:40:10] d2.utils.events INFO:  eta: 0:50:20  iter: 179  total_loss: 23.32  loss_ce: 0.6236  loss_mask: 0.1883  loss_dice: 1.387  loss_ce_0: 0.7378  loss_mask_0: 0.2205  loss_dice_0: 1.688  loss_ce_1: 0.8643  loss_mask_1: 0.2034  loss_dice_1: 1.55  loss_ce_2: 0.7867  loss_mask_2: 0.1992  loss_dice_2: 1.481  loss_ce_3: 0.6912  loss_mask_3: 0.1956  loss_dice_3: 1.433  loss_ce_4: 0.6799  loss_mask_4: 0.1917  loss_dice_4: 1.434  loss_ce_5: 0.6576  loss_mask_5: 0.1907  loss_dice_5: 1.42  loss_ce_6: 0.6723  loss_mask_6: 0.1895  loss_dice_6: 1.393  loss_ce_7: 0.637  loss_mask_7: 0.1922  loss_dice_7: 1.372  loss_ce_8: 0.6405  loss_mask_8: 0.188  loss_dice_8: 1.387    time: 1.0718  last_time: 1.1360  data_time: 0.0747  last_data_time: 0.0672   lr: 0.0001  max_mem: 32153M
[10/09 19:40:32] d2.utils.events INFO:  eta: 0:49:55  iter: 199  total_loss: 21.57  loss_ce: 0.5717  loss_mask: 0.1901  loss_dice: 1.274  loss_ce_0: 0.6579  loss_mask_0: 0.2167  loss_dice_0: 1.517  loss_ce_1: 0.7491  loss_mask_1: 0.207  loss_dice_1: 1.418  loss_ce_2: 0.6887  loss_mask_2: 0.2023  loss_dice_2: 1.373  loss_ce_3: 0.6495  loss_mask_3: 0.198  loss_dice_3: 1.31  loss_ce_4: 0.5901  loss_mask_4: 0.1957  loss_dice_4: 1.298  loss_ce_5: 0.6048  loss_mask_5: 0.1915  loss_dice_5: 1.291  loss_ce_6: 0.6051  loss_mask_6: 0.1961  loss_dice_6: 1.3  loss_ce_7: 0.5911  loss_mask_7: 0.191  loss_dice_7: 1.283  loss_ce_8: 0.5742  loss_mask_8: 0.1913  loss_dice_8: 1.305    time: 1.0712  last_time: 1.1168  data_time: 0.0707  last_data_time: 0.0945   lr: 0.0001  max_mem: 32153M
[10/09 19:40:53] d2.utils.events INFO:  eta: 0:49:36  iter: 219  total_loss: 22.73  loss_ce: 0.6342  loss_mask: 0.1981  loss_dice: 1.374  loss_ce_0: 0.67  loss_mask_0: 0.2262  loss_dice_0: 1.587  loss_ce_1: 0.7766  loss_mask_1: 0.2123  loss_dice_1: 1.513  loss_ce_2: 0.7042  loss_mask_2: 0.1975  loss_dice_2: 1.458  loss_ce_3: 0.6959  loss_mask_3: 0.1951  loss_dice_3: 1.402  loss_ce_4: 0.6628  loss_mask_4: 0.1967  loss_dice_4: 1.363  loss_ce_5: 0.6394  loss_mask_5: 0.1939  loss_dice_5: 1.394  loss_ce_6: 0.6544  loss_mask_6: 0.1925  loss_dice_6: 1.363  loss_ce_7: 0.6144  loss_mask_7: 0.1929  loss_dice_7: 1.359  loss_ce_8: 0.6342  loss_mask_8: 0.1964  loss_dice_8: 1.365    time: 1.0724  last_time: 1.1514  data_time: 0.0713  last_data_time: 0.0818   lr: 0.0001  max_mem: 32971M
[10/09 19:41:15] d2.utils.events INFO:  eta: 0:49:12  iter: 239  total_loss: 21.56  loss_ce: 0.5445  loss_mask: 0.1777  loss_dice: 1.326  loss_ce_0: 0.6393  loss_mask_0: 0.2078  loss_dice_0: 1.515  loss_ce_1: 0.7537  loss_mask_1: 0.1912  loss_dice_1: 1.425  loss_ce_2: 0.6952  loss_mask_2: 0.1782  loss_dice_2: 1.356  loss_ce_3: 0.6262  loss_mask_3: 0.1783  loss_dice_3: 1.361  loss_ce_4: 0.5861  loss_mask_4: 0.1784  loss_dice_4: 1.314  loss_ce_5: 0.5836  loss_mask_5: 0.1799  loss_dice_5: 1.337  loss_ce_6: 0.564  loss_mask_6: 0.1823  loss_dice_6: 1.33  loss_ce_7: 0.5502  loss_mask_7: 0.1779  loss_dice_7: 1.321  loss_ce_8: 0.5669  loss_mask_8: 0.1785  loss_dice_8: 1.299    time: 1.0725  last_time: 1.0536  data_time: 0.0730  last_data_time: 0.0844   lr: 0.0001  max_mem: 32971M
[10/09 19:41:37] d2.utils.events INFO:  eta: 0:48:50  iter: 259  total_loss: 22.19  loss_ce: 0.5503  loss_mask: 0.188  loss_dice: 1.348  loss_ce_0: 0.5809  loss_mask_0: 0.2159  loss_dice_0: 1.588  loss_ce_1: 0.7046  loss_mask_1: 0.2025  loss_dice_1: 1.492  loss_ce_2: 0.681  loss_mask_2: 0.2007  loss_dice_2: 1.398  loss_ce_3: 0.6179  loss_mask_3: 0.1904  loss_dice_3: 1.388  loss_ce_4: 0.5885  loss_mask_4: 0.1874  loss_dice_4: 1.397  loss_ce_5: 0.5585  loss_mask_5: 0.188  loss_dice_5: 1.368  loss_ce_6: 0.5533  loss_mask_6: 0.1891  loss_dice_6: 1.392  loss_ce_7: 0.5772  loss_mask_7: 0.1896  loss_dice_7: 1.379  loss_ce_8: 0.5541  loss_mask_8: 0.1868  loss_dice_8: 1.33    time: 1.0729  last_time: 1.0349  data_time: 0.0721  last_data_time: 0.0769   lr: 0.0001  max_mem: 32971M
[10/09 19:41:58] d2.utils.events INFO:  eta: 0:48:29  iter: 279  total_loss: 21.38  loss_ce: 0.5429  loss_mask: 0.1986  loss_dice: 1.311  loss_ce_0: 0.6442  loss_mask_0: 0.2197  loss_dice_0: 1.544  loss_ce_1: 0.7218  loss_mask_1: 0.2071  loss_dice_1: 1.487  loss_ce_2: 0.6547  loss_mask_2: 0.1986  loss_dice_2: 1.377  loss_ce_3: 0.5768  loss_mask_3: 0.1948  loss_dice_3: 1.355  loss_ce_4: 0.5644  loss_mask_4: 0.1928  loss_dice_4: 1.399  loss_ce_5: 0.5568  loss_mask_5: 0.1923  loss_dice_5: 1.343  loss_ce_6: 0.5519  loss_mask_6: 0.193  loss_dice_6: 1.342  loss_ce_7: 0.5774  loss_mask_7: 0.1922  loss_dice_7: 1.297  loss_ce_8: 0.5443  loss_mask_8: 0.1948  loss_dice_8: 1.322    time: 1.0732  last_time: 1.0533  data_time: 0.0723  last_data_time: 0.0539   lr: 0.0001  max_mem: 32971M
[10/09 19:42:20] d2.utils.events INFO:  eta: 0:48:08  iter: 299  total_loss: 21.43  loss_ce: 0.5908  loss_mask: 0.1868  loss_dice: 1.323  loss_ce_0: 0.6397  loss_mask_0: 0.2244  loss_dice_0: 1.525  loss_ce_1: 0.684  loss_mask_1: 0.2016  loss_dice_1: 1.42  loss_ce_2: 0.658  loss_mask_2: 0.1912  loss_dice_2: 1.383  loss_ce_3: 0.6514  loss_mask_3: 0.1894  loss_dice_3: 1.309  loss_ce_4: 0.6028  loss_mask_4: 0.194  loss_dice_4: 1.315  loss_ce_5: 0.5764  loss_mask_5: 0.1908  loss_dice_5: 1.305  loss_ce_6: 0.559  loss_mask_6: 0.1902  loss_dice_6: 1.33  loss_ce_7: 0.5653  loss_mask_7: 0.1888  loss_dice_7: 1.289  loss_ce_8: 0.5867  loss_mask_8: 0.1895  loss_dice_8: 1.293    time: 1.0741  last_time: 1.1746  data_time: 0.0715  last_data_time: 0.0849   lr: 0.0001  max_mem: 32971M
[10/09 19:42:42] d2.utils.events INFO:  eta: 0:47:47  iter: 319  total_loss: 21.3  loss_ce: 0.5397  loss_mask: 0.1798  loss_dice: 1.284  loss_ce_0: 0.62  loss_mask_0: 0.2143  loss_dice_0: 1.531  loss_ce_1: 0.697  loss_mask_1: 0.1977  loss_dice_1: 1.427  loss_ce_2: 0.6505  loss_mask_2: 0.1885  loss_dice_2: 1.368  loss_ce_3: 0.5853  loss_mask_3: 0.1857  loss_dice_3: 1.339  loss_ce_4: 0.5852  loss_mask_4: 0.1868  loss_dice_4: 1.331  loss_ce_5: 0.5585  loss_mask_5: 0.1872  loss_dice_5: 1.295  loss_ce_6: 0.5313  loss_mask_6: 0.1854  loss_dice_6: 1.29  loss_ce_7: 0.59  loss_mask_7: 0.1809  loss_dice_7: 1.314  loss_ce_8: 0.5433  loss_mask_8: 0.1822  loss_dice_8: 1.268    time: 1.0741  last_time: 1.0913  data_time: 0.0742  last_data_time: 0.0769   lr: 0.0001  max_mem: 32971M
[10/09 19:43:03] d2.utils.events INFO:  eta: 0:47:26  iter: 339  total_loss: 21.22  loss_ce: 0.5525  loss_mask: 0.1793  loss_dice: 1.292  loss_ce_0: 0.626  loss_mask_0: 0.2197  loss_dice_0: 1.52  loss_ce_1: 0.7155  loss_mask_1: 0.1944  loss_dice_1: 1.429  loss_ce_2: 0.6707  loss_mask_2: 0.1861  loss_dice_2: 1.373  loss_ce_3: 0.6022  loss_mask_3: 0.1791  loss_dice_3: 1.346  loss_ce_4: 0.5881  loss_mask_4: 0.1842  loss_dice_4: 1.334  loss_ce_5: 0.5638  loss_mask_5: 0.1843  loss_dice_5: 1.308  loss_ce_6: 0.5777  loss_mask_6: 0.1812  loss_dice_6: 1.25  loss_ce_7: 0.5322  loss_mask_7: 0.1819  loss_dice_7: 1.301  loss_ce_8: 0.5574  loss_mask_8: 0.1818  loss_dice_8: 1.296    time: 1.0749  last_time: 1.0392  data_time: 0.0734  last_data_time: 0.0741   lr: 0.0001  max_mem: 32971M
[10/09 19:43:25] d2.utils.events INFO:  eta: 0:47:05  iter: 359  total_loss: 22.07  loss_ce: 0.6073  loss_mask: 0.1961  loss_dice: 1.296  loss_ce_0: 0.6203  loss_mask_0: 0.2176  loss_dice_0: 1.62  loss_ce_1: 0.7092  loss_mask_1: 0.2088  loss_dice_1: 1.482  loss_ce_2: 0.6812  loss_mask_2: 0.2055  loss_dice_2: 1.424  loss_ce_3: 0.6425  loss_mask_3: 0.1988  loss_dice_3: 1.372  loss_ce_4: 0.6122  loss_mask_4: 0.1976  loss_dice_4: 1.37  loss_ce_5: 0.622  loss_mask_5: 0.1959  loss_dice_5: 1.356  loss_ce_6: 0.6011  loss_mask_6: 0.195  loss_dice_6: 1.346  loss_ce_7: 0.6066  loss_mask_7: 0.1927  loss_dice_7: 1.318  loss_ce_8: 0.6114  loss_mask_8: 0.1931  loss_dice_8: 1.317    time: 1.0751  last_time: 1.0804  data_time: 0.0728  last_data_time: 0.0827   lr: 0.0001  max_mem: 32971M
[10/09 19:43:46] d2.utils.events INFO:  eta: 0:46:42  iter: 379  total_loss: 20.62  loss_ce: 0.5414  loss_mask: 0.1861  loss_dice: 1.272  loss_ce_0: 0.5928  loss_mask_0: 0.2042  loss_dice_0: 1.512  loss_ce_1: 0.6847  loss_mask_1: 0.1919  loss_dice_1: 1.391  loss_ce_2: 0.6263  loss_mask_2: 0.1959  loss_dice_2: 1.323  loss_ce_3: 0.601  loss_mask_3: 0.1923  loss_dice_3: 1.289  loss_ce_4: 0.5389  loss_mask_4: 0.1882  loss_dice_4: 1.294  loss_ce_5: 0.5336  loss_mask_5: 0.1888  loss_dice_5: 1.296  loss_ce_6: 0.532  loss_mask_6: 0.187  loss_dice_6: 1.271  loss_ce_7: 0.5352  loss_mask_7: 0.1884  loss_dice_7: 1.279  loss_ce_8: 0.5577  loss_mask_8: 0.1883  loss_dice_8: 1.27    time: 1.0745  last_time: 1.0938  data_time: 0.0713  last_data_time: 0.0729   lr: 0.0001  max_mem: 32971M
[10/09 19:44:08] d2.utils.events INFO:  eta: 0:46:21  iter: 399  total_loss: 20.44  loss_ce: 0.5075  loss_mask: 0.181  loss_dice: 1.232  loss_ce_0: 0.6033  loss_mask_0: 0.205  loss_dice_0: 1.467  loss_ce_1: 0.6876  loss_mask_1: 0.1949  loss_dice_1: 1.367  loss_ce_2: 0.6164  loss_mask_2: 0.1847  loss_dice_2: 1.32  loss_ce_3: 0.5714  loss_mask_3: 0.1812  loss_dice_3: 1.252  loss_ce_4: 0.5878  loss_mask_4: 0.1843  loss_dice_4: 1.285  loss_ce_5: 0.569  loss_mask_5: 0.1818  loss_dice_5: 1.238  loss_ce_6: 0.5537  loss_mask_6: 0.1815  loss_dice_6: 1.211  loss_ce_7: 0.5452  loss_mask_7: 0.1818  loss_dice_7: 1.206  loss_ce_8: 0.5289  loss_mask_8: 0.1824  loss_dice_8: 1.219    time: 1.0742  last_time: 1.1019  data_time: 0.0678  last_data_time: 0.0651   lr: 0.0001  max_mem: 32971M
[10/09 19:44:30] d2.utils.events INFO:  eta: 0:46:04  iter: 419  total_loss: 21.03  loss_ce: 0.5147  loss_mask: 0.1899  loss_dice: 1.268  loss_ce_0: 0.624  loss_mask_0: 0.2226  loss_dice_0: 1.5  loss_ce_1: 0.68  loss_mask_1: 0.1988  loss_dice_1: 1.413  loss_ce_2: 0.6315  loss_mask_2: 0.1918  loss_dice_2: 1.341  loss_ce_3: 0.564  loss_mask_3: 0.1893  loss_dice_3: 1.317  loss_ce_4: 0.5493  loss_mask_4: 0.1927  loss_dice_4: 1.317  loss_ce_5: 0.5527  loss_mask_5: 0.1901  loss_dice_5: 1.286  loss_ce_6: 0.5499  loss_mask_6: 0.1908  loss_dice_6: 1.245  loss_ce_7: 0.5279  loss_mask_7: 0.1909  loss_dice_7: 1.278  loss_ce_8: 0.5347  loss_mask_8: 0.19  loss_dice_8: 1.244    time: 1.0749  last_time: 1.0903  data_time: 0.0755  last_data_time: 0.0790   lr: 0.0001  max_mem: 32971M
[10/09 19:44:51] d2.utils.events INFO:  eta: 0:45:43  iter: 439  total_loss: 20.44  loss_ce: 0.5137  loss_mask: 0.1829  loss_dice: 1.254  loss_ce_0: 0.6048  loss_mask_0: 0.2192  loss_dice_0: 1.479  loss_ce_1: 0.6719  loss_mask_1: 0.2003  loss_dice_1: 1.398  loss_ce_2: 0.5948  loss_mask_2: 0.188  loss_dice_2: 1.339  loss_ce_3: 0.5543  loss_mask_3: 0.1888  loss_dice_3: 1.267  loss_ce_4: 0.5623  loss_mask_4: 0.1919  loss_dice_4: 1.304  loss_ce_5: 0.5284  loss_mask_5: 0.1893  loss_dice_5: 1.266  loss_ce_6: 0.5268  loss_mask_6: 0.1791  loss_dice_6: 1.262  loss_ce_7: 0.5109  loss_mask_7: 0.1808  loss_dice_7: 1.258  loss_ce_8: 0.5188  loss_mask_8: 0.1824  loss_dice_8: 1.254    time: 1.0750  last_time: 1.0867  data_time: 0.0686  last_data_time: 0.0837   lr: 0.0001  max_mem: 32971M
[10/09 19:45:13] d2.utils.events INFO:  eta: 0:45:24  iter: 459  total_loss: 21.35  loss_ce: 0.4878  loss_mask: 0.1848  loss_dice: 1.303  loss_ce_0: 0.604  loss_mask_0: 0.2094  loss_dice_0: 1.55  loss_ce_1: 0.6867  loss_mask_1: 0.2044  loss_dice_1: 1.459  loss_ce_2: 0.6231  loss_mask_2: 0.1914  loss_dice_2: 1.35  loss_ce_3: 0.5743  loss_mask_3: 0.1884  loss_dice_3: 1.329  loss_ce_4: 0.5707  loss_mask_4: 0.1892  loss_dice_4: 1.365  loss_ce_5: 0.5218  loss_mask_5: 0.1863  loss_dice_5: 1.34  loss_ce_6: 0.4779  loss_mask_6: 0.1887  loss_dice_6: 1.317  loss_ce_7: 0.4925  loss_mask_7: 0.1896  loss_dice_7: 1.297  loss_ce_8: 0.4879  loss_mask_8: 0.1902  loss_dice_8: 1.291    time: 1.0755  last_time: 1.0390  data_time: 0.0723  last_data_time: 0.0793   lr: 0.0001  max_mem: 32971M
[10/09 19:45:34] d2.utils.events INFO:  eta: 0:45:01  iter: 479  total_loss: 20.87  loss_ce: 0.5169  loss_mask: 0.1843  loss_dice: 1.237  loss_ce_0: 0.5941  loss_mask_0: 0.2149  loss_dice_0: 1.469  loss_ce_1: 0.6728  loss_mask_1: 0.1959  loss_dice_1: 1.379  loss_ce_2: 0.6026  loss_mask_2: 0.1857  loss_dice_2: 1.308  loss_ce_3: 0.5789  loss_mask_3: 0.1871  loss_dice_3: 1.296  loss_ce_4: 0.5554  loss_mask_4: 0.1842  loss_dice_4: 1.256  loss_ce_5: 0.531  loss_mask_5: 0.1858  loss_dice_5: 1.287  loss_ce_6: 0.5352  loss_mask_6: 0.1793  loss_dice_6: 1.235  loss_ce_7: 0.4949  loss_mask_7: 0.1804  loss_dice_7: 1.231  loss_ce_8: 0.5067  loss_mask_8: 0.1831  loss_dice_8: 1.239    time: 1.0754  last_time: 1.0626  data_time: 0.0705  last_data_time: 0.0622   lr: 0.0001  max_mem: 32971M
[10/09 19:45:56] d2.utils.events INFO:  eta: 0:44:41  iter: 499  total_loss: 20.97  loss_ce: 0.495  loss_mask: 0.1813  loss_dice: 1.247  loss_ce_0: 0.6029  loss_mask_0: 0.2121  loss_dice_0: 1.504  loss_ce_1: 0.6461  loss_mask_1: 0.2006  loss_dice_1: 1.438  loss_ce_2: 0.6106  loss_mask_2: 0.1887  loss_dice_2: 1.369  loss_ce_3: 0.5676  loss_mask_3: 0.1875  loss_dice_3: 1.304  loss_ce_4: 0.5597  loss_mask_4: 0.1841  loss_dice_4: 1.284  loss_ce_5: 0.5503  loss_mask_5: 0.1836  loss_dice_5: 1.308  loss_ce_6: 0.5283  loss_mask_6: 0.1848  loss_dice_6: 1.276  loss_ce_7: 0.5046  loss_mask_7: 0.1829  loss_dice_7: 1.285  loss_ce_8: 0.5038  loss_mask_8: 0.1828  loss_dice_8: 1.287    time: 1.0757  last_time: 1.1238  data_time: 0.0733  last_data_time: 0.0508   lr: 0.0001  max_mem: 32971M
[10/09 19:46:17] d2.utils.events INFO:  eta: 0:44:19  iter: 519  total_loss: 19.88  loss_ce: 0.5004  loss_mask: 0.1816  loss_dice: 1.23  loss_ce_0: 0.5792  loss_mask_0: 0.2134  loss_dice_0: 1.503  loss_ce_1: 0.6342  loss_mask_1: 0.2002  loss_dice_1: 1.385  loss_ce_2: 0.5894  loss_mask_2: 0.1883  loss_dice_2: 1.314  loss_ce_3: 0.5762  loss_mask_3: 0.1832  loss_dice_3: 1.263  loss_ce_4: 0.5224  loss_mask_4: 0.1839  loss_dice_4: 1.249  loss_ce_5: 0.5114  loss_mask_5: 0.1819  loss_dice_5: 1.243  loss_ce_6: 0.516  loss_mask_6: 0.1831  loss_dice_6: 1.209  loss_ce_7: 0.4897  loss_mask_7: 0.1826  loss_dice_7: 1.247  loss_ce_8: 0.4687  loss_mask_8: 0.1826  loss_dice_8: 1.209    time: 1.0752  last_time: 1.1365  data_time: 0.0674  last_data_time: 0.0827   lr: 0.0001  max_mem: 32971M
[10/09 19:46:39] d2.utils.events INFO:  eta: 0:43:59  iter: 539  total_loss: 20.49  loss_ce: 0.5261  loss_mask: 0.1775  loss_dice: 1.239  loss_ce_0: 0.6162  loss_mask_0: 0.2076  loss_dice_0: 1.474  loss_ce_1: 0.6612  loss_mask_1: 0.1885  loss_dice_1: 1.384  loss_ce_2: 0.6446  loss_mask_2: 0.177  loss_dice_2: 1.321  loss_ce_3: 0.5789  loss_mask_3: 0.1804  loss_dice_3: 1.264  loss_ce_4: 0.5573  loss_mask_4: 0.1798  loss_dice_4: 1.249  loss_ce_5: 0.5416  loss_mask_5: 0.1778  loss_dice_5: 1.232  loss_ce_6: 0.5292  loss_mask_6: 0.1796  loss_dice_6: 1.209  loss_ce_7: 0.5407  loss_mask_7: 0.1793  loss_dice_7: 1.202  loss_ce_8: 0.5335  loss_mask_8: 0.1763  loss_dice_8: 1.241    time: 1.0759  last_time: 1.1587  data_time: 0.0750  last_data_time: 0.0972   lr: 0.0001  max_mem: 32971M
[10/09 19:47:01] d2.utils.events INFO:  eta: 0:43:41  iter: 559  total_loss: 21.49  loss_ce: 0.5269  loss_mask: 0.1764  loss_dice: 1.342  loss_ce_0: 0.6284  loss_mask_0: 0.2097  loss_dice_0: 1.597  loss_ce_1: 0.6763  loss_mask_1: 0.1932  loss_dice_1: 1.428  loss_ce_2: 0.6135  loss_mask_2: 0.1804  loss_dice_2: 1.419  loss_ce_3: 0.6001  loss_mask_3: 0.1808  loss_dice_3: 1.355  loss_ce_4: 0.5706  loss_mask_4: 0.1782  loss_dice_4: 1.362  loss_ce_5: 0.5472  loss_mask_5: 0.1763  loss_dice_5: 1.375  loss_ce_6: 0.5088  loss_mask_6: 0.1777  loss_dice_6: 1.321  loss_ce_7: 0.505  loss_mask_7: 0.177  loss_dice_7: 1.325  loss_ce_8: 0.5053  loss_mask_8: 0.176  loss_dice_8: 1.366    time: 1.0762  last_time: 1.0399  data_time: 0.0704  last_data_time: 0.0783   lr: 0.0001  max_mem: 32971M
[10/09 19:47:23] d2.utils.events INFO:  eta: 0:43:21  iter: 579  total_loss: 21.06  loss_ce: 0.5207  loss_mask: 0.1786  loss_dice: 1.314  loss_ce_0: 0.6272  loss_mask_0: 0.2029  loss_dice_0: 1.57  loss_ce_1: 0.6445  loss_mask_1: 0.196  loss_dice_1: 1.435  loss_ce_2: 0.6072  loss_mask_2: 0.185  loss_dice_2: 1.388  loss_ce_3: 0.5336  loss_mask_3: 0.1833  loss_dice_3: 1.339  loss_ce_4: 0.5285  loss_mask_4: 0.1853  loss_dice_4: 1.342  loss_ce_5: 0.5309  loss_mask_5: 0.1802  loss_dice_5: 1.342  loss_ce_6: 0.511  loss_mask_6: 0.182  loss_dice_6: 1.3  loss_ce_7: 0.5234  loss_mask_7: 0.1784  loss_dice_7: 1.323  loss_ce_8: 0.5142  loss_mask_8: 0.1812  loss_dice_8: 1.322    time: 1.0770  last_time: 1.0929  data_time: 0.0724  last_data_time: 0.0746   lr: 0.0001  max_mem: 32971M
[10/09 19:47:45] d2.utils.events INFO:  eta: 0:43:00  iter: 599  total_loss: 20.49  loss_ce: 0.5353  loss_mask: 0.1679  loss_dice: 1.253  loss_ce_0: 0.5885  loss_mask_0: 0.1967  loss_dice_0: 1.495  loss_ce_1: 0.664  loss_mask_1: 0.1846  loss_dice_1: 1.375  loss_ce_2: 0.6232  loss_mask_2: 0.1752  loss_dice_2: 1.31  loss_ce_3: 0.5947  loss_mask_3: 0.1683  loss_dice_3: 1.296  loss_ce_4: 0.5699  loss_mask_4: 0.172  loss_dice_4: 1.27  loss_ce_5: 0.5608  loss_mask_5: 0.1711  loss_dice_5: 1.264  loss_ce_6: 0.5179  loss_mask_6: 0.174  loss_dice_6: 1.247  loss_ce_7: 0.522  loss_mask_7: 0.169  loss_dice_7: 1.256  loss_ce_8: 0.5428  loss_mask_8: 0.1686  loss_dice_8: 1.247    time: 1.0771  last_time: 1.0090  data_time: 0.0771  last_data_time: 0.0598   lr: 0.0001  max_mem: 32971M
[10/09 19:48:07] d2.utils.events INFO:  eta: 0:42:40  iter: 619  total_loss: 21.88  loss_ce: 0.5307  loss_mask: 0.1809  loss_dice: 1.318  loss_ce_0: 0.6352  loss_mask_0: 0.2013  loss_dice_0: 1.57  loss_ce_1: 0.7014  loss_mask_1: 0.1929  loss_dice_1: 1.445  loss_ce_2: 0.6392  loss_mask_2: 0.1808  loss_dice_2: 1.461  loss_ce_3: 0.6052  loss_mask_3: 0.1845  loss_dice_3: 1.329  loss_ce_4: 0.5641  loss_mask_4: 0.1817  loss_dice_4: 1.316  loss_ce_5: 0.5735  loss_mask_5: 0.1772  loss_dice_5: 1.335  loss_ce_6: 0.5481  loss_mask_6: 0.179  loss_dice_6: 1.369  loss_ce_7: 0.5277  loss_mask_7: 0.1818  loss_dice_7: 1.317  loss_ce_8: 0.5484  loss_mask_8: 0.1795  loss_dice_8: 1.343    time: 1.0776  last_time: 1.0897  data_time: 0.0764  last_data_time: 0.0740   lr: 0.0001  max_mem: 32971M
[10/09 19:48:29] d2.utils.events INFO:  eta: 0:42:20  iter: 639  total_loss: 20.52  loss_ce: 0.5088  loss_mask: 0.1806  loss_dice: 1.234  loss_ce_0: 0.582  loss_mask_0: 0.2031  loss_dice_0: 1.436  loss_ce_1: 0.6868  loss_mask_1: 0.1933  loss_dice_1: 1.385  loss_ce_2: 0.6047  loss_mask_2: 0.1767  loss_dice_2: 1.324  loss_ce_3: 0.5954  loss_mask_3: 0.1811  loss_dice_3: 1.278  loss_ce_4: 0.5522  loss_mask_4: 0.1747  loss_dice_4: 1.269  loss_ce_5: 0.5391  loss_mask_5: 0.1757  loss_dice_5: 1.263  loss_ce_6: 0.5177  loss_mask_6: 0.1745  loss_dice_6: 1.24  loss_ce_7: 0.494  loss_mask_7: 0.1792  loss_dice_7: 1.257  loss_ce_8: 0.5035  loss_mask_8: 0.1791  loss_dice_8: 1.262    time: 1.0781  last_time: 1.0314  data_time: 0.0743  last_data_time: 0.0738   lr: 0.0001  max_mem: 32971M
[10/09 19:48:50] d2.utils.events INFO:  eta: 0:42:01  iter: 659  total_loss: 21.1  loss_ce: 0.5035  loss_mask: 0.1751  loss_dice: 1.319  loss_ce_0: 0.5885  loss_mask_0: 0.1989  loss_dice_0: 1.545  loss_ce_1: 0.6707  loss_mask_1: 0.1895  loss_dice_1: 1.505  loss_ce_2: 0.6344  loss_mask_2: 0.1811  loss_dice_2: 1.421  loss_ce_3: 0.559  loss_mask_3: 0.1774  loss_dice_3: 1.378  loss_ce_4: 0.5575  loss_mask_4: 0.177  loss_dice_4: 1.34  loss_ce_5: 0.5559  loss_mask_5: 0.1764  loss_dice_5: 1.379  loss_ce_6: 0.5323  loss_mask_6: 0.176  loss_dice_6: 1.333  loss_ce_7: 0.5264  loss_mask_7: 0.175  loss_dice_7: 1.32  loss_ce_8: 0.5206  loss_mask_8: 0.174  loss_dice_8: 1.312    time: 1.0784  last_time: 1.0790  data_time: 0.0779  last_data_time: 0.0753   lr: 0.0001  max_mem: 32971M
[10/09 19:49:12] d2.utils.events INFO:  eta: 0:41:41  iter: 679  total_loss: 21.92  loss_ce: 0.5829  loss_mask: 0.1731  loss_dice: 1.36  loss_ce_0: 0.6497  loss_mask_0: 0.2075  loss_dice_0: 1.545  loss_ce_1: 0.6854  loss_mask_1: 0.1958  loss_dice_1: 1.5  loss_ce_2: 0.6042  loss_mask_2: 0.186  loss_dice_2: 1.452  loss_ce_3: 0.6204  loss_mask_3: 0.1809  loss_dice_3: 1.392  loss_ce_4: 0.5707  loss_mask_4: 0.1784  loss_dice_4: 1.381  loss_ce_5: 0.5583  loss_mask_5: 0.1765  loss_dice_5: 1.381  loss_ce_6: 0.5204  loss_mask_6: 0.1747  loss_dice_6: 1.383  loss_ce_7: 0.5618  loss_mask_7: 0.173  loss_dice_7: 1.373  loss_ce_8: 0.5695  loss_mask_8: 0.1748  loss_dice_8: 1.384    time: 1.0787  last_time: 1.0800  data_time: 0.0765  last_data_time: 0.0899   lr: 0.0001  max_mem: 32971M
[10/09 19:49:34] d2.utils.events INFO:  eta: 0:41:16  iter: 699  total_loss: 20.57  loss_ce: 0.5072  loss_mask: 0.186  loss_dice: 1.224  loss_ce_0: 0.5832  loss_mask_0: 0.2151  loss_dice_0: 1.44  loss_ce_1: 0.6676  loss_mask_1: 0.1976  loss_dice_1: 1.346  loss_ce_2: 0.6323  loss_mask_2: 0.1885  loss_dice_2: 1.343  loss_ce_3: 0.5876  loss_mask_3: 0.1923  loss_dice_3: 1.268  loss_ce_4: 0.5489  loss_mask_4: 0.1926  loss_dice_4: 1.263  loss_ce_5: 0.5559  loss_mask_5: 0.1874  loss_dice_5: 1.235  loss_ce_6: 0.5428  loss_mask_6: 0.1891  loss_dice_6: 1.221  loss_ce_7: 0.5189  loss_mask_7: 0.1866  loss_dice_7: 1.267  loss_ce_8: 0.5315  loss_mask_8: 0.1852  loss_dice_8: 1.284    time: 1.0782  last_time: 1.0713  data_time: 0.0725  last_data_time: 0.0952   lr: 0.0001  max_mem: 32971M
[10/09 19:49:55] d2.utils.events INFO:  eta: 0:40:52  iter: 719  total_loss: 20.86  loss_ce: 0.5221  loss_mask: 0.173  loss_dice: 1.272  loss_ce_0: 0.6572  loss_mask_0: 0.2134  loss_dice_0: 1.49  loss_ce_1: 0.6487  loss_mask_1: 0.1868  loss_dice_1: 1.429  loss_ce_2: 0.6094  loss_mask_2: 0.181  loss_dice_2: 1.335  loss_ce_3: 0.562  loss_mask_3: 0.1802  loss_dice_3: 1.31  loss_ce_4: 0.5626  loss_mask_4: 0.1779  loss_dice_4: 1.311  loss_ce_5: 0.539  loss_mask_5: 0.1766  loss_dice_5: 1.314  loss_ce_6: 0.5278  loss_mask_6: 0.1768  loss_dice_6: 1.273  loss_ce_7: 0.5318  loss_mask_7: 0.1748  loss_dice_7: 1.255  loss_ce_8: 0.5122  loss_mask_8: 0.1711  loss_dice_8: 1.251    time: 1.0778  last_time: 1.0571  data_time: 0.0689  last_data_time: 0.0654   lr: 0.0001  max_mem: 32971M
[10/09 19:50:16] d2.utils.events INFO:  eta: 0:40:31  iter: 739  total_loss: 20.57  loss_ce: 0.5123  loss_mask: 0.1813  loss_dice: 1.216  loss_ce_0: 0.5991  loss_mask_0: 0.2082  loss_dice_0: 1.463  loss_ce_1: 0.68  loss_mask_1: 0.1924  loss_dice_1: 1.374  loss_ce_2: 0.6498  loss_mask_2: 0.1879  loss_dice_2: 1.287  loss_ce_3: 0.5847  loss_mask_3: 0.1792  loss_dice_3: 1.283  loss_ce_4: 0.5452  loss_mask_4: 0.1791  loss_dice_4: 1.296  loss_ce_5: 0.5446  loss_mask_5: 0.1801  loss_dice_5: 1.271  loss_ce_6: 0.5225  loss_mask_6: 0.1836  loss_dice_6: 1.255  loss_ce_7: 0.5401  loss_mask_7: 0.1827  loss_dice_7: 1.242  loss_ce_8: 0.5363  loss_mask_8: 0.1817  loss_dice_8: 1.269    time: 1.0777  last_time: 1.0379  data_time: 0.0731  last_data_time: 0.0733   lr: 0.0001  max_mem: 32971M
[10/09 19:50:38] d2.utils.events INFO:  eta: 0:40:09  iter: 759  total_loss: 20.88  loss_ce: 0.5023  loss_mask: 0.1679  loss_dice: 1.269  loss_ce_0: 0.5776  loss_mask_0: 0.191  loss_dice_0: 1.56  loss_ce_1: 0.6114  loss_mask_1: 0.1811  loss_dice_1: 1.449  loss_ce_2: 0.6055  loss_mask_2: 0.1724  loss_dice_2: 1.378  loss_ce_3: 0.5403  loss_mask_3: 0.1716  loss_dice_3: 1.325  loss_ce_4: 0.5033  loss_mask_4: 0.1685  loss_dice_4: 1.345  loss_ce_5: 0.5157  loss_mask_5: 0.1677  loss_dice_5: 1.299  loss_ce_6: 0.5065  loss_mask_6: 0.1666  loss_dice_6: 1.282  loss_ce_7: 0.4992  loss_mask_7: 0.1687  loss_dice_7: 1.31  loss_ce_8: 0.5037  loss_mask_8: 0.1675  loss_dice_8: 1.296    time: 1.0775  last_time: 1.0760  data_time: 0.0685  last_data_time: 0.0702   lr: 0.0001  max_mem: 32971M
[10/09 19:50:59] d2.utils.events INFO:  eta: 0:39:46  iter: 779  total_loss: 20.01  loss_ce: 0.4961  loss_mask: 0.1753  loss_dice: 1.234  loss_ce_0: 0.5657  loss_mask_0: 0.1946  loss_dice_0: 1.458  loss_ce_1: 0.6619  loss_mask_1: 0.185  loss_dice_1: 1.373  loss_ce_2: 0.5805  loss_mask_2: 0.1723  loss_dice_2: 1.338  loss_ce_3: 0.5402  loss_mask_3: 0.1781  loss_dice_3: 1.285  loss_ce_4: 0.5061  loss_mask_4: 0.1747  loss_dice_4: 1.259  loss_ce_5: 0.5038  loss_mask_5: 0.1746  loss_dice_5: 1.273  loss_ce_6: 0.4817  loss_mask_6: 0.1745  loss_dice_6: 1.259  loss_ce_7: 0.5005  loss_mask_7: 0.1761  loss_dice_7: 1.221  loss_ce_8: 0.4966  loss_mask_8: 0.1769  loss_dice_8: 1.222    time: 1.0771  last_time: 1.1075  data_time: 0.0691  last_data_time: 0.0881   lr: 0.0001  max_mem: 32971M
[10/09 19:51:21] d2.utils.events INFO:  eta: 0:39:26  iter: 799  total_loss: 20.64  loss_ce: 0.5227  loss_mask: 0.1701  loss_dice: 1.253  loss_ce_0: 0.5756  loss_mask_0: 0.1975  loss_dice_0: 1.516  loss_ce_1: 0.6853  loss_mask_1: 0.1816  loss_dice_1: 1.408  loss_ce_2: 0.5757  loss_mask_2: 0.1757  loss_dice_2: 1.31  loss_ce_3: 0.5482  loss_mask_3: 0.1742  loss_dice_3: 1.278  loss_ce_4: 0.5576  loss_mask_4: 0.1747  loss_dice_4: 1.315  loss_ce_5: 0.5104  loss_mask_5: 0.1716  loss_dice_5: 1.292  loss_ce_6: 0.5064  loss_mask_6: 0.1739  loss_dice_6: 1.298  loss_ce_7: 0.5174  loss_mask_7: 0.173  loss_dice_7: 1.274  loss_ce_8: 0.5162  loss_mask_8: 0.1722  loss_dice_8: 1.305    time: 1.0773  last_time: 1.0492  data_time: 0.0786  last_data_time: 0.0660   lr: 0.0001  max_mem: 32971M
[10/09 19:51:43] d2.utils.events INFO:  eta: 0:39:05  iter: 819  total_loss: 20.29  loss_ce: 0.5072  loss_mask: 0.1778  loss_dice: 1.21  loss_ce_0: 0.605  loss_mask_0: 0.2083  loss_dice_0: 1.476  loss_ce_1: 0.6718  loss_mask_1: 0.1949  loss_dice_1: 1.338  loss_ce_2: 0.6462  loss_mask_2: 0.1851  loss_dice_2: 1.263  loss_ce_3: 0.5663  loss_mask_3: 0.1792  loss_dice_3: 1.252  loss_ce_4: 0.5597  loss_mask_4: 0.1795  loss_dice_4: 1.245  loss_ce_5: 0.5235  loss_mask_5: 0.1766  loss_dice_5: 1.266  loss_ce_6: 0.5238  loss_mask_6: 0.1762  loss_dice_6: 1.244  loss_ce_7: 0.5125  loss_mask_7: 0.1759  loss_dice_7: 1.212  loss_ce_8: 0.5226  loss_mask_8: 0.1757  loss_dice_8: 1.247    time: 1.0777  last_time: 1.1102  data_time: 0.0695  last_data_time: 0.0797   lr: 0.0001  max_mem: 32971M
[10/09 19:52:05] d2.utils.events INFO:  eta: 0:38:45  iter: 839  total_loss: 21.47  loss_ce: 0.5594  loss_mask: 0.1729  loss_dice: 1.311  loss_ce_0: 0.6402  loss_mask_0: 0.2079  loss_dice_0: 1.545  loss_ce_1: 0.7382  loss_mask_1: 0.1939  loss_dice_1: 1.447  loss_ce_2: 0.6038  loss_mask_2: 0.1829  loss_dice_2: 1.389  loss_ce_3: 0.5706  loss_mask_3: 0.1753  loss_dice_3: 1.298  loss_ce_4: 0.5993  loss_mask_4: 0.1746  loss_dice_4: 1.311  loss_ce_5: 0.5623  loss_mask_5: 0.1744  loss_dice_5: 1.335  loss_ce_6: 0.5531  loss_mask_6: 0.1701  loss_dice_6: 1.305  loss_ce_7: 0.5711  loss_mask_7: 0.1723  loss_dice_7: 1.311  loss_ce_8: 0.5618  loss_mask_8: 0.1733  loss_dice_8: 1.323    time: 1.0779  last_time: 1.1157  data_time: 0.0710  last_data_time: 0.0514   lr: 0.0001  max_mem: 32971M
[10/09 19:52:26] d2.utils.events INFO:  eta: 0:38:22  iter: 859  total_loss: 20.53  loss_ce: 0.5012  loss_mask: 0.1768  loss_dice: 1.224  loss_ce_0: 0.5703  loss_mask_0: 0.1957  loss_dice_0: 1.423  loss_ce_1: 0.6066  loss_mask_1: 0.1891  loss_dice_1: 1.338  loss_ce_2: 0.5649  loss_mask_2: 0.1791  loss_dice_2: 1.307  loss_ce_3: 0.5465  loss_mask_3: 0.1767  loss_dice_3: 1.238  loss_ce_4: 0.5148  loss_mask_4: 0.1752  loss_dice_4: 1.238  loss_ce_5: 0.5145  loss_mask_5: 0.1793  loss_dice_5: 1.219  loss_ce_6: 0.4632  loss_mask_6: 0.1737  loss_dice_6: 1.216  loss_ce_7: 0.5037  loss_mask_7: 0.173  loss_dice_7: 1.225  loss_ce_8: 0.4798  loss_mask_8: 0.1748  loss_dice_8: 1.209    time: 1.0780  last_time: 1.0458  data_time: 0.0758  last_data_time: 0.0622   lr: 0.0001  max_mem: 32971M
[10/09 19:52:48] d2.utils.events INFO:  eta: 0:38:01  iter: 879  total_loss: 20.49  loss_ce: 0.4857  loss_mask: 0.1699  loss_dice: 1.321  loss_ce_0: 0.5517  loss_mask_0: 0.1999  loss_dice_0: 1.488  loss_ce_1: 0.6144  loss_mask_1: 0.1836  loss_dice_1: 1.385  loss_ce_2: 0.5437  loss_mask_2: 0.1737  loss_dice_2: 1.367  loss_ce_3: 0.4946  loss_mask_3: 0.1721  loss_dice_3: 1.354  loss_ce_4: 0.5088  loss_mask_4: 0.1769  loss_dice_4: 1.317  loss_ce_5: 0.4674  loss_mask_5: 0.175  loss_dice_5: 1.314  loss_ce_6: 0.4323  loss_mask_6: 0.1775  loss_dice_6: 1.322  loss_ce_7: 0.4779  loss_mask_7: 0.1724  loss_dice_7: 1.294  loss_ce_8: 0.461  loss_mask_8: 0.1717  loss_dice_8: 1.319    time: 1.0780  last_time: 1.1088  data_time: 0.0737  last_data_time: 0.0798   lr: 0.0001  max_mem: 32971M
[10/09 19:53:10] d2.utils.events INFO:  eta: 0:37:40  iter: 899  total_loss: 20.87  loss_ce: 0.5207  loss_mask: 0.173  loss_dice: 1.257  loss_ce_0: 0.628  loss_mask_0: 0.2122  loss_dice_0: 1.479  loss_ce_1: 0.6587  loss_mask_1: 0.1861  loss_dice_1: 1.355  loss_ce_2: 0.6114  loss_mask_2: 0.1814  loss_dice_2: 1.302  loss_ce_3: 0.5638  loss_mask_3: 0.1794  loss_dice_3: 1.281  loss_ce_4: 0.5394  loss_mask_4: 0.1756  loss_dice_4: 1.269  loss_ce_5: 0.5644  loss_mask_5: 0.1712  loss_dice_5: 1.272  loss_ce_6: 0.516  loss_mask_6: 0.1755  loss_dice_6: 1.249  loss_ce_7: 0.5446  loss_mask_7: 0.1779  loss_dice_7: 1.229  loss_ce_8: 0.5232  loss_mask_8: 0.1747  loss_dice_8: 1.239    time: 1.0781  last_time: 1.1336  data_time: 0.0726  last_data_time: 0.0705   lr: 0.0001  max_mem: 32971M
[10/09 19:53:32] d2.utils.events INFO:  eta: 0:37:19  iter: 919  total_loss: 21.77  loss_ce: 0.5225  loss_mask: 0.171  loss_dice: 1.347  loss_ce_0: 0.5923  loss_mask_0: 0.1966  loss_dice_0: 1.566  loss_ce_1: 0.6556  loss_mask_1: 0.1845  loss_dice_1: 1.451  loss_ce_2: 0.6343  loss_mask_2: 0.1774  loss_dice_2: 1.398  loss_ce_3: 0.5689  loss_mask_3: 0.1787  loss_dice_3: 1.362  loss_ce_4: 0.5553  loss_mask_4: 0.1757  loss_dice_4: 1.349  loss_ce_5: 0.5351  loss_mask_5: 0.1726  loss_dice_5: 1.369  loss_ce_6: 0.4997  loss_mask_6: 0.1727  loss_dice_6: 1.378  loss_ce_7: 0.5397  loss_mask_7: 0.1726  loss_dice_7: 1.332  loss_ce_8: 0.5404  loss_mask_8: 0.1716  loss_dice_8: 1.355    time: 1.0789  last_time: 1.1826  data_time: 0.0760  last_data_time: 0.0793   lr: 0.0001  max_mem: 32971M
[10/09 19:53:54] d2.utils.events INFO:  eta: 0:36:59  iter: 939  total_loss: 20.52  loss_ce: 0.4788  loss_mask: 0.1676  loss_dice: 1.268  loss_ce_0: 0.625  loss_mask_0: 0.1954  loss_dice_0: 1.521  loss_ce_1: 0.6402  loss_mask_1: 0.1794  loss_dice_1: 1.409  loss_ce_2: 0.5841  loss_mask_2: 0.1738  loss_dice_2: 1.361  loss_ce_3: 0.5089  loss_mask_3: 0.172  loss_dice_3: 1.308  loss_ce_4: 0.4957  loss_mask_4: 0.1696  loss_dice_4: 1.289  loss_ce_5: 0.497  loss_mask_5: 0.1695  loss_dice_5: 1.304  loss_ce_6: 0.4614  loss_mask_6: 0.1703  loss_dice_6: 1.258  loss_ce_7: 0.5032  loss_mask_7: 0.1711  loss_dice_7: 1.233  loss_ce_8: 0.526  loss_mask_8: 0.1675  loss_dice_8: 1.249    time: 1.0793  last_time: 1.0419  data_time: 0.0768  last_data_time: 0.0711   lr: 0.0001  max_mem: 32971M
[10/09 19:54:16] d2.utils.events INFO:  eta: 0:36:37  iter: 959  total_loss: 20.5  loss_ce: 0.5081  loss_mask: 0.1708  loss_dice: 1.232  loss_ce_0: 0.5794  loss_mask_0: 0.2002  loss_dice_0: 1.424  loss_ce_1: 0.6391  loss_mask_1: 0.1865  loss_dice_1: 1.366  loss_ce_2: 0.5757  loss_mask_2: 0.1769  loss_dice_2: 1.339  loss_ce_3: 0.547  loss_mask_3: 0.1755  loss_dice_3: 1.315  loss_ce_4: 0.5069  loss_mask_4: 0.1742  loss_dice_4: 1.325  loss_ce_5: 0.5149  loss_mask_5: 0.1725  loss_dice_5: 1.277  loss_ce_6: 0.5242  loss_mask_6: 0.1735  loss_dice_6: 1.262  loss_ce_7: 0.517  loss_mask_7: 0.174  loss_dice_7: 1.3  loss_ce_8: 0.4853  loss_mask_8: 0.1731  loss_dice_8: 1.274    time: 1.0796  last_time: 1.0451  data_time: 0.0856  last_data_time: 0.0877   lr: 0.0001  max_mem: 32971M
[10/09 19:54:38] d2.utils.events INFO:  eta: 0:36:15  iter: 979  total_loss: 19.73  loss_ce: 0.4809  loss_mask: 0.1662  loss_dice: 1.165  loss_ce_0: 0.5851  loss_mask_0: 0.1995  loss_dice_0: 1.374  loss_ce_1: 0.6571  loss_mask_1: 0.1793  loss_dice_1: 1.266  loss_ce_2: 0.5752  loss_mask_2: 0.1741  loss_dice_2: 1.236  loss_ce_3: 0.5128  loss_mask_3: 0.1717  loss_dice_3: 1.249  loss_ce_4: 0.4822  loss_mask_4: 0.1704  loss_dice_4: 1.219  loss_ce_5: 0.4597  loss_mask_5: 0.1679  loss_dice_5: 1.162  loss_ce_6: 0.5032  loss_mask_6: 0.1699  loss_dice_6: 1.17  loss_ce_7: 0.4343  loss_mask_7: 0.1698  loss_dice_7: 1.195  loss_ce_8: 0.4775  loss_mask_8: 0.1664  loss_dice_8: 1.203    time: 1.0795  last_time: 1.0626  data_time: 0.0758  last_data_time: 0.0548   lr: 0.0001  max_mem: 32971M
[10/09 19:54:59] d2.utils.events INFO:  eta: 0:35:55  iter: 999  total_loss: 20.11  loss_ce: 0.5318  loss_mask: 0.1737  loss_dice: 1.249  loss_ce_0: 0.5722  loss_mask_0: 0.2074  loss_dice_0: 1.487  loss_ce_1: 0.664  loss_mask_1: 0.1931  loss_dice_1: 1.386  loss_ce_2: 0.5531  loss_mask_2: 0.1837  loss_dice_2: 1.33  loss_ce_3: 0.5436  loss_mask_3: 0.1802  loss_dice_3: 1.297  loss_ce_4: 0.5155  loss_mask_4: 0.1824  loss_dice_4: 1.279  loss_ce_5: 0.5251  loss_mask_5: 0.1794  loss_dice_5: 1.239  loss_ce_6: 0.5143  loss_mask_6: 0.1754  loss_dice_6: 1.274  loss_ce_7: 0.514  loss_mask_7: 0.1753  loss_dice_7: 1.268  loss_ce_8: 0.5328  loss_mask_8: 0.1749  loss_dice_8: 1.259    time: 1.0797  last_time: 1.0693  data_time: 0.0738  last_data_time: 0.0778   lr: 0.0001  max_mem: 32971M
[10/09 19:55:21] d2.utils.events INFO:  eta: 0:35:33  iter: 1019  total_loss: 19.36  loss_ce: 0.4658  loss_mask: 0.1737  loss_dice: 1.219  loss_ce_0: 0.5536  loss_mask_0: 0.2143  loss_dice_0: 1.384  loss_ce_1: 0.5916  loss_mask_1: 0.1932  loss_dice_1: 1.335  loss_ce_2: 0.5637  loss_mask_2: 0.186  loss_dice_2: 1.303  loss_ce_3: 0.4668  loss_mask_3: 0.1835  loss_dice_3: 1.275  loss_ce_4: 0.4478  loss_mask_4: 0.1783  loss_dice_4: 1.275  loss_ce_5: 0.4601  loss_mask_5: 0.176  loss_dice_5: 1.248  loss_ce_6: 0.4412  loss_mask_6: 0.1734  loss_dice_6: 1.242  loss_ce_7: 0.4442  loss_mask_7: 0.1737  loss_dice_7: 1.226  loss_ce_8: 0.461  loss_mask_8: 0.1749  loss_dice_8: 1.241    time: 1.0796  last_time: 1.0322  data_time: 0.0695  last_data_time: 0.0687   lr: 0.0001  max_mem: 32971M
[10/09 19:55:43] d2.utils.events INFO:  eta: 0:35:11  iter: 1039  total_loss: 20.37  loss_ce: 0.522  loss_mask: 0.1665  loss_dice: 1.247  loss_ce_0: 0.6066  loss_mask_0: 0.1853  loss_dice_0: 1.441  loss_ce_1: 0.6482  loss_mask_1: 0.1769  loss_dice_1: 1.381  loss_ce_2: 0.6002  loss_mask_2: 0.1726  loss_dice_2: 1.304  loss_ce_3: 0.56  loss_mask_3: 0.1723  loss_dice_3: 1.287  loss_ce_4: 0.5525  loss_mask_4: 0.1709  loss_dice_4: 1.282  loss_ce_5: 0.5334  loss_mask_5: 0.1649  loss_dice_5: 1.269  loss_ce_6: 0.483  loss_mask_6: 0.1673  loss_dice_6: 1.286  loss_ce_7: 0.5471  loss_mask_7: 0.166  loss_dice_7: 1.233  loss_ce_8: 0.5386  loss_mask_8: 0.1644  loss_dice_8: 1.24    time: 1.0798  last_time: 1.0875  data_time: 0.0767  last_data_time: 0.0738   lr: 0.0001  max_mem: 32971M
[10/09 19:56:04] d2.utils.events INFO:  eta: 0:34:50  iter: 1059  total_loss: 19.97  loss_ce: 0.4755  loss_mask: 0.1655  loss_dice: 1.22  loss_ce_0: 0.614  loss_mask_0: 0.1957  loss_dice_0: 1.429  loss_ce_1: 0.6439  loss_mask_1: 0.1834  loss_dice_1: 1.333  loss_ce_2: 0.5912  loss_mask_2: 0.1761  loss_dice_2: 1.314  loss_ce_3: 0.5209  loss_mask_3: 0.1729  loss_dice_3: 1.239  loss_ce_4: 0.4978  loss_mask_4: 0.1721  loss_dice_4: 1.26  loss_ce_5: 0.4989  loss_mask_5: 0.1679  loss_dice_5: 1.216  loss_ce_6: 0.4804  loss_mask_6: 0.1677  loss_dice_6: 1.203  loss_ce_7: 0.4648  loss_mask_7: 0.1684  loss_dice_7: 1.185  loss_ce_8: 0.4793  loss_mask_8: 0.1653  loss_dice_8: 1.21    time: 1.0797  last_time: 1.0816  data_time: 0.0711  last_data_time: 0.0879   lr: 0.0001  max_mem: 32971M
[10/09 19:56:26] d2.utils.events INFO:  eta: 0:34:29  iter: 1079  total_loss: 20.56  loss_ce: 0.5179  loss_mask: 0.1611  loss_dice: 1.31  loss_ce_0: 0.602  loss_mask_0: 0.1842  loss_dice_0: 1.537  loss_ce_1: 0.6428  loss_mask_1: 0.1761  loss_dice_1: 1.438  loss_ce_2: 0.5461  loss_mask_2: 0.1654  loss_dice_2: 1.33  loss_ce_3: 0.5245  loss_mask_3: 0.1632  loss_dice_3: 1.312  loss_ce_4: 0.509  loss_mask_4: 0.1626  loss_dice_4: 1.294  loss_ce_5: 0.5161  loss_mask_5: 0.1627  loss_dice_5: 1.292  loss_ce_6: 0.4818  loss_mask_6: 0.163  loss_dice_6: 1.27  loss_ce_7: 0.4981  loss_mask_7: 0.1628  loss_dice_7: 1.279  loss_ce_8: 0.5322  loss_mask_8: 0.1615  loss_dice_8: 1.303    time: 1.0798  last_time: 1.1261  data_time: 0.0754  last_data_time: 0.0753   lr: 0.0001  max_mem: 32971M
[10/09 19:56:48] d2.utils.events INFO:  eta: 0:34:09  iter: 1099  total_loss: 19.59  loss_ce: 0.487  loss_mask: 0.1709  loss_dice: 1.194  loss_ce_0: 0.5996  loss_mask_0: 0.1928  loss_dice_0: 1.379  loss_ce_1: 0.6519  loss_mask_1: 0.181  loss_dice_1: 1.335  loss_ce_2: 0.6065  loss_mask_2: 0.1781  loss_dice_2: 1.251  loss_ce_3: 0.5536  loss_mask_3: 0.1742  loss_dice_3: 1.238  loss_ce_4: 0.5104  loss_mask_4: 0.1785  loss_dice_4: 1.21  loss_ce_5: 0.4948  loss_mask_5: 0.1764  loss_dice_5: 1.197  loss_ce_6: 0.5017  loss_mask_6: 0.1735  loss_dice_6: 1.208  loss_ce_7: 0.5083  loss_mask_7: 0.1751  loss_dice_7: 1.196  loss_ce_8: 0.4993  loss_mask_8: 0.1733  loss_dice_8: 1.199    time: 1.0799  last_time: 1.1420  data_time: 0.0707  last_data_time: 0.0742   lr: 0.0001  max_mem: 32971M
[10/09 19:57:09] d2.utils.events INFO:  eta: 0:33:48  iter: 1119  total_loss: 20.26  loss_ce: 0.4787  loss_mask: 0.1803  loss_dice: 1.231  loss_ce_0: 0.5728  loss_mask_0: 0.2041  loss_dice_0: 1.435  loss_ce_1: 0.6716  loss_mask_1: 0.1941  loss_dice_1: 1.333  loss_ce_2: 0.5833  loss_mask_2: 0.185  loss_dice_2: 1.313  loss_ce_3: 0.5728  loss_mask_3: 0.1807  loss_dice_3: 1.239  loss_ce_4: 0.5212  loss_mask_4: 0.1838  loss_dice_4: 1.228  loss_ce_5: 0.4862  loss_mask_5: 0.1815  loss_dice_5: 1.202  loss_ce_6: 0.4987  loss_mask_6: 0.1842  loss_dice_6: 1.2  loss_ce_7: 0.4954  loss_mask_7: 0.1823  loss_dice_7: 1.222  loss_ce_8: 0.4995  loss_mask_8: 0.1768  loss_dice_8: 1.219    time: 1.0798  last_time: 1.0450  data_time: 0.0710  last_data_time: 0.0728   lr: 0.0001  max_mem: 32971M
[10/09 19:57:31] d2.utils.events INFO:  eta: 0:33:25  iter: 1139  total_loss: 18.38  loss_ce: 0.44  loss_mask: 0.1887  loss_dice: 1.124  loss_ce_0: 0.5476  loss_mask_0: 0.2114  loss_dice_0: 1.36  loss_ce_1: 0.6018  loss_mask_1: 0.1952  loss_dice_1: 1.257  loss_ce_2: 0.5307  loss_mask_2: 0.1873  loss_dice_2: 1.21  loss_ce_3: 0.4753  loss_mask_3: 0.1838  loss_dice_3: 1.174  loss_ce_4: 0.4651  loss_mask_4: 0.1862  loss_dice_4: 1.172  loss_ce_5: 0.4404  loss_mask_5: 0.1866  loss_dice_5: 1.135  loss_ce_6: 0.4579  loss_mask_6: 0.1903  loss_dice_6: 1.134  loss_ce_7: 0.4697  loss_mask_7: 0.1874  loss_dice_7: 1.145  loss_ce_8: 0.467  loss_mask_8: 0.1871  loss_dice_8: 1.123    time: 1.0794  last_time: 1.0240  data_time: 0.0689  last_data_time: 0.0471   lr: 0.0001  max_mem: 32971M
[10/09 19:57:52] d2.utils.events INFO:  eta: 0:33:03  iter: 1159  total_loss: 19.37  loss_ce: 0.4672  loss_mask: 0.1718  loss_dice: 1.209  loss_ce_0: 0.498  loss_mask_0: 0.1998  loss_dice_0: 1.454  loss_ce_1: 0.6116  loss_mask_1: 0.191  loss_dice_1: 1.324  loss_ce_2: 0.5726  loss_mask_2: 0.1793  loss_dice_2: 1.278  loss_ce_3: 0.5245  loss_mask_3: 0.1764  loss_dice_3: 1.216  loss_ce_4: 0.4818  loss_mask_4: 0.1796  loss_dice_4: 1.225  loss_ce_5: 0.5063  loss_mask_5: 0.1726  loss_dice_5: 1.208  loss_ce_6: 0.4632  loss_mask_6: 0.1735  loss_dice_6: 1.18  loss_ce_7: 0.4709  loss_mask_7: 0.1724  loss_dice_7: 1.212  loss_ce_8: 0.4827  loss_mask_8: 0.1725  loss_dice_8: 1.175    time: 1.0793  last_time: 1.1395  data_time: 0.0727  last_data_time: 0.0739   lr: 0.0001  max_mem: 32971M
[10/09 19:58:14] d2.utils.events INFO:  eta: 0:32:43  iter: 1179  total_loss: 19.95  loss_ce: 0.497  loss_mask: 0.161  loss_dice: 1.211  loss_ce_0: 0.593  loss_mask_0: 0.1888  loss_dice_0: 1.461  loss_ce_1: 0.7003  loss_mask_1: 0.1786  loss_dice_1: 1.358  loss_ce_2: 0.6066  loss_mask_2: 0.1707  loss_dice_2: 1.273  loss_ce_3: 0.5338  loss_mask_3: 0.1662  loss_dice_3: 1.23  loss_ce_4: 0.5077  loss_mask_4: 0.1682  loss_dice_4: 1.243  loss_ce_5: 0.5134  loss_mask_5: 0.1648  loss_dice_5: 1.224  loss_ce_6: 0.4668  loss_mask_6: 0.164  loss_dice_6: 1.207  loss_ce_7: 0.494  loss_mask_7: 0.1637  loss_dice_7: 1.197  loss_ce_8: 0.4936  loss_mask_8: 0.1646  loss_dice_8: 1.223    time: 1.0797  last_time: 1.0428  data_time: 0.0727  last_data_time: 0.0658   lr: 0.0001  max_mem: 32971M
[10/09 19:58:36] d2.utils.events INFO:  eta: 0:32:24  iter: 1199  total_loss: 20.51  loss_ce: 0.5334  loss_mask: 0.1641  loss_dice: 1.28  loss_ce_0: 0.584  loss_mask_0: 0.1907  loss_dice_0: 1.472  loss_ce_1: 0.6671  loss_mask_1: 0.1732  loss_dice_1: 1.418  loss_ce_2: 0.6449  loss_mask_2: 0.1661  loss_dice_2: 1.373  loss_ce_3: 0.5387  loss_mask_3: 0.1662  loss_dice_3: 1.322  loss_ce_4: 0.5269  loss_mask_4: 0.1655  loss_dice_4: 1.321  loss_ce_5: 0.5356  loss_mask_5: 0.1635  loss_dice_5: 1.308  loss_ce_6: 0.5063  loss_mask_6: 0.1667  loss_dice_6: 1.281  loss_ce_7: 0.5276  loss_mask_7: 0.1643  loss_dice_7: 1.275  loss_ce_8: 0.5145  loss_mask_8: 0.1641  loss_dice_8: 1.299    time: 1.0801  last_time: 1.0346  data_time: 0.0736  last_data_time: 0.0720   lr: 0.0001  max_mem: 32971M
[10/09 19:58:58] d2.utils.events INFO:  eta: 0:32:02  iter: 1219  total_loss: 20.64  loss_ce: 0.5056  loss_mask: 0.1566  loss_dice: 1.302  loss_ce_0: 0.5878  loss_mask_0: 0.1843  loss_dice_0: 1.515  loss_ce_1: 0.6701  loss_mask_1: 0.1665  loss_dice_1: 1.407  loss_ce_2: 0.6319  loss_mask_2: 0.1632  loss_dice_2: 1.369  loss_ce_3: 0.5572  loss_mask_3: 0.162  loss_dice_3: 1.34  loss_ce_4: 0.5144  loss_mask_4: 0.1628  loss_dice_4: 1.353  loss_ce_5: 0.5189  loss_mask_5: 0.1631  loss_dice_5: 1.302  loss_ce_6: 0.5069  loss_mask_6: 0.1614  loss_dice_6: 1.305  loss_ce_7: 0.4897  loss_mask_7: 0.1587  loss_dice_7: 1.305  loss_ce_8: 0.505  loss_mask_8: 0.1556  loss_dice_8: 1.326    time: 1.0800  last_time: 1.0476  data_time: 0.0712  last_data_time: 0.0765   lr: 0.0001  max_mem: 32971M
[10/09 19:59:19] d2.utils.events INFO:  eta: 0:31:40  iter: 1239  total_loss: 19.54  loss_ce: 0.4571  loss_mask: 0.1784  loss_dice: 1.198  loss_ce_0: 0.5299  loss_mask_0: 0.2081  loss_dice_0: 1.398  loss_ce_1: 0.5855  loss_mask_1: 0.1909  loss_dice_1: 1.331  loss_ce_2: 0.5424  loss_mask_2: 0.184  loss_dice_2: 1.287  loss_ce_3: 0.4774  loss_mask_3: 0.1819  loss_dice_3: 1.291  loss_ce_4: 0.4573  loss_mask_4: 0.1824  loss_dice_4: 1.26  loss_ce_5: 0.4679  loss_mask_5: 0.1824  loss_dice_5: 1.236  loss_ce_6: 0.4427  loss_mask_6: 0.1807  loss_dice_6: 1.254  loss_ce_7: 0.4483  loss_mask_7: 0.1798  loss_dice_7: 1.24  loss_ce_8: 0.44  loss_mask_8: 0.1805  loss_dice_8: 1.255    time: 1.0798  last_time: 1.1317  data_time: 0.0695  last_data_time: 0.0628   lr: 0.0001  max_mem: 32971M
[10/09 19:59:41] d2.utils.events INFO:  eta: 0:31:19  iter: 1259  total_loss: 20.44  loss_ce: 0.5411  loss_mask: 0.1629  loss_dice: 1.245  loss_ce_0: 0.5954  loss_mask_0: 0.1917  loss_dice_0: 1.489  loss_ce_1: 0.6791  loss_mask_1: 0.179  loss_dice_1: 1.415  loss_ce_2: 0.633  loss_mask_2: 0.1724  loss_dice_2: 1.363  loss_ce_3: 0.5374  loss_mask_3: 0.169  loss_dice_3: 1.355  loss_ce_4: 0.5429  loss_mask_4: 0.1684  loss_dice_4: 1.362  loss_ce_5: 0.5325  loss_mask_5: 0.1661  loss_dice_5: 1.322  loss_ce_6: 0.5281  loss_mask_6: 0.1671  loss_dice_6: 1.306  loss_ce_7: 0.4764  loss_mask_7: 0.1663  loss_dice_7: 1.294  loss_ce_8: 0.4917  loss_mask_8: 0.1648  loss_dice_8: 1.302    time: 1.0801  last_time: 1.1843  data_time: 0.0735  last_data_time: 0.0751   lr: 0.0001  max_mem: 32971M
[10/09 20:00:03] d2.utils.events INFO:  eta: 0:30:58  iter: 1279  total_loss: 19.61  loss_ce: 0.4822  loss_mask: 0.1588  loss_dice: 1.167  loss_ce_0: 0.5939  loss_mask_0: 0.184  loss_dice_0: 1.4  loss_ce_1: 0.6263  loss_mask_1: 0.1769  loss_dice_1: 1.29  loss_ce_2: 0.6011  loss_mask_2: 0.166  loss_dice_2: 1.272  loss_ce_3: 0.5293  loss_mask_3: 0.1655  loss_dice_3: 1.21  loss_ce_4: 0.4868  loss_mask_4: 0.1618  loss_dice_4: 1.21  loss_ce_5: 0.4875  loss_mask_5: 0.1616  loss_dice_5: 1.198  loss_ce_6: 0.4799  loss_mask_6: 0.1601  loss_dice_6: 1.193  loss_ce_7: 0.482  loss_mask_7: 0.1593  loss_dice_7: 1.169  loss_ce_8: 0.483  loss_mask_8: 0.1595  loss_dice_8: 1.192    time: 1.0802  last_time: 1.0943  data_time: 0.0719  last_data_time: 0.0674   lr: 0.0001  max_mem: 32971M
[10/09 20:00:25] d2.utils.events INFO:  eta: 0:30:36  iter: 1299  total_loss: 18.92  loss_ce: 0.4343  loss_mask: 0.1825  loss_dice: 1.129  loss_ce_0: 0.5192  loss_mask_0: 0.2111  loss_dice_0: 1.392  loss_ce_1: 0.5979  loss_mask_1: 0.1913  loss_dice_1: 1.329  loss_ce_2: 0.5499  loss_mask_2: 0.1863  loss_dice_2: 1.248  loss_ce_3: 0.4904  loss_mask_3: 0.1865  loss_dice_3: 1.173  loss_ce_4: 0.4662  loss_mask_4: 0.1836  loss_dice_4: 1.173  loss_ce_5: 0.4534  loss_mask_5: 0.1824  loss_dice_5: 1.226  loss_ce_6: 0.4626  loss_mask_6: 0.1839  loss_dice_6: 1.19  loss_ce_7: 0.4452  loss_mask_7: 0.1803  loss_dice_7: 1.187  loss_ce_8: 0.4451  loss_mask_8: 0.1798  loss_dice_8: 1.17    time: 1.0805  last_time: 1.0963  data_time: 0.0722  last_data_time: 0.0707   lr: 0.0001  max_mem: 32971M
[10/09 20:00:46] d2.utils.events INFO:  eta: 0:30:15  iter: 1319  total_loss: 19.42  loss_ce: 0.4405  loss_mask: 0.1714  loss_dice: 1.197  loss_ce_0: 0.5797  loss_mask_0: 0.1973  loss_dice_0: 1.393  loss_ce_1: 0.6188  loss_mask_1: 0.1777  loss_dice_1: 1.36  loss_ce_2: 0.5419  loss_mask_2: 0.1744  loss_dice_2: 1.274  loss_ce_3: 0.5237  loss_mask_3: 0.1739  loss_dice_3: 1.26  loss_ce_4: 0.4886  loss_mask_4: 0.1734  loss_dice_4: 1.287  loss_ce_5: 0.4716  loss_mask_5: 0.17  loss_dice_5: 1.222  loss_ce_6: 0.4638  loss_mask_6: 0.171  loss_dice_6: 1.23  loss_ce_7: 0.465  loss_mask_7: 0.1721  loss_dice_7: 1.186  loss_ce_8: 0.4631  loss_mask_8: 0.171  loss_dice_8: 1.214    time: 1.0803  last_time: 1.0090  data_time: 0.0704  last_data_time: 0.0627   lr: 0.0001  max_mem: 32971M
[10/09 20:01:08] d2.utils.events INFO:  eta: 0:29:53  iter: 1339  total_loss: 19.86  loss_ce: 0.4369  loss_mask: 0.1752  loss_dice: 1.239  loss_ce_0: 0.5828  loss_mask_0: 0.2006  loss_dice_0: 1.385  loss_ce_1: 0.6545  loss_mask_1: 0.1899  loss_dice_1: 1.364  loss_ce_2: 0.5484  loss_mask_2: 0.1811  loss_dice_2: 1.31  loss_ce_3: 0.4766  loss_mask_3: 0.1793  loss_dice_3: 1.26  loss_ce_4: 0.475  loss_mask_4: 0.177  loss_dice_4: 1.256  loss_ce_5: 0.4429  loss_mask_5: 0.1741  loss_dice_5: 1.253  loss_ce_6: 0.4522  loss_mask_6: 0.1769  loss_dice_6: 1.275  loss_ce_7: 0.4525  loss_mask_7: 0.1745  loss_dice_7: 1.221  loss_ce_8: 0.442  loss_mask_8: 0.1724  loss_dice_8: 1.243    time: 1.0803  last_time: 1.1382  data_time: 0.0749  last_data_time: 0.0665   lr: 0.0001  max_mem: 32971M
[10/09 20:01:30] d2.utils.events INFO:  eta: 0:29:32  iter: 1359  total_loss: 19.94  loss_ce: 0.4768  loss_mask: 0.166  loss_dice: 1.233  loss_ce_0: 0.5777  loss_mask_0: 0.1959  loss_dice_0: 1.467  loss_ce_1: 0.6517  loss_mask_1: 0.1817  loss_dice_1: 1.366  loss_ce_2: 0.5884  loss_mask_2: 0.1693  loss_dice_2: 1.356  loss_ce_3: 0.5235  loss_mask_3: 0.1667  loss_dice_3: 1.298  loss_ce_4: 0.5011  loss_mask_4: 0.1647  loss_dice_4: 1.255  loss_ce_5: 0.5032  loss_mask_5: 0.1652  loss_dice_5: 1.287  loss_ce_6: 0.504  loss_mask_6: 0.1688  loss_dice_6: 1.262  loss_ce_7: 0.4584  loss_mask_7: 0.166  loss_dice_7: 1.245  loss_ce_8: 0.4818  loss_mask_8: 0.1638  loss_dice_8: 1.235    time: 1.0806  last_time: 1.1721  data_time: 0.0730  last_data_time: 0.0808   lr: 0.0001  max_mem: 32971M
[10/09 20:01:52] d2.utils.events INFO:  eta: 0:29:11  iter: 1379  total_loss: 20.11  loss_ce: 0.4791  loss_mask: 0.1566  loss_dice: 1.213  loss_ce_0: 0.5714  loss_mask_0: 0.1833  loss_dice_0: 1.426  loss_ce_1: 0.6446  loss_mask_1: 0.1725  loss_dice_1: 1.364  loss_ce_2: 0.5942  loss_mask_2: 0.1637  loss_dice_2: 1.317  loss_ce_3: 0.5539  loss_mask_3: 0.1628  loss_dice_3: 1.266  loss_ce_4: 0.5121  loss_mask_4: 0.1632  loss_dice_4: 1.287  loss_ce_5: 0.5031  loss_mask_5: 0.1583  loss_dice_5: 1.266  loss_ce_6: 0.4839  loss_mask_6: 0.159  loss_dice_6: 1.208  loss_ce_7: 0.485  loss_mask_7: 0.1596  loss_dice_7: 1.247  loss_ce_8: 0.5062  loss_mask_8: 0.1578  loss_dice_8: 1.226    time: 1.0806  last_time: 1.1994  data_time: 0.0728  last_data_time: 0.0845   lr: 0.0001  max_mem: 32971M
[10/09 20:02:14] d2.utils.events INFO:  eta: 0:28:50  iter: 1399  total_loss: 20.37  loss_ce: 0.4737  loss_mask: 0.1697  loss_dice: 1.278  loss_ce_0: 0.568  loss_mask_0: 0.1941  loss_dice_0: 1.432  loss_ce_1: 0.6057  loss_mask_1: 0.1812  loss_dice_1: 1.389  loss_ce_2: 0.5639  loss_mask_2: 0.1738  loss_dice_2: 1.351  loss_ce_3: 0.5244  loss_mask_3: 0.1729  loss_dice_3: 1.277  loss_ce_4: 0.4896  loss_mask_4: 0.1728  loss_dice_4: 1.308  loss_ce_5: 0.4891  loss_mask_5: 0.1681  loss_dice_5: 1.284  loss_ce_6: 0.4892  loss_mask_6: 0.167  loss_dice_6: 1.229  loss_ce_7: 0.4769  loss_mask_7: 0.1659  loss_dice_7: 1.282  loss_ce_8: 0.4716  loss_mask_8: 0.1695  loss_dice_8: 1.287    time: 1.0807  last_time: 1.1131  data_time: 0.0729  last_data_time: 0.0691   lr: 0.0001  max_mem: 32971M
[10/09 20:02:36] d2.utils.events INFO:  eta: 0:28:28  iter: 1419  total_loss: 20.72  loss_ce: 0.5251  loss_mask: 0.1604  loss_dice: 1.219  loss_ce_0: 0.643  loss_mask_0: 0.1891  loss_dice_0: 1.468  loss_ce_1: 0.6484  loss_mask_1: 0.172  loss_dice_1: 1.39  loss_ce_2: 0.6112  loss_mask_2: 0.1685  loss_dice_2: 1.348  loss_ce_3: 0.5458  loss_mask_3: 0.1645  loss_dice_3: 1.299  loss_ce_4: 0.5438  loss_mask_4: 0.162  loss_dice_4: 1.284  loss_ce_5: 0.5208  loss_mask_5: 0.1607  loss_dice_5: 1.271  loss_ce_6: 0.5116  loss_mask_6: 0.1612  loss_dice_6: 1.261  loss_ce_7: 0.4731  loss_mask_7: 0.1605  loss_dice_7: 1.237  loss_ce_8: 0.4861  loss_mask_8: 0.1618  loss_dice_8: 1.261    time: 1.0811  last_time: 1.1332  data_time: 0.0755  last_data_time: 0.0984   lr: 0.0001  max_mem: 32971M
[10/09 20:02:58] d2.utils.events INFO:  eta: 0:28:07  iter: 1439  total_loss: 20.54  loss_ce: 0.4982  loss_mask: 0.1615  loss_dice: 1.261  loss_ce_0: 0.5874  loss_mask_0: 0.1856  loss_dice_0: 1.45  loss_ce_1: 0.6417  loss_mask_1: 0.1771  loss_dice_1: 1.404  loss_ce_2: 0.618  loss_mask_2: 0.1657  loss_dice_2: 1.322  loss_ce_3: 0.5655  loss_mask_3: 0.1577  loss_dice_3: 1.307  loss_ce_4: 0.5552  loss_mask_4: 0.1568  loss_dice_4: 1.311  loss_ce_5: 0.5151  loss_mask_5: 0.1576  loss_dice_5: 1.281  loss_ce_6: 0.5159  loss_mask_6: 0.1613  loss_dice_6: 1.266  loss_ce_7: 0.5122  loss_mask_7: 0.1533  loss_dice_7: 1.304  loss_ce_8: 0.5154  loss_mask_8: 0.1571  loss_dice_8: 1.285    time: 1.0812  last_time: 1.0463  data_time: 0.0738  last_data_time: 0.0747   lr: 0.0001  max_mem: 32971M
[10/09 20:03:20] d2.utils.events INFO:  eta: 0:27:45  iter: 1459  total_loss: 19.87  loss_ce: 0.5187  loss_mask: 0.1637  loss_dice: 1.217  loss_ce_0: 0.5659  loss_mask_0: 0.1936  loss_dice_0: 1.465  loss_ce_1: 0.6549  loss_mask_1: 0.1805  loss_dice_1: 1.383  loss_ce_2: 0.5703  loss_mask_2: 0.17  loss_dice_2: 1.342  loss_ce_3: 0.543  loss_mask_3: 0.1648  loss_dice_3: 1.271  loss_ce_4: 0.4955  loss_mask_4: 0.1663  loss_dice_4: 1.266  loss_ce_5: 0.5386  loss_mask_5: 0.1635  loss_dice_5: 1.284  loss_ce_6: 0.5265  loss_mask_6: 0.1649  loss_dice_6: 1.231  loss_ce_7: 0.5353  loss_mask_7: 0.1643  loss_dice_7: 1.239  loss_ce_8: 0.5076  loss_mask_8: 0.1644  loss_dice_8: 1.239    time: 1.0813  last_time: 1.0859  data_time: 0.0705  last_data_time: 0.0636   lr: 0.0001  max_mem: 32971M
[10/09 20:03:41] d2.utils.events INFO:  eta: 0:27:23  iter: 1479  total_loss: 19.6  loss_ce: 0.4746  loss_mask: 0.1712  loss_dice: 1.229  loss_ce_0: 0.5619  loss_mask_0: 0.1955  loss_dice_0: 1.406  loss_ce_1: 0.6213  loss_mask_1: 0.1795  loss_dice_1: 1.346  loss_ce_2: 0.5851  loss_mask_2: 0.1728  loss_dice_2: 1.27  loss_ce_3: 0.5237  loss_mask_3: 0.1747  loss_dice_3: 1.226  loss_ce_4: 0.4969  loss_mask_4: 0.1741  loss_dice_4: 1.226  loss_ce_5: 0.508  loss_mask_5: 0.1713  loss_dice_5: 1.187  loss_ce_6: 0.4742  loss_mask_6: 0.1693  loss_dice_6: 1.184  loss_ce_7: 0.4833  loss_mask_7: 0.1706  loss_dice_7: 1.194  loss_ce_8: 0.4606  loss_mask_8: 0.1706  loss_dice_8: 1.238    time: 1.0811  last_time: 1.1609  data_time: 0.0714  last_data_time: 0.0698   lr: 0.0001  max_mem: 32971M
[10/09 20:04:03] d2.utils.events INFO:  eta: 0:27:02  iter: 1499  total_loss: 19.91  loss_ce: 0.4595  loss_mask: 0.162  loss_dice: 1.238  loss_ce_0: 0.5937  loss_mask_0: 0.1881  loss_dice_0: 1.425  loss_ce_1: 0.6552  loss_mask_1: 0.1755  loss_dice_1: 1.394  loss_ce_2: 0.5901  loss_mask_2: 0.1692  loss_dice_2: 1.298  loss_ce_3: 0.5642  loss_mask_3: 0.1635  loss_dice_3: 1.311  loss_ce_4: 0.5087  loss_mask_4: 0.1622  loss_dice_4: 1.304  loss_ce_5: 0.4969  loss_mask_5: 0.1588  loss_dice_5: 1.272  loss_ce_6: 0.4746  loss_mask_6: 0.1612  loss_dice_6: 1.249  loss_ce_7: 0.4805  loss_mask_7: 0.1596  loss_dice_7: 1.247  loss_ce_8: 0.4464  loss_mask_8: 0.1614  loss_dice_8: 1.234    time: 1.0814  last_time: 1.0250  data_time: 0.0719  last_data_time: 0.0574   lr: 0.0001  max_mem: 32971M
[10/09 20:04:25] d2.utils.events INFO:  eta: 0:26:41  iter: 1519  total_loss: 19.8  loss_ce: 0.4727  loss_mask: 0.1637  loss_dice: 1.19  loss_ce_0: 0.5796  loss_mask_0: 0.1836  loss_dice_0: 1.411  loss_ce_1: 0.6757  loss_mask_1: 0.1692  loss_dice_1: 1.353  loss_ce_2: 0.6172  loss_mask_2: 0.1608  loss_dice_2: 1.31  loss_ce_3: 0.5443  loss_mask_3: 0.1635  loss_dice_3: 1.272  loss_ce_4: 0.5192  loss_mask_4: 0.1635  loss_dice_4: 1.248  loss_ce_5: 0.5183  loss_mask_5: 0.1618  loss_dice_5: 1.24  loss_ce_6: 0.4951  loss_mask_6: 0.162  loss_dice_6: 1.226  loss_ce_7: 0.4963  loss_mask_7: 0.1643  loss_dice_7: 1.228  loss_ce_8: 0.4881  loss_mask_8: 0.1663  loss_dice_8: 1.208    time: 1.0814  last_time: 1.1233  data_time: 0.0729  last_data_time: 0.0795   lr: 0.0001  max_mem: 32971M
[10/09 20:04:46] d2.utils.events INFO:  eta: 0:26:19  iter: 1539  total_loss: 19.6  loss_ce: 0.4856  loss_mask: 0.161  loss_dice: 1.212  loss_ce_0: 0.5824  loss_mask_0: 0.1874  loss_dice_0: 1.386  loss_ce_1: 0.63  loss_mask_1: 0.1766  loss_dice_1: 1.376  loss_ce_2: 0.5705  loss_mask_2: 0.1677  loss_dice_2: 1.302  loss_ce_3: 0.5321  loss_mask_3: 0.1647  loss_dice_3: 1.251  loss_ce_4: 0.4975  loss_mask_4: 0.1671  loss_dice_4: 1.229  loss_ce_5: 0.5098  loss_mask_5: 0.1599  loss_dice_5: 1.221  loss_ce_6: 0.4682  loss_mask_6: 0.1598  loss_dice_6: 1.215  loss_ce_7: 0.4853  loss_mask_7: 0.1626  loss_dice_7: 1.245  loss_ce_8: 0.4913  loss_mask_8: 0.1612  loss_dice_8: 1.225    time: 1.0814  last_time: 1.0486  data_time: 0.0692  last_data_time: 0.0587   lr: 0.0001  max_mem: 32971M
[10/09 20:05:08] d2.utils.events INFO:  eta: 0:25:57  iter: 1559  total_loss: 19.63  loss_ce: 0.4584  loss_mask: 0.1577  loss_dice: 1.213  loss_ce_0: 0.5639  loss_mask_0: 0.187  loss_dice_0: 1.425  loss_ce_1: 0.6455  loss_mask_1: 0.1711  loss_dice_1: 1.404  loss_ce_2: 0.5848  loss_mask_2: 0.1606  loss_dice_2: 1.318  loss_ce_3: 0.5053  loss_mask_3: 0.1589  loss_dice_3: 1.275  loss_ce_4: 0.4844  loss_mask_4: 0.1588  loss_dice_4: 1.27  loss_ce_5: 0.4725  loss_mask_5: 0.1626  loss_dice_5: 1.284  loss_ce_6: 0.4893  loss_mask_6: 0.159  loss_dice_6: 1.272  loss_ce_7: 0.4546  loss_mask_7: 0.1582  loss_dice_7: 1.265  loss_ce_8: 0.4653  loss_mask_8: 0.1602  loss_dice_8: 1.251    time: 1.0814  last_time: 1.1019  data_time: 0.0715  last_data_time: 0.0785   lr: 0.0001  max_mem: 32971M
[10/09 20:05:30] d2.utils.events INFO:  eta: 0:25:35  iter: 1579  total_loss: 19.47  loss_ce: 0.4684  loss_mask: 0.1698  loss_dice: 1.191  loss_ce_0: 0.5814  loss_mask_0: 0.1962  loss_dice_0: 1.433  loss_ce_1: 0.5943  loss_mask_1: 0.1776  loss_dice_1: 1.328  loss_ce_2: 0.5757  loss_mask_2: 0.1744  loss_dice_2: 1.221  loss_ce_3: 0.5406  loss_mask_3: 0.1726  loss_dice_3: 1.212  loss_ce_4: 0.5396  loss_mask_4: 0.1735  loss_dice_4: 1.238  loss_ce_5: 0.5074  loss_mask_5: 0.1697  loss_dice_5: 1.234  loss_ce_6: 0.4936  loss_mask_6: 0.1696  loss_dice_6: 1.175  loss_ce_7: 0.4845  loss_mask_7: 0.1718  loss_dice_7: 1.201  loss_ce_8: 0.4942  loss_mask_8: 0.1689  loss_dice_8: 1.168    time: 1.0815  last_time: 1.1564  data_time: 0.0711  last_data_time: 0.0824   lr: 0.0001  max_mem: 32971M
[10/09 20:05:52] d2.utils.events INFO:  eta: 0:25:14  iter: 1599  total_loss: 18.9  loss_ce: 0.4409  loss_mask: 0.1566  loss_dice: 1.17  loss_ce_0: 0.5347  loss_mask_0: 0.1927  loss_dice_0: 1.408  loss_ce_1: 0.6275  loss_mask_1: 0.1763  loss_dice_1: 1.295  loss_ce_2: 0.5554  loss_mask_2: 0.1618  loss_dice_2: 1.239  loss_ce_3: 0.4941  loss_mask_3: 0.1633  loss_dice_3: 1.188  loss_ce_4: 0.4798  loss_mask_4: 0.1623  loss_dice_4: 1.222  loss_ce_5: 0.4811  loss_mask_5: 0.1595  loss_dice_5: 1.216  loss_ce_6: 0.4802  loss_mask_6: 0.1566  loss_dice_6: 1.146  loss_ce_7: 0.4546  loss_mask_7: 0.1568  loss_dice_7: 1.175  loss_ce_8: 0.4482  loss_mask_8: 0.1572  loss_dice_8: 1.16    time: 1.0816  last_time: 1.1224  data_time: 0.0753  last_data_time: 0.0858   lr: 0.0001  max_mem: 32971M
[10/09 20:06:13] d2.utils.events INFO:  eta: 0:24:52  iter: 1619  total_loss: 20.14  loss_ce: 0.4961  loss_mask: 0.1651  loss_dice: 1.263  loss_ce_0: 0.5561  loss_mask_0: 0.1947  loss_dice_0: 1.445  loss_ce_1: 0.6503  loss_mask_1: 0.1791  loss_dice_1: 1.371  loss_ce_2: 0.6038  loss_mask_2: 0.1698  loss_dice_2: 1.318  loss_ce_3: 0.5526  loss_mask_3: 0.1668  loss_dice_3: 1.277  loss_ce_4: 0.542  loss_mask_4: 0.1636  loss_dice_4: 1.257  loss_ce_5: 0.5145  loss_mask_5: 0.1654  loss_dice_5: 1.266  loss_ce_6: 0.4771  loss_mask_6: 0.1656  loss_dice_6: 1.229  loss_ce_7: 0.5058  loss_mask_7: 0.1657  loss_dice_7: 1.241  loss_ce_8: 0.4883  loss_mask_8: 0.1652  loss_dice_8: 1.242    time: 1.0816  last_time: 1.0503  data_time: 0.0738  last_data_time: 0.0781   lr: 0.0001  max_mem: 32971M
[10/09 20:06:35] d2.utils.events INFO:  eta: 0:24:30  iter: 1639  total_loss: 20.23  loss_ce: 0.4315  loss_mask: 0.1515  loss_dice: 1.209  loss_ce_0: 0.5545  loss_mask_0: 0.1795  loss_dice_0: 1.429  loss_ce_1: 0.5981  loss_mask_1: 0.1676  loss_dice_1: 1.391  loss_ce_2: 0.5246  loss_mask_2: 0.1572  loss_dice_2: 1.298  loss_ce_3: 0.4689  loss_mask_3: 0.1549  loss_dice_3: 1.269  loss_ce_4: 0.4665  loss_mask_4: 0.1538  loss_dice_4: 1.268  loss_ce_5: 0.4533  loss_mask_5: 0.1525  loss_dice_5: 1.249  loss_ce_6: 0.444  loss_mask_6: 0.1539  loss_dice_6: 1.231  loss_ce_7: 0.4628  loss_mask_7: 0.1536  loss_dice_7: 1.217  loss_ce_8: 0.4369  loss_mask_8: 0.1512  loss_dice_8: 1.221    time: 1.0818  last_time: 1.0685  data_time: 0.0710  last_data_time: 0.0493   lr: 0.0001  max_mem: 32971M
[10/09 20:06:57] d2.utils.events INFO:  eta: 0:24:08  iter: 1659  total_loss: 19.52  loss_ce: 0.4522  loss_mask: 0.1544  loss_dice: 1.229  loss_ce_0: 0.5788  loss_mask_0: 0.1816  loss_dice_0: 1.401  loss_ce_1: 0.6312  loss_mask_1: 0.172  loss_dice_1: 1.341  loss_ce_2: 0.5977  loss_mask_2: 0.1639  loss_dice_2: 1.28  loss_ce_3: 0.515  loss_mask_3: 0.1566  loss_dice_3: 1.236  loss_ce_4: 0.475  loss_mask_4: 0.1562  loss_dice_4: 1.214  loss_ce_5: 0.4849  loss_mask_5: 0.1567  loss_dice_5: 1.219  loss_ce_6: 0.4645  loss_mask_6: 0.1568  loss_dice_6: 1.197  loss_ce_7: 0.4469  loss_mask_7: 0.1554  loss_dice_7: 1.23  loss_ce_8: 0.4653  loss_mask_8: 0.1534  loss_dice_8: 1.196    time: 1.0817  last_time: 1.0514  data_time: 0.0726  last_data_time: 0.0715   lr: 0.0001  max_mem: 32971M
[10/09 21:02:53] detectron2 INFO: Rank of current process: 0. World size: 1
[10/09 21:02:54] detectron2 INFO: Environment info:
-------------------------------  -------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:47:35) [GCC 12.3.0]
numpy                            1.24.4
detectron2                       0.6 @/home/ids/gbrison/segmentation/segmentation/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    CUDA 12.5
detectron2 arch flags            8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.0+cu121 @/home/ids/gbrison/segmentation/miniconda3/envs/fc/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA L40S (arch=8.9)
Driver version                   555.42.06
CUDA_HOME                        /usr/local/cuda
Pillow                           9.4.0
torchvision                      0.19.0+cu121 @/home/ids/gbrison/segmentation/miniconda3/envs/fc/lib/python3.8/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.10.0
-------------------------------  -------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[10/09 21:02:54] detectron2 INFO: Command line arguments: Namespace(config_file='configs/coco/panoptic-segmentation/fcclip/r50_exp_3000_a_decoder.yaml', dist_url='tcp://127.0.0.1:51163', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[10/09 21:02:54] detectron2 INFO: Contents of args.config_file=configs/coco/panoptic-segmentation/fcclip/r50_exp_3000_a_decoder.yaml:
_BASE_: ./fcclip_convnext_large_eval_ade20k_r50.yaml

INPUT:
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TEST: 2560

MODEL:
  SEM_SEG_HEAD:
    NUM_CLASSES: 19
  WEIGHTS: /tsi/hi-paris/GB/segmentation/models/fcclip_cocopan_r50.pth
OUTPUT_DIR: /tsi/hi-paris/GB/segmentation/results/In_vocab/r50_008_3000_19_a_decoder
DATASETS:
  TRAIN: ("openvocab_cityscapes_fine_panoptic_train",)
  TEST: ("openvocab_cityscapes_fine_panoptic_val",)
SOLVER:
  IMS_PER_BATCH: 8
  MAX_ITER: 3000
TEST:
  EVAL_PERIOD: 3000


[10/09 21:02:54] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - openvocab_cityscapes_fine_panoptic_val
  TRAIN:
  - openvocab_cityscapes_fine_panoptic_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    MINIMUM_INST_AREA: 1
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_panoptic_lsj
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 1024
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: -1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: CLIP
  DEVICE: cuda
  FC_CLIP:
    CLIP_MODEL_NAME: RN50
    CLIP_PRETRAINED_WEIGHTS: openai
    EMBED_DIM: 1024
    ENSEMBLE_ON_VALID_MASK: true
    GEOMETRIC_ENSEMBLE_ALPHA: 0.4
    GEOMETRIC_ENSEMBLE_BETA: 0.8
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 250
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.0
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: true
      SEMANTIC_ON: true
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: FCCLIP
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.32316305
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 1
    - 1
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: basic
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: FCCLIPHead
    NORM: GN
    NUM_CLASSES: 19
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: /tsi/hi-paris/GB/segmentation/models/fcclip_cocopan_r50.pth
OUTPUT_DIR: /tsi/hi-paris/GB/segmentation/results/In_vocab/r50_008_3000_19_a_decoder
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 3000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 3000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[10/09 21:02:54] detectron2 INFO: Full config saved to /tsi/hi-paris/GB/segmentation/results/In_vocab/r50_008_3000_19_a_decoder/config.yaml
[10/09 21:02:54] d2.utils.env INFO: Using a generated random seed 57106215
[10/09 21:02:59] d2.engine.defaults INFO: Model:
FCCLIP(
  (backbone): CLIP(
    (clip_model): CLIP(
      (visual): ModifiedResNet(
        (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (layer1): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer2): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer3): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer4): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (attnpool): AttentionPool2d(
          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (c_proj): Linear(in_features=2048, out_features=1024, bias=True)
        )
      )
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ls_1): Identity()
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ls_2): Identity()
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (sem_seg_head): FCCLIPHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(250, 256)
      (query_embed): Embedding(250, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (mask_pooling): MaskPooling()
      (_mask_pooling_proj): Sequential(
        (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
      )
      (class_embed): MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=1024, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 19
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU()
  (mask_pooling): MaskPooling()
  (decoder_adapter): DecoderAdapter(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (conv2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (norm1): LayerNorm((64, 1, 1), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((256, 1, 1), eps=1e-05, elementwise_affine=True)
    (relu): ReLU()
  )
  (void_embedding): Embedding(1, 1024)
)
[10/09 21:02:59] fcclip.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerPanopticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1333, sample_style='choice'), RandomFlip()]
[10/09 21:02:59] fcclip.data.datasets.register_cityscapes_panoptic INFO: 18 cities found in 'datasets/cityscapes/leftImg8bit/train'.
[10/09 21:02:59] d2.data.build INFO: Using training sampler TrainingSampler
[10/09 21:02:59] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/09 21:02:59] d2.data.common INFO: Serializing 2975 elements to byte tensors and concatenating them all ...
[10/09 21:02:59] d2.data.common INFO: Serialized dataset takes 4.12 MiB
[10/09 21:02:59] d2.data.build INFO: Making batched data loader with batch_size=8
[10/09 21:02:59] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[10/09 21:02:59] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /tsi/hi-paris/GB/segmentation/models/fcclip_cocopan_r50.pth ...
[10/09 21:02:59] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /tsi/hi-paris/GB/segmentation/models/fcclip_cocopan_r50.pth ...
[10/09 21:03:02] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (134,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.
[10/09 21:03:02] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.clip_model.ln_final.{bias, weight}[0m
[34mbackbone.clip_model.token_embedding.weight[0m
[34mbackbone.clip_model.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.k_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.positional_embedding[0m
[34mbackbone.clip_model.visual.attnpool.q_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.v_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.conv1.weight[0m
[34mbackbone.clip_model.visual.conv2.weight[0m
[34mbackbone.clip_model.visual.conv3.weight[0m
[34mbackbone.clip_model.visual.layer1.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer1.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer1.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer1.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer1.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer1.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer1.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer1.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer1.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer1.2.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer2.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.2.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.3.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.3.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.3.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.3.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.3.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.3.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer3.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.2.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.3.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.3.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.3.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.3.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.3.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.3.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.4.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.4.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.4.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.4.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.4.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.4.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.5.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.5.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.5.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.5.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.5.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.5.conv3.weight[0m
[34mbackbone.clip_model.visual.layer4.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer4.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer4.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer4.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer4.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer4.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer4.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer4.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer4.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer4.2.conv3.weight[0m
[34mbackbone.clip_model.{logit_scale, positional_embedding, text_projection}[0m
[34mbn1.{bias, running_mean, running_var, weight}[0m
[34mbn2.{bias, running_mean, running_var, weight}[0m
[34mconv1.{bias, weight}[0m
[34mconv2.{bias, weight}[0m
[34mcriterion.empty_weight[0m
[34mdecoder_adapter.conv1.{bias, weight}[0m
[34mdecoder_adapter.conv2.{bias, weight}[0m
[34mdecoder_adapter.norm1.{bias, weight}[0m
[34mdecoder_adapter.norm2.{bias, weight}[0m
[10/09 21:03:02] d2.engine.train_loop INFO: Starting training from iteration 0
[10/09 21:03:27] d2.utils.events INFO:  eta: 0:52:27  iter: 19  total_loss: 32.52  loss_ce: 1.254  loss_mask: 0.289  loss_dice: 1.564  loss_ce_0: 1.463  loss_mask_0: 0.2988  loss_dice_0: 1.921  loss_ce_1: 1.503  loss_mask_1: 0.3088  loss_dice_1: 1.731  loss_ce_2: 1.402  loss_mask_2: 0.294  loss_dice_2: 1.653  loss_ce_3: 1.341  loss_mask_3: 0.2932  loss_dice_3: 1.597  loss_ce_4: 1.322  loss_mask_4: 0.2998  loss_dice_4: 1.613  loss_ce_5: 1.263  loss_mask_5: 0.291  loss_dice_5: 1.58  loss_ce_6: 1.224  loss_mask_6: 0.2897  loss_dice_6: 1.551  loss_ce_7: 1.231  loss_mask_7: 0.2904  loss_dice_7: 1.562  loss_ce_8: 1.251  loss_mask_8: 0.2852  loss_dice_8: 1.552    time: 1.0662  last_time: 1.0618  data_time: 0.1104  last_data_time: 0.0716   lr: 0.0001  max_mem: 31166M
[10/09 21:03:48] d2.utils.events INFO:  eta: 0:51:43  iter: 39  total_loss: 25.31  loss_ce: 0.7744  loss_mask: 0.2452  loss_dice: 1.366  loss_ce_0: 0.8059  loss_mask_0: 0.268  loss_dice_0: 1.711  loss_ce_1: 0.8897  loss_mask_1: 0.2723  loss_dice_1: 1.565  loss_ce_2: 0.8414  loss_mask_2: 0.2506  loss_dice_2: 1.524  loss_ce_3: 0.7922  loss_mask_3: 0.2466  loss_dice_3: 1.45  loss_ce_4: 0.7725  loss_mask_4: 0.2486  loss_dice_4: 1.411  loss_ce_5: 0.7553  loss_mask_5: 0.2473  loss_dice_5: 1.438  loss_ce_6: 0.7406  loss_mask_6: 0.2447  loss_dice_6: 1.401  loss_ce_7: 0.7476  loss_mask_7: 0.2476  loss_dice_7: 1.428  loss_ce_8: 0.772  loss_mask_8: 0.2438  loss_dice_8: 1.394    time: 1.0573  last_time: 1.0054  data_time: 0.0669  last_data_time: 0.0624   lr: 0.0001  max_mem: 31663M
[10/09 21:04:09] d2.utils.events INFO:  eta: 0:51:14  iter: 59  total_loss: 23.34  loss_ce: 0.6573  loss_mask: 0.2238  loss_dice: 1.365  loss_ce_0: 0.692  loss_mask_0: 0.2629  loss_dice_0: 1.631  loss_ce_1: 0.8205  loss_mask_1: 0.2365  loss_dice_1: 1.501  loss_ce_2: 0.754  loss_mask_2: 0.2314  loss_dice_2: 1.422  loss_ce_3: 0.6982  loss_mask_3: 0.2227  loss_dice_3: 1.352  loss_ce_4: 0.6892  loss_mask_4: 0.2238  loss_dice_4: 1.387  loss_ce_5: 0.6787  loss_mask_5: 0.2253  loss_dice_5: 1.364  loss_ce_6: 0.6627  loss_mask_6: 0.2275  loss_dice_6: 1.351  loss_ce_7: 0.6395  loss_mask_7: 0.229  loss_dice_7: 1.333  loss_ce_8: 0.6536  loss_mask_8: 0.2281  loss_dice_8: 1.353    time: 1.0570  last_time: 1.0405  data_time: 0.0685  last_data_time: 0.0511   lr: 0.0001  max_mem: 31663M
[10/09 21:04:31] d2.utils.events INFO:  eta: 0:51:12  iter: 79  total_loss: 24.01  loss_ce: 0.6478  loss_mask: 0.2182  loss_dice: 1.349  loss_ce_0: 0.7838  loss_mask_0: 0.2463  loss_dice_0: 1.652  loss_ce_1: 0.8537  loss_mask_1: 0.2357  loss_dice_1: 1.576  loss_ce_2: 0.7927  loss_mask_2: 0.2233  loss_dice_2: 1.445  loss_ce_3: 0.7176  loss_mask_3: 0.2191  loss_dice_3: 1.383  loss_ce_4: 0.6829  loss_mask_4: 0.2164  loss_dice_4: 1.382  loss_ce_5: 0.6869  loss_mask_5: 0.2204  loss_dice_5: 1.401  loss_ce_6: 0.6699  loss_mask_6: 0.2194  loss_dice_6: 1.357  loss_ce_7: 0.6452  loss_mask_7: 0.2164  loss_dice_7: 1.368  loss_ce_8: 0.6445  loss_mask_8: 0.2171  loss_dice_8: 1.363    time: 1.0578  last_time: 1.0500  data_time: 0.0722  last_data_time: 0.0747   lr: 0.0001  max_mem: 31663M
[10/09 21:04:52] d2.utils.events INFO:  eta: 0:50:40  iter: 99  total_loss: 23.31  loss_ce: 0.6655  loss_mask: 0.2231  loss_dice: 1.347  loss_ce_0: 0.7445  loss_mask_0: 0.2529  loss_dice_0: 1.6  loss_ce_1: 0.8146  loss_mask_1: 0.2411  loss_dice_1: 1.507  loss_ce_2: 0.7553  loss_mask_2: 0.2224  loss_dice_2: 1.433  loss_ce_3: 0.6936  loss_mask_3: 0.2229  loss_dice_3: 1.376  loss_ce_4: 0.6698  loss_mask_4: 0.2272  loss_dice_4: 1.357  loss_ce_5: 0.6709  loss_mask_5: 0.227  loss_dice_5: 1.34  loss_ce_6: 0.6351  loss_mask_6: 0.2206  loss_dice_6: 1.319  loss_ce_7: 0.6516  loss_mask_7: 0.2231  loss_dice_7: 1.332  loss_ce_8: 0.6228  loss_mask_8: 0.2235  loss_dice_8: 1.339    time: 1.0552  last_time: 1.0519  data_time: 0.0664  last_data_time: 0.0594   lr: 0.0001  max_mem: 31663M
[10/09 21:05:13] d2.utils.events INFO:  eta: 0:50:24  iter: 119  total_loss: 23.65  loss_ce: 0.6542  loss_mask: 0.2117  loss_dice: 1.364  loss_ce_0: 0.7662  loss_mask_0: 0.234  loss_dice_0: 1.632  loss_ce_1: 0.8522  loss_mask_1: 0.2333  loss_dice_1: 1.522  loss_ce_2: 0.7591  loss_mask_2: 0.2172  loss_dice_2: 1.452  loss_ce_3: 0.7164  loss_mask_3: 0.216  loss_dice_3: 1.439  loss_ce_4: 0.6743  loss_mask_4: 0.2091  loss_dice_4: 1.41  loss_ce_5: 0.7008  loss_mask_5: 0.2118  loss_dice_5: 1.4  loss_ce_6: 0.6864  loss_mask_6: 0.2049  loss_dice_6: 1.388  loss_ce_7: 0.6783  loss_mask_7: 0.2046  loss_dice_7: 1.348  loss_ce_8: 0.649  loss_mask_8: 0.2071  loss_dice_8: 1.398    time: 1.0564  last_time: 1.1128  data_time: 0.0670  last_data_time: 0.0688   lr: 0.0001  max_mem: 31812M
[10/09 21:05:34] d2.utils.events INFO:  eta: 0:50:03  iter: 139  total_loss: 21.93  loss_ce: 0.5875  loss_mask: 0.1943  loss_dice: 1.266  loss_ce_0: 0.7079  loss_mask_0: 0.2192  loss_dice_0: 1.538  loss_ce_1: 0.7519  loss_mask_1: 0.2109  loss_dice_1: 1.431  loss_ce_2: 0.6817  loss_mask_2: 0.1998  loss_dice_2: 1.329  loss_ce_3: 0.6285  loss_mask_3: 0.1984  loss_dice_3: 1.301  loss_ce_4: 0.6288  loss_mask_4: 0.1992  loss_dice_4: 1.309  loss_ce_5: 0.6113  loss_mask_5: 0.1986  loss_dice_5: 1.326  loss_ce_6: 0.6022  loss_mask_6: 0.194  loss_dice_6: 1.307  loss_ce_7: 0.5728  loss_mask_7: 0.1945  loss_dice_7: 1.281  loss_ce_8: 0.56  loss_mask_8: 0.1949  loss_dice_8: 1.302    time: 1.0555  last_time: 1.0443  data_time: 0.0617  last_data_time: 0.0752   lr: 0.0001  max_mem: 31812M
[10/09 21:05:55] d2.utils.events INFO:  eta: 0:49:42  iter: 159  total_loss: 22.58  loss_ce: 0.5868  loss_mask: 0.1805  loss_dice: 1.326  loss_ce_0: 0.691  loss_mask_0: 0.2055  loss_dice_0: 1.528  loss_ce_1: 0.7459  loss_mask_1: 0.1949  loss_dice_1: 1.444  loss_ce_2: 0.6726  loss_mask_2: 0.1831  loss_dice_2: 1.392  loss_ce_3: 0.6457  loss_mask_3: 0.1866  loss_dice_3: 1.294  loss_ce_4: 0.6447  loss_mask_4: 0.1855  loss_dice_4: 1.332  loss_ce_5: 0.6151  loss_mask_5: 0.1854  loss_dice_5: 1.279  loss_ce_6: 0.6132  loss_mask_6: 0.185  loss_dice_6: 1.292  loss_ce_7: 0.5973  loss_mask_7: 0.1834  loss_dice_7: 1.31  loss_ce_8: 0.6133  loss_mask_8: 0.1838  loss_dice_8: 1.299    time: 1.0567  last_time: 1.0315  data_time: 0.0677  last_data_time: 0.0552   lr: 0.0001  max_mem: 32147M
[10/09 21:06:16] d2.utils.events INFO:  eta: 0:49:21  iter: 179  total_loss: 21.14  loss_ce: 0.5513  loss_mask: 0.1993  loss_dice: 1.25  loss_ce_0: 0.6473  loss_mask_0: 0.2357  loss_dice_0: 1.531  loss_ce_1: 0.7426  loss_mask_1: 0.2202  loss_dice_1: 1.44  loss_ce_2: 0.6414  loss_mask_2: 0.2008  loss_dice_2: 1.352  loss_ce_3: 0.5988  loss_mask_3: 0.2027  loss_dice_3: 1.274  loss_ce_4: 0.5908  loss_mask_4: 0.2016  loss_dice_4: 1.297  loss_ce_5: 0.5781  loss_mask_5: 0.2007  loss_dice_5: 1.284  loss_ce_6: 0.5581  loss_mask_6: 0.2068  loss_dice_6: 1.258  loss_ce_7: 0.5501  loss_mask_7: 0.1993  loss_dice_7: 1.275  loss_ce_8: 0.5744  loss_mask_8: 0.1976  loss_dice_8: 1.252    time: 1.0565  last_time: 1.1056  data_time: 0.0680  last_data_time: 0.0808   lr: 0.0001  max_mem: 32147M
[10/09 21:06:38] d2.utils.events INFO:  eta: 0:49:05  iter: 199  total_loss: 22.96  loss_ce: 0.6201  loss_mask: 0.1825  loss_dice: 1.305  loss_ce_0: 0.701  loss_mask_0: 0.2195  loss_dice_0: 1.567  loss_ce_1: 0.8074  loss_mask_1: 0.2041  loss_dice_1: 1.473  loss_ce_2: 0.684  loss_mask_2: 0.1914  loss_dice_2: 1.421  loss_ce_3: 0.6422  loss_mask_3: 0.1871  loss_dice_3: 1.348  loss_ce_4: 0.6301  loss_mask_4: 0.1823  loss_dice_4: 1.368  loss_ce_5: 0.6265  loss_mask_5: 0.1899  loss_dice_5: 1.372  loss_ce_6: 0.6362  loss_mask_6: 0.1837  loss_dice_6: 1.288  loss_ce_7: 0.6111  loss_mask_7: 0.1797  loss_dice_7: 1.323  loss_ce_8: 0.664  loss_mask_8: 0.1828  loss_dice_8: 1.317    time: 1.0588  last_time: 1.1092  data_time: 0.0692  last_data_time: 0.0631   lr: 0.0001  max_mem: 32147M
[10/09 21:06:59] d2.utils.events INFO:  eta: 0:48:45  iter: 219  total_loss: 21.45  loss_ce: 0.5582  loss_mask: 0.2145  loss_dice: 1.283  loss_ce_0: 0.6622  loss_mask_0: 0.2342  loss_dice_0: 1.542  loss_ce_1: 0.75  loss_mask_1: 0.2184  loss_dice_1: 1.422  loss_ce_2: 0.6669  loss_mask_2: 0.2125  loss_dice_2: 1.381  loss_ce_3: 0.6091  loss_mask_3: 0.2136  loss_dice_3: 1.32  loss_ce_4: 0.564  loss_mask_4: 0.2151  loss_dice_4: 1.322  loss_ce_5: 0.5563  loss_mask_5: 0.2149  loss_dice_5: 1.291  loss_ce_6: 0.5939  loss_mask_6: 0.2121  loss_dice_6: 1.291  loss_ce_7: 0.5581  loss_mask_7: 0.2094  loss_dice_7: 1.264  loss_ce_8: 0.5517  loss_mask_8: 0.2119  loss_dice_8: 1.277    time: 1.0594  last_time: 1.1083  data_time: 0.0710  last_data_time: 0.0689   lr: 0.0001  max_mem: 32147M
[10/09 21:07:21] d2.utils.events INFO:  eta: 0:48:26  iter: 239  total_loss: 21.98  loss_ce: 0.6023  loss_mask: 0.1841  loss_dice: 1.28  loss_ce_0: 0.6702  loss_mask_0: 0.2131  loss_dice_0: 1.605  loss_ce_1: 0.7729  loss_mask_1: 0.1967  loss_dice_1: 1.484  loss_ce_2: 0.663  loss_mask_2: 0.1946  loss_dice_2: 1.448  loss_ce_3: 0.6245  loss_mask_3: 0.1864  loss_dice_3: 1.35  loss_ce_4: 0.5931  loss_mask_4: 0.1859  loss_dice_4: 1.353  loss_ce_5: 0.6009  loss_mask_5: 0.1855  loss_dice_5: 1.344  loss_ce_6: 0.5968  loss_mask_6: 0.1887  loss_dice_6: 1.308  loss_ce_7: 0.5898  loss_mask_7: 0.1884  loss_dice_7: 1.324  loss_ce_8: 0.6164  loss_mask_8: 0.1877  loss_dice_8: 1.29    time: 1.0611  last_time: 1.0195  data_time: 0.0755  last_data_time: 0.0621   lr: 0.0001  max_mem: 32422M
[10/09 21:07:43] d2.utils.events INFO:  eta: 0:48:12  iter: 259  total_loss: 22.26  loss_ce: 0.6393  loss_mask: 0.1733  loss_dice: 1.32  loss_ce_0: 0.7239  loss_mask_0: 0.2058  loss_dice_0: 1.597  loss_ce_1: 0.8449  loss_mask_1: 0.1874  loss_dice_1: 1.465  loss_ce_2: 0.7353  loss_mask_2: 0.178  loss_dice_2: 1.421  loss_ce_3: 0.6972  loss_mask_3: 0.1774  loss_dice_3: 1.387  loss_ce_4: 0.6824  loss_mask_4: 0.1773  loss_dice_4: 1.311  loss_ce_5: 0.6337  loss_mask_5: 0.175  loss_dice_5: 1.34  loss_ce_6: 0.6367  loss_mask_6: 0.1721  loss_dice_6: 1.292  loss_ce_7: 0.6239  loss_mask_7: 0.1738  loss_dice_7: 1.346  loss_ce_8: 0.64  loss_mask_8: 0.1729  loss_dice_8: 1.309    time: 1.0625  last_time: 1.1157  data_time: 0.0692  last_data_time: 0.0872   lr: 0.0001  max_mem: 32422M
[10/09 21:08:04] d2.utils.events INFO:  eta: 0:47:56  iter: 279  total_loss: 21.89  loss_ce: 0.568  loss_mask: 0.1832  loss_dice: 1.341  loss_ce_0: 0.6747  loss_mask_0: 0.216  loss_dice_0: 1.587  loss_ce_1: 0.7439  loss_mask_1: 0.1971  loss_dice_1: 1.451  loss_ce_2: 0.6795  loss_mask_2: 0.1905  loss_dice_2: 1.425  loss_ce_3: 0.6114  loss_mask_3: 0.1868  loss_dice_3: 1.341  loss_ce_4: 0.5916  loss_mask_4: 0.1867  loss_dice_4: 1.344  loss_ce_5: 0.595  loss_mask_5: 0.1845  loss_dice_5: 1.39  loss_ce_6: 0.5816  loss_mask_6: 0.1855  loss_dice_6: 1.34  loss_ce_7: 0.5865  loss_mask_7: 0.1842  loss_dice_7: 1.342  loss_ce_8: 0.5602  loss_mask_8: 0.1825  loss_dice_8: 1.337    time: 1.0638  last_time: 1.0686  data_time: 0.0714  last_data_time: 0.0903   lr: 0.0001  max_mem: 32422M
[10/09 21:08:26] d2.utils.events INFO:  eta: 0:47:27  iter: 299  total_loss: 21.9  loss_ce: 0.5822  loss_mask: 0.1878  loss_dice: 1.281  loss_ce_0: 0.6331  loss_mask_0: 0.2327  loss_dice_0: 1.554  loss_ce_1: 0.6862  loss_mask_1: 0.2174  loss_dice_1: 1.434  loss_ce_2: 0.6809  loss_mask_2: 0.2073  loss_dice_2: 1.384  loss_ce_3: 0.6033  loss_mask_3: 0.1927  loss_dice_3: 1.301  loss_ce_4: 0.5945  loss_mask_4: 0.196  loss_dice_4: 1.273  loss_ce_5: 0.5785  loss_mask_5: 0.195  loss_dice_5: 1.339  loss_ce_6: 0.5712  loss_mask_6: 0.192  loss_dice_6: 1.253  loss_ce_7: 0.5924  loss_mask_7: 0.1947  loss_dice_7: 1.263  loss_ce_8: 0.583  loss_mask_8: 0.191  loss_dice_8: 1.292    time: 1.0629  last_time: 1.0520  data_time: 0.0647  last_data_time: 0.0728   lr: 0.0001  max_mem: 32422M
[10/09 21:08:47] d2.utils.events INFO:  eta: 0:47:09  iter: 319  total_loss: 21.79  loss_ce: 0.5371  loss_mask: 0.1809  loss_dice: 1.352  loss_ce_0: 0.5787  loss_mask_0: 0.2164  loss_dice_0: 1.631  loss_ce_1: 0.6607  loss_mask_1: 0.194  loss_dice_1: 1.528  loss_ce_2: 0.5981  loss_mask_2: 0.1869  loss_dice_2: 1.44  loss_ce_3: 0.5663  loss_mask_3: 0.1836  loss_dice_3: 1.432  loss_ce_4: 0.5527  loss_mask_4: 0.1821  loss_dice_4: 1.411  loss_ce_5: 0.5626  loss_mask_5: 0.1817  loss_dice_5: 1.384  loss_ce_6: 0.5397  loss_mask_6: 0.1798  loss_dice_6: 1.369  loss_ce_7: 0.5499  loss_mask_7: 0.1793  loss_dice_7: 1.338  loss_ce_8: 0.5263  loss_mask_8: 0.1819  loss_dice_8: 1.352    time: 1.0630  last_time: 1.0085  data_time: 0.0707  last_data_time: 0.0615   lr: 0.0001  max_mem: 32422M
[10/09 21:09:08] d2.utils.events INFO:  eta: 0:46:52  iter: 339  total_loss: 21.43  loss_ce: 0.5426  loss_mask: 0.179  loss_dice: 1.303  loss_ce_0: 0.6036  loss_mask_0: 0.2017  loss_dice_0: 1.579  loss_ce_1: 0.7097  loss_mask_1: 0.1958  loss_dice_1: 1.495  loss_ce_2: 0.632  loss_mask_2: 0.182  loss_dice_2: 1.444  loss_ce_3: 0.583  loss_mask_3: 0.1844  loss_dice_3: 1.397  loss_ce_4: 0.5731  loss_mask_4: 0.1865  loss_dice_4: 1.374  loss_ce_5: 0.5911  loss_mask_5: 0.1802  loss_dice_5: 1.367  loss_ce_6: 0.5537  loss_mask_6: 0.1815  loss_dice_6: 1.35  loss_ce_7: 0.5413  loss_mask_7: 0.1831  loss_dice_7: 1.357  loss_ce_8: 0.5659  loss_mask_8: 0.18  loss_dice_8: 1.342    time: 1.0631  last_time: 1.0821  data_time: 0.0734  last_data_time: 0.0706   lr: 0.0001  max_mem: 32422M
[10/09 21:09:29] d2.utils.events INFO:  eta: 0:46:32  iter: 359  total_loss: 21.11  loss_ce: 0.5342  loss_mask: 0.2003  loss_dice: 1.341  loss_ce_0: 0.6186  loss_mask_0: 0.2278  loss_dice_0: 1.536  loss_ce_1: 0.6568  loss_mask_1: 0.2161  loss_dice_1: 1.497  loss_ce_2: 0.6307  loss_mask_2: 0.1977  loss_dice_2: 1.394  loss_ce_3: 0.529  loss_mask_3: 0.2001  loss_dice_3: 1.349  loss_ce_4: 0.519  loss_mask_4: 0.2003  loss_dice_4: 1.359  loss_ce_5: 0.5325  loss_mask_5: 0.1958  loss_dice_5: 1.339  loss_ce_6: 0.5204  loss_mask_6: 0.197  loss_dice_6: 1.324  loss_ce_7: 0.5369  loss_mask_7: 0.1982  loss_dice_7: 1.344  loss_ce_8: 0.5465  loss_mask_8: 0.1963  loss_dice_8: 1.327    time: 1.0628  last_time: 1.0970  data_time: 0.0731  last_data_time: 0.0805   lr: 0.0001  max_mem: 32422M
[10/09 21:09:51] d2.utils.events INFO:  eta: 0:46:10  iter: 379  total_loss: 21.2  loss_ce: 0.5135  loss_mask: 0.1911  loss_dice: 1.298  loss_ce_0: 0.6247  loss_mask_0: 0.2236  loss_dice_0: 1.524  loss_ce_1: 0.6759  loss_mask_1: 0.2132  loss_dice_1: 1.462  loss_ce_2: 0.634  loss_mask_2: 0.2083  loss_dice_2: 1.397  loss_ce_3: 0.5575  loss_mask_3: 0.1971  loss_dice_3: 1.307  loss_ce_4: 0.5351  loss_mask_4: 0.1963  loss_dice_4: 1.323  loss_ce_5: 0.5271  loss_mask_5: 0.1952  loss_dice_5: 1.343  loss_ce_6: 0.5197  loss_mask_6: 0.1931  loss_dice_6: 1.29  loss_ce_7: 0.5319  loss_mask_7: 0.1921  loss_dice_7: 1.287  loss_ce_8: 0.5194  loss_mask_8: 0.1907  loss_dice_8: 1.307    time: 1.0629  last_time: 1.0325  data_time: 0.0725  last_data_time: 0.0730   lr: 0.0001  max_mem: 32422M
[10/09 21:10:12] d2.utils.events INFO:  eta: 0:45:47  iter: 399  total_loss: 21.65  loss_ce: 0.5275  loss_mask: 0.1812  loss_dice: 1.326  loss_ce_0: 0.6492  loss_mask_0: 0.2065  loss_dice_0: 1.527  loss_ce_1: 0.7008  loss_mask_1: 0.1966  loss_dice_1: 1.456  loss_ce_2: 0.6356  loss_mask_2: 0.1867  loss_dice_2: 1.387  loss_ce_3: 0.5878  loss_mask_3: 0.186  loss_dice_3: 1.32  loss_ce_4: 0.5479  loss_mask_4: 0.1853  loss_dice_4: 1.349  loss_ce_5: 0.5362  loss_mask_5: 0.1829  loss_dice_5: 1.337  loss_ce_6: 0.543  loss_mask_6: 0.1831  loss_dice_6: 1.287  loss_ce_7: 0.5416  loss_mask_7: 0.18  loss_dice_7: 1.284  loss_ce_8: 0.505  loss_mask_8: 0.1824  loss_dice_8: 1.328    time: 1.0625  last_time: 1.0304  data_time: 0.0703  last_data_time: 0.0703   lr: 0.0001  max_mem: 32422M
[10/09 21:10:34] d2.utils.events INFO:  eta: 0:45:29  iter: 419  total_loss: 21.83  loss_ce: 0.5229  loss_mask: 0.1723  loss_dice: 1.306  loss_ce_0: 0.638  loss_mask_0: 0.2016  loss_dice_0: 1.615  loss_ce_1: 0.6699  loss_mask_1: 0.1859  loss_dice_1: 1.445  loss_ce_2: 0.6009  loss_mask_2: 0.1827  loss_dice_2: 1.431  loss_ce_3: 0.5992  loss_mask_3: 0.1804  loss_dice_3: 1.35  loss_ce_4: 0.5484  loss_mask_4: 0.1792  loss_dice_4: 1.321  loss_ce_5: 0.5396  loss_mask_5: 0.1747  loss_dice_5: 1.312  loss_ce_6: 0.5399  loss_mask_6: 0.1732  loss_dice_6: 1.299  loss_ce_7: 0.5189  loss_mask_7: 0.1738  loss_dice_7: 1.257  loss_ce_8: 0.5322  loss_mask_8: 0.1724  loss_dice_8: 1.302    time: 1.0631  last_time: 1.0700  data_time: 0.0746  last_data_time: 0.0825   lr: 0.0001  max_mem: 32458M
[10/09 21:10:55] d2.utils.events INFO:  eta: 0:45:07  iter: 439  total_loss: 21.61  loss_ce: 0.5274  loss_mask: 0.1771  loss_dice: 1.305  loss_ce_0: 0.6219  loss_mask_0: 0.2139  loss_dice_0: 1.612  loss_ce_1: 0.6805  loss_mask_1: 0.1981  loss_dice_1: 1.495  loss_ce_2: 0.644  loss_mask_2: 0.1919  loss_dice_2: 1.431  loss_ce_3: 0.5936  loss_mask_3: 0.1884  loss_dice_3: 1.379  loss_ce_4: 0.5264  loss_mask_4: 0.1906  loss_dice_4: 1.374  loss_ce_5: 0.5568  loss_mask_5: 0.1801  loss_dice_5: 1.349  loss_ce_6: 0.5517  loss_mask_6: 0.1805  loss_dice_6: 1.291  loss_ce_7: 0.5338  loss_mask_7: 0.1784  loss_dice_7: 1.297  loss_ce_8: 0.5452  loss_mask_8: 0.1765  loss_dice_8: 1.301    time: 1.0631  last_time: 1.0716  data_time: 0.0701  last_data_time: 0.0913   lr: 0.0001  max_mem: 32458M
[10/09 21:11:17] d2.utils.events INFO:  eta: 0:44:47  iter: 459  total_loss: 20.62  loss_ce: 0.5543  loss_mask: 0.1682  loss_dice: 1.202  loss_ce_0: 0.6416  loss_mask_0: 0.2141  loss_dice_0: 1.472  loss_ce_1: 0.7326  loss_mask_1: 0.1862  loss_dice_1: 1.387  loss_ce_2: 0.6388  loss_mask_2: 0.1841  loss_dice_2: 1.349  loss_ce_3: 0.5946  loss_mask_3: 0.1728  loss_dice_3: 1.243  loss_ce_4: 0.5697  loss_mask_4: 0.1727  loss_dice_4: 1.276  loss_ce_5: 0.5483  loss_mask_5: 0.1706  loss_dice_5: 1.225  loss_ce_6: 0.553  loss_mask_6: 0.1716  loss_dice_6: 1.245  loss_ce_7: 0.5416  loss_mask_7: 0.1666  loss_dice_7: 1.229  loss_ce_8: 0.5773  loss_mask_8: 0.1703  loss_dice_8: 1.244    time: 1.0642  last_time: 1.1057  data_time: 0.0800  last_data_time: 0.0882   lr: 0.0001  max_mem: 32458M
[10/09 21:11:38] d2.utils.events INFO:  eta: 0:44:30  iter: 479  total_loss: 21.59  loss_ce: 0.5261  loss_mask: 0.1715  loss_dice: 1.343  loss_ce_0: 0.6095  loss_mask_0: 0.2033  loss_dice_0: 1.546  loss_ce_1: 0.6871  loss_mask_1: 0.1875  loss_dice_1: 1.477  loss_ce_2: 0.6206  loss_mask_2: 0.1739  loss_dice_2: 1.371  loss_ce_3: 0.5851  loss_mask_3: 0.1786  loss_dice_3: 1.328  loss_ce_4: 0.5715  loss_mask_4: 0.1758  loss_dice_4: 1.363  loss_ce_5: 0.554  loss_mask_5: 0.1716  loss_dice_5: 1.358  loss_ce_6: 0.5615  loss_mask_6: 0.1734  loss_dice_6: 1.325  loss_ce_7: 0.5341  loss_mask_7: 0.1713  loss_dice_7: 1.306  loss_ce_8: 0.5291  loss_mask_8: 0.1689  loss_dice_8: 1.29    time: 1.0649  last_time: 1.1130  data_time: 0.0768  last_data_time: 0.0739   lr: 0.0001  max_mem: 32458M
[10/09 21:12:00] d2.utils.events INFO:  eta: 0:44:09  iter: 499  total_loss: 20.69  loss_ce: 0.4966  loss_mask: 0.1789  loss_dice: 1.259  loss_ce_0: 0.5914  loss_mask_0: 0.1986  loss_dice_0: 1.496  loss_ce_1: 0.6363  loss_mask_1: 0.188  loss_dice_1: 1.415  loss_ce_2: 0.582  loss_mask_2: 0.1843  loss_dice_2: 1.379  loss_ce_3: 0.5285  loss_mask_3: 0.1828  loss_dice_3: 1.316  loss_ce_4: 0.5275  loss_mask_4: 0.1789  loss_dice_4: 1.271  loss_ce_5: 0.5051  loss_mask_5: 0.179  loss_dice_5: 1.29  loss_ce_6: 0.5025  loss_mask_6: 0.1789  loss_dice_6: 1.284  loss_ce_7: 0.5103  loss_mask_7: 0.1765  loss_dice_7: 1.253  loss_ce_8: 0.5204  loss_mask_8: 0.1786  loss_dice_8: 1.233    time: 1.0655  last_time: 1.0444  data_time: 0.0812  last_data_time: 0.0766   lr: 0.0001  max_mem: 32458M
[10/09 21:12:22] d2.utils.events INFO:  eta: 0:43:49  iter: 519  total_loss: 19.57  loss_ce: 0.4884  loss_mask: 0.1826  loss_dice: 1.213  loss_ce_0: 0.5674  loss_mask_0: 0.2087  loss_dice_0: 1.415  loss_ce_1: 0.6564  loss_mask_1: 0.1983  loss_dice_1: 1.328  loss_ce_2: 0.5978  loss_mask_2: 0.1901  loss_dice_2: 1.274  loss_ce_3: 0.5254  loss_mask_3: 0.1841  loss_dice_3: 1.218  loss_ce_4: 0.4998  loss_mask_4: 0.1834  loss_dice_4: 1.254  loss_ce_5: 0.5092  loss_mask_5: 0.1825  loss_dice_5: 1.241  loss_ce_6: 0.4832  loss_mask_6: 0.1828  loss_dice_6: 1.208  loss_ce_7: 0.4874  loss_mask_7: 0.1826  loss_dice_7: 1.212  loss_ce_8: 0.4739  loss_mask_8: 0.1819  loss_dice_8: 1.208    time: 1.0659  last_time: 1.0935  data_time: 0.0776  last_data_time: 0.0683   lr: 0.0001  max_mem: 32458M
[10/09 21:12:43] d2.utils.events INFO:  eta: 0:43:30  iter: 539  total_loss: 20.78  loss_ce: 0.5248  loss_mask: 0.1708  loss_dice: 1.28  loss_ce_0: 0.6221  loss_mask_0: 0.1987  loss_dice_0: 1.556  loss_ce_1: 0.7158  loss_mask_1: 0.1858  loss_dice_1: 1.432  loss_ce_2: 0.616  loss_mask_2: 0.172  loss_dice_2: 1.333  loss_ce_3: 0.5475  loss_mask_3: 0.1759  loss_dice_3: 1.297  loss_ce_4: 0.5467  loss_mask_4: 0.1724  loss_dice_4: 1.31  loss_ce_5: 0.5481  loss_mask_5: 0.172  loss_dice_5: 1.318  loss_ce_6: 0.5382  loss_mask_6: 0.1701  loss_dice_6: 1.294  loss_ce_7: 0.5092  loss_mask_7: 0.1707  loss_dice_7: 1.277  loss_ce_8: 0.5328  loss_mask_8: 0.1715  loss_dice_8: 1.25    time: 1.0662  last_time: 1.0855  data_time: 0.0783  last_data_time: 0.1033   lr: 0.0001  max_mem: 32458M
[10/09 21:13:05] d2.utils.events INFO:  eta: 0:43:10  iter: 559  total_loss: 20.65  loss_ce: 0.5273  loss_mask: 0.1966  loss_dice: 1.282  loss_ce_0: 0.5374  loss_mask_0: 0.2332  loss_dice_0: 1.593  loss_ce_1: 0.6445  loss_mask_1: 0.2167  loss_dice_1: 1.451  loss_ce_2: 0.58  loss_mask_2: 0.2058  loss_dice_2: 1.367  loss_ce_3: 0.5479  loss_mask_3: 0.1996  loss_dice_3: 1.342  loss_ce_4: 0.5328  loss_mask_4: 0.2003  loss_dice_4: 1.345  loss_ce_5: 0.5239  loss_mask_5: 0.1989  loss_dice_5: 1.345  loss_ce_6: 0.5055  loss_mask_6: 0.1978  loss_dice_6: 1.281  loss_ce_7: 0.5074  loss_mask_7: 0.2  loss_dice_7: 1.328  loss_ce_8: 0.5244  loss_mask_8: 0.1987  loss_dice_8: 1.292    time: 1.0663  last_time: 1.1060  data_time: 0.0765  last_data_time: 0.0860   lr: 0.0001  max_mem: 32458M
[10/09 21:13:26] d2.utils.events INFO:  eta: 0:42:49  iter: 579  total_loss: 20.68  loss_ce: 0.4952  loss_mask: 0.1874  loss_dice: 1.223  loss_ce_0: 0.6127  loss_mask_0: 0.2298  loss_dice_0: 1.49  loss_ce_1: 0.6744  loss_mask_1: 0.2028  loss_dice_1: 1.38  loss_ce_2: 0.5958  loss_mask_2: 0.1958  loss_dice_2: 1.314  loss_ce_3: 0.5414  loss_mask_3: 0.1912  loss_dice_3: 1.282  loss_ce_4: 0.5436  loss_mask_4: 0.1963  loss_dice_4: 1.243  loss_ce_5: 0.5363  loss_mask_5: 0.1902  loss_dice_5: 1.277  loss_ce_6: 0.5109  loss_mask_6: 0.1902  loss_dice_6: 1.244  loss_ce_7: 0.5151  loss_mask_7: 0.1912  loss_dice_7: 1.243  loss_ce_8: 0.5027  loss_mask_8: 0.1859  loss_dice_8: 1.251    time: 1.0669  last_time: 1.1262  data_time: 0.0807  last_data_time: 0.0802   lr: 0.0001  max_mem: 32458M
[10/09 21:13:48] d2.utils.events INFO:  eta: 0:42:30  iter: 599  total_loss: 20.16  loss_ce: 0.476  loss_mask: 0.1713  loss_dice: 1.232  loss_ce_0: 0.6071  loss_mask_0: 0.193  loss_dice_0: 1.455  loss_ce_1: 0.6895  loss_mask_1: 0.1764  loss_dice_1: 1.4  loss_ce_2: 0.6376  loss_mask_2: 0.1707  loss_dice_2: 1.322  loss_ce_3: 0.5918  loss_mask_3: 0.1711  loss_dice_3: 1.305  loss_ce_4: 0.5384  loss_mask_4: 0.1753  loss_dice_4: 1.289  loss_ce_5: 0.5452  loss_mask_5: 0.1742  loss_dice_5: 1.272  loss_ce_6: 0.515  loss_mask_6: 0.1729  loss_dice_6: 1.247  loss_ce_7: 0.499  loss_mask_7: 0.1718  loss_dice_7: 1.266  loss_ce_8: 0.5097  loss_mask_8: 0.1732  loss_dice_8: 1.26    time: 1.0678  last_time: 1.0462  data_time: 0.0853  last_data_time: 0.0951   lr: 0.0001  max_mem: 32458M
[10/09 21:14:10] d2.utils.events INFO:  eta: 0:42:09  iter: 619  total_loss: 20.76  loss_ce: 0.5424  loss_mask: 0.1674  loss_dice: 1.28  loss_ce_0: 0.5943  loss_mask_0: 0.1942  loss_dice_0: 1.525  loss_ce_1: 0.6726  loss_mask_1: 0.1819  loss_dice_1: 1.438  loss_ce_2: 0.6211  loss_mask_2: 0.1724  loss_dice_2: 1.363  loss_ce_3: 0.5591  loss_mask_3: 0.1697  loss_dice_3: 1.348  loss_ce_4: 0.5469  loss_mask_4: 0.1731  loss_dice_4: 1.358  loss_ce_5: 0.529  loss_mask_5: 0.1697  loss_dice_5: 1.333  loss_ce_6: 0.5448  loss_mask_6: 0.1724  loss_dice_6: 1.281  loss_ce_7: 0.5336  loss_mask_7: 0.17  loss_dice_7: 1.293  loss_ce_8: 0.538  loss_mask_8: 0.169  loss_dice_8: 1.287    time: 1.0682  last_time: 1.0460  data_time: 0.0758  last_data_time: 0.0655   lr: 0.0001  max_mem: 32458M
[10/09 21:14:32] d2.utils.events INFO:  eta: 0:41:49  iter: 639  total_loss: 20.71  loss_ce: 0.5708  loss_mask: 0.1809  loss_dice: 1.245  loss_ce_0: 0.6088  loss_mask_0: 0.2023  loss_dice_0: 1.496  loss_ce_1: 0.6595  loss_mask_1: 0.1902  loss_dice_1: 1.447  loss_ce_2: 0.5986  loss_mask_2: 0.1836  loss_dice_2: 1.377  loss_ce_3: 0.546  loss_mask_3: 0.1834  loss_dice_3: 1.322  loss_ce_4: 0.5428  loss_mask_4: 0.1818  loss_dice_4: 1.275  loss_ce_5: 0.5405  loss_mask_5: 0.1797  loss_dice_5: 1.311  loss_ce_6: 0.5618  loss_mask_6: 0.1793  loss_dice_6: 1.281  loss_ce_7: 0.5316  loss_mask_7: 0.1791  loss_dice_7: 1.245  loss_ce_8: 0.5575  loss_mask_8: 0.1806  loss_dice_8: 1.308    time: 1.0684  last_time: 1.0759  data_time: 0.0790  last_data_time: 0.0632   lr: 0.0001  max_mem: 32458M
[10/09 21:14:53] d2.utils.events INFO:  eta: 0:41:28  iter: 659  total_loss: 20.62  loss_ce: 0.5129  loss_mask: 0.1831  loss_dice: 1.278  loss_ce_0: 0.5957  loss_mask_0: 0.2156  loss_dice_0: 1.479  loss_ce_1: 0.6652  loss_mask_1: 0.2014  loss_dice_1: 1.39  loss_ce_2: 0.6197  loss_mask_2: 0.1876  loss_dice_2: 1.353  loss_ce_3: 0.5865  loss_mask_3: 0.1858  loss_dice_3: 1.292  loss_ce_4: 0.5532  loss_mask_4: 0.1831  loss_dice_4: 1.278  loss_ce_5: 0.5667  loss_mask_5: 0.1847  loss_dice_5: 1.278  loss_ce_6: 0.5495  loss_mask_6: 0.1841  loss_dice_6: 1.231  loss_ce_7: 0.5215  loss_mask_7: 0.1837  loss_dice_7: 1.24  loss_ce_8: 0.5356  loss_mask_8: 0.1843  loss_dice_8: 1.266    time: 1.0687  last_time: 1.0768  data_time: 0.0795  last_data_time: 0.0619   lr: 0.0001  max_mem: 32458M
[10/09 21:15:15] d2.utils.events INFO:  eta: 0:41:07  iter: 679  total_loss: 21.75  loss_ce: 0.5551  loss_mask: 0.1697  loss_dice: 1.301  loss_ce_0: 0.6198  loss_mask_0: 0.1982  loss_dice_0: 1.479  loss_ce_1: 0.7096  loss_mask_1: 0.1857  loss_dice_1: 1.446  loss_ce_2: 0.6532  loss_mask_2: 0.1754  loss_dice_2: 1.413  loss_ce_3: 0.5997  loss_mask_3: 0.1773  loss_dice_3: 1.33  loss_ce_4: 0.5859  loss_mask_4: 0.1728  loss_dice_4: 1.339  loss_ce_5: 0.5873  loss_mask_5: 0.1717  loss_dice_5: 1.317  loss_ce_6: 0.5721  loss_mask_6: 0.1706  loss_dice_6: 1.298  loss_ce_7: 0.548  loss_mask_7: 0.1712  loss_dice_7: 1.281  loss_ce_8: 0.5521  loss_mask_8: 0.1702  loss_dice_8: 1.289    time: 1.0691  last_time: 1.0785  data_time: 0.0804  last_data_time: 0.0940   lr: 0.0001  max_mem: 32458M
[10/09 21:15:36] d2.utils.events INFO:  eta: 0:40:45  iter: 699  total_loss: 20.31  loss_ce: 0.5535  loss_mask: 0.1818  loss_dice: 1.195  loss_ce_0: 0.6199  loss_mask_0: 0.2237  loss_dice_0: 1.438  loss_ce_1: 0.7195  loss_mask_1: 0.2033  loss_dice_1: 1.36  loss_ce_2: 0.6441  loss_mask_2: 0.1859  loss_dice_2: 1.287  loss_ce_3: 0.5961  loss_mask_3: 0.1853  loss_dice_3: 1.282  loss_ce_4: 0.5769  loss_mask_4: 0.1821  loss_dice_4: 1.232  loss_ce_5: 0.57  loss_mask_5: 0.1845  loss_dice_5: 1.224  loss_ce_6: 0.5906  loss_mask_6: 0.1833  loss_dice_6: 1.225  loss_ce_7: 0.5457  loss_mask_7: 0.1825  loss_dice_7: 1.231  loss_ce_8: 0.5688  loss_mask_8: 0.1804  loss_dice_8: 1.226    time: 1.0690  last_time: 1.0468  data_time: 0.0719  last_data_time: 0.0671   lr: 0.0001  max_mem: 32458M
[10/09 21:15:58] d2.utils.events INFO:  eta: 0:40:24  iter: 719  total_loss: 19.98  loss_ce: 0.5432  loss_mask: 0.1744  loss_dice: 1.231  loss_ce_0: 0.6114  loss_mask_0: 0.203  loss_dice_0: 1.421  loss_ce_1: 0.6983  loss_mask_1: 0.1975  loss_dice_1: 1.347  loss_ce_2: 0.6408  loss_mask_2: 0.1782  loss_dice_2: 1.32  loss_ce_3: 0.543  loss_mask_3: 0.1766  loss_dice_3: 1.248  loss_ce_4: 0.5385  loss_mask_4: 0.1725  loss_dice_4: 1.235  loss_ce_5: 0.5603  loss_mask_5: 0.1723  loss_dice_5: 1.228  loss_ce_6: 0.5126  loss_mask_6: 0.1755  loss_dice_6: 1.226  loss_ce_7: 0.5191  loss_mask_7: 0.1737  loss_dice_7: 1.234  loss_ce_8: 0.5483  loss_mask_8: 0.1767  loss_dice_8: 1.244    time: 1.0690  last_time: 1.0704  data_time: 0.0739  last_data_time: 0.0632   lr: 0.0001  max_mem: 32458M
[10/09 21:16:19] d2.utils.events INFO:  eta: 0:40:03  iter: 739  total_loss: 20.36  loss_ce: 0.5239  loss_mask: 0.1779  loss_dice: 1.229  loss_ce_0: 0.5965  loss_mask_0: 0.2218  loss_dice_0: 1.466  loss_ce_1: 0.6505  loss_mask_1: 0.2114  loss_dice_1: 1.368  loss_ce_2: 0.5787  loss_mask_2: 0.192  loss_dice_2: 1.337  loss_ce_3: 0.5762  loss_mask_3: 0.1887  loss_dice_3: 1.251  loss_ce_4: 0.5365  loss_mask_4: 0.1808  loss_dice_4: 1.256  loss_ce_5: 0.5606  loss_mask_5: 0.1819  loss_dice_5: 1.264  loss_ce_6: 0.5317  loss_mask_6: 0.1763  loss_dice_6: 1.249  loss_ce_7: 0.5198  loss_mask_7: 0.1776  loss_dice_7: 1.241  loss_ce_8: 0.5285  loss_mask_8: 0.1894  loss_dice_8: 1.239    time: 1.0689  last_time: 1.1026  data_time: 0.0719  last_data_time: 0.0632   lr: 0.0001  max_mem: 32458M
[10/09 21:16:41] d2.utils.events INFO:  eta: 0:39:42  iter: 759  total_loss: 20.97  loss_ce: 0.5185  loss_mask: 0.1713  loss_dice: 1.259  loss_ce_0: 0.5681  loss_mask_0: 0.2011  loss_dice_0: 1.509  loss_ce_1: 0.6446  loss_mask_1: 0.1925  loss_dice_1: 1.429  loss_ce_2: 0.588  loss_mask_2: 0.1802  loss_dice_2: 1.327  loss_ce_3: 0.5661  loss_mask_3: 0.1799  loss_dice_3: 1.306  loss_ce_4: 0.508  loss_mask_4: 0.1763  loss_dice_4: 1.288  loss_ce_5: 0.5339  loss_mask_5: 0.1747  loss_dice_5: 1.32  loss_ce_6: 0.5042  loss_mask_6: 0.1744  loss_dice_6: 1.264  loss_ce_7: 0.4977  loss_mask_7: 0.1754  loss_dice_7: 1.267  loss_ce_8: 0.5072  loss_mask_8: 0.1734  loss_dice_8: 1.278    time: 1.0692  last_time: 1.0518  data_time: 0.0802  last_data_time: 0.0839   lr: 0.0001  max_mem: 32458M
[10/09 21:17:02] d2.utils.events INFO:  eta: 0:39:20  iter: 779  total_loss: 19.82  loss_ce: 0.4965  loss_mask: 0.1737  loss_dice: 1.232  loss_ce_0: 0.5748  loss_mask_0: 0.205  loss_dice_0: 1.447  loss_ce_1: 0.6097  loss_mask_1: 0.1889  loss_dice_1: 1.329  loss_ce_2: 0.5702  loss_mask_2: 0.1859  loss_dice_2: 1.286  loss_ce_3: 0.5145  loss_mask_3: 0.1803  loss_dice_3: 1.256  loss_ce_4: 0.5224  loss_mask_4: 0.1772  loss_dice_4: 1.229  loss_ce_5: 0.5053  loss_mask_5: 0.174  loss_dice_5: 1.235  loss_ce_6: 0.5117  loss_mask_6: 0.1772  loss_dice_6: 1.211  loss_ce_7: 0.4979  loss_mask_7: 0.1775  loss_dice_7: 1.219  loss_ce_8: 0.5263  loss_mask_8: 0.176  loss_dice_8: 1.217    time: 1.0689  last_time: 1.0520  data_time: 0.0710  last_data_time: 0.0755   lr: 0.0001  max_mem: 32458M
[10/09 21:17:23] d2.utils.events INFO:  eta: 0:38:59  iter: 799  total_loss: 20.3  loss_ce: 0.5432  loss_mask: 0.1781  loss_dice: 1.197  loss_ce_0: 0.6075  loss_mask_0: 0.2019  loss_dice_0: 1.472  loss_ce_1: 0.6845  loss_mask_1: 0.1859  loss_dice_1: 1.346  loss_ce_2: 0.598  loss_mask_2: 0.1776  loss_dice_2: 1.343  loss_ce_3: 0.5521  loss_mask_3: 0.1738  loss_dice_3: 1.219  loss_ce_4: 0.5094  loss_mask_4: 0.1755  loss_dice_4: 1.236  loss_ce_5: 0.5185  loss_mask_5: 0.1729  loss_dice_5: 1.243  loss_ce_6: 0.5207  loss_mask_6: 0.176  loss_dice_6: 1.237  loss_ce_7: 0.4907  loss_mask_7: 0.1777  loss_dice_7: 1.225  loss_ce_8: 0.4978  loss_mask_8: 0.1743  loss_dice_8: 1.229    time: 1.0687  last_time: 1.0801  data_time: 0.0727  last_data_time: 0.0980   lr: 0.0001  max_mem: 32458M
[10/09 21:17:45] d2.utils.events INFO:  eta: 0:38:39  iter: 819  total_loss: 21.12  loss_ce: 0.5222  loss_mask: 0.1688  loss_dice: 1.327  loss_ce_0: 0.5959  loss_mask_0: 0.1909  loss_dice_0: 1.534  loss_ce_1: 0.6483  loss_mask_1: 0.1835  loss_dice_1: 1.456  loss_ce_2: 0.5976  loss_mask_2: 0.1762  loss_dice_2: 1.388  loss_ce_3: 0.5527  loss_mask_3: 0.1746  loss_dice_3: 1.36  loss_ce_4: 0.5393  loss_mask_4: 0.1713  loss_dice_4: 1.324  loss_ce_5: 0.5229  loss_mask_5: 0.1688  loss_dice_5: 1.312  loss_ce_6: 0.5166  loss_mask_6: 0.1706  loss_dice_6: 1.297  loss_ce_7: 0.5443  loss_mask_7: 0.1684  loss_dice_7: 1.333  loss_ce_8: 0.5109  loss_mask_8: 0.1679  loss_dice_8: 1.284    time: 1.0694  last_time: 1.0591  data_time: 0.0801  last_data_time: 0.0733   lr: 0.0001  max_mem: 32458M
[10/09 21:18:07] d2.utils.events INFO:  eta: 0:38:18  iter: 839  total_loss: 21.33  loss_ce: 0.5308  loss_mask: 0.1838  loss_dice: 1.248  loss_ce_0: 0.6493  loss_mask_0: 0.2146  loss_dice_0: 1.482  loss_ce_1: 0.6749  loss_mask_1: 0.195  loss_dice_1: 1.409  loss_ce_2: 0.6401  loss_mask_2: 0.1825  loss_dice_2: 1.369  loss_ce_3: 0.5584  loss_mask_3: 0.1853  loss_dice_3: 1.294  loss_ce_4: 0.5336  loss_mask_4: 0.1842  loss_dice_4: 1.306  loss_ce_5: 0.5292  loss_mask_5: 0.182  loss_dice_5: 1.259  loss_ce_6: 0.5118  loss_mask_6: 0.1853  loss_dice_6: 1.262  loss_ce_7: 0.5168  loss_mask_7: 0.1833  loss_dice_7: 1.293  loss_ce_8: 0.5088  loss_mask_8: 0.1844  loss_dice_8: 1.254    time: 1.0696  last_time: 1.0557  data_time: 0.0802  last_data_time: 0.0865   lr: 0.0001  max_mem: 32458M
[10/09 21:18:29] d2.utils.events INFO:  eta: 0:37:57  iter: 859  total_loss: 20.62  loss_ce: 0.5002  loss_mask: 0.1733  loss_dice: 1.246  loss_ce_0: 0.5501  loss_mask_0: 0.2011  loss_dice_0: 1.478  loss_ce_1: 0.6578  loss_mask_1: 0.1901  loss_dice_1: 1.402  loss_ce_2: 0.5999  loss_mask_2: 0.1811  loss_dice_2: 1.347  loss_ce_3: 0.5679  loss_mask_3: 0.1768  loss_dice_3: 1.267  loss_ce_4: 0.518  loss_mask_4: 0.1756  loss_dice_4: 1.294  loss_ce_5: 0.525  loss_mask_5: 0.1754  loss_dice_5: 1.264  loss_ce_6: 0.5019  loss_mask_6: 0.1752  loss_dice_6: 1.255  loss_ce_7: 0.4886  loss_mask_7: 0.1729  loss_dice_7: 1.249  loss_ce_8: 0.5133  loss_mask_8: 0.173  loss_dice_8: 1.287    time: 1.0698  last_time: 1.1093  data_time: 0.0765  last_data_time: 0.0697   lr: 0.0001  max_mem: 32458M
[10/09 21:18:51] d2.utils.events INFO:  eta: 0:37:37  iter: 879  total_loss: 20.48  loss_ce: 0.531  loss_mask: 0.1743  loss_dice: 1.204  loss_ce_0: 0.6121  loss_mask_0: 0.1945  loss_dice_0: 1.449  loss_ce_1: 0.6871  loss_mask_1: 0.1852  loss_dice_1: 1.385  loss_ce_2: 0.6076  loss_mask_2: 0.1729  loss_dice_2: 1.304  loss_ce_3: 0.546  loss_mask_3: 0.1756  loss_dice_3: 1.269  loss_ce_4: 0.4928  loss_mask_4: 0.176  loss_dice_4: 1.26  loss_ce_5: 0.4977  loss_mask_5: 0.1742  loss_dice_5: 1.281  loss_ce_6: 0.4787  loss_mask_6: 0.1755  loss_dice_6: 1.254  loss_ce_7: 0.4786  loss_mask_7: 0.1739  loss_dice_7: 1.241  loss_ce_8: 0.5041  loss_mask_8: 0.1735  loss_dice_8: 1.244    time: 1.0700  last_time: 1.0414  data_time: 0.0811  last_data_time: 0.0675   lr: 0.0001  max_mem: 32458M
[10/09 21:19:12] d2.utils.events INFO:  eta: 0:37:16  iter: 899  total_loss: 20.82  loss_ce: 0.5198  loss_mask: 0.1762  loss_dice: 1.239  loss_ce_0: 0.5886  loss_mask_0: 0.2001  loss_dice_0: 1.486  loss_ce_1: 0.6761  loss_mask_1: 0.1935  loss_dice_1: 1.422  loss_ce_2: 0.6204  loss_mask_2: 0.1849  loss_dice_2: 1.345  loss_ce_3: 0.5534  loss_mask_3: 0.1786  loss_dice_3: 1.3  loss_ce_4: 0.515  loss_mask_4: 0.178  loss_dice_4: 1.314  loss_ce_5: 0.5347  loss_mask_5: 0.1777  loss_dice_5: 1.288  loss_ce_6: 0.4948  loss_mask_6: 0.1779  loss_dice_6: 1.279  loss_ce_7: 0.5157  loss_mask_7: 0.1783  loss_dice_7: 1.277  loss_ce_8: 0.533  loss_mask_8: 0.1767  loss_dice_8: 1.242    time: 1.0700  last_time: 1.0650  data_time: 0.0735  last_data_time: 0.0817   lr: 0.0001  max_mem: 32458M
[10/09 21:19:34] d2.utils.events INFO:  eta: 0:36:54  iter: 919  total_loss: 20.5  loss_ce: 0.4821  loss_mask: 0.1649  loss_dice: 1.283  loss_ce_0: 0.5651  loss_mask_0: 0.1874  loss_dice_0: 1.523  loss_ce_1: 0.6534  loss_mask_1: 0.1762  loss_dice_1: 1.455  loss_ce_2: 0.5857  loss_mask_2: 0.1709  loss_dice_2: 1.372  loss_ce_3: 0.549  loss_mask_3: 0.167  loss_dice_3: 1.296  loss_ce_4: 0.5215  loss_mask_4: 0.1649  loss_dice_4: 1.304  loss_ce_5: 0.4924  loss_mask_5: 0.1662  loss_dice_5: 1.323  loss_ce_6: 0.4928  loss_mask_6: 0.1647  loss_dice_6: 1.311  loss_ce_7: 0.4974  loss_mask_7: 0.1632  loss_dice_7: 1.275  loss_ce_8: 0.5006  loss_mask_8: 0.1651  loss_dice_8: 1.293    time: 1.0701  last_time: 1.1255  data_time: 0.0781  last_data_time: 0.0854   lr: 0.0001  max_mem: 32458M
[10/09 21:19:55] d2.utils.events INFO:  eta: 0:36:33  iter: 939  total_loss: 19.87  loss_ce: 0.4835  loss_mask: 0.1691  loss_dice: 1.254  loss_ce_0: 0.5905  loss_mask_0: 0.1881  loss_dice_0: 1.447  loss_ce_1: 0.6511  loss_mask_1: 0.1775  loss_dice_1: 1.371  loss_ce_2: 0.5803  loss_mask_2: 0.1688  loss_dice_2: 1.307  loss_ce_3: 0.5637  loss_mask_3: 0.1692  loss_dice_3: 1.264  loss_ce_4: 0.5142  loss_mask_4: 0.1676  loss_dice_4: 1.233  loss_ce_5: 0.5192  loss_mask_5: 0.1673  loss_dice_5: 1.259  loss_ce_6: 0.5048  loss_mask_6: 0.1681  loss_dice_6: 1.241  loss_ce_7: 0.5127  loss_mask_7: 0.1671  loss_dice_7: 1.24  loss_ce_8: 0.519  loss_mask_8: 0.1658  loss_dice_8: 1.238    time: 1.0701  last_time: 1.0298  data_time: 0.0784  last_data_time: 0.0640   lr: 0.0001  max_mem: 32458M
[10/09 21:20:16] d2.utils.events INFO:  eta: 0:36:11  iter: 959  total_loss: 20.13  loss_ce: 0.5149  loss_mask: 0.1748  loss_dice: 1.169  loss_ce_0: 0.5798  loss_mask_0: 0.2041  loss_dice_0: 1.384  loss_ce_1: 0.6748  loss_mask_1: 0.1894  loss_dice_1: 1.314  loss_ce_2: 0.6464  loss_mask_2: 0.1744  loss_dice_2: 1.252  loss_ce_3: 0.5529  loss_mask_3: 0.1752  loss_dice_3: 1.235  loss_ce_4: 0.5602  loss_mask_4: 0.1727  loss_dice_4: 1.239  loss_ce_5: 0.5148  loss_mask_5: 0.172  loss_dice_5: 1.205  loss_ce_6: 0.5256  loss_mask_6: 0.1732  loss_dice_6: 1.176  loss_ce_7: 0.5234  loss_mask_7: 0.1749  loss_dice_7: 1.19  loss_ce_8: 0.535  loss_mask_8: 0.1741  loss_dice_8: 1.206    time: 1.0700  last_time: 1.0455  data_time: 0.0703  last_data_time: 0.0558   lr: 0.0001  max_mem: 32458M
[10/09 21:20:38] d2.utils.events INFO:  eta: 0:35:49  iter: 979  total_loss: 20.05  loss_ce: 0.4655  loss_mask: 0.1784  loss_dice: 1.241  loss_ce_0: 0.6054  loss_mask_0: 0.2098  loss_dice_0: 1.441  loss_ce_1: 0.6566  loss_mask_1: 0.1966  loss_dice_1: 1.369  loss_ce_2: 0.6236  loss_mask_2: 0.1841  loss_dice_2: 1.331  loss_ce_3: 0.5604  loss_mask_3: 0.1817  loss_dice_3: 1.251  loss_ce_4: 0.5047  loss_mask_4: 0.18  loss_dice_4: 1.241  loss_ce_5: 0.4912  loss_mask_5: 0.1792  loss_dice_5: 1.24  loss_ce_6: 0.4942  loss_mask_6: 0.1784  loss_dice_6: 1.203  loss_ce_7: 0.4868  loss_mask_7: 0.1796  loss_dice_7: 1.236  loss_ce_8: 0.5031  loss_mask_8: 0.1778  loss_dice_8: 1.195    time: 1.0698  last_time: 1.0450  data_time: 0.0747  last_data_time: 0.0580   lr: 0.0001  max_mem: 32458M
[10/09 21:20:59] d2.utils.events INFO:  eta: 0:35:29  iter: 999  total_loss: 20.81  loss_ce: 0.4889  loss_mask: 0.1707  loss_dice: 1.3  loss_ce_0: 0.5629  loss_mask_0: 0.2011  loss_dice_0: 1.52  loss_ce_1: 0.61  loss_mask_1: 0.1775  loss_dice_1: 1.452  loss_ce_2: 0.5625  loss_mask_2: 0.1731  loss_dice_2: 1.39  loss_ce_3: 0.5253  loss_mask_3: 0.1726  loss_dice_3: 1.322  loss_ce_4: 0.5084  loss_mask_4: 0.1724  loss_dice_4: 1.355  loss_ce_5: 0.4699  loss_mask_5: 0.1687  loss_dice_5: 1.288  loss_ce_6: 0.4779  loss_mask_6: 0.1734  loss_dice_6: 1.29  loss_ce_7: 0.4754  loss_mask_7: 0.1719  loss_dice_7: 1.287  loss_ce_8: 0.4597  loss_mask_8: 0.17  loss_dice_8: 1.338    time: 1.0700  last_time: 1.0258  data_time: 0.0736  last_data_time: 0.0692   lr: 0.0001  max_mem: 32479M
[10/09 21:21:21] d2.utils.events INFO:  eta: 0:35:08  iter: 1019  total_loss: 19.85  loss_ce: 0.4825  loss_mask: 0.1825  loss_dice: 1.206  loss_ce_0: 0.5646  loss_mask_0: 0.2082  loss_dice_0: 1.436  loss_ce_1: 0.657  loss_mask_1: 0.191  loss_dice_1: 1.375  loss_ce_2: 0.5701  loss_mask_2: 0.1873  loss_dice_2: 1.306  loss_ce_3: 0.5156  loss_mask_3: 0.1867  loss_dice_3: 1.242  loss_ce_4: 0.4995  loss_mask_4: 0.1829  loss_dice_4: 1.208  loss_ce_5: 0.4812  loss_mask_5: 0.182  loss_dice_5: 1.227  loss_ce_6: 0.5035  loss_mask_6: 0.1821  loss_dice_6: 1.199  loss_ce_7: 0.4924  loss_mask_7: 0.1773  loss_dice_7: 1.24  loss_ce_8: 0.4785  loss_mask_8: 0.1817  loss_dice_8: 1.223    time: 1.0699  last_time: 1.0575  data_time: 0.0710  last_data_time: 0.0995   lr: 0.0001  max_mem: 32479M
[10/09 21:21:42] d2.utils.events INFO:  eta: 0:34:47  iter: 1039  total_loss: 19.63  loss_ce: 0.497  loss_mask: 0.1726  loss_dice: 1.179  loss_ce_0: 0.5867  loss_mask_0: 0.2011  loss_dice_0: 1.442  loss_ce_1: 0.6582  loss_mask_1: 0.1861  loss_dice_1: 1.297  loss_ce_2: 0.5744  loss_mask_2: 0.1785  loss_dice_2: 1.3  loss_ce_3: 0.5237  loss_mask_3: 0.1793  loss_dice_3: 1.211  loss_ce_4: 0.5205  loss_mask_4: 0.1791  loss_dice_4: 1.24  loss_ce_5: 0.4827  loss_mask_5: 0.1747  loss_dice_5: 1.231  loss_ce_6: 0.4878  loss_mask_6: 0.1751  loss_dice_6: 1.24  loss_ce_7: 0.4835  loss_mask_7: 0.172  loss_dice_7: 1.237  loss_ce_8: 0.5211  loss_mask_8: 0.1719  loss_dice_8: 1.231    time: 1.0699  last_time: 1.1755  data_time: 0.0776  last_data_time: 0.0770   lr: 0.0001  max_mem: 32479M
[10/09 21:22:03] d2.utils.events INFO:  eta: 0:34:26  iter: 1059  total_loss: 19.42  loss_ce: 0.4537  loss_mask: 0.1787  loss_dice: 1.177  loss_ce_0: 0.5288  loss_mask_0: 0.199  loss_dice_0: 1.367  loss_ce_1: 0.6237  loss_mask_1: 0.1876  loss_dice_1: 1.29  loss_ce_2: 0.5299  loss_mask_2: 0.1794  loss_dice_2: 1.265  loss_ce_3: 0.4928  loss_mask_3: 0.1773  loss_dice_3: 1.181  loss_ce_4: 0.4969  loss_mask_4: 0.179  loss_dice_4: 1.195  loss_ce_5: 0.4748  loss_mask_5: 0.1794  loss_dice_5: 1.199  loss_ce_6: 0.4804  loss_mask_6: 0.1746  loss_dice_6: 1.141  loss_ce_7: 0.4548  loss_mask_7: 0.1775  loss_dice_7: 1.187  loss_ce_8: 0.4997  loss_mask_8: 0.178  loss_dice_8: 1.163    time: 1.0697  last_time: 1.0226  data_time: 0.0738  last_data_time: 0.0618   lr: 0.0001  max_mem: 32479M
[10/09 21:22:25] d2.utils.events INFO:  eta: 0:34:04  iter: 1079  total_loss: 19.48  loss_ce: 0.4884  loss_mask: 0.1758  loss_dice: 1.168  loss_ce_0: 0.5905  loss_mask_0: 0.1947  loss_dice_0: 1.388  loss_ce_1: 0.636  loss_mask_1: 0.1925  loss_dice_1: 1.346  loss_ce_2: 0.5729  loss_mask_2: 0.1824  loss_dice_2: 1.266  loss_ce_3: 0.5252  loss_mask_3: 0.1844  loss_dice_3: 1.192  loss_ce_4: 0.512  loss_mask_4: 0.1846  loss_dice_4: 1.211  loss_ce_5: 0.498  loss_mask_5: 0.1809  loss_dice_5: 1.176  loss_ce_6: 0.4843  loss_mask_6: 0.1811  loss_dice_6: 1.19  loss_ce_7: 0.4859  loss_mask_7: 0.1762  loss_dice_7: 1.22  loss_ce_8: 0.4847  loss_mask_8: 0.1752  loss_dice_8: 1.175    time: 1.0696  last_time: 1.0763  data_time: 0.0716  last_data_time: 0.0624   lr: 0.0001  max_mem: 32479M
[10/09 21:22:46] d2.utils.events INFO:  eta: 0:33:44  iter: 1099  total_loss: 19.41  loss_ce: 0.4624  loss_mask: 0.167  loss_dice: 1.178  loss_ce_0: 0.5695  loss_mask_0: 0.1956  loss_dice_0: 1.38  loss_ce_1: 0.6464  loss_mask_1: 0.1859  loss_dice_1: 1.319  loss_ce_2: 0.5511  loss_mask_2: 0.1751  loss_dice_2: 1.294  loss_ce_3: 0.504  loss_mask_3: 0.1768  loss_dice_3: 1.232  loss_ce_4: 0.481  loss_mask_4: 0.1736  loss_dice_4: 1.196  loss_ce_5: 0.4621  loss_mask_5: 0.1699  loss_dice_5: 1.199  loss_ce_6: 0.4719  loss_mask_6: 0.1694  loss_dice_6: 1.21  loss_ce_7: 0.4903  loss_mask_7: 0.1701  loss_dice_7: 1.19  loss_ce_8: 0.4425  loss_mask_8: 0.1672  loss_dice_8: 1.174    time: 1.0695  last_time: 1.1562  data_time: 0.0763  last_data_time: 0.0579   lr: 0.0001  max_mem: 32479M
[10/09 21:23:08] d2.utils.events INFO:  eta: 0:33:23  iter: 1119  total_loss: 20.19  loss_ce: 0.4907  loss_mask: 0.173  loss_dice: 1.268  loss_ce_0: 0.5584  loss_mask_0: 0.1937  loss_dice_0: 1.506  loss_ce_1: 0.6333  loss_mask_1: 0.1755  loss_dice_1: 1.399  loss_ce_2: 0.5971  loss_mask_2: 0.1724  loss_dice_2: 1.31  loss_ce_3: 0.5403  loss_mask_3: 0.1738  loss_dice_3: 1.304  loss_ce_4: 0.4941  loss_mask_4: 0.1752  loss_dice_4: 1.288  loss_ce_5: 0.4865  loss_mask_5: 0.171  loss_dice_5: 1.319  loss_ce_6: 0.4687  loss_mask_6: 0.1716  loss_dice_6: 1.263  loss_ce_7: 0.4603  loss_mask_7: 0.1727  loss_dice_7: 1.291  loss_ce_8: 0.4446  loss_mask_8: 0.1732  loss_dice_8: 1.252    time: 1.0695  last_time: 1.0365  data_time: 0.0781  last_data_time: 0.0709   lr: 0.0001  max_mem: 32479M
[10/09 21:23:29] d2.utils.events INFO:  eta: 0:33:03  iter: 1139  total_loss: 19.79  loss_ce: 0.4691  loss_mask: 0.1764  loss_dice: 1.254  loss_ce_0: 0.5453  loss_mask_0: 0.2083  loss_dice_0: 1.455  loss_ce_1: 0.6683  loss_mask_1: 0.2002  loss_dice_1: 1.362  loss_ce_2: 0.5828  loss_mask_2: 0.1813  loss_dice_2: 1.303  loss_ce_3: 0.5265  loss_mask_3: 0.1799  loss_dice_3: 1.245  loss_ce_4: 0.4998  loss_mask_4: 0.1791  loss_dice_4: 1.227  loss_ce_5: 0.5107  loss_mask_5: 0.1748  loss_dice_5: 1.258  loss_ce_6: 0.4983  loss_mask_6: 0.1746  loss_dice_6: 1.223  loss_ce_7: 0.4866  loss_mask_7: 0.1753  loss_dice_7: 1.22  loss_ce_8: 0.4995  loss_mask_8: 0.1709  loss_dice_8: 1.24    time: 1.0693  last_time: 1.0289  data_time: 0.0731  last_data_time: 0.0676   lr: 0.0001  max_mem: 32479M
[10/09 21:23:50] d2.utils.events INFO:  eta: 0:32:42  iter: 1159  total_loss: 18.83  loss_ce: 0.4645  loss_mask: 0.1662  loss_dice: 1.214  loss_ce_0: 0.5609  loss_mask_0: 0.1947  loss_dice_0: 1.353  loss_ce_1: 0.6167  loss_mask_1: 0.1805  loss_dice_1: 1.293  loss_ce_2: 0.5636  loss_mask_2: 0.1699  loss_dice_2: 1.24  loss_ce_3: 0.5129  loss_mask_3: 0.1711  loss_dice_3: 1.188  loss_ce_4: 0.4961  loss_mask_4: 0.1671  loss_dice_4: 1.187  loss_ce_5: 0.4948  loss_mask_5: 0.167  loss_dice_5: 1.172  loss_ce_6: 0.4614  loss_mask_6: 0.17  loss_dice_6: 1.177  loss_ce_7: 0.4497  loss_mask_7: 0.1673  loss_dice_7: 1.165  loss_ce_8: 0.457  loss_mask_8: 0.1696  loss_dice_8: 1.124    time: 1.0693  last_time: 1.0317  data_time: 0.0764  last_data_time: 0.0753   lr: 0.0001  max_mem: 32479M
[10/09 21:24:12] d2.utils.events INFO:  eta: 0:32:21  iter: 1179  total_loss: 19.84  loss_ce: 0.5001  loss_mask: 0.1549  loss_dice: 1.229  loss_ce_0: 0.6029  loss_mask_0: 0.1971  loss_dice_0: 1.506  loss_ce_1: 0.6185  loss_mask_1: 0.1808  loss_dice_1: 1.414  loss_ce_2: 0.5758  loss_mask_2: 0.1615  loss_dice_2: 1.305  loss_ce_3: 0.5378  loss_mask_3: 0.1606  loss_dice_3: 1.244  loss_ce_4: 0.5108  loss_mask_4: 0.162  loss_dice_4: 1.256  loss_ce_5: 0.4955  loss_mask_5: 0.156  loss_dice_5: 1.209  loss_ce_6: 0.4794  loss_mask_6: 0.1577  loss_dice_6: 1.24  loss_ce_7: 0.4947  loss_mask_7: 0.1543  loss_dice_7: 1.252  loss_ce_8: 0.4966  loss_mask_8: 0.1574  loss_dice_8: 1.222    time: 1.0694  last_time: 1.0391  data_time: 0.0776  last_data_time: 0.0622   lr: 0.0001  max_mem: 32479M
[10/09 21:24:34] d2.utils.events INFO:  eta: 0:32:00  iter: 1199  total_loss: 20.41  loss_ce: 0.5365  loss_mask: 0.1459  loss_dice: 1.243  loss_ce_0: 0.6084  loss_mask_0: 0.1744  loss_dice_0: 1.504  loss_ce_1: 0.6548  loss_mask_1: 0.1583  loss_dice_1: 1.401  loss_ce_2: 0.612  loss_mask_2: 0.1512  loss_dice_2: 1.341  loss_ce_3: 0.5911  loss_mask_3: 0.1509  loss_dice_3: 1.264  loss_ce_4: 0.5548  loss_mask_4: 0.1487  loss_dice_4: 1.26  loss_ce_5: 0.5256  loss_mask_5: 0.146  loss_dice_5: 1.272  loss_ce_6: 0.5035  loss_mask_6: 0.1466  loss_dice_6: 1.246  loss_ce_7: 0.528  loss_mask_7: 0.1455  loss_dice_7: 1.252  loss_ce_8: 0.5291  loss_mask_8: 0.1458  loss_dice_8: 1.244    time: 1.0697  last_time: 1.1000  data_time: 0.0798  last_data_time: 0.0752   lr: 0.0001  max_mem: 32479M
[10/09 21:24:55] d2.utils.events INFO:  eta: 0:31:39  iter: 1219  total_loss: 19.21  loss_ce: 0.4697  loss_mask: 0.1789  loss_dice: 1.154  loss_ce_0: 0.5549  loss_mask_0: 0.2219  loss_dice_0: 1.376  loss_ce_1: 0.6023  loss_mask_1: 0.1896  loss_dice_1: 1.256  loss_ce_2: 0.5503  loss_mask_2: 0.1839  loss_dice_2: 1.218  loss_ce_3: 0.5228  loss_mask_3: 0.1872  loss_dice_3: 1.18  loss_ce_4: 0.4967  loss_mask_4: 0.1815  loss_dice_4: 1.158  loss_ce_5: 0.4894  loss_mask_5: 0.1792  loss_dice_5: 1.197  loss_ce_6: 0.5255  loss_mask_6: 0.179  loss_dice_6: 1.166  loss_ce_7: 0.4859  loss_mask_7: 0.1782  loss_dice_7: 1.173  loss_ce_8: 0.4957  loss_mask_8: 0.179  loss_dice_8: 1.177    time: 1.0695  last_time: 1.0354  data_time: 0.0772  last_data_time: 0.0746   lr: 0.0001  max_mem: 32479M
[10/09 21:25:16] d2.utils.events INFO:  eta: 0:31:16  iter: 1239  total_loss: 19.09  loss_ce: 0.4468  loss_mask: 0.1738  loss_dice: 1.107  loss_ce_0: 0.5711  loss_mask_0: 0.2029  loss_dice_0: 1.316  loss_ce_1: 0.601  loss_mask_1: 0.18  loss_dice_1: 1.255  loss_ce_2: 0.5589  loss_mask_2: 0.1764  loss_dice_2: 1.167  loss_ce_3: 0.5035  loss_mask_3: 0.1729  loss_dice_3: 1.141  loss_ce_4: 0.482  loss_mask_4: 0.172  loss_dice_4: 1.139  loss_ce_5: 0.4586  loss_mask_5: 0.1713  loss_dice_5: 1.127  loss_ce_6: 0.4706  loss_mask_6: 0.1726  loss_dice_6: 1.096  loss_ce_7: 0.475  loss_mask_7: 0.1716  loss_dice_7: 1.09  loss_ce_8: 0.4632  loss_mask_8: 0.1728  loss_dice_8: 1.097    time: 1.0691  last_time: 1.0327  data_time: 0.0677  last_data_time: 0.0547   lr: 0.0001  max_mem: 32479M
[10/09 21:25:37] d2.utils.events INFO:  eta: 0:30:55  iter: 1259  total_loss: 20.18  loss_ce: 0.5552  loss_mask: 0.1676  loss_dice: 1.2  loss_ce_0: 0.6178  loss_mask_0: 0.1963  loss_dice_0: 1.456  loss_ce_1: 0.6884  loss_mask_1: 0.1793  loss_dice_1: 1.361  loss_ce_2: 0.6399  loss_mask_2: 0.174  loss_dice_2: 1.291  loss_ce_3: 0.5671  loss_mask_3: 0.172  loss_dice_3: 1.253  loss_ce_4: 0.5343  loss_mask_4: 0.1708  loss_dice_4: 1.249  loss_ce_5: 0.5477  loss_mask_5: 0.1684  loss_dice_5: 1.228  loss_ce_6: 0.5185  loss_mask_6: 0.1698  loss_dice_6: 1.237  loss_ce_7: 0.5329  loss_mask_7: 0.1703  loss_dice_7: 1.233  loss_ce_8: 0.5227  loss_mask_8: 0.1683  loss_dice_8: 1.225    time: 1.0691  last_time: 1.1134  data_time: 0.0717  last_data_time: 0.0598   lr: 0.0001  max_mem: 32479M
[10/09 21:25:59] d2.utils.events INFO:  eta: 0:30:34  iter: 1279  total_loss: 19.75  loss_ce: 0.5359  loss_mask: 0.1702  loss_dice: 1.197  loss_ce_0: 0.5772  loss_mask_0: 0.1972  loss_dice_0: 1.435  loss_ce_1: 0.6359  loss_mask_1: 0.1822  loss_dice_1: 1.35  loss_ce_2: 0.6034  loss_mask_2: 0.1727  loss_dice_2: 1.255  loss_ce_3: 0.533  loss_mask_3: 0.175  loss_dice_3: 1.233  loss_ce_4: 0.5043  loss_mask_4: 0.1693  loss_dice_4: 1.2  loss_ce_5: 0.5447  loss_mask_5: 0.1698  loss_dice_5: 1.208  loss_ce_6: 0.4981  loss_mask_6: 0.1724  loss_dice_6: 1.178  loss_ce_7: 0.4926  loss_mask_7: 0.1722  loss_dice_7: 1.209  loss_ce_8: 0.4871  loss_mask_8: 0.1691  loss_dice_8: 1.237    time: 1.0692  last_time: 1.1889  data_time: 0.0775  last_data_time: 0.0958   lr: 0.0001  max_mem: 32479M
[10/09 21:26:20] d2.utils.events INFO:  eta: 0:30:13  iter: 1299  total_loss: 19.38  loss_ce: 0.4547  loss_mask: 0.1607  loss_dice: 1.229  loss_ce_0: 0.5357  loss_mask_0: 0.188  loss_dice_0: 1.41  loss_ce_1: 0.6053  loss_mask_1: 0.1667  loss_dice_1: 1.361  loss_ce_2: 0.5385  loss_mask_2: 0.1633  loss_dice_2: 1.301  loss_ce_3: 0.5088  loss_mask_3: 0.1643  loss_dice_3: 1.248  loss_ce_4: 0.487  loss_mask_4: 0.162  loss_dice_4: 1.288  loss_ce_5: 0.4661  loss_mask_5: 0.1609  loss_dice_5: 1.251  loss_ce_6: 0.4988  loss_mask_6: 0.1616  loss_dice_6: 1.231  loss_ce_7: 0.4858  loss_mask_7: 0.1601  loss_dice_7: 1.233  loss_ce_8: 0.4514  loss_mask_8: 0.1617  loss_dice_8: 1.219    time: 1.0692  last_time: 1.1213  data_time: 0.0807  last_data_time: 0.0620   lr: 0.0001  max_mem: 32479M
[10/09 21:26:42] d2.utils.events INFO:  eta: 0:29:52  iter: 1319  total_loss: 19.08  loss_ce: 0.4657  loss_mask: 0.1747  loss_dice: 1.17  loss_ce_0: 0.5283  loss_mask_0: 0.1911  loss_dice_0: 1.376  loss_ce_1: 0.599  loss_mask_1: 0.1796  loss_dice_1: 1.308  loss_ce_2: 0.5523  loss_mask_2: 0.1742  loss_dice_2: 1.276  loss_ce_3: 0.5193  loss_mask_3: 0.1763  loss_dice_3: 1.17  loss_ce_4: 0.5137  loss_mask_4: 0.175  loss_dice_4: 1.193  loss_ce_5: 0.4969  loss_mask_5: 0.175  loss_dice_5: 1.188  loss_ce_6: 0.4875  loss_mask_6: 0.1746  loss_dice_6: 1.176  loss_ce_7: 0.4693  loss_mask_7: 0.1734  loss_dice_7: 1.175  loss_ce_8: 0.5014  loss_mask_8: 0.1733  loss_dice_8: 1.194    time: 1.0691  last_time: 1.0529  data_time: 0.0778  last_data_time: 0.0780   lr: 0.0001  max_mem: 32479M
[10/09 21:27:03] d2.utils.events INFO:  eta: 0:29:30  iter: 1339  total_loss: 21.17  loss_ce: 0.514  loss_mask: 0.1784  loss_dice: 1.347  loss_ce_0: 0.6202  loss_mask_0: 0.2086  loss_dice_0: 1.511  loss_ce_1: 0.6345  loss_mask_1: 0.1909  loss_dice_1: 1.472  loss_ce_2: 0.5736  loss_mask_2: 0.1814  loss_dice_2: 1.407  loss_ce_3: 0.545  loss_mask_3: 0.1783  loss_dice_3: 1.346  loss_ce_4: 0.5057  loss_mask_4: 0.18  loss_dice_4: 1.351  loss_ce_5: 0.5085  loss_mask_5: 0.177  loss_dice_5: 1.315  loss_ce_6: 0.5438  loss_mask_6: 0.1792  loss_dice_6: 1.358  loss_ce_7: 0.5219  loss_mask_7: 0.1759  loss_dice_7: 1.31  loss_ce_8: 0.5128  loss_mask_8: 0.1751  loss_dice_8: 1.334    time: 1.0691  last_time: 1.0423  data_time: 0.0806  last_data_time: 0.0865   lr: 0.0001  max_mem: 32479M
[10/09 21:27:25] d2.utils.events INFO:  eta: 0:29:09  iter: 1359  total_loss: 20.43  loss_ce: 0.4851  loss_mask: 0.1619  loss_dice: 1.214  loss_ce_0: 0.6122  loss_mask_0: 0.1807  loss_dice_0: 1.454  loss_ce_1: 0.6212  loss_mask_1: 0.1762  loss_dice_1: 1.399  loss_ce_2: 0.601  loss_mask_2: 0.1675  loss_dice_2: 1.363  loss_ce_3: 0.5451  loss_mask_3: 0.1623  loss_dice_3: 1.263  loss_ce_4: 0.5041  loss_mask_4: 0.1641  loss_dice_4: 1.284  loss_ce_5: 0.537  loss_mask_5: 0.1622  loss_dice_5: 1.264  loss_ce_6: 0.5028  loss_mask_6: 0.1613  loss_dice_6: 1.227  loss_ce_7: 0.497  loss_mask_7: 0.1642  loss_dice_7: 1.251  loss_ce_8: 0.4642  loss_mask_8: 0.1619  loss_dice_8: 1.23    time: 1.0692  last_time: 1.0678  data_time: 0.0753  last_data_time: 0.0532   lr: 0.0001  max_mem: 32479M
[10/09 21:27:46] d2.utils.events INFO:  eta: 0:28:49  iter: 1379  total_loss: 19.41  loss_ce: 0.4481  loss_mask: 0.1881  loss_dice: 1.153  loss_ce_0: 0.5763  loss_mask_0: 0.2099  loss_dice_0: 1.412  loss_ce_1: 0.6194  loss_mask_1: 0.194  loss_dice_1: 1.342  loss_ce_2: 0.5714  loss_mask_2: 0.1909  loss_dice_2: 1.275  loss_ce_3: 0.5096  loss_mask_3: 0.19  loss_dice_3: 1.21  loss_ce_4: 0.495  loss_mask_4: 0.1885  loss_dice_4: 1.188  loss_ce_5: 0.4856  loss_mask_5: 0.1871  loss_dice_5: 1.229  loss_ce_6: 0.4576  loss_mask_6: 0.1863  loss_dice_6: 1.203  loss_ce_7: 0.4746  loss_mask_7: 0.1862  loss_dice_7: 1.173  loss_ce_8: 0.463  loss_mask_8: 0.1893  loss_dice_8: 1.198    time: 1.0692  last_time: 1.0476  data_time: 0.0796  last_data_time: 0.0792   lr: 0.0001  max_mem: 32479M
[10/09 21:28:08] d2.utils.events INFO:  eta: 0:28:28  iter: 1399  total_loss: 19.91  loss_ce: 0.5117  loss_mask: 0.1579  loss_dice: 1.19  loss_ce_0: 0.6032  loss_mask_0: 0.1792  loss_dice_0: 1.446  loss_ce_1: 0.6193  loss_mask_1: 0.1668  loss_dice_1: 1.375  loss_ce_2: 0.5744  loss_mask_2: 0.1622  loss_dice_2: 1.289  loss_ce_3: 0.512  loss_mask_3: 0.1629  loss_dice_3: 1.25  loss_ce_4: 0.4935  loss_mask_4: 0.159  loss_dice_4: 1.276  loss_ce_5: 0.5238  loss_mask_5: 0.1572  loss_dice_5: 1.266  loss_ce_6: 0.5269  loss_mask_6: 0.1578  loss_dice_6: 1.223  loss_ce_7: 0.499  loss_mask_7: 0.1577  loss_dice_7: 1.239  loss_ce_8: 0.4787  loss_mask_8: 0.1592  loss_dice_8: 1.26    time: 1.0693  last_time: 1.0359  data_time: 0.0818  last_data_time: 0.0540   lr: 0.0001  max_mem: 32479M
[10/09 21:28:29] d2.utils.events INFO:  eta: 0:28:06  iter: 1419  total_loss: 19.95  loss_ce: 0.4994  loss_mask: 0.1487  loss_dice: 1.22  loss_ce_0: 0.5854  loss_mask_0: 0.1733  loss_dice_0: 1.421  loss_ce_1: 0.6231  loss_mask_1: 0.1584  loss_dice_1: 1.373  loss_ce_2: 0.6016  loss_mask_2: 0.154  loss_dice_2: 1.296  loss_ce_3: 0.5556  loss_mask_3: 0.1513  loss_dice_3: 1.26  loss_ce_4: 0.5203  loss_mask_4: 0.1509  loss_dice_4: 1.255  loss_ce_5: 0.5146  loss_mask_5: 0.15  loss_dice_5: 1.278  loss_ce_6: 0.5138  loss_mask_6: 0.1487  loss_dice_6: 1.282  loss_ce_7: 0.5007  loss_mask_7: 0.1491  loss_dice_7: 1.232  loss_ce_8: 0.498  loss_mask_8: 0.1505  loss_dice_8: 1.22    time: 1.0693  last_time: 1.1386  data_time: 0.0777  last_data_time: 0.0942   lr: 0.0001  max_mem: 32479M
[10/09 21:28:50] d2.utils.events INFO:  eta: 0:27:45  iter: 1439  total_loss: 19.12  loss_ce: 0.4633  loss_mask: 0.1669  loss_dice: 1.203  loss_ce_0: 0.5409  loss_mask_0: 0.1985  loss_dice_0: 1.471  loss_ce_1: 0.5833  loss_mask_1: 0.1839  loss_dice_1: 1.351  loss_ce_2: 0.5352  loss_mask_2: 0.1755  loss_dice_2: 1.295  loss_ce_3: 0.5063  loss_mask_3: 0.1686  loss_dice_3: 1.271  loss_ce_4: 0.4959  loss_mask_4: 0.1748  loss_dice_4: 1.25  loss_ce_5: 0.4622  loss_mask_5: 0.1705  loss_dice_5: 1.251  loss_ce_6: 0.468  loss_mask_6: 0.1688  loss_dice_6: 1.199  loss_ce_7: 0.4685  loss_mask_7: 0.1712  loss_dice_7: 1.184  loss_ce_8: 0.4619  loss_mask_8: 0.168  loss_dice_8: 1.189    time: 1.0693  last_time: 1.0951  data_time: 0.0767  last_data_time: 0.0846   lr: 0.0001  max_mem: 32479M
[10/09 21:29:12] d2.utils.events INFO:  eta: 0:27:24  iter: 1459  total_loss: 18.86  loss_ce: 0.4365  loss_mask: 0.1729  loss_dice: 1.181  loss_ce_0: 0.5618  loss_mask_0: 0.2054  loss_dice_0: 1.373  loss_ce_1: 0.6041  loss_mask_1: 0.1941  loss_dice_1: 1.296  loss_ce_2: 0.5511  loss_mask_2: 0.1768  loss_dice_2: 1.263  loss_ce_3: 0.4607  loss_mask_3: 0.1753  loss_dice_3: 1.228  loss_ce_4: 0.4348  loss_mask_4: 0.1766  loss_dice_4: 1.198  loss_ce_5: 0.4446  loss_mask_5: 0.1745  loss_dice_5: 1.215  loss_ce_6: 0.4447  loss_mask_6: 0.1735  loss_dice_6: 1.186  loss_ce_7: 0.4364  loss_mask_7: 0.1757  loss_dice_7: 1.169  loss_ce_8: 0.4386  loss_mask_8: 0.1761  loss_dice_8: 1.169    time: 1.0692  last_time: 1.0530  data_time: 0.0737  last_data_time: 0.0768   lr: 0.0001  max_mem: 32479M
[10/09 21:29:33] d2.utils.events INFO:  eta: 0:27:02  iter: 1479  total_loss: 19.87  loss_ce: 0.4657  loss_mask: 0.1685  loss_dice: 1.186  loss_ce_0: 0.5818  loss_mask_0: 0.1961  loss_dice_0: 1.445  loss_ce_1: 0.6124  loss_mask_1: 0.1831  loss_dice_1: 1.346  loss_ce_2: 0.5923  loss_mask_2: 0.1712  loss_dice_2: 1.272  loss_ce_3: 0.527  loss_mask_3: 0.1713  loss_dice_3: 1.243  loss_ce_4: 0.4939  loss_mask_4: 0.1722  loss_dice_4: 1.249  loss_ce_5: 0.5102  loss_mask_5: 0.169  loss_dice_5: 1.258  loss_ce_6: 0.4728  loss_mask_6: 0.1695  loss_dice_6: 1.218  loss_ce_7: 0.492  loss_mask_7: 0.1695  loss_dice_7: 1.223  loss_ce_8: 0.4534  loss_mask_8: 0.1687  loss_dice_8: 1.217    time: 1.0693  last_time: 1.0945  data_time: 0.0777  last_data_time: 0.0862   lr: 0.0001  max_mem: 32479M
[10/09 21:29:55] d2.utils.events INFO:  eta: 0:26:41  iter: 1499  total_loss: 19.78  loss_ce: 0.466  loss_mask: 0.1585  loss_dice: 1.218  loss_ce_0: 0.5906  loss_mask_0: 0.1843  loss_dice_0: 1.43  loss_ce_1: 0.621  loss_mask_1: 0.1751  loss_dice_1: 1.324  loss_ce_2: 0.5523  loss_mask_2: 0.1683  loss_dice_2: 1.315  loss_ce_3: 0.4856  loss_mask_3: 0.1677  loss_dice_3: 1.281  loss_ce_4: 0.4946  loss_mask_4: 0.1679  loss_dice_4: 1.21  loss_ce_5: 0.4655  loss_mask_5: 0.1636  loss_dice_5: 1.221  loss_ce_6: 0.4556  loss_mask_6: 0.1592  loss_dice_6: 1.217  loss_ce_7: 0.4379  loss_mask_7: 0.1601  loss_dice_7: 1.205  loss_ce_8: 0.4491  loss_mask_8: 0.1588  loss_dice_8: 1.224    time: 1.0694  last_time: 1.0562  data_time: 0.0842  last_data_time: 0.0750   lr: 0.0001  max_mem: 32479M
[10/09 21:30:16] d2.utils.events INFO:  eta: 0:26:19  iter: 1519  total_loss: 17.56  loss_ce: 0.4497  loss_mask: 0.1502  loss_dice: 1.101  loss_ce_0: 0.5389  loss_mask_0: 0.1835  loss_dice_0: 1.311  loss_ce_1: 0.609  loss_mask_1: 0.1644  loss_dice_1: 1.209  loss_ce_2: 0.5238  loss_mask_2: 0.1578  loss_dice_2: 1.168  loss_ce_3: 0.4956  loss_mask_3: 0.1567  loss_dice_3: 1.118  loss_ce_4: 0.4328  loss_mask_4: 0.1579  loss_dice_4: 1.117  loss_ce_5: 0.453  loss_mask_5: 0.157  loss_dice_5: 1.122  loss_ce_6: 0.4607  loss_mask_6: 0.1526  loss_dice_6: 1.041  loss_ce_7: 0.4409  loss_mask_7: 0.1558  loss_dice_7: 1.066  loss_ce_8: 0.4807  loss_mask_8: 0.1531  loss_dice_8: 1.108    time: 1.0692  last_time: 1.0724  data_time: 0.0723  last_data_time: 0.0608   lr: 0.0001  max_mem: 32479M
[10/09 21:30:38] d2.utils.events INFO:  eta: 0:25:58  iter: 1539  total_loss: 19.44  loss_ce: 0.4263  loss_mask: 0.1608  loss_dice: 1.245  loss_ce_0: 0.5745  loss_mask_0: 0.1939  loss_dice_0: 1.43  loss_ce_1: 0.5645  loss_mask_1: 0.1744  loss_dice_1: 1.338  loss_ce_2: 0.5481  loss_mask_2: 0.1653  loss_dice_2: 1.303  loss_ce_3: 0.4823  loss_mask_3: 0.1606  loss_dice_3: 1.257  loss_ce_4: 0.4775  loss_mask_4: 0.1646  loss_dice_4: 1.253  loss_ce_5: 0.4784  loss_mask_5: 0.1652  loss_dice_5: 1.263  loss_ce_6: 0.4306  loss_mask_6: 0.1628  loss_dice_6: 1.239  loss_ce_7: 0.4397  loss_mask_7: 0.1618  loss_dice_7: 1.199  loss_ce_8: 0.4372  loss_mask_8: 0.1627  loss_dice_8: 1.221    time: 1.0694  last_time: 1.0920  data_time: 0.0840  last_data_time: 0.0782   lr: 0.0001  max_mem: 32479M
[10/09 21:31:00] d2.utils.events INFO:  eta: 0:25:37  iter: 1559  total_loss: 20.66  loss_ce: 0.4849  loss_mask: 0.1608  loss_dice: 1.267  loss_ce_0: 0.6337  loss_mask_0: 0.187  loss_dice_0: 1.491  loss_ce_1: 0.6691  loss_mask_1: 0.1703  loss_dice_1: 1.432  loss_ce_2: 0.6066  loss_mask_2: 0.1722  loss_dice_2: 1.363  loss_ce_3: 0.5442  loss_mask_3: 0.1655  loss_dice_3: 1.369  loss_ce_4: 0.5304  loss_mask_4: 0.1641  loss_dice_4: 1.291  loss_ce_5: 0.5229  loss_mask_5: 0.162  loss_dice_5: 1.31  loss_ce_6: 0.5148  loss_mask_6: 0.163  loss_dice_6: 1.303  loss_ce_7: 0.4715  loss_mask_7: 0.1618  loss_dice_7: 1.295  loss_ce_8: 0.5091  loss_mask_8: 0.1607  loss_dice_8: 1.264    time: 1.0697  last_time: 1.0783  data_time: 0.0839  last_data_time: 0.0781   lr: 0.0001  max_mem: 32985M
[10/09 21:31:21] d2.utils.events INFO:  eta: 0:25:16  iter: 1579  total_loss: 18.07  loss_ce: 0.3812  loss_mask: 0.1619  loss_dice: 1.125  loss_ce_0: 0.5685  loss_mask_0: 0.1868  loss_dice_0: 1.315  loss_ce_1: 0.5715  loss_mask_1: 0.1763  loss_dice_1: 1.257  loss_ce_2: 0.5167  loss_mask_2: 0.169  loss_dice_2: 1.188  loss_ce_3: 0.4516  loss_mask_3: 0.1694  loss_dice_3: 1.155  loss_ce_4: 0.4605  loss_mask_4: 0.1628  loss_dice_4: 1.13  loss_ce_5: 0.4383  loss_mask_5: 0.1612  loss_dice_5: 1.141  loss_ce_6: 0.4142  loss_mask_6: 0.1583  loss_dice_6: 1.13  loss_ce_7: 0.4148  loss_mask_7: 0.1617  loss_dice_7: 1.137  loss_ce_8: 0.4056  loss_mask_8: 0.1601  loss_dice_8: 1.131    time: 1.0697  last_time: 1.0541  data_time: 0.0771  last_data_time: 0.0859   lr: 0.0001  max_mem: 32985M
[10/09 21:31:43] d2.utils.events INFO:  eta: 0:24:54  iter: 1599  total_loss: 19.49  loss_ce: 0.4685  loss_mask: 0.1581  loss_dice: 1.214  loss_ce_0: 0.5875  loss_mask_0: 0.1831  loss_dice_0: 1.391  loss_ce_1: 0.6168  loss_mask_1: 0.1723  loss_dice_1: 1.362  loss_ce_2: 0.5619  loss_mask_2: 0.1685  loss_dice_2: 1.285  loss_ce_3: 0.4902  loss_mask_3: 0.1621  loss_dice_3: 1.226  loss_ce_4: 0.4584  loss_mask_4: 0.1594  loss_dice_4: 1.231  loss_ce_5: 0.4755  loss_mask_5: 0.1587  loss_dice_5: 1.24  loss_ce_6: 0.487  loss_mask_6: 0.1586  loss_dice_6: 1.228  loss_ce_7: 0.4642  loss_mask_7: 0.1576  loss_dice_7: 1.219  loss_ce_8: 0.4826  loss_mask_8: 0.1562  loss_dice_8: 1.205    time: 1.0699  last_time: 1.0648  data_time: 0.0808  last_data_time: 0.0777   lr: 0.0001  max_mem: 32985M
[10/09 21:32:05] d2.utils.events INFO:  eta: 0:24:33  iter: 1619  total_loss: 19.53  loss_ce: 0.4356  loss_mask: 0.1555  loss_dice: 1.211  loss_ce_0: 0.5558  loss_mask_0: 0.1865  loss_dice_0: 1.398  loss_ce_1: 0.5912  loss_mask_1: 0.1735  loss_dice_1: 1.317  loss_ce_2: 0.5398  loss_mask_2: 0.1664  loss_dice_2: 1.276  loss_ce_3: 0.5124  loss_mask_3: 0.1636  loss_dice_3: 1.264  loss_ce_4: 0.4919  loss_mask_4: 0.1585  loss_dice_4: 1.215  loss_ce_5: 0.4851  loss_mask_5: 0.1567  loss_dice_5: 1.199  loss_ce_6: 0.4582  loss_mask_6: 0.156  loss_dice_6: 1.216  loss_ce_7: 0.4608  loss_mask_7: 0.1547  loss_dice_7: 1.201  loss_ce_8: 0.4565  loss_mask_8: 0.1541  loss_dice_8: 1.181    time: 1.0700  last_time: 1.0657  data_time: 0.0829  last_data_time: 0.0823   lr: 0.0001  max_mem: 32985M
[10/09 21:32:26] d2.utils.events INFO:  eta: 0:24:11  iter: 1639  total_loss: 19.59  loss_ce: 0.4447  loss_mask: 0.1658  loss_dice: 1.206  loss_ce_0: 0.5621  loss_mask_0: 0.1907  loss_dice_0: 1.399  loss_ce_1: 0.576  loss_mask_1: 0.1793  loss_dice_1: 1.359  loss_ce_2: 0.525  loss_mask_2: 0.1705  loss_dice_2: 1.29  loss_ce_3: 0.4785  loss_mask_3: 0.1674  loss_dice_3: 1.257  loss_ce_4: 0.4654  loss_mask_4: 0.1691  loss_dice_4: 1.248  loss_ce_5: 0.4731  loss_mask_5: 0.1681  loss_dice_5: 1.239  loss_ce_6: 0.4544  loss_mask_6: 0.1697  loss_dice_6: 1.219  loss_ce_7: 0.4608  loss_mask_7: 0.1661  loss_dice_7: 1.231  loss_ce_8: 0.4316  loss_mask_8: 0.1664  loss_dice_8: 1.264    time: 1.0702  last_time: 1.2103  data_time: 0.0780  last_data_time: 0.1037   lr: 0.0001  max_mem: 32985M
[10/09 21:32:48] d2.utils.events INFO:  eta: 0:23:50  iter: 1659  total_loss: 19.78  loss_ce: 0.4693  loss_mask: 0.1719  loss_dice: 1.225  loss_ce_0: 0.5704  loss_mask_0: 0.2034  loss_dice_0: 1.449  loss_ce_1: 0.6072  loss_mask_1: 0.1884  loss_dice_1: 1.372  loss_ce_2: 0.5369  loss_mask_2: 0.1834  loss_dice_2: 1.323  loss_ce_3: 0.5195  loss_mask_3: 0.18  loss_dice_3: 1.256  loss_ce_4: 0.5272  loss_mask_4: 0.1783  loss_dice_4: 1.274  loss_ce_5: 0.5009  loss_mask_5: 0.1778  loss_dice_5: 1.278  loss_ce_6: 0.473  loss_mask_6: 0.1737  loss_dice_6: 1.221  loss_ce_7: 0.4757  loss_mask_7: 0.1724  loss_dice_7: 1.225  loss_ce_8: 0.4616  loss_mask_8: 0.1729  loss_dice_8: 1.22    time: 1.0704  last_time: 1.0771  data_time: 0.0790  last_data_time: 0.0675   lr: 0.0001  max_mem: 32985M
[10/09 21:33:10] d2.utils.events INFO:  eta: 0:23:29  iter: 1679  total_loss: 18.91  loss_ce: 0.4351  loss_mask: 0.167  loss_dice: 1.165  loss_ce_0: 0.5459  loss_mask_0: 0.1993  loss_dice_0: 1.385  loss_ce_1: 0.5871  loss_mask_1: 0.1769  loss_dice_1: 1.309  loss_ce_2: 0.5315  loss_mask_2: 0.1696  loss_dice_2: 1.269  loss_ce_3: 0.4919  loss_mask_3: 0.1675  loss_dice_3: 1.172  loss_ce_4: 0.4791  loss_mask_4: 0.166  loss_dice_4: 1.218  loss_ce_5: 0.4658  loss_mask_5: 0.1694  loss_dice_5: 1.196  loss_ce_6: 0.4688  loss_mask_6: 0.1653  loss_dice_6: 1.188  loss_ce_7: 0.446  loss_mask_7: 0.1673  loss_dice_7: 1.187  loss_ce_8: 0.4461  loss_mask_8: 0.1644  loss_dice_8: 1.181    time: 1.0704  last_time: 1.0535  data_time: 0.0772  last_data_time: 0.0727   lr: 0.0001  max_mem: 32985M
[10/09 21:33:32] d2.utils.events INFO:  eta: 0:23:09  iter: 1699  total_loss: 20.02  loss_ce: 0.4609  loss_mask: 0.1633  loss_dice: 1.281  loss_ce_0: 0.5421  loss_mask_0: 0.1876  loss_dice_0: 1.446  loss_ce_1: 0.6093  loss_mask_1: 0.1737  loss_dice_1: 1.408  loss_ce_2: 0.5649  loss_mask_2: 0.1654  loss_dice_2: 1.334  loss_ce_3: 0.4862  loss_mask_3: 0.1653  loss_dice_3: 1.316  loss_ce_4: 0.5037  loss_mask_4: 0.1629  loss_dice_4: 1.292  loss_ce_5: 0.4906  loss_mask_5: 0.1629  loss_dice_5: 1.265  loss_ce_6: 0.4572  loss_mask_6: 0.1622  loss_dice_6: 1.262  loss_ce_7: 0.4679  loss_mask_7: 0.1629  loss_dice_7: 1.264  loss_ce_8: 0.4722  loss_mask_8: 0.1633  loss_dice_8: 1.282    time: 1.0708  last_time: 1.0950  data_time: 0.0816  last_data_time: 0.0741   lr: 0.0001  max_mem: 32985M
[10/09 21:33:53] d2.utils.events INFO:  eta: 0:22:47  iter: 1719  total_loss: 18.8  loss_ce: 0.4458  loss_mask: 0.1634  loss_dice: 1.124  loss_ce_0: 0.5311  loss_mask_0: 0.1934  loss_dice_0: 1.393  loss_ce_1: 0.5945  loss_mask_1: 0.1817  loss_dice_1: 1.295  loss_ce_2: 0.555  loss_mask_2: 0.1722  loss_dice_2: 1.232  loss_ce_3: 0.4636  loss_mask_3: 0.1708  loss_dice_3: 1.193  loss_ce_4: 0.4857  loss_mask_4: 0.1615  loss_dice_4: 1.202  loss_ce_5: 0.4683  loss_mask_5: 0.1618  loss_dice_5: 1.187  loss_ce_6: 0.4472  loss_mask_6: 0.1635  loss_dice_6: 1.156  loss_ce_7: 0.4217  loss_mask_7: 0.1651  loss_dice_7: 1.162  loss_ce_8: 0.4345  loss_mask_8: 0.1626  loss_dice_8: 1.145    time: 1.0707  last_time: 1.0697  data_time: 0.0754  last_data_time: 0.0741   lr: 0.0001  max_mem: 32985M
[10/09 21:34:15] d2.utils.events INFO:  eta: 0:22:26  iter: 1739  total_loss: 18.67  loss_ce: 0.4341  loss_mask: 0.1729  loss_dice: 1.169  loss_ce_0: 0.5624  loss_mask_0: 0.2036  loss_dice_0: 1.414  loss_ce_1: 0.6143  loss_mask_1: 0.1896  loss_dice_1: 1.319  loss_ce_2: 0.5225  loss_mask_2: 0.1805  loss_dice_2: 1.261  loss_ce_3: 0.4701  loss_mask_3: 0.1816  loss_dice_3: 1.204  loss_ce_4: 0.448  loss_mask_4: 0.1811  loss_dice_4: 1.19  loss_ce_5: 0.428  loss_mask_5: 0.1747  loss_dice_5: 1.182  loss_ce_6: 0.4313  loss_mask_6: 0.1738  loss_dice_6: 1.183  loss_ce_7: 0.439  loss_mask_7: 0.176  loss_dice_7: 1.155  loss_ce_8: 0.435  loss_mask_8: 0.1738  loss_dice_8: 1.178    time: 1.0707  last_time: 1.0370  data_time: 0.0760  last_data_time: 0.0638   lr: 0.0001  max_mem: 32985M
[10/09 21:34:36] d2.utils.events INFO:  eta: 0:22:04  iter: 1759  total_loss: 18.95  loss_ce: 0.4553  loss_mask: 0.1683  loss_dice: 1.24  loss_ce_0: 0.5548  loss_mask_0: 0.205  loss_dice_0: 1.409  loss_ce_1: 0.5918  loss_mask_1: 0.1856  loss_dice_1: 1.328  loss_ce_2: 0.5266  loss_mask_2: 0.1754  loss_dice_2: 1.22  loss_ce_3: 0.4939  loss_mask_3: 0.1757  loss_dice_3: 1.233  loss_ce_4: 0.4219  loss_mask_4: 0.1711  loss_dice_4: 1.234  loss_ce_5: 0.4279  loss_mask_5: 0.1688  loss_dice_5: 1.224  loss_ce_6: 0.4452  loss_mask_6: 0.172  loss_dice_6: 1.205  loss_ce_7: 0.4405  loss_mask_7: 0.1683  loss_dice_7: 1.236  loss_ce_8: 0.4302  loss_mask_8: 0.1699  loss_dice_8: 1.186    time: 1.0708  last_time: 1.1795  data_time: 0.0749  last_data_time: 0.0936   lr: 0.0001  max_mem: 32985M
[10/09 21:34:58] d2.utils.events INFO:  eta: 0:21:44  iter: 1779  total_loss: 19.21  loss_ce: 0.4899  loss_mask: 0.1554  loss_dice: 1.176  loss_ce_0: 0.5645  loss_mask_0: 0.1762  loss_dice_0: 1.425  loss_ce_1: 0.632  loss_mask_1: 0.1646  loss_dice_1: 1.318  loss_ce_2: 0.5895  loss_mask_2: 0.159  loss_dice_2: 1.275  loss_ce_3: 0.5062  loss_mask_3: 0.1571  loss_dice_3: 1.216  loss_ce_4: 0.476  loss_mask_4: 0.1552  loss_dice_4: 1.201  loss_ce_5: 0.4689  loss_mask_5: 0.1565  loss_dice_5: 1.233  loss_ce_6: 0.4808  loss_mask_6: 0.1551  loss_dice_6: 1.165  loss_ce_7: 0.4734  loss_mask_7: 0.155  loss_dice_7: 1.168  loss_ce_8: 0.4708  loss_mask_8: 0.1555  loss_dice_8: 1.167    time: 1.0708  last_time: 1.0497  data_time: 0.0766  last_data_time: 0.0644   lr: 0.0001  max_mem: 32985M
[10/09 21:35:19] d2.utils.events INFO:  eta: 0:21:23  iter: 1799  total_loss: 19.29  loss_ce: 0.477  loss_mask: 0.1633  loss_dice: 1.19  loss_ce_0: 0.5711  loss_mask_0: 0.19  loss_dice_0: 1.381  loss_ce_1: 0.6109  loss_mask_1: 0.1763  loss_dice_1: 1.286  loss_ce_2: 0.5523  loss_mask_2: 0.1685  loss_dice_2: 1.254  loss_ce_3: 0.4748  loss_mask_3: 0.171  loss_dice_3: 1.22  loss_ce_4: 0.4979  loss_mask_4: 0.1685  loss_dice_4: 1.233  loss_ce_5: 0.4533  loss_mask_5: 0.1642  loss_dice_5: 1.24  loss_ce_6: 0.4921  loss_mask_6: 0.1649  loss_dice_6: 1.166  loss_ce_7: 0.4534  loss_mask_7: 0.1627  loss_dice_7: 1.191  loss_ce_8: 0.4758  loss_mask_8: 0.1647  loss_dice_8: 1.215    time: 1.0710  last_time: 1.0964  data_time: 0.0831  last_data_time: 0.0758   lr: 0.0001  max_mem: 32985M
[10/09 21:35:41] d2.utils.events INFO:  eta: 0:21:01  iter: 1819  total_loss: 19.67  loss_ce: 0.4823  loss_mask: 0.167  loss_dice: 1.214  loss_ce_0: 0.5571  loss_mask_0: 0.1891  loss_dice_0: 1.443  loss_ce_1: 0.5809  loss_mask_1: 0.1803  loss_dice_1: 1.363  loss_ce_2: 0.5416  loss_mask_2: 0.1705  loss_dice_2: 1.292  loss_ce_3: 0.5089  loss_mask_3: 0.1716  loss_dice_3: 1.227  loss_ce_4: 0.4699  loss_mask_4: 0.1723  loss_dice_4: 1.252  loss_ce_5: 0.4338  loss_mask_5: 0.1692  loss_dice_5: 1.256  loss_ce_6: 0.4617  loss_mask_6: 0.1683  loss_dice_6: 1.229  loss_ce_7: 0.4779  loss_mask_7: 0.1709  loss_dice_7: 1.213  loss_ce_8: 0.4618  loss_mask_8: 0.1679  loss_dice_8: 1.185    time: 1.0709  last_time: 1.0534  data_time: 0.0743  last_data_time: 0.0639   lr: 0.0001  max_mem: 32985M
[10/09 21:36:03] d2.utils.events INFO:  eta: 0:20:40  iter: 1839  total_loss: 20.03  loss_ce: 0.4844  loss_mask: 0.1509  loss_dice: 1.227  loss_ce_0: 0.5739  loss_mask_0: 0.1836  loss_dice_0: 1.482  loss_ce_1: 0.6245  loss_mask_1: 0.1682  loss_dice_1: 1.347  loss_ce_2: 0.546  loss_mask_2: 0.1545  loss_dice_2: 1.343  loss_ce_3: 0.5094  loss_mask_3: 0.1522  loss_dice_3: 1.286  loss_ce_4: 0.4743  loss_mask_4: 0.152  loss_dice_4: 1.3  loss_ce_5: 0.4462  loss_mask_5: 0.1528  loss_dice_5: 1.308  loss_ce_6: 0.5024  loss_mask_6: 0.1523  loss_dice_6: 1.24  loss_ce_7: 0.488  loss_mask_7: 0.1543  loss_dice_7: 1.232  loss_ce_8: 0.4738  loss_mask_8: 0.1508  loss_dice_8: 1.229    time: 1.0710  last_time: 1.0955  data_time: 0.0753  last_data_time: 0.0902   lr: 0.0001  max_mem: 32985M
[10/09 21:36:25] d2.utils.events INFO:  eta: 0:20:19  iter: 1859  total_loss: 19.61  loss_ce: 0.4621  loss_mask: 0.1612  loss_dice: 1.242  loss_ce_0: 0.5933  loss_mask_0: 0.1902  loss_dice_0: 1.481  loss_ce_1: 0.633  loss_mask_1: 0.1823  loss_dice_1: 1.409  loss_ce_2: 0.5626  loss_mask_2: 0.1722  loss_dice_2: 1.337  loss_ce_3: 0.4767  loss_mask_3: 0.1692  loss_dice_3: 1.307  loss_ce_4: 0.4779  loss_mask_4: 0.1677  loss_dice_4: 1.319  loss_ce_5: 0.4543  loss_mask_5: 0.1677  loss_dice_5: 1.282  loss_ce_6: 0.491  loss_mask_6: 0.1648  loss_dice_6: 1.259  loss_ce_7: 0.4933  loss_mask_7: 0.1655  loss_dice_7: 1.25  loss_ce_8: 0.4871  loss_mask_8: 0.1637  loss_dice_8: 1.218    time: 1.0711  last_time: 1.0402  data_time: 0.0766  last_data_time: 0.0683   lr: 0.0001  max_mem: 32985M
[10/09 21:36:46] d2.utils.events INFO:  eta: 0:19:57  iter: 1879  total_loss: 18.73  loss_ce: 0.4486  loss_mask: 0.1622  loss_dice: 1.138  loss_ce_0: 0.5806  loss_mask_0: 0.1945  loss_dice_0: 1.384  loss_ce_1: 0.5845  loss_mask_1: 0.1779  loss_dice_1: 1.315  loss_ce_2: 0.557  loss_mask_2: 0.1715  loss_dice_2: 1.239  loss_ce_3: 0.5171  loss_mask_3: 0.1694  loss_dice_3: 1.194  loss_ce_4: 0.4651  loss_mask_4: 0.1653  loss_dice_4: 1.179  loss_ce_5: 0.4237  loss_mask_5: 0.1639  loss_dice_5: 1.163  loss_ce_6: 0.4162  loss_mask_6: 0.1629  loss_dice_6: 1.182  loss_ce_7: 0.4349  loss_mask_7: 0.1621  loss_dice_7: 1.176  loss_ce_8: 0.4285  loss_mask_8: 0.1602  loss_dice_8: 1.159    time: 1.0711  last_time: 1.0604  data_time: 0.0735  last_data_time: 0.0780   lr: 0.0001  max_mem: 32985M
[10/09 21:37:07] d2.utils.events INFO:  eta: 0:19:35  iter: 1899  total_loss: 18.38  loss_ce: 0.3745  loss_mask: 0.166  loss_dice: 1.163  loss_ce_0: 0.5187  loss_mask_0: 0.1929  loss_dice_0: 1.363  loss_ce_1: 0.589  loss_mask_1: 0.1768  loss_dice_1: 1.262  loss_ce_2: 0.5459  loss_mask_2: 0.169  loss_dice_2: 1.242  loss_ce_3: 0.5136  loss_mask_3: 0.1681  loss_dice_3: 1.15  loss_ce_4: 0.4486  loss_mask_4: 0.1686  loss_dice_4: 1.151  loss_ce_5: 0.4188  loss_mask_5: 0.1646  loss_dice_5: 1.17  loss_ce_6: 0.4195  loss_mask_6: 0.1643  loss_dice_6: 1.159  loss_ce_7: 0.3884  loss_mask_7: 0.1601  loss_dice_7: 1.162  loss_ce_8: 0.3992  loss_mask_8: 0.1649  loss_dice_8: 1.145    time: 1.0710  last_time: 1.1025  data_time: 0.0758  last_data_time: 0.0665   lr: 0.0001  max_mem: 32985M
[10/09 21:37:29] d2.utils.events INFO:  eta: 0:19:15  iter: 1919  total_loss: 19.71  loss_ce: 0.4595  loss_mask: 0.1518  loss_dice: 1.252  loss_ce_0: 0.5337  loss_mask_0: 0.1697  loss_dice_0: 1.468  loss_ce_1: 0.5939  loss_mask_1: 0.164  loss_dice_1: 1.36  loss_ce_2: 0.5248  loss_mask_2: 0.1542  loss_dice_2: 1.283  loss_ce_3: 0.4954  loss_mask_3: 0.1543  loss_dice_3: 1.299  loss_ce_4: 0.4689  loss_mask_4: 0.1533  loss_dice_4: 1.318  loss_ce_5: 0.4505  loss_mask_5: 0.1533  loss_dice_5: 1.274  loss_ce_6: 0.4815  loss_mask_6: 0.1523  loss_dice_6: 1.254  loss_ce_7: 0.4811  loss_mask_7: 0.1512  loss_dice_7: 1.266  loss_ce_8: 0.4675  loss_mask_8: 0.1518  loss_dice_8: 1.224    time: 1.0713  last_time: 1.0248  data_time: 0.0770  last_data_time: 0.0594   lr: 0.0001  max_mem: 32985M
[10/09 21:37:51] d2.utils.events INFO:  eta: 0:18:53  iter: 1939  total_loss: 19.16  loss_ce: 0.4344  loss_mask: 0.1706  loss_dice: 1.163  loss_ce_0: 0.5331  loss_mask_0: 0.1938  loss_dice_0: 1.421  loss_ce_1: 0.6013  loss_mask_1: 0.1843  loss_dice_1: 1.328  loss_ce_2: 0.5429  loss_mask_2: 0.1804  loss_dice_2: 1.279  loss_ce_3: 0.4952  loss_mask_3: 0.1711  loss_dice_3: 1.223  loss_ce_4: 0.4568  loss_mask_4: 0.1706  loss_dice_4: 1.223  loss_ce_5: 0.456  loss_mask_5: 0.1696  loss_dice_5: 1.229  loss_ce_6: 0.4675  loss_mask_6: 0.1691  loss_dice_6: 1.236  loss_ce_7: 0.4552  loss_mask_7: 0.1697  loss_dice_7: 1.208  loss_ce_8: 0.4418  loss_mask_8: 0.1713  loss_dice_8: 1.224    time: 1.0713  last_time: 1.1164  data_time: 0.0758  last_data_time: 0.0913   lr: 0.0001  max_mem: 32985M
[10/09 21:38:13] d2.utils.events INFO:  eta: 0:18:33  iter: 1959  total_loss: 19.64  loss_ce: 0.4549  loss_mask: 0.1581  loss_dice: 1.23  loss_ce_0: 0.5538  loss_mask_0: 0.1811  loss_dice_0: 1.464  loss_ce_1: 0.6062  loss_mask_1: 0.1744  loss_dice_1: 1.354  loss_ce_2: 0.5621  loss_mask_2: 0.1613  loss_dice_2: 1.278  loss_ce_3: 0.5261  loss_mask_3: 0.1586  loss_dice_3: 1.25  loss_ce_4: 0.4872  loss_mask_4: 0.1576  loss_dice_4: 1.238  loss_ce_5: 0.4633  loss_mask_5: 0.1572  loss_dice_5: 1.241  loss_ce_6: 0.4977  loss_mask_6: 0.1587  loss_dice_6: 1.23  loss_ce_7: 0.4652  loss_mask_7: 0.1584  loss_dice_7: 1.231  loss_ce_8: 0.4609  loss_mask_8: 0.1577  loss_dice_8: 1.232    time: 1.0716  last_time: 1.0613  data_time: 0.0827  last_data_time: 0.0578   lr: 0.0001  max_mem: 33192M
[10/09 21:38:35] d2.utils.events INFO:  eta: 0:18:12  iter: 1979  total_loss: 19  loss_ce: 0.4458  loss_mask: 0.1536  loss_dice: 1.19  loss_ce_0: 0.5706  loss_mask_0: 0.1713  loss_dice_0: 1.42  loss_ce_1: 0.5672  loss_mask_1: 0.169  loss_dice_1: 1.297  loss_ce_2: 0.5496  loss_mask_2: 0.1615  loss_dice_2: 1.23  loss_ce_3: 0.4857  loss_mask_3: 0.1554  loss_dice_3: 1.249  loss_ce_4: 0.4866  loss_mask_4: 0.1566  loss_dice_4: 1.232  loss_ce_5: 0.4639  loss_mask_5: 0.1516  loss_dice_5: 1.19  loss_ce_6: 0.4774  loss_mask_6: 0.1537  loss_dice_6: 1.147  loss_ce_7: 0.4512  loss_mask_7: 0.1561  loss_dice_7: 1.211  loss_ce_8: 0.4645  loss_mask_8: 0.1522  loss_dice_8: 1.173    time: 1.0717  last_time: 1.1130  data_time: 0.0808  last_data_time: 0.0865   lr: 0.0001  max_mem: 33192M
[10/09 21:38:56] d2.utils.events INFO:  eta: 0:17:51  iter: 1999  total_loss: 18.69  loss_ce: 0.4363  loss_mask: 0.1674  loss_dice: 1.163  loss_ce_0: 0.5329  loss_mask_0: 0.1912  loss_dice_0: 1.343  loss_ce_1: 0.5596  loss_mask_1: 0.1779  loss_dice_1: 1.298  loss_ce_2: 0.54  loss_mask_2: 0.172  loss_dice_2: 1.246  loss_ce_3: 0.4802  loss_mask_3: 0.1726  loss_dice_3: 1.173  loss_ce_4: 0.4525  loss_mask_4: 0.1707  loss_dice_4: 1.185  loss_ce_5: 0.4758  loss_mask_5: 0.169  loss_dice_5: 1.212  loss_ce_6: 0.4484  loss_mask_6: 0.17  loss_dice_6: 1.163  loss_ce_7: 0.4405  loss_mask_7: 0.1688  loss_dice_7: 1.145  loss_ce_8: 0.4382  loss_mask_8: 0.1656  loss_dice_8: 1.174    time: 1.0716  last_time: 1.0301  data_time: 0.0739  last_data_time: 0.0645   lr: 0.0001  max_mem: 33192M
[10/09 21:39:18] d2.utils.events INFO:  eta: 0:17:30  iter: 2019  total_loss: 19.65  loss_ce: 0.4306  loss_mask: 0.1505  loss_dice: 1.217  loss_ce_0: 0.5491  loss_mask_0: 0.1708  loss_dice_0: 1.433  loss_ce_1: 0.6089  loss_mask_1: 0.1552  loss_dice_1: 1.382  loss_ce_2: 0.5485  loss_mask_2: 0.1544  loss_dice_2: 1.278  loss_ce_3: 0.4932  loss_mask_3: 0.1507  loss_dice_3: 1.218  loss_ce_4: 0.4523  loss_mask_4: 0.1495  loss_dice_4: 1.204  loss_ce_5: 0.4352  loss_mask_5: 0.1495  loss_dice_5: 1.22  loss_ce_6: 0.4257  loss_mask_6: 0.1489  loss_dice_6: 1.201  loss_ce_7: 0.4245  loss_mask_7: 0.1503  loss_dice_7: 1.199  loss_ce_8: 0.4125  loss_mask_8: 0.1489  loss_dice_8: 1.201    time: 1.0718  last_time: 1.0871  data_time: 0.0788  last_data_time: 0.0872   lr: 0.0001  max_mem: 33192M
[10/09 21:39:40] d2.utils.events INFO:  eta: 0:17:09  iter: 2039  total_loss: 19.26  loss_ce: 0.438  loss_mask: 0.1694  loss_dice: 1.159  loss_ce_0: 0.556  loss_mask_0: 0.2011  loss_dice_0: 1.41  loss_ce_1: 0.5684  loss_mask_1: 0.1812  loss_dice_1: 1.295  loss_ce_2: 0.536  loss_mask_2: 0.1772  loss_dice_2: 1.249  loss_ce_3: 0.5078  loss_mask_3: 0.1744  loss_dice_3: 1.204  loss_ce_4: 0.4591  loss_mask_4: 0.1728  loss_dice_4: 1.208  loss_ce_5: 0.4743  loss_mask_5: 0.1714  loss_dice_5: 1.214  loss_ce_6: 0.4278  loss_mask_6: 0.1677  loss_dice_6: 1.171  loss_ce_7: 0.4209  loss_mask_7: 0.1663  loss_dice_7: 1.17  loss_ce_8: 0.4112  loss_mask_8: 0.1664  loss_dice_8: 1.176    time: 1.0720  last_time: 1.0985  data_time: 0.0770  last_data_time: 0.0857   lr: 0.0001  max_mem: 33192M
[10/09 21:40:01] d2.utils.events INFO:  eta: 0:16:47  iter: 2059  total_loss: 18.65  loss_ce: 0.4285  loss_mask: 0.1599  loss_dice: 1.158  loss_ce_0: 0.5486  loss_mask_0: 0.1875  loss_dice_0: 1.387  loss_ce_1: 0.5461  loss_mask_1: 0.1739  loss_dice_1: 1.299  loss_ce_2: 0.5111  loss_mask_2: 0.1647  loss_dice_2: 1.255  loss_ce_3: 0.4622  loss_mask_3: 0.1609  loss_dice_3: 1.19  loss_ce_4: 0.4363  loss_mask_4: 0.1612  loss_dice_4: 1.156  loss_ce_5: 0.4359  loss_mask_5: 0.1608  loss_dice_5: 1.176  loss_ce_6: 0.4482  loss_mask_6: 0.1631  loss_dice_6: 1.158  loss_ce_7: 0.4451  loss_mask_7: 0.1621  loss_dice_7: 1.15  loss_ce_8: 0.442  loss_mask_8: 0.1591  loss_dice_8: 1.185    time: 1.0720  last_time: 1.0500  data_time: 0.0718  last_data_time: 0.0749   lr: 0.0001  max_mem: 33192M
[10/09 21:40:23] d2.utils.events INFO:  eta: 0:16:26  iter: 2079  total_loss: 18.81  loss_ce: 0.4625  loss_mask: 0.1553  loss_dice: 1.154  loss_ce_0: 0.556  loss_mask_0: 0.1896  loss_dice_0: 1.378  loss_ce_1: 0.6071  loss_mask_1: 0.1735  loss_dice_1: 1.318  loss_ce_2: 0.5674  loss_mask_2: 0.1618  loss_dice_2: 1.242  loss_ce_3: 0.5026  loss_mask_3: 0.158  loss_dice_3: 1.183  loss_ce_4: 0.4823  loss_mask_4: 0.1583  loss_dice_4: 1.192  loss_ce_5: 0.4427  loss_mask_5: 0.1571  loss_dice_5: 1.148  loss_ce_6: 0.4228  loss_mask_6: 0.1547  loss_dice_6: 1.168  loss_ce_7: 0.446  loss_mask_7: 0.1565  loss_dice_7: 1.209  loss_ce_8: 0.416  loss_mask_8: 0.1546  loss_dice_8: 1.152    time: 1.0720  last_time: 1.0664  data_time: 0.0734  last_data_time: 0.0540   lr: 0.0001  max_mem: 33192M
[10/09 21:40:44] d2.utils.events INFO:  eta: 0:16:05  iter: 2099  total_loss: 18.35  loss_ce: 0.4071  loss_mask: 0.1643  loss_dice: 1.126  loss_ce_0: 0.4905  loss_mask_0: 0.1883  loss_dice_0: 1.35  loss_ce_1: 0.5554  loss_mask_1: 0.1792  loss_dice_1: 1.283  loss_ce_2: 0.4769  loss_mask_2: 0.1724  loss_dice_2: 1.232  loss_ce_3: 0.4499  loss_mask_3: 0.1675  loss_dice_3: 1.176  loss_ce_4: 0.4632  loss_mask_4: 0.1648  loss_dice_4: 1.185  loss_ce_5: 0.4224  loss_mask_5: 0.1624  loss_dice_5: 1.168  loss_ce_6: 0.4011  loss_mask_6: 0.1635  loss_dice_6: 1.141  loss_ce_7: 0.4177  loss_mask_7: 0.1626  loss_dice_7: 1.154  loss_ce_8: 0.4205  loss_mask_8: 0.1645  loss_dice_8: 1.16    time: 1.0719  last_time: 1.0787  data_time: 0.0726  last_data_time: 0.0864   lr: 0.0001  max_mem: 33192M
[10/09 21:41:05] d2.utils.events INFO:  eta: 0:15:43  iter: 2119  total_loss: 20.23  loss_ce: 0.462  loss_mask: 0.1687  loss_dice: 1.254  loss_ce_0: 0.5498  loss_mask_0: 0.2056  loss_dice_0: 1.501  loss_ce_1: 0.6075  loss_mask_1: 0.1839  loss_dice_1: 1.411  loss_ce_2: 0.5649  loss_mask_2: 0.1749  loss_dice_2: 1.315  loss_ce_3: 0.5006  loss_mask_3: 0.1703  loss_dice_3: 1.293  loss_ce_4: 0.481  loss_mask_4: 0.1708  loss_dice_4: 1.284  loss_ce_5: 0.4818  loss_mask_5: 0.1679  loss_dice_5: 1.278  loss_ce_6: 0.4574  loss_mask_6: 0.1701  loss_dice_6: 1.258  loss_ce_7: 0.439  loss_mask_7: 0.17  loss_dice_7: 1.255  loss_ce_8: 0.4426  loss_mask_8: 0.1696  loss_dice_8: 1.267    time: 1.0718  last_time: 1.0570  data_time: 0.0709  last_data_time: 0.0675   lr: 0.0001  max_mem: 33192M
[10/09 21:41:27] d2.utils.events INFO:  eta: 0:15:22  iter: 2139  total_loss: 18.23  loss_ce: 0.3959  loss_mask: 0.1696  loss_dice: 1.15  loss_ce_0: 0.5463  loss_mask_0: 0.1914  loss_dice_0: 1.325  loss_ce_1: 0.5541  loss_mask_1: 0.1747  loss_dice_1: 1.252  loss_ce_2: 0.5219  loss_mask_2: 0.1726  loss_dice_2: 1.209  loss_ce_3: 0.4752  loss_mask_3: 0.1738  loss_dice_3: 1.15  loss_ce_4: 0.4612  loss_mask_4: 0.1707  loss_dice_4: 1.14  loss_ce_5: 0.4286  loss_mask_5: 0.1708  loss_dice_5: 1.145  loss_ce_6: 0.4205  loss_mask_6: 0.1695  loss_dice_6: 1.126  loss_ce_7: 0.3998  loss_mask_7: 0.1705  loss_dice_7: 1.128  loss_ce_8: 0.4185  loss_mask_8: 0.1701  loss_dice_8: 1.15    time: 1.0718  last_time: 1.0590  data_time: 0.0702  last_data_time: 0.0559   lr: 0.0001  max_mem: 33192M
[10/09 21:41:48] d2.utils.events INFO:  eta: 0:15:00  iter: 2159  total_loss: 19.66  loss_ce: 0.436  loss_mask: 0.1578  loss_dice: 1.18  loss_ce_0: 0.5552  loss_mask_0: 0.1806  loss_dice_0: 1.433  loss_ce_1: 0.6366  loss_mask_1: 0.1686  loss_dice_1: 1.333  loss_ce_2: 0.5435  loss_mask_2: 0.1609  loss_dice_2: 1.274  loss_ce_3: 0.5104  loss_mask_3: 0.1596  loss_dice_3: 1.206  loss_ce_4: 0.4719  loss_mask_4: 0.1608  loss_dice_4: 1.232  loss_ce_5: 0.4767  loss_mask_5: 0.1561  loss_dice_5: 1.233  loss_ce_6: 0.4657  loss_mask_6: 0.1589  loss_dice_6: 1.177  loss_ce_7: 0.4615  loss_mask_7: 0.1573  loss_dice_7: 1.215  loss_ce_8: 0.4627  loss_mask_8: 0.1587  loss_dice_8: 1.2    time: 1.0718  last_time: 1.1769  data_time: 0.0744  last_data_time: 0.0831   lr: 0.0001  max_mem: 33192M
[10/09 21:42:10] d2.utils.events INFO:  eta: 0:14:39  iter: 2179  total_loss: 18.7  loss_ce: 0.4287  loss_mask: 0.1603  loss_dice: 1.169  loss_ce_0: 0.5235  loss_mask_0: 0.1846  loss_dice_0: 1.411  loss_ce_1: 0.6162  loss_mask_1: 0.1713  loss_dice_1: 1.301  loss_ce_2: 0.534  loss_mask_2: 0.1621  loss_dice_2: 1.254  loss_ce_3: 0.5067  loss_mask_3: 0.1631  loss_dice_3: 1.202  loss_ce_4: 0.4559  loss_mask_4: 0.1628  loss_dice_4: 1.189  loss_ce_5: 0.4668  loss_mask_5: 0.162  loss_dice_5: 1.218  loss_ce_6: 0.4212  loss_mask_6: 0.1629  loss_dice_6: 1.207  loss_ce_7: 0.4228  loss_mask_7: 0.1635  loss_dice_7: 1.193  loss_ce_8: 0.4264  loss_mask_8: 0.1618  loss_dice_8: 1.19    time: 1.0718  last_time: 1.0477  data_time: 0.0747  last_data_time: 0.0654   lr: 0.0001  max_mem: 33192M
[10/09 21:42:32] d2.utils.events INFO:  eta: 0:14:17  iter: 2199  total_loss: 19.53  loss_ce: 0.4669  loss_mask: 0.1545  loss_dice: 1.22  loss_ce_0: 0.5616  loss_mask_0: 0.1778  loss_dice_0: 1.447  loss_ce_1: 0.6207  loss_mask_1: 0.1743  loss_dice_1: 1.36  loss_ce_2: 0.5269  loss_mask_2: 0.1618  loss_dice_2: 1.269  loss_ce_3: 0.4592  loss_mask_3: 0.1588  loss_dice_3: 1.269  loss_ce_4: 0.4695  loss_mask_4: 0.1601  loss_dice_4: 1.279  loss_ce_5: 0.4505  loss_mask_5: 0.155  loss_dice_5: 1.256  loss_ce_6: 0.4448  loss_mask_6: 0.1561  loss_dice_6: 1.22  loss_ce_7: 0.4476  loss_mask_7: 0.157  loss_dice_7: 1.229  loss_ce_8: 0.4649  loss_mask_8: 0.1543  loss_dice_8: 1.211    time: 1.0719  last_time: 1.1832  data_time: 0.0755  last_data_time: 0.0894   lr: 0.0001  max_mem: 33192M
[10/09 21:42:53] d2.utils.events INFO:  eta: 0:13:56  iter: 2219  total_loss: 19.98  loss_ce: 0.5265  loss_mask: 0.161  loss_dice: 1.266  loss_ce_0: 0.6097  loss_mask_0: 0.1871  loss_dice_0: 1.416  loss_ce_1: 0.6518  loss_mask_1: 0.1649  loss_dice_1: 1.363  loss_ce_2: 0.5605  loss_mask_2: 0.1634  loss_dice_2: 1.325  loss_ce_3: 0.5232  loss_mask_3: 0.1614  loss_dice_3: 1.23  loss_ce_4: 0.5067  loss_mask_4: 0.1602  loss_dice_4: 1.288  loss_ce_5: 0.4998  loss_mask_5: 0.1562  loss_dice_5: 1.255  loss_ce_6: 0.4922  loss_mask_6: 0.1594  loss_dice_6: 1.25  loss_ce_7: 0.4696  loss_mask_7: 0.158  loss_dice_7: 1.235  loss_ce_8: 0.5081  loss_mask_8: 0.1593  loss_dice_8: 1.237    time: 1.0721  last_time: 1.0912  data_time: 0.0821  last_data_time: 0.0702   lr: 0.0001  max_mem: 33192M
[10/09 21:43:15] d2.utils.events INFO:  eta: 0:13:35  iter: 2239  total_loss: 18.69  loss_ce: 0.4204  loss_mask: 0.1514  loss_dice: 1.16  loss_ce_0: 0.5422  loss_mask_0: 0.1851  loss_dice_0: 1.353  loss_ce_1: 0.5726  loss_mask_1: 0.1629  loss_dice_1: 1.319  loss_ce_2: 0.5581  loss_mask_2: 0.1565  loss_dice_2: 1.247  loss_ce_3: 0.498  loss_mask_3: 0.1551  loss_dice_3: 1.2  loss_ce_4: 0.4753  loss_mask_4: 0.1542  loss_dice_4: 1.212  loss_ce_5: 0.4368  loss_mask_5: 0.1527  loss_dice_5: 1.195  loss_ce_6: 0.4415  loss_mask_6: 0.1518  loss_dice_6: 1.176  loss_ce_7: 0.4341  loss_mask_7: 0.1522  loss_dice_7: 1.195  loss_ce_8: 0.4365  loss_mask_8: 0.1527  loss_dice_8: 1.184    time: 1.0721  last_time: 1.0081  data_time: 0.0764  last_data_time: 0.0642   lr: 0.0001  max_mem: 33192M
[10/09 21:43:37] d2.utils.events INFO:  eta: 0:13:13  iter: 2259  total_loss: 18.82  loss_ce: 0.4591  loss_mask: 0.1593  loss_dice: 1.212  loss_ce_0: 0.5483  loss_mask_0: 0.1877  loss_dice_0: 1.363  loss_ce_1: 0.6388  loss_mask_1: 0.1676  loss_dice_1: 1.347  loss_ce_2: 0.581  loss_mask_2: 0.1629  loss_dice_2: 1.267  loss_ce_3: 0.5086  loss_mask_3: 0.1609  loss_dice_3: 1.244  loss_ce_4: 0.4704  loss_mask_4: 0.163  loss_dice_4: 1.235  loss_ce_5: 0.4655  loss_mask_5: 0.1621  loss_dice_5: 1.216  loss_ce_6: 0.4618  loss_mask_6: 0.1609  loss_dice_6: 1.225  loss_ce_7: 0.4377  loss_mask_7: 0.1593  loss_dice_7: 1.21  loss_ce_8: 0.4561  loss_mask_8: 0.1589  loss_dice_8: 1.194    time: 1.0723  last_time: 1.1382  data_time: 0.0850  last_data_time: 0.0971   lr: 0.0001  max_mem: 33192M
[10/09 21:43:58] d2.utils.events INFO:  eta: 0:12:52  iter: 2279  total_loss: 18.79  loss_ce: 0.4557  loss_mask: 0.1754  loss_dice: 1.167  loss_ce_0: 0.5535  loss_mask_0: 0.2051  loss_dice_0: 1.343  loss_ce_1: 0.5753  loss_mask_1: 0.1857  loss_dice_1: 1.309  loss_ce_2: 0.5219  loss_mask_2: 0.1774  loss_dice_2: 1.278  loss_ce_3: 0.4881  loss_mask_3: 0.1756  loss_dice_3: 1.222  loss_ce_4: 0.4476  loss_mask_4: 0.1794  loss_dice_4: 1.221  loss_ce_5: 0.4572  loss_mask_5: 0.1764  loss_dice_5: 1.192  loss_ce_6: 0.4418  loss_mask_6: 0.1777  loss_dice_6: 1.163  loss_ce_7: 0.4383  loss_mask_7: 0.176  loss_dice_7: 1.197  loss_ce_8: 0.4287  loss_mask_8: 0.1761  loss_dice_8: 1.173    time: 1.0723  last_time: 1.0072  data_time: 0.0753  last_data_time: 0.0597   lr: 0.0001  max_mem: 33192M
[10/09 21:44:20] d2.utils.events INFO:  eta: 0:12:30  iter: 2299  total_loss: 18.42  loss_ce: 0.4211  loss_mask: 0.1556  loss_dice: 1.173  loss_ce_0: 0.5386  loss_mask_0: 0.1819  loss_dice_0: 1.369  loss_ce_1: 0.6178  loss_mask_1: 0.1661  loss_dice_1: 1.321  loss_ce_2: 0.542  loss_mask_2: 0.1662  loss_dice_2: 1.27  loss_ce_3: 0.4733  loss_mask_3: 0.1615  loss_dice_3: 1.18  loss_ce_4: 0.4474  loss_mask_4: 0.161  loss_dice_4: 1.197  loss_ce_5: 0.4388  loss_mask_5: 0.1557  loss_dice_5: 1.193  loss_ce_6: 0.4139  loss_mask_6: 0.1567  loss_dice_6: 1.182  loss_ce_7: 0.4261  loss_mask_7: 0.1567  loss_dice_7: 1.168  loss_ce_8: 0.4189  loss_mask_8: 0.1543  loss_dice_8: 1.17    time: 1.0723  last_time: 1.1094  data_time: 0.0735  last_data_time: 0.0673   lr: 0.0001  max_mem: 33192M
[10/09 21:44:42] d2.utils.events INFO:  eta: 0:12:09  iter: 2319  total_loss: 18.06  loss_ce: 0.3945  loss_mask: 0.1537  loss_dice: 1.153  loss_ce_0: 0.4946  loss_mask_0: 0.1805  loss_dice_0: 1.351  loss_ce_1: 0.5482  loss_mask_1: 0.1628  loss_dice_1: 1.282  loss_ce_2: 0.4733  loss_mask_2: 0.1559  loss_dice_2: 1.296  loss_ce_3: 0.4322  loss_mask_3: 0.1524  loss_dice_3: 1.224  loss_ce_4: 0.4199  loss_mask_4: 0.151  loss_dice_4: 1.207  loss_ce_5: 0.3824  loss_mask_5: 0.1501  loss_dice_5: 1.186  loss_ce_6: 0.4025  loss_mask_6: 0.1521  loss_dice_6: 1.2  loss_ce_7: 0.3859  loss_mask_7: 0.1505  loss_dice_7: 1.195  loss_ce_8: 0.3769  loss_mask_8: 0.1495  loss_dice_8: 1.172    time: 1.0724  last_time: 1.0817  data_time: 0.0820  last_data_time: 0.0729   lr: 0.0001  max_mem: 33192M
[10/09 21:45:03] d2.utils.events INFO:  eta: 0:11:48  iter: 2339  total_loss: 18.97  loss_ce: 0.4672  loss_mask: 0.1592  loss_dice: 1.215  loss_ce_0: 0.5334  loss_mask_0: 0.1878  loss_dice_0: 1.386  loss_ce_1: 0.5723  loss_mask_1: 0.1685  loss_dice_1: 1.311  loss_ce_2: 0.5307  loss_mask_2: 0.166  loss_dice_2: 1.279  loss_ce_3: 0.4721  loss_mask_3: 0.1643  loss_dice_3: 1.25  loss_ce_4: 0.453  loss_mask_4: 0.1604  loss_dice_4: 1.234  loss_ce_5: 0.4223  loss_mask_5: 0.1585  loss_dice_5: 1.226  loss_ce_6: 0.4236  loss_mask_6: 0.1595  loss_dice_6: 1.206  loss_ce_7: 0.4261  loss_mask_7: 0.1581  loss_dice_7: 1.222  loss_ce_8: 0.4468  loss_mask_8: 0.1597  loss_dice_8: 1.209    time: 1.0724  last_time: 1.0821  data_time: 0.0753  last_data_time: 0.0753   lr: 0.0001  max_mem: 33192M
[10/09 21:45:25] d2.utils.events INFO:  eta: 0:11:26  iter: 2359  total_loss: 17.94  loss_ce: 0.4244  loss_mask: 0.154  loss_dice: 1.078  loss_ce_0: 0.5733  loss_mask_0: 0.1796  loss_dice_0: 1.288  loss_ce_1: 0.6024  loss_mask_1: 0.1655  loss_dice_1: 1.232  loss_ce_2: 0.5252  loss_mask_2: 0.1582  loss_dice_2: 1.203  loss_ce_3: 0.4789  loss_mask_3: 0.1551  loss_dice_3: 1.151  loss_ce_4: 0.4345  loss_mask_4: 0.1556  loss_dice_4: 1.157  loss_ce_5: 0.424  loss_mask_5: 0.1547  loss_dice_5: 1.149  loss_ce_6: 0.4415  loss_mask_6: 0.1529  loss_dice_6: 1.136  loss_ce_7: 0.4313  loss_mask_7: 0.1549  loss_dice_7: 1.107  loss_ce_8: 0.4182  loss_mask_8: 0.1553  loss_dice_8: 1.102    time: 1.0723  last_time: 1.0711  data_time: 0.0697  last_data_time: 0.0705   lr: 0.0001  max_mem: 33192M
[10/09 21:45:46] d2.utils.events INFO:  eta: 0:11:04  iter: 2379  total_loss: 18.74  loss_ce: 0.4458  loss_mask: 0.1639  loss_dice: 1.172  loss_ce_0: 0.5569  loss_mask_0: 0.1913  loss_dice_0: 1.373  loss_ce_1: 0.6125  loss_mask_1: 0.181  loss_dice_1: 1.304  loss_ce_2: 0.5529  loss_mask_2: 0.1662  loss_dice_2: 1.265  loss_ce_3: 0.4896  loss_mask_3: 0.1653  loss_dice_3: 1.225  loss_ce_4: 0.4384  loss_mask_4: 0.159  loss_dice_4: 1.21  loss_ce_5: 0.4451  loss_mask_5: 0.1631  loss_dice_5: 1.209  loss_ce_6: 0.4455  loss_mask_6: 0.1643  loss_dice_6: 1.183  loss_ce_7: 0.4223  loss_mask_7: 0.1639  loss_dice_7: 1.197  loss_ce_8: 0.4188  loss_mask_8: 0.1637  loss_dice_8: 1.197    time: 1.0722  last_time: 1.0533  data_time: 0.0720  last_data_time: 0.0856   lr: 0.0001  max_mem: 33192M
[10/09 21:46:07] d2.utils.events INFO:  eta: 0:10:43  iter: 2399  total_loss: 18.29  loss_ce: 0.4307  loss_mask: 0.1574  loss_dice: 1.138  loss_ce_0: 0.5351  loss_mask_0: 0.1941  loss_dice_0: 1.349  loss_ce_1: 0.576  loss_mask_1: 0.1734  loss_dice_1: 1.225  loss_ce_2: 0.5143  loss_mask_2: 0.1663  loss_dice_2: 1.185  loss_ce_3: 0.4774  loss_mask_3: 0.1561  loss_dice_3: 1.155  loss_ce_4: 0.4056  loss_mask_4: 0.1582  loss_dice_4: 1.15  loss_ce_5: 0.4277  loss_mask_5: 0.1579  loss_dice_5: 1.15  loss_ce_6: 0.4469  loss_mask_6: 0.1565  loss_dice_6: 1.129  loss_ce_7: 0.4453  loss_mask_7: 0.1551  loss_dice_7: 1.119  loss_ce_8: 0.4378  loss_mask_8: 0.1553  loss_dice_8: 1.111    time: 1.0723  last_time: 1.1562  data_time: 0.0723  last_data_time: 0.0630   lr: 0.0001  max_mem: 33192M
[10/09 21:46:29] d2.utils.events INFO:  eta: 0:10:22  iter: 2419  total_loss: 18.75  loss_ce: 0.4148  loss_mask: 0.1517  loss_dice: 1.161  loss_ce_0: 0.5842  loss_mask_0: 0.1819  loss_dice_0: 1.393  loss_ce_1: 0.5949  loss_mask_1: 0.1682  loss_dice_1: 1.269  loss_ce_2: 0.5495  loss_mask_2: 0.1525  loss_dice_2: 1.249  loss_ce_3: 0.4998  loss_mask_3: 0.1548  loss_dice_3: 1.201  loss_ce_4: 0.4492  loss_mask_4: 0.1522  loss_dice_4: 1.194  loss_ce_5: 0.4406  loss_mask_5: 0.1532  loss_dice_5: 1.212  loss_ce_6: 0.4299  loss_mask_6: 0.1521  loss_dice_6: 1.162  loss_ce_7: 0.4161  loss_mask_7: 0.1524  loss_dice_7: 1.186  loss_ce_8: 0.4119  loss_mask_8: 0.1509  loss_dice_8: 1.141    time: 1.0724  last_time: 1.0592  data_time: 0.0824  last_data_time: 0.0665   lr: 0.0001  max_mem: 33192M
[10/09 21:46:51] d2.utils.events INFO:  eta: 0:10:00  iter: 2439  total_loss: 19.48  loss_ce: 0.4658  loss_mask: 0.1499  loss_dice: 1.215  loss_ce_0: 0.5627  loss_mask_0: 0.1816  loss_dice_0: 1.492  loss_ce_1: 0.6014  loss_mask_1: 0.1696  loss_dice_1: 1.384  loss_ce_2: 0.5297  loss_mask_2: 0.1584  loss_dice_2: 1.321  loss_ce_3: 0.473  loss_mask_3: 0.1553  loss_dice_3: 1.255  loss_ce_4: 0.4509  loss_mask_4: 0.1545  loss_dice_4: 1.247  loss_ce_5: 0.4375  loss_mask_5: 0.1525  loss_dice_5: 1.293  loss_ce_6: 0.4712  loss_mask_6: 0.1517  loss_dice_6: 1.234  loss_ce_7: 0.4514  loss_mask_7: 0.1531  loss_dice_7: 1.25  loss_ce_8: 0.4689  loss_mask_8: 0.1501  loss_dice_8: 1.267    time: 1.0726  last_time: 1.0839  data_time: 0.0793  last_data_time: 0.0989   lr: 0.0001  max_mem: 33192M
[10/09 21:47:13] d2.utils.events INFO:  eta: 0:09:39  iter: 2459  total_loss: 18.38  loss_ce: 0.415  loss_mask: 0.1717  loss_dice: 1.142  loss_ce_0: 0.5554  loss_mask_0: 0.1956  loss_dice_0: 1.336  loss_ce_1: 0.57  loss_mask_1: 0.1893  loss_dice_1: 1.282  loss_ce_2: 0.5384  loss_mask_2: 0.1792  loss_dice_2: 1.213  loss_ce_3: 0.4559  loss_mask_3: 0.1777  loss_dice_3: 1.173  loss_ce_4: 0.4258  loss_mask_4: 0.1751  loss_dice_4: 1.15  loss_ce_5: 0.4384  loss_mask_5: 0.174  loss_dice_5: 1.174  loss_ce_6: 0.4374  loss_mask_6: 0.172  loss_dice_6: 1.124  loss_ce_7: 0.4282  loss_mask_7: 0.1707  loss_dice_7: 1.158  loss_ce_8: 0.4206  loss_mask_8: 0.1711  loss_dice_8: 1.155    time: 1.0726  last_time: 1.0759  data_time: 0.0730  last_data_time: 0.0732   lr: 0.0001  max_mem: 33192M
[10/09 21:47:30] detectron2 INFO: Rank of current process: 0. World size: 1
[10/09 21:47:31] detectron2 INFO: Environment info:
-------------------------------  -------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:47:35) [GCC 12.3.0]
numpy                            1.24.4
detectron2                       0.6 @/home/ids/gbrison/segmentation/segmentation/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    CUDA 12.5
detectron2 arch flags            8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.0+cu121 @/home/ids/gbrison/segmentation/miniconda3/envs/fc/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA L40S (arch=8.9)
Driver version                   555.42.06
CUDA_HOME                        /usr/local/cuda
Pillow                           9.4.0
torchvision                      0.19.0+cu121 @/home/ids/gbrison/segmentation/miniconda3/envs/fc/lib/python3.8/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.10.0
-------------------------------  -------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[10/09 21:47:31] detectron2 INFO: Command line arguments: Namespace(config_file='configs/coco/panoptic-segmentation/fcclip/r50_exp_3000_a_decoder.yaml', dist_url='tcp://127.0.0.1:51163', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[10/09 21:47:31] detectron2 INFO: Contents of args.config_file=configs/coco/panoptic-segmentation/fcclip/r50_exp_3000_a_decoder.yaml:
_BASE_: ./fcclip_convnext_large_eval_ade20k_r50.yaml

INPUT:
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TEST: 2560

MODEL:
  SEM_SEG_HEAD:
    NUM_CLASSES: 19
  WEIGHTS: /tsi/hi-paris/GB/segmentation/models/fcclip_cocopan_r50.pth
OUTPUT_DIR: /tsi/hi-paris/GB/segmentation/results/In_vocab/r50_008_3000_19_a_decoder
DATASETS:
  TRAIN: ("openvocab_cityscapes_fine_panoptic_train",)
  TEST: ("openvocab_cityscapes_fine_panoptic_val",)
SOLVER:
  IMS_PER_BATCH: 8
  MAX_ITER: 3000
TEST:
  EVAL_PERIOD: 3000


[10/09 21:47:31] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - openvocab_cityscapes_fine_panoptic_val
  TRAIN:
  - openvocab_cityscapes_fine_panoptic_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    MINIMUM_INST_AREA: 1
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_panoptic_lsj
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 1024
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: -1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: CLIP
  DEVICE: cuda
  FC_CLIP:
    CLIP_MODEL_NAME: RN50
    CLIP_PRETRAINED_WEIGHTS: openai
    EMBED_DIM: 1024
    ENSEMBLE_ON_VALID_MASK: true
    GEOMETRIC_ENSEMBLE_ALPHA: 0.4
    GEOMETRIC_ENSEMBLE_BETA: 0.8
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 250
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.0
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: true
      SEMANTIC_ON: true
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: FCCLIP
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.32316305
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 1
    - 1
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: basic
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: FCCLIPHead
    NORM: GN
    NUM_CLASSES: 19
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: /tsi/hi-paris/GB/segmentation/models/fcclip_cocopan_r50.pth
OUTPUT_DIR: /tsi/hi-paris/GB/segmentation/results/In_vocab/r50_008_3000_19_a_decoder
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 3000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 3000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[10/09 21:47:31] detectron2 INFO: Full config saved to /tsi/hi-paris/GB/segmentation/results/In_vocab/r50_008_3000_19_a_decoder/config.yaml
[10/09 21:47:31] d2.utils.env INFO: Using a generated random seed 34183484
[10/09 21:47:34] d2.utils.events INFO:  eta: 0:09:18  iter: 2479  total_loss: 18.08  loss_ce: 0.4057  loss_mask: 0.1599  loss_dice: 1.136  loss_ce_0: 0.5182  loss_mask_0: 0.1863  loss_dice_0: 1.391  loss_ce_1: 0.5608  loss_mask_1: 0.1723  loss_dice_1: 1.282  loss_ce_2: 0.4845  loss_mask_2: 0.1645  loss_dice_2: 1.236  loss_ce_3: 0.4669  loss_mask_3: 0.1644  loss_dice_3: 1.2  loss_ce_4: 0.4179  loss_mask_4: 0.1608  loss_dice_4: 1.195  loss_ce_5: 0.3891  loss_mask_5: 0.1587  loss_dice_5: 1.15  loss_ce_6: 0.3974  loss_mask_6: 0.1576  loss_dice_6: 1.146  loss_ce_7: 0.4103  loss_mask_7: 0.1565  loss_dice_7: 1.168  loss_ce_8: 0.3956  loss_mask_8: 0.1582  loss_dice_8: 1.165    time: 1.0726  last_time: 1.0813  data_time: 0.0750  last_data_time: 0.0601   lr: 0.0001  max_mem: 33192M
[10/09 21:47:35] d2.engine.defaults INFO: Model:
FCCLIP(
  (backbone): CLIP(
    (clip_model): CLIP(
      (visual): ModifiedResNet(
        (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (layer1): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer2): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer3): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer4): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (attnpool): AttentionPool2d(
          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (c_proj): Linear(in_features=2048, out_features=1024, bias=True)
        )
      )
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ls_1): Identity()
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ls_2): Identity()
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (sem_seg_head): FCCLIPHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(250, 256)
      (query_embed): Embedding(250, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (mask_pooling): MaskPooling()
      (_mask_pooling_proj): Sequential(
        (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
      )
      (class_embed): MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=1024, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 19
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU()
  (mask_pooling): MaskPooling()
  (decoder_adapter): DecoderAdapter(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (conv2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (norm1): LayerNorm((64, 1, 1), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((256, 1, 1), eps=1e-05, elementwise_affine=True)
    (relu): ReLU()
  )
  (void_embedding): Embedding(1, 1024)
)
[10/09 21:47:35] fcclip.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerPanopticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1333, sample_style='choice'), RandomFlip()]
[10/09 21:47:36] fcclip.data.datasets.register_cityscapes_panoptic INFO: 18 cities found in 'datasets/cityscapes/leftImg8bit/train'.
[10/09 21:47:36] d2.data.build INFO: Using training sampler TrainingSampler
[10/09 21:47:36] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/09 21:47:36] d2.data.common INFO: Serializing 2975 elements to byte tensors and concatenating them all ...
[10/09 21:47:36] d2.data.common INFO: Serialized dataset takes 4.12 MiB
[10/09 21:47:36] d2.data.build INFO: Making batched data loader with batch_size=8
[10/09 21:47:36] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[10/09 21:47:36] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /tsi/hi-paris/GB/segmentation/models/fcclip_cocopan_r50.pth ...
[10/09 21:47:36] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /tsi/hi-paris/GB/segmentation/models/fcclip_cocopan_r50.pth ...
[10/09 21:47:39] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (134,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.
[10/09 21:47:39] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.clip_model.ln_final.{bias, weight}[0m
[34mbackbone.clip_model.token_embedding.weight[0m
[34mbackbone.clip_model.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mbackbone.clip_model.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.c_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.k_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.positional_embedding[0m
[34mbackbone.clip_model.visual.attnpool.q_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.attnpool.v_proj.{bias, weight}[0m
[34mbackbone.clip_model.visual.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.conv1.weight[0m
[34mbackbone.clip_model.visual.conv2.weight[0m
[34mbackbone.clip_model.visual.conv3.weight[0m
[34mbackbone.clip_model.visual.layer1.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer1.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer1.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer1.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer1.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer1.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer1.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer1.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer1.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer1.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer1.2.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer2.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.2.conv3.weight[0m
[34mbackbone.clip_model.visual.layer2.3.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.3.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.3.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer2.3.conv1.weight[0m
[34mbackbone.clip_model.visual.layer2.3.conv2.weight[0m
[34mbackbone.clip_model.visual.layer2.3.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer3.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.2.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.3.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.3.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.3.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.3.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.3.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.3.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.4.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.4.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.4.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.4.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.4.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.4.conv3.weight[0m
[34mbackbone.clip_model.visual.layer3.5.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.5.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.5.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer3.5.conv1.weight[0m
[34mbackbone.clip_model.visual.layer3.5.conv2.weight[0m
[34mbackbone.clip_model.visual.layer3.5.conv3.weight[0m
[34mbackbone.clip_model.visual.layer4.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.0.conv1.weight[0m
[34mbackbone.clip_model.visual.layer4.0.conv2.weight[0m
[34mbackbone.clip_model.visual.layer4.0.conv3.weight[0m
[34mbackbone.clip_model.visual.layer4.0.downsample.0.weight[0m
[34mbackbone.clip_model.visual.layer4.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.1.conv1.weight[0m
[34mbackbone.clip_model.visual.layer4.1.conv2.weight[0m
[34mbackbone.clip_model.visual.layer4.1.conv3.weight[0m
[34mbackbone.clip_model.visual.layer4.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}[0m
[34mbackbone.clip_model.visual.layer4.2.conv1.weight[0m
[34mbackbone.clip_model.visual.layer4.2.conv2.weight[0m
[34mbackbone.clip_model.visual.layer4.2.conv3.weight[0m
[34mbackbone.clip_model.{logit_scale, positional_embedding, text_projection}[0m
[34mbn1.{bias, running_mean, running_var, weight}[0m
[34mbn2.{bias, running_mean, running_var, weight}[0m
[34mconv1.{bias, weight}[0m
[34mconv2.{bias, weight}[0m
[34mcriterion.empty_weight[0m
[34mdecoder_adapter.conv1.{bias, weight}[0m
[34mdecoder_adapter.conv2.{bias, weight}[0m
[34mdecoder_adapter.norm1.{bias, weight}[0m
[34mdecoder_adapter.norm2.{bias, weight}[0m
[10/09 21:47:39] d2.engine.train_loop INFO: Starting training from iteration 0
[10/09 21:47:56] d2.utils.events INFO:  eta: 0:08:56  iter: 2499  total_loss: 19.25  loss_ce: 0.4243  loss_mask: 0.1461  loss_dice: 1.218  loss_ce_0: 0.5354  loss_mask_0: 0.1693  loss_dice_0: 1.423  loss_ce_1: 0.5642  loss_mask_1: 0.1591  loss_dice_1: 1.382  loss_ce_2: 0.5002  loss_mask_2: 0.1516  loss_dice_2: 1.305  loss_ce_3: 0.4568  loss_mask_3: 0.1513  loss_dice_3: 1.278  loss_ce_4: 0.4328  loss_mask_4: 0.1513  loss_dice_4: 1.225  loss_ce_5: 0.4381  loss_mask_5: 0.1502  loss_dice_5: 1.244  loss_ce_6: 0.4455  loss_mask_6: 0.1466  loss_dice_6: 1.233  loss_ce_7: 0.4186  loss_mask_7: 0.1483  loss_dice_7: 1.212  loss_ce_8: 0.4057  loss_mask_8: 0.1443  loss_dice_8: 1.204    time: 1.0728  last_time: 1.1114  data_time: 0.0795  last_data_time: 0.0871   lr: 0.0001  max_mem: 33192M
[10/09 21:48:03] d2.utils.events INFO:  eta: 0:52:42  iter: 19  total_loss: 32.12  loss_ce: 1.163  loss_mask: 0.2982  loss_dice: 1.497  loss_ce_0: 1.535  loss_mask_0: 0.312  loss_dice_0: 1.834  loss_ce_1: 1.518  loss_mask_1: 0.3117  loss_dice_1: 1.691  loss_ce_2: 1.415  loss_mask_2: 0.3047  loss_dice_2: 1.637  loss_ce_3: 1.321  loss_mask_3: 0.3082  loss_dice_3: 1.558  loss_ce_4: 1.294  loss_mask_4: 0.3096  loss_dice_4: 1.569  loss_ce_5: 1.183  loss_mask_5: 0.3015  loss_dice_5: 1.568  loss_ce_6: 1.244  loss_mask_6: 0.3014  loss_dice_6: 1.563  loss_ce_7: 1.224  loss_mask_7: 0.3028  loss_dice_7: 1.525  loss_ce_8: 1.199  loss_mask_8: 0.3017  loss_dice_8: 1.535    time: 1.0745  last_time: 1.0992  data_time: 0.1024  last_data_time: 0.0680   lr: 0.0001  max_mem: 31357M
[10/09 21:48:18] d2.utils.events INFO:  eta: 0:08:35  iter: 2519  total_loss: 19.41  loss_ce: 0.4401  loss_mask: 0.1631  loss_dice: 1.216  loss_ce_0: 0.5715  loss_mask_0: 0.1999  loss_dice_0: 1.4  loss_ce_1: 0.5995  loss_mask_1: 0.1744  loss_dice_1: 1.31  loss_ce_2: 0.5312  loss_mask_2: 0.1691  loss_dice_2: 1.271  loss_ce_3: 0.5042  loss_mask_3: 0.1626  loss_dice_3: 1.233  loss_ce_4: 0.4614  loss_mask_4: 0.1638  loss_dice_4: 1.201  loss_ce_5: 0.4587  loss_mask_5: 0.1634  loss_dice_5: 1.231  loss_ce_6: 0.4389  loss_mask_6: 0.1632  loss_dice_6: 1.197  loss_ce_7: 0.4481  loss_mask_7: 0.1623  loss_dice_7: 1.195  loss_ce_8: 0.4513  loss_mask_8: 0.1628  loss_dice_8: 1.21    time: 1.0728  last_time: 1.0834  data_time: 0.0738  last_data_time: 0.0815   lr: 0.0001  max_mem: 33192M
[10/09 21:48:24] d2.utils.events INFO:  eta: 0:51:42  iter: 39  total_loss: 25.49  loss_ce: 0.7649  loss_mask: 0.2341  loss_dice: 1.423  loss_ce_0: 0.8323  loss_mask_0: 0.2526  loss_dice_0: 1.757  loss_ce_1: 0.9712  loss_mask_1: 0.2505  loss_dice_1: 1.62  loss_ce_2: 0.8945  loss_mask_2: 0.2417  loss_dice_2: 1.552  loss_ce_3: 0.8066  loss_mask_3: 0.239  loss_dice_3: 1.464  loss_ce_4: 0.7884  loss_mask_4: 0.2368  loss_dice_4: 1.479  loss_ce_5: 0.7982  loss_mask_5: 0.237  loss_dice_5: 1.427  loss_ce_6: 0.7504  loss_mask_6: 0.2319  loss_dice_6: 1.431  loss_ce_7: 0.7821  loss_mask_7: 0.2352  loss_dice_7: 1.411  loss_ce_8: 0.7491  loss_mask_8: 0.2344  loss_dice_8: 1.442    time: 1.0576  last_time: 1.0723  data_time: 0.0670  last_data_time: 0.0551   lr: 0.0001  max_mem: 32383M
[10/09 21:48:40] d2.utils.events INFO:  eta: 0:08:14  iter: 2539  total_loss: 20.04  loss_ce: 0.4743  loss_mask: 0.149  loss_dice: 1.231  loss_ce_0: 0.5524  loss_mask_0: 0.1784  loss_dice_0: 1.487  loss_ce_1: 0.5666  loss_mask_1: 0.1602  loss_dice_1: 1.366  loss_ce_2: 0.5128  loss_mask_2: 0.1531  loss_dice_2: 1.337  loss_ce_3: 0.4674  loss_mask_3: 0.148  loss_dice_3: 1.309  loss_ce_4: 0.4741  loss_mask_4: 0.1465  loss_dice_4: 1.305  loss_ce_5: 0.4653  loss_mask_5: 0.1469  loss_dice_5: 1.313  loss_ce_6: 0.4407  loss_mask_6: 0.1473  loss_dice_6: 1.306  loss_ce_7: 0.4683  loss_mask_7: 0.1468  loss_dice_7: 1.325  loss_ce_8: 0.4508  loss_mask_8: 0.1495  loss_dice_8: 1.275    time: 1.0730  last_time: 1.0503  data_time: 0.0812  last_data_time: 0.0719   lr: 0.0001  max_mem: 33192M
[10/09 21:48:45] d2.utils.events INFO:  eta: 0:51:14  iter: 59  total_loss: 24.2  loss_ce: 0.7067  loss_mask: 0.2142  loss_dice: 1.391  loss_ce_0: 0.7564  loss_mask_0: 0.2432  loss_dice_0: 1.703  loss_ce_1: 0.8431  loss_mask_1: 0.2338  loss_dice_1: 1.598  loss_ce_2: 0.778  loss_mask_2: 0.2252  loss_dice_2: 1.511  loss_ce_3: 0.7379  loss_mask_3: 0.215  loss_dice_3: 1.449  loss_ce_4: 0.7189  loss_mask_4: 0.2154  loss_dice_4: 1.446  loss_ce_5: 0.6942  loss_mask_5: 0.2203  loss_dice_5: 1.461  loss_ce_6: 0.6948  loss_mask_6: 0.217  loss_dice_6: 1.391  loss_ce_7: 0.6736  loss_mask_7: 0.2175  loss_dice_7: 1.397  loss_ce_8: 0.676  loss_mask_8: 0.2204  loss_dice_8: 1.398    time: 1.0518  last_time: 1.0385  data_time: 0.0689  last_data_time: 0.0678   lr: 0.0001  max_mem: 32383M
[10/09 21:49:02] d2.utils.events INFO:  eta: 0:07:52  iter: 2559  total_loss: 18.41  loss_ce: 0.423  loss_mask: 0.1471  loss_dice: 1.176  loss_ce_0: 0.5812  loss_mask_0: 0.1681  loss_dice_0: 1.356  loss_ce_1: 0.6287  loss_mask_1: 0.1594  loss_dice_1: 1.28  loss_ce_2: 0.5764  loss_mask_2: 0.1503  loss_dice_2: 1.23  loss_ce_3: 0.495  loss_mask_3: 0.1474  loss_dice_3: 1.192  loss_ce_4: 0.4712  loss_mask_4: 0.1495  loss_dice_4: 1.184  loss_ce_5: 0.4691  loss_mask_5: 0.1483  loss_dice_5: 1.189  loss_ce_6: 0.4279  loss_mask_6: 0.1466  loss_dice_6: 1.149  loss_ce_7: 0.4355  loss_mask_7: 0.1472  loss_dice_7: 1.147  loss_ce_8: 0.4135  loss_mask_8: 0.1452  loss_dice_8: 1.155    time: 1.0731  last_time: 1.0449  data_time: 0.0745  last_data_time: 0.0769   lr: 0.0001  max_mem: 33192M
[10/09 21:49:06] d2.utils.events INFO:  eta: 0:51:01  iter: 79  total_loss: 24.38  loss_ce: 0.6567  loss_mask: 0.1984  loss_dice: 1.419  loss_ce_0: 0.7258  loss_mask_0: 0.2429  loss_dice_0: 1.698  loss_ce_1: 0.8525  loss_mask_1: 0.22  loss_dice_1: 1.573  loss_ce_2: 0.7567  loss_mask_2: 0.2071  loss_dice_2: 1.515  loss_ce_3: 0.7243  loss_mask_3: 0.206  loss_dice_3: 1.442  loss_ce_4: 0.6919  loss_mask_4: 0.2086  loss_dice_4: 1.464  loss_ce_5: 0.7008  loss_mask_5: 0.2004  loss_dice_5: 1.425  loss_ce_6: 0.6514  loss_mask_6: 0.2058  loss_dice_6: 1.422  loss_ce_7: 0.6467  loss_mask_7: 0.2032  loss_dice_7: 1.41  loss_ce_8: 0.6437  loss_mask_8: 0.2033  loss_dice_8: 1.425    time: 1.0531  last_time: 1.0596  data_time: 0.0719  last_data_time: 0.1018   lr: 0.0001  max_mem: 32383M
[10/09 21:49:24] d2.utils.events INFO:  eta: 0:07:31  iter: 2579  total_loss: 19.22  loss_ce: 0.4317  loss_mask: 0.1545  loss_dice: 1.186  loss_ce_0: 0.5527  loss_mask_0: 0.1814  loss_dice_0: 1.404  loss_ce_1: 0.6371  loss_mask_1: 0.165  loss_dice_1: 1.343  loss_ce_2: 0.55  loss_mask_2: 0.159  loss_dice_2: 1.295  loss_ce_3: 0.4933  loss_mask_3: 0.1565  loss_dice_3: 1.244  loss_ce_4: 0.4334  loss_mask_4: 0.1548  loss_dice_4: 1.228  loss_ce_5: 0.4538  loss_mask_5: 0.1569  loss_dice_5: 1.24  loss_ce_6: 0.4241  loss_mask_6: 0.1556  loss_dice_6: 1.195  loss_ce_7: 0.468  loss_mask_7: 0.1547  loss_dice_7: 1.186  loss_ce_8: 0.4385  loss_mask_8: 0.1541  loss_dice_8: 1.171    time: 1.0733  last_time: 1.1025  data_time: 0.0786  last_data_time: 0.0912   lr: 0.0001  max_mem: 33192M
[10/09 21:49:27] d2.utils.events INFO:  eta: 0:50:20  iter: 99  total_loss: 22.95  loss_ce: 0.5739  loss_mask: 0.2022  loss_dice: 1.312  loss_ce_0: 0.6912  loss_mask_0: 0.2313  loss_dice_0: 1.58  loss_ce_1: 0.7662  loss_mask_1: 0.2174  loss_dice_1: 1.511  loss_ce_2: 0.6805  loss_mask_2: 0.2117  loss_dice_2: 1.409  loss_ce_3: 0.6291  loss_mask_3: 0.2091  loss_dice_3: 1.368  loss_ce_4: 0.6307  loss_mask_4: 0.208  loss_dice_4: 1.395  loss_ce_5: 0.5818  loss_mask_5: 0.203  loss_dice_5: 1.35  loss_ce_6: 0.6028  loss_mask_6: 0.2046  loss_dice_6: 1.322  loss_ce_7: 0.6077  loss_mask_7: 0.2027  loss_dice_7: 1.342  loss_ce_8: 0.5774  loss_mask_8: 0.2016  loss_dice_8: 1.348    time: 1.0489  last_time: 1.0312  data_time: 0.0655  last_data_time: 0.0602   lr: 0.0001  max_mem: 32383M
[10/09 21:49:46] d2.utils.events INFO:  eta: 0:07:10  iter: 2599  total_loss: 18.7  loss_ce: 0.4501  loss_mask: 0.1499  loss_dice: 1.17  loss_ce_0: 0.5395  loss_mask_0: 0.1716  loss_dice_0: 1.364  loss_ce_1: 0.6256  loss_mask_1: 0.1615  loss_dice_1: 1.29  loss_ce_2: 0.5547  loss_mask_2: 0.1534  loss_dice_2: 1.249  loss_ce_3: 0.4954  loss_mask_3: 0.1512  loss_dice_3: 1.177  loss_ce_4: 0.4716  loss_mask_4: 0.1493  loss_dice_4: 1.186  loss_ce_5: 0.4515  loss_mask_5: 0.1493  loss_dice_5: 1.21  loss_ce_6: 0.4621  loss_mask_6: 0.1487  loss_dice_6: 1.169  loss_ce_7: 0.4299  loss_mask_7: 0.1488  loss_dice_7: 1.141  loss_ce_8: 0.4216  loss_mask_8: 0.1478  loss_dice_8: 1.163    time: 1.0734  last_time: 1.0758  data_time: 0.0797  last_data_time: 0.1018   lr: 0.0001  max_mem: 33192M
[10/09 21:49:48] d2.utils.events INFO:  eta: 0:50:17  iter: 119  total_loss: 23.72  loss_ce: 0.6349  loss_mask: 0.1722  loss_dice: 1.394  loss_ce_0: 0.731  loss_mask_0: 0.1959  loss_dice_0: 1.72  loss_ce_1: 0.8412  loss_mask_1: 0.185  loss_dice_1: 1.563  loss_ce_2: 0.7484  loss_mask_2: 0.18  loss_dice_2: 1.513  loss_ce_3: 0.7074  loss_mask_3: 0.174  loss_dice_3: 1.425  loss_ce_4: 0.6618  loss_mask_4: 0.1755  loss_dice_4: 1.447  loss_ce_5: 0.6684  loss_mask_5: 0.173  loss_dice_5: 1.455  loss_ce_6: 0.683  loss_mask_6: 0.1701  loss_dice_6: 1.395  loss_ce_7: 0.6408  loss_mask_7: 0.1758  loss_dice_7: 1.404  loss_ce_8: 0.6612  loss_mask_8: 0.1725  loss_dice_8: 1.413    time: 1.0508  last_time: 1.1567  data_time: 0.0686  last_data_time: 0.0610   lr: 0.0001  max_mem: 32383M
[10/09 21:50:07] d2.utils.events INFO:  eta: 0:06:48  iter: 2619  total_loss: 17.16  loss_ce: 0.3691  loss_mask: 0.1529  loss_dice: 1.084  loss_ce_0: 0.527  loss_mask_0: 0.175  loss_dice_0: 1.3  loss_ce_1: 0.527  loss_mask_1: 0.163  loss_dice_1: 1.194  loss_ce_2: 0.4768  loss_mask_2: 0.1603  loss_dice_2: 1.155  loss_ce_3: 0.4279  loss_mask_3: 0.1547  loss_dice_3: 1.121  loss_ce_4: 0.4085  loss_mask_4: 0.1565  loss_dice_4: 1.111  loss_ce_5: 0.4049  loss_mask_5: 0.153  loss_dice_5: 1.106  loss_ce_6: 0.3882  loss_mask_6: 0.1519  loss_dice_6: 1.075  loss_ce_7: 0.3616  loss_mask_7: 0.1527  loss_dice_7: 1.066  loss_ce_8: 0.3842  loss_mask_8: 0.1511  loss_dice_8: 1.087    time: 1.0733  last_time: 1.0465  data_time: 0.0704  last_data_time: 0.0780   lr: 0.0001  max_mem: 33192M
[10/09 21:50:09] d2.utils.events INFO:  eta: 0:49:58  iter: 139  total_loss: 22.05  loss_ce: 0.5861  loss_mask: 0.2073  loss_dice: 1.297  loss_ce_0: 0.6864  loss_mask_0: 0.2381  loss_dice_0: 1.565  loss_ce_1: 0.7762  loss_mask_1: 0.2213  loss_dice_1: 1.437  loss_ce_2: 0.6879  loss_mask_2: 0.2171  loss_dice_2: 1.374  loss_ce_3: 0.6113  loss_mask_3: 0.211  loss_dice_3: 1.329  loss_ce_4: 0.5938  loss_mask_4: 0.2152  loss_dice_4: 1.332  loss_ce_5: 0.6146  loss_mask_5: 0.211  loss_dice_5: 1.324  loss_ce_6: 0.59  loss_mask_6: 0.2091  loss_dice_6: 1.305  loss_ce_7: 0.611  loss_mask_7: 0.2104  loss_dice_7: 1.302  loss_ce_8: 0.6045  loss_mask_8: 0.2072  loss_dice_8: 1.308    time: 1.0505  last_time: 1.0377  data_time: 0.0632  last_data_time: 0.0620   lr: 0.0001  max_mem: 32383M
[10/09 21:50:28] d2.utils.events INFO:  eta: 0:06:27  iter: 2639  total_loss: 19.02  loss_ce: 0.4053  loss_mask: 0.1524  loss_dice: 1.171  loss_ce_0: 0.5632  loss_mask_0: 0.1836  loss_dice_0: 1.356  loss_ce_1: 0.5539  loss_mask_1: 0.1646  loss_dice_1: 1.274  loss_ce_2: 0.527  loss_mask_2: 0.157  loss_dice_2: 1.262  loss_ce_3: 0.4384  loss_mask_3: 0.1531  loss_dice_3: 1.233  loss_ce_4: 0.4074  loss_mask_4: 0.1533  loss_dice_4: 1.218  loss_ce_5: 0.4136  loss_mask_5: 0.1545  loss_dice_5: 1.226  loss_ce_6: 0.4077  loss_mask_6: 0.1553  loss_dice_6: 1.188  loss_ce_7: 0.3964  loss_mask_7: 0.1551  loss_dice_7: 1.189  loss_ce_8: 0.3897  loss_mask_8: 0.1537  loss_dice_8: 1.159    time: 1.0733  last_time: 1.1465  data_time: 0.0761  last_data_time: 0.0693   lr: 0.0001  max_mem: 33192M
[10/09 21:50:30] d2.utils.events INFO:  eta: 0:49:29  iter: 159  total_loss: 21.88  loss_ce: 0.5299  loss_mask: 0.193  loss_dice: 1.302  loss_ce_0: 0.6203  loss_mask_0: 0.2365  loss_dice_0: 1.577  loss_ce_1: 0.7626  loss_mask_1: 0.2083  loss_dice_1: 1.472  loss_ce_2: 0.6652  loss_mask_2: 0.2012  loss_dice_2: 1.409  loss_ce_3: 0.6033  loss_mask_3: 0.1973  loss_dice_3: 1.37  loss_ce_4: 0.5891  loss_mask_4: 0.1961  loss_dice_4: 1.339  loss_ce_5: 0.5898  loss_mask_5: 0.1964  loss_dice_5: 1.336  loss_ce_6: 0.5592  loss_mask_6: 0.1891  loss_dice_6: 1.304  loss_ce_7: 0.5605  loss_mask_7: 0.1912  loss_dice_7: 1.285  loss_ce_8: 0.5739  loss_mask_8: 0.1943  loss_dice_8: 1.3    time: 1.0489  last_time: 1.0818  data_time: 0.0645  last_data_time: 0.0683   lr: 0.0001  max_mem: 32383M
[10/09 21:50:50] d2.utils.events INFO:  eta: 0:06:05  iter: 2659  total_loss: 18.06  loss_ce: 0.4067  loss_mask: 0.1648  loss_dice: 1.149  loss_ce_0: 0.4984  loss_mask_0: 0.1846  loss_dice_0: 1.285  loss_ce_1: 0.5541  loss_mask_1: 0.1724  loss_dice_1: 1.232  loss_ce_2: 0.5062  loss_mask_2: 0.173  loss_dice_2: 1.236  loss_ce_3: 0.4323  loss_mask_3: 0.1667  loss_dice_3: 1.163  loss_ce_4: 0.3987  loss_mask_4: 0.1673  loss_dice_4: 1.182  loss_ce_5: 0.3946  loss_mask_5: 0.165  loss_dice_5: 1.168  loss_ce_6: 0.4375  loss_mask_6: 0.1646  loss_dice_6: 1.156  loss_ce_7: 0.397  loss_mask_7: 0.165  loss_dice_7: 1.138  loss_ce_8: 0.4179  loss_mask_8: 0.1662  loss_dice_8: 1.162    time: 1.0733  last_time: 1.0297  data_time: 0.0742  last_data_time: 0.0758   lr: 0.0001  max_mem: 33192M
[10/09 21:50:51] d2.utils.events INFO:  eta: 0:49:12  iter: 179  total_loss: 22.7  loss_ce: 0.6007  loss_mask: 0.191  loss_dice: 1.345  loss_ce_0: 0.6831  loss_mask_0: 0.2324  loss_dice_0: 1.591  loss_ce_1: 0.8272  loss_mask_1: 0.2118  loss_dice_1: 1.509  loss_ce_2: 0.733  loss_mask_2: 0.202  loss_dice_2: 1.407  loss_ce_3: 0.698  loss_mask_3: 0.2059  loss_dice_3: 1.418  loss_ce_4: 0.6505  loss_mask_4: 0.1968  loss_dice_4: 1.353  loss_ce_5: 0.6147  loss_mask_5: 0.1958  loss_dice_5: 1.37  loss_ce_6: 0.6124  loss_mask_6: 0.1956  loss_dice_6: 1.34  loss_ce_7: 0.6012  loss_mask_7: 0.1978  loss_dice_7: 1.336  loss_ce_8: 0.6017  loss_mask_8: 0.1919  loss_dice_8: 1.357    time: 1.0498  last_time: 1.0931  data_time: 0.0715  last_data_time: 0.0687   lr: 0.0001  max_mem: 32456M
[10/09 21:51:12] d2.utils.events INFO:  eta: 0:05:44  iter: 2679  total_loss: 19.36  loss_ce: 0.4411  loss_mask: 0.1568  loss_dice: 1.192  loss_ce_0: 0.5664  loss_mask_0: 0.1868  loss_dice_0: 1.367  loss_ce_1: 0.6038  loss_mask_1: 0.1715  loss_dice_1: 1.313  loss_ce_2: 0.5333  loss_mask_2: 0.1626  loss_dice_2: 1.254  loss_ce_3: 0.4676  loss_mask_3: 0.1615  loss_dice_3: 1.23  loss_ce_4: 0.451  loss_mask_4: 0.1572  loss_dice_4: 1.227  loss_ce_5: 0.4213  loss_mask_5: 0.1571  loss_dice_5: 1.21  loss_ce_6: 0.4455  loss_mask_6: 0.1583  loss_dice_6: 1.177  loss_ce_7: 0.4286  loss_mask_7: 0.1551  loss_dice_7: 1.171  loss_ce_8: 0.426  loss_mask_8: 0.1563  loss_dice_8: 1.177    time: 1.0734  last_time: 1.0898  data_time: 0.0784  last_data_time: 0.0963   lr: 0.0001  max_mem: 33192M
[10/09 21:51:12] d2.utils.events INFO:  eta: 0:48:57  iter: 199  total_loss: 21.66  loss_ce: 0.6107  loss_mask: 0.1879  loss_dice: 1.289  loss_ce_0: 0.6443  loss_mask_0: 0.2235  loss_dice_0: 1.557  loss_ce_1: 0.7416  loss_mask_1: 0.2133  loss_dice_1: 1.437  loss_ce_2: 0.6906  loss_mask_2: 0.2065  loss_dice_2: 1.359  loss_ce_3: 0.6582  loss_mask_3: 0.2022  loss_dice_3: 1.315  loss_ce_4: 0.644  loss_mask_4: 0.2006  loss_dice_4: 1.296  loss_ce_5: 0.6281  loss_mask_5: 0.1992  loss_dice_5: 1.301  loss_ce_6: 0.6004  loss_mask_6: 0.1987  loss_dice_6: 1.28  loss_ce_7: 0.6085  loss_mask_7: 0.1985  loss_dice_7: 1.268  loss_ce_8: 0.6025  loss_mask_8: 0.1982  loss_dice_8: 1.242    time: 1.0520  last_time: 1.0301  data_time: 0.0742  last_data_time: 0.0786   lr: 0.0001  max_mem: 32456M
[10/09 21:51:33] d2.utils.events INFO:  eta: 0:05:22  iter: 2699  total_loss: 17.98  loss_ce: 0.3922  loss_mask: 0.1592  loss_dice: 1.101  loss_ce_0: 0.5469  loss_mask_0: 0.1902  loss_dice_0: 1.285  loss_ce_1: 0.5543  loss_mask_1: 0.1706  loss_dice_1: 1.236  loss_ce_2: 0.5238  loss_mask_2: 0.1659  loss_dice_2: 1.173  loss_ce_3: 0.4402  loss_mask_3: 0.162  loss_dice_3: 1.109  loss_ce_4: 0.4107  loss_mask_4: 0.1623  loss_dice_4: 1.128  loss_ce_5: 0.4089  loss_mask_5: 0.1655  loss_dice_5: 1.11  loss_ce_6: 0.4007  loss_mask_6: 0.1627  loss_dice_6: 1.106  loss_ce_7: 0.3774  loss_mask_7: 0.1609  loss_dice_7: 1.124  loss_ce_8: 0.4085  loss_mask_8: 0.1595  loss_dice_8: 1.063    time: 1.0734  last_time: 1.0444  data_time: 0.0775  last_data_time: 0.0695   lr: 0.0001  max_mem: 33192M
[10/09 21:51:34] d2.utils.events INFO:  eta: 0:48:38  iter: 219  total_loss: 21.59  loss_ce: 0.6044  loss_mask: 0.1842  loss_dice: 1.278  loss_ce_0: 0.6449  loss_mask_0: 0.2184  loss_dice_0: 1.517  loss_ce_1: 0.7673  loss_mask_1: 0.1972  loss_dice_1: 1.434  loss_ce_2: 0.6815  loss_mask_2: 0.1889  loss_dice_2: 1.381  loss_ce_3: 0.607  loss_mask_3: 0.1866  loss_dice_3: 1.306  loss_ce_4: 0.593  loss_mask_4: 0.1825  loss_dice_4: 1.333  loss_ce_5: 0.5931  loss_mask_5: 0.1831  loss_dice_5: 1.321  loss_ce_6: 0.5755  loss_mask_6: 0.1858  loss_dice_6: 1.327  loss_ce_7: 0.5776  loss_mask_7: 0.185  loss_dice_7: 1.254  loss_ce_8: 0.5847  loss_mask_8: 0.1842  loss_dice_8: 1.276    time: 1.0535  last_time: 1.0298  data_time: 0.0756  last_data_time: 0.0669   lr: 0.0001  max_mem: 32456M
[10/09 21:51:55] d2.utils.events INFO:  eta: 0:05:00  iter: 2719  total_loss: 18.73  loss_ce: 0.4393  loss_mask: 0.1499  loss_dice: 1.156  loss_ce_0: 0.595  loss_mask_0: 0.1752  loss_dice_0: 1.36  loss_ce_1: 0.6315  loss_mask_1: 0.1642  loss_dice_1: 1.305  loss_ce_2: 0.5386  loss_mask_2: 0.1564  loss_dice_2: 1.253  loss_ce_3: 0.4793  loss_mask_3: 0.1565  loss_dice_3: 1.224  loss_ce_4: 0.4438  loss_mask_4: 0.1567  loss_dice_4: 1.204  loss_ce_5: 0.4406  loss_mask_5: 0.1538  loss_dice_5: 1.196  loss_ce_6: 0.4344  loss_mask_6: 0.1527  loss_dice_6: 1.203  loss_ce_7: 0.4563  loss_mask_7: 0.154  loss_dice_7: 1.184  loss_ce_8: 0.454  loss_mask_8: 0.1515  loss_dice_8: 1.188    time: 1.0735  last_time: 1.0724  data_time: 0.0750  last_data_time: 0.0678   lr: 0.0001  max_mem: 33192M
[10/09 21:51:55] d2.utils.events INFO:  eta: 0:48:18  iter: 239  total_loss: 20.64  loss_ce: 0.5514  loss_mask: 0.1926  loss_dice: 1.23  loss_ce_0: 0.6149  loss_mask_0: 0.2385  loss_dice_0: 1.533  loss_ce_1: 0.7089  loss_mask_1: 0.2141  loss_dice_1: 1.418  loss_ce_2: 0.6251  loss_mask_2: 0.2002  loss_dice_2: 1.321  loss_ce_3: 0.5715  loss_mask_3: 0.2028  loss_dice_3: 1.264  loss_ce_4: 0.5543  loss_mask_4: 0.1994  loss_dice_4: 1.295  loss_ce_5: 0.5398  loss_mask_5: 0.1955  loss_dice_5: 1.27  loss_ce_6: 0.5447  loss_mask_6: 0.1961  loss_dice_6: 1.273  loss_ce_7: 0.5303  loss_mask_7: 0.1932  loss_dice_7: 1.249  loss_ce_8: 0.5092  loss_mask_8: 0.1929  loss_dice_8: 1.245    time: 1.0541  last_time: 1.0544  data_time: 0.0717  last_data_time: 0.0578   lr: 0.0001  max_mem: 32456M
[10/09 21:52:17] d2.utils.events INFO:  eta: 0:04:39  iter: 2739  total_loss: 19.81  loss_ce: 0.4457  loss_mask: 0.1492  loss_dice: 1.216  loss_ce_0: 0.5466  loss_mask_0: 0.1768  loss_dice_0: 1.424  loss_ce_1: 0.5706  loss_mask_1: 0.159  loss_dice_1: 1.354  loss_ce_2: 0.55  loss_mask_2: 0.1536  loss_dice_2: 1.319  loss_ce_3: 0.4901  loss_mask_3: 0.1532  loss_dice_3: 1.233  loss_ce_4: 0.4485  loss_mask_4: 0.1499  loss_dice_4: 1.251  loss_ce_5: 0.4753  loss_mask_5: 0.1524  loss_dice_5: 1.242  loss_ce_6: 0.4701  loss_mask_6: 0.1507  loss_dice_6: 1.247  loss_ce_7: 0.4415  loss_mask_7: 0.1511  loss_dice_7: 1.249  loss_ce_8: 0.4558  loss_mask_8: 0.151  loss_dice_8: 1.244    time: 1.0736  last_time: 1.0654  data_time: 0.0822  last_data_time: 0.0783   lr: 0.0001  max_mem: 33192M
[10/09 21:52:17] d2.utils.events INFO:  eta: 0:48:00  iter: 259  total_loss: 22.52  loss_ce: 0.5766  loss_mask: 0.1879  loss_dice: 1.347  loss_ce_0: 0.6507  loss_mask_0: 0.2179  loss_dice_0: 1.587  loss_ce_1: 0.7704  loss_mask_1: 0.2011  loss_dice_1: 1.488  loss_ce_2: 0.7292  loss_mask_2: 0.1967  loss_dice_2: 1.411  loss_ce_3: 0.6777  loss_mask_3: 0.1991  loss_dice_3: 1.326  loss_ce_4: 0.6372  loss_mask_4: 0.1973  loss_dice_4: 1.346  loss_ce_5: 0.6392  loss_mask_5: 0.1914  loss_dice_5: 1.319  loss_ce_6: 0.6116  loss_mask_6: 0.187  loss_dice_6: 1.304  loss_ce_7: 0.625  loss_mask_7: 0.1864  loss_dice_7: 1.295  loss_ce_8: 0.5854  loss_mask_8: 0.1857  loss_dice_8: 1.322    time: 1.0558  last_time: 1.1012  data_time: 0.0755  last_data_time: 0.0873   lr: 0.0001  max_mem: 32772M
[10/09 21:52:38] d2.utils.events INFO:  eta: 0:04:17  iter: 2759  total_loss: 17.7  loss_ce: 0.4496  loss_mask: 0.1635  loss_dice: 1.13  loss_ce_0: 0.4793  loss_mask_0: 0.1837  loss_dice_0: 1.353  loss_ce_1: 0.5655  loss_mask_1: 0.1767  loss_dice_1: 1.234  loss_ce_2: 0.5251  loss_mask_2: 0.1709  loss_dice_2: 1.226  loss_ce_3: 0.4676  loss_mask_3: 0.1687  loss_dice_3: 1.168  loss_ce_4: 0.457  loss_mask_4: 0.1671  loss_dice_4: 1.178  loss_ce_5: 0.4354  loss_mask_5: 0.166  loss_dice_5: 1.167  loss_ce_6: 0.4091  loss_mask_6: 0.1657  loss_dice_6: 1.16  loss_ce_7: 0.4136  loss_mask_7: 0.1658  loss_dice_7: 1.121  loss_ce_8: 0.4292  loss_mask_8: 0.1637  loss_dice_8: 1.133    time: 1.0734  last_time: 1.0605  data_time: 0.0682  last_data_time: 0.0654   lr: 0.0001  max_mem: 33192M
[10/09 21:52:38] d2.utils.events INFO:  eta: 0:47:39  iter: 279  total_loss: 21.96  loss_ce: 0.5563  loss_mask: 0.1887  loss_dice: 1.336  loss_ce_0: 0.6007  loss_mask_0: 0.213  loss_dice_0: 1.51  loss_ce_1: 0.7227  loss_mask_1: 0.2065  loss_dice_1: 1.418  loss_ce_2: 0.6602  loss_mask_2: 0.1972  loss_dice_2: 1.389  loss_ce_3: 0.6314  loss_mask_3: 0.1974  loss_dice_3: 1.371  loss_ce_4: 0.5929  loss_mask_4: 0.1966  loss_dice_4: 1.33  loss_ce_5: 0.5959  loss_mask_5: 0.1941  loss_dice_5: 1.337  loss_ce_6: 0.5972  loss_mask_6: 0.194  loss_dice_6: 1.318  loss_ce_7: 0.5668  loss_mask_7: 0.1885  loss_dice_7: 1.33  loss_ce_8: 0.609  loss_mask_8: 0.1918  loss_dice_8: 1.333    time: 1.0565  last_time: 1.1389  data_time: 0.0749  last_data_time: 0.0814   lr: 0.0001  max_mem: 32772M
[10/09 21:52:59] d2.utils.events INFO:  eta: 0:03:56  iter: 2779  total_loss: 18.9  loss_ce: 0.3994  loss_mask: 0.1621  loss_dice: 1.172  loss_ce_0: 0.4975  loss_mask_0: 0.1732  loss_dice_0: 1.362  loss_ce_1: 0.5501  loss_mask_1: 0.1706  loss_dice_1: 1.332  loss_ce_2: 0.5305  loss_mask_2: 0.16  loss_dice_2: 1.277  loss_ce_3: 0.4436  loss_mask_3: 0.1639  loss_dice_3: 1.176  loss_ce_4: 0.413  loss_mask_4: 0.1597  loss_dice_4: 1.193  loss_ce_5: 0.433  loss_mask_5: 0.1588  loss_dice_5: 1.208  loss_ce_6: 0.4174  loss_mask_6: 0.1607  loss_dice_6: 1.197  loss_ce_7: 0.4123  loss_mask_7: 0.1602  loss_dice_7: 1.193  loss_ce_8: 0.4003  loss_mask_8: 0.1595  loss_dice_8: 1.19    time: 1.0734  last_time: 1.0834  data_time: 0.0756  last_data_time: 0.0714   lr: 0.0001  max_mem: 33192M
[10/09 21:53:00] d2.utils.events INFO:  eta: 0:47:25  iter: 299  total_loss: 21.33  loss_ce: 0.5541  loss_mask: 0.1883  loss_dice: 1.291  loss_ce_0: 0.6466  loss_mask_0: 0.2197  loss_dice_0: 1.513  loss_ce_1: 0.7389  loss_mask_1: 0.2026  loss_dice_1: 1.423  loss_ce_2: 0.6874  loss_mask_2: 0.1941  loss_dice_2: 1.372  loss_ce_3: 0.5863  loss_mask_3: 0.1906  loss_dice_3: 1.321  loss_ce_4: 0.5774  loss_mask_4: 0.1918  loss_dice_4: 1.318  loss_ce_5: 0.5745  loss_mask_5: 0.1902  loss_dice_5: 1.315  loss_ce_6: 0.5677  loss_mask_6: 0.1891  loss_dice_6: 1.28  loss_ce_7: 0.5444  loss_mask_7: 0.189  loss_dice_7: 1.284  loss_ce_8: 0.5742  loss_mask_8: 0.1878  loss_dice_8: 1.279    time: 1.0585  last_time: 1.0568  data_time: 0.0785  last_data_time: 0.0781   lr: 0.0001  max_mem: 32772M
[10/09 21:53:21] d2.utils.events INFO:  eta: 0:03:34  iter: 2799  total_loss: 18.22  loss_ce: 0.44  loss_mask: 0.1431  loss_dice: 1.186  loss_ce_0: 0.536  loss_mask_0: 0.1639  loss_dice_0: 1.389  loss_ce_1: 0.5822  loss_mask_1: 0.1537  loss_dice_1: 1.319  loss_ce_2: 0.54  loss_mask_2: 0.1536  loss_dice_2: 1.249  loss_ce_3: 0.46  loss_mask_3: 0.1448  loss_dice_3: 1.205  loss_ce_4: 0.44  loss_mask_4: 0.1463  loss_dice_4: 1.189  loss_ce_5: 0.4108  loss_mask_5: 0.1478  loss_dice_5: 1.209  loss_ce_6: 0.4247  loss_mask_6: 0.1446  loss_dice_6: 1.185  loss_ce_7: 0.4686  loss_mask_7: 0.1435  loss_dice_7: 1.158  loss_ce_8: 0.4419  loss_mask_8: 0.1436  loss_dice_8: 1.172    time: 1.0734  last_time: 1.0708  data_time: 0.0768  last_data_time: 0.0926   lr: 0.0001  max_mem: 33192M
[10/09 21:53:22] d2.utils.events INFO:  eta: 0:47:08  iter: 319  total_loss: 20.94  loss_ce: 0.559  loss_mask: 0.1922  loss_dice: 1.243  loss_ce_0: 0.5703  loss_mask_0: 0.2247  loss_dice_0: 1.483  loss_ce_1: 0.6564  loss_mask_1: 0.2082  loss_dice_1: 1.416  loss_ce_2: 0.5766  loss_mask_2: 0.196  loss_dice_2: 1.368  loss_ce_3: 0.5534  loss_mask_3: 0.1932  loss_dice_3: 1.296  loss_ce_4: 0.5473  loss_mask_4: 0.1923  loss_dice_4: 1.302  loss_ce_5: 0.5566  loss_mask_5: 0.1898  loss_dice_5: 1.294  loss_ce_6: 0.5018  loss_mask_6: 0.194  loss_dice_6: 1.252  loss_ce_7: 0.5303  loss_mask_7: 0.1923  loss_dice_7: 1.289  loss_ce_8: 0.5137  loss_mask_8: 0.1945  loss_dice_8: 1.265    time: 1.0595  last_time: 1.0708  data_time: 0.0756  last_data_time: 0.0682   lr: 0.0001  max_mem: 32772M
[10/09 21:53:43] d2.utils.events INFO:  eta: 0:03:13  iter: 2819  total_loss: 19.49  loss_ce: 0.455  loss_mask: 0.1475  loss_dice: 1.248  loss_ce_0: 0.5325  loss_mask_0: 0.1748  loss_dice_0: 1.517  loss_ce_1: 0.6142  loss_mask_1: 0.1573  loss_dice_1: 1.445  loss_ce_2: 0.5168  loss_mask_2: 0.1479  loss_dice_2: 1.344  loss_ce_3: 0.4644  loss_mask_3: 0.1458  loss_dice_3: 1.296  loss_ce_4: 0.462  loss_mask_4: 0.1472  loss_dice_4: 1.289  loss_ce_5: 0.4446  loss_mask_5: 0.1449  loss_dice_5: 1.273  loss_ce_6: 0.4626  loss_mask_6: 0.1453  loss_dice_6: 1.254  loss_ce_7: 0.467  loss_mask_7: 0.1471  loss_dice_7: 1.279  loss_ce_8: 0.4578  loss_mask_8: 0.1467  loss_dice_8: 1.237    time: 1.0735  last_time: 1.0731  data_time: 0.0757  last_data_time: 0.0710   lr: 0.0001  max_mem: 33192M
[10/09 21:53:43] d2.utils.events INFO:  eta: 0:46:50  iter: 339  total_loss: 22.2  loss_ce: 0.5822  loss_mask: 0.193  loss_dice: 1.313  loss_ce_0: 0.6681  loss_mask_0: 0.2268  loss_dice_0: 1.579  loss_ce_1: 0.7554  loss_mask_1: 0.1999  loss_dice_1: 1.477  loss_ce_2: 0.723  loss_mask_2: 0.1929  loss_dice_2: 1.403  loss_ce_3: 0.643  loss_mask_3: 0.1937  loss_dice_3: 1.32  loss_ce_4: 0.6394  loss_mask_4: 0.1937  loss_dice_4: 1.337  loss_ce_5: 0.6361  loss_mask_5: 0.198  loss_dice_5: 1.321  loss_ce_6: 0.5964  loss_mask_6: 0.1942  loss_dice_6: 1.314  loss_ce_7: 0.5871  loss_mask_7: 0.1925  loss_dice_7: 1.291  loss_ce_8: 0.6001  loss_mask_8: 0.1927  loss_dice_8: 1.365    time: 1.0605  last_time: 1.1629  data_time: 0.0758  last_data_time: 0.0709   lr: 0.0001  max_mem: 32772M
[10/09 21:54:04] d2.utils.events INFO:  eta: 0:02:51  iter: 2839  total_loss: 17.61  loss_ce: 0.3969  loss_mask: 0.1744  loss_dice: 1.097  loss_ce_0: 0.4947  loss_mask_0: 0.2077  loss_dice_0: 1.331  loss_ce_1: 0.5917  loss_mask_1: 0.1831  loss_dice_1: 1.214  loss_ce_2: 0.5294  loss_mask_2: 0.179  loss_dice_2: 1.177  loss_ce_3: 0.4679  loss_mask_3: 0.174  loss_dice_3: 1.116  loss_ce_4: 0.4118  loss_mask_4: 0.1798  loss_dice_4: 1.13  loss_ce_5: 0.4077  loss_mask_5: 0.1729  loss_dice_5: 1.135  loss_ce_6: 0.3988  loss_mask_6: 0.1769  loss_dice_6: 1.121  loss_ce_7: 0.4242  loss_mask_7: 0.1746  loss_dice_7: 1.102  loss_ce_8: 0.3597  loss_mask_8: 0.1738  loss_dice_8: 1.14    time: 1.0734  last_time: 1.0701  data_time: 0.0753  last_data_time: 0.0728   lr: 0.0001  max_mem: 33192M
[10/09 21:54:05] d2.utils.events INFO:  eta: 0:46:32  iter: 359  total_loss: 21.92  loss_ce: 0.5807  loss_mask: 0.1831  loss_dice: 1.302  loss_ce_0: 0.6651  loss_mask_0: 0.212  loss_dice_0: 1.566  loss_ce_1: 0.727  loss_mask_1: 0.2007  loss_dice_1: 1.42  loss_ce_2: 0.6705  loss_mask_2: 0.1886  loss_dice_2: 1.379  loss_ce_3: 0.6345  loss_mask_3: 0.1827  loss_dice_3: 1.353  loss_ce_4: 0.6348  loss_mask_4: 0.1781  loss_dice_4: 1.335  loss_ce_5: 0.5941  loss_mask_5: 0.1793  loss_dice_5: 1.32  loss_ce_6: 0.6011  loss_mask_6: 0.1756  loss_dice_6: 1.306  loss_ce_7: 0.5881  loss_mask_7: 0.186  loss_dice_7: 1.306  loss_ce_8: 0.5995  loss_mask_8: 0.1786  loss_dice_8: 1.276    time: 1.0617  last_time: 1.0707  data_time: 0.0766  last_data_time: 0.0734   lr: 0.0001  max_mem: 32772M
[10/09 21:54:25] d2.utils.events INFO:  eta: 0:02:30  iter: 2859  total_loss: 17.67  loss_ce: 0.3993  loss_mask: 0.1669  loss_dice: 1.114  loss_ce_0: 0.5014  loss_mask_0: 0.1989  loss_dice_0: 1.268  loss_ce_1: 0.5695  loss_mask_1: 0.1776  loss_dice_1: 1.217  loss_ce_2: 0.5169  loss_mask_2: 0.1682  loss_dice_2: 1.13  loss_ce_3: 0.4439  loss_mask_3: 0.1699  loss_dice_3: 1.146  loss_ce_4: 0.4245  loss_mask_4: 0.1687  loss_dice_4: 1.129  loss_ce_5: 0.4447  loss_mask_5: 0.1692  loss_dice_5: 1.093  loss_ce_6: 0.4069  loss_mask_6: 0.1674  loss_dice_6: 1.105  loss_ce_7: 0.4144  loss_mask_7: 0.1689  loss_dice_7: 1.077  loss_ce_8: 0.4075  loss_mask_8: 0.167  loss_dice_8: 1.116    time: 1.0734  last_time: 1.0538  data_time: 0.0730  last_data_time: 0.0698   lr: 0.0001  max_mem: 33192M
[10/09 21:54:27] d2.utils.events INFO:  eta: 0:46:12  iter: 379  total_loss: 21.04  loss_ce: 0.5675  loss_mask: 0.1944  loss_dice: 1.233  loss_ce_0: 0.6163  loss_mask_0: 0.2277  loss_dice_0: 1.5  loss_ce_1: 0.7321  loss_mask_1: 0.2118  loss_dice_1: 1.434  loss_ce_2: 0.6712  loss_mask_2: 0.1989  loss_dice_2: 1.324  loss_ce_3: 0.5887  loss_mask_3: 0.2001  loss_dice_3: 1.292  loss_ce_4: 0.5812  loss_mask_4: 0.1988  loss_dice_4: 1.337  loss_ce_5: 0.5799  loss_mask_5: 0.1939  loss_dice_5: 1.251  loss_ce_6: 0.5538  loss_mask_6: 0.1926  loss_dice_6: 1.25  loss_ce_7: 0.5494  loss_mask_7: 0.1931  loss_dice_7: 1.259  loss_ce_8: 0.56  loss_mask_8: 0.1934  loss_dice_8: 1.226    time: 1.0625  last_time: 1.0427  data_time: 0.0817  last_data_time: 0.1094   lr: 0.0001  max_mem: 32772M
[10/09 21:54:47] d2.utils.events INFO:  eta: 0:02:08  iter: 2879  total_loss: 18.77  loss_ce: 0.405  loss_mask: 0.1503  loss_dice: 1.169  loss_ce_0: 0.5198  loss_mask_0: 0.1676  loss_dice_0: 1.447  loss_ce_1: 0.5622  loss_mask_1: 0.1633  loss_dice_1: 1.345  loss_ce_2: 0.4839  loss_mask_2: 0.1536  loss_dice_2: 1.265  loss_ce_3: 0.4329  loss_mask_3: 0.1537  loss_dice_3: 1.216  loss_ce_4: 0.4367  loss_mask_4: 0.1533  loss_dice_4: 1.218  loss_ce_5: 0.4295  loss_mask_5: 0.1514  loss_dice_5: 1.202  loss_ce_6: 0.4161  loss_mask_6: 0.151  loss_dice_6: 1.192  loss_ce_7: 0.3878  loss_mask_7: 0.1515  loss_dice_7: 1.214  loss_ce_8: 0.4031  loss_mask_8: 0.1498  loss_dice_8: 1.208    time: 1.0734  last_time: 1.0281  data_time: 0.0803  last_data_time: 0.0579   lr: 0.0001  max_mem: 33192M
[10/09 21:54:48] d2.utils.events INFO:  eta: 0:45:51  iter: 399  total_loss: 20.94  loss_ce: 0.5174  loss_mask: 0.1835  loss_dice: 1.247  loss_ce_0: 0.6047  loss_mask_0: 0.219  loss_dice_0: 1.482  loss_ce_1: 0.6521  loss_mask_1: 0.2057  loss_dice_1: 1.387  loss_ce_2: 0.5851  loss_mask_2: 0.1962  loss_dice_2: 1.357  loss_ce_3: 0.54  loss_mask_3: 0.1992  loss_dice_3: 1.329  loss_ce_4: 0.5042  loss_mask_4: 0.1919  loss_dice_4: 1.292  loss_ce_5: 0.5226  loss_mask_5: 0.1861  loss_dice_5: 1.283  loss_ce_6: 0.5024  loss_mask_6: 0.1844  loss_dice_6: 1.29  loss_ce_7: 0.4732  loss_mask_7: 0.1845  loss_dice_7: 1.291  loss_ce_8: 0.4631  loss_mask_8: 0.1862  loss_dice_8: 1.232    time: 1.0630  last_time: 1.0311  data_time: 0.0711  last_data_time: 0.0559   lr: 0.0001  max_mem: 32772M
[10/09 21:55:09] d2.utils.events INFO:  eta: 0:01:47  iter: 2899  total_loss: 18.85  loss_ce: 0.4292  loss_mask: 0.1635  loss_dice: 1.2  loss_ce_0: 0.5275  loss_mask_0: 0.1849  loss_dice_0: 1.398  loss_ce_1: 0.5711  loss_mask_1: 0.176  loss_dice_1: 1.331  loss_ce_2: 0.4829  loss_mask_2: 0.1699  loss_dice_2: 1.276  loss_ce_3: 0.4596  loss_mask_3: 0.166  loss_dice_3: 1.253  loss_ce_4: 0.4403  loss_mask_4: 0.166  loss_dice_4: 1.221  loss_ce_5: 0.4114  loss_mask_5: 0.1634  loss_dice_5: 1.205  loss_ce_6: 0.436  loss_mask_6: 0.1622  loss_dice_6: 1.191  loss_ce_7: 0.4339  loss_mask_7: 0.1633  loss_dice_7: 1.16  loss_ce_8: 0.4225  loss_mask_8: 0.1625  loss_dice_8: 1.201    time: 1.0734  last_time: 1.0700  data_time: 0.0773  last_data_time: 0.0644   lr: 0.0001  max_mem: 33192M
[10/09 21:55:10] d2.utils.events INFO:  eta: 0:45:32  iter: 419  total_loss: 20.71  loss_ce: 0.5504  loss_mask: 0.1919  loss_dice: 1.217  loss_ce_0: 0.6337  loss_mask_0: 0.2109  loss_dice_0: 1.449  loss_ce_1: 0.6857  loss_mask_1: 0.2053  loss_dice_1: 1.37  loss_ce_2: 0.6465  loss_mask_2: 0.1951  loss_dice_2: 1.276  loss_ce_3: 0.6263  loss_mask_3: 0.1978  loss_dice_3: 1.226  loss_ce_4: 0.6274  loss_mask_4: 0.1938  loss_dice_4: 1.243  loss_ce_5: 0.5876  loss_mask_5: 0.1943  loss_dice_5: 1.227  loss_ce_6: 0.592  loss_mask_6: 0.188  loss_dice_6: 1.221  loss_ce_7: 0.5525  loss_mask_7: 0.1891  loss_dice_7: 1.217  loss_ce_8: 0.543  loss_mask_8: 0.1897  loss_dice_8: 1.232    time: 1.0634  last_time: 1.0764  data_time: 0.0772  last_data_time: 0.0984   lr: 0.0001  max_mem: 32772M
[10/09 21:55:30] d2.utils.events INFO:  eta: 0:01:25  iter: 2919  total_loss: 18.42  loss_ce: 0.3924  loss_mask: 0.1537  loss_dice: 1.183  loss_ce_0: 0.5265  loss_mask_0: 0.1773  loss_dice_0: 1.357  loss_ce_1: 0.5664  loss_mask_1: 0.1666  loss_dice_1: 1.311  loss_ce_2: 0.5156  loss_mask_2: 0.1574  loss_dice_2: 1.232  loss_ce_3: 0.4532  loss_mask_3: 0.1569  loss_dice_3: 1.179  loss_ce_4: 0.4044  loss_mask_4: 0.1558  loss_dice_4: 1.211  loss_ce_5: 0.4325  loss_mask_5: 0.1543  loss_dice_5: 1.189  loss_ce_6: 0.4122  loss_mask_6: 0.1523  loss_dice_6: 1.173  loss_ce_7: 0.3866  loss_mask_7: 0.1524  loss_dice_7: 1.155  loss_ce_8: 0.3968  loss_mask_8: 0.1547  loss_dice_8: 1.175    time: 1.0735  last_time: 1.0483  data_time: 0.0794  last_data_time: 0.0701   lr: 0.0001  max_mem: 33192M
[10/09 21:55:31] d2.utils.events INFO:  eta: 0:45:15  iter: 439  total_loss: 22.06  loss_ce: 0.5118  loss_mask: 0.1809  loss_dice: 1.31  loss_ce_0: 0.6036  loss_mask_0: 0.2001  loss_dice_0: 1.558  loss_ce_1: 0.7143  loss_mask_1: 0.1906  loss_dice_1: 1.485  loss_ce_2: 0.6701  loss_mask_2: 0.1847  loss_dice_2: 1.451  loss_ce_3: 0.594  loss_mask_3: 0.1862  loss_dice_3: 1.341  loss_ce_4: 0.5873  loss_mask_4: 0.1809  loss_dice_4: 1.39  loss_ce_5: 0.5344  loss_mask_5: 0.1826  loss_dice_5: 1.356  loss_ce_6: 0.538  loss_mask_6: 0.18  loss_dice_6: 1.364  loss_ce_7: 0.5214  loss_mask_7: 0.182  loss_dice_7: 1.334  loss_ce_8: 0.4983  loss_mask_8: 0.1821  loss_dice_8: 1.347    time: 1.0648  last_time: 1.1191  data_time: 0.0781  last_data_time: 0.0799   lr: 0.0001  max_mem: 32772M
[10/09 21:55:52] d2.utils.events INFO:  eta: 0:01:04  iter: 2939  total_loss: 18.53  loss_ce: 0.4357  loss_mask: 0.1483  loss_dice: 1.173  loss_ce_0: 0.5361  loss_mask_0: 0.1718  loss_dice_0: 1.383  loss_ce_1: 0.5839  loss_mask_1: 0.1603  loss_dice_1: 1.293  loss_ce_2: 0.5363  loss_mask_2: 0.1535  loss_dice_2: 1.217  loss_ce_3: 0.5101  loss_mask_3: 0.153  loss_dice_3: 1.215  loss_ce_4: 0.4491  loss_mask_4: 0.1521  loss_dice_4: 1.199  loss_ce_5: 0.4781  loss_mask_5: 0.1505  loss_dice_5: 1.203  loss_ce_6: 0.4639  loss_mask_6: 0.1485  loss_dice_6: 1.186  loss_ce_7: 0.459  loss_mask_7: 0.15  loss_dice_7: 1.201  loss_ce_8: 0.4529  loss_mask_8: 0.1492  loss_dice_8: 1.155    time: 1.0737  last_time: 1.0795  data_time: 0.0775  last_data_time: 0.0730   lr: 0.0001  max_mem: 33192M
[10/09 21:55:53] d2.utils.events INFO:  eta: 0:44:54  iter: 459  total_loss: 21.22  loss_ce: 0.5279  loss_mask: 0.1899  loss_dice: 1.276  loss_ce_0: 0.6321  loss_mask_0: 0.2193  loss_dice_0: 1.501  loss_ce_1: 0.6969  loss_mask_1: 0.2114  loss_dice_1: 1.409  loss_ce_2: 0.635  loss_mask_2: 0.2041  loss_dice_2: 1.37  loss_ce_3: 0.577  loss_mask_3: 0.1953  loss_dice_3: 1.313  loss_ce_4: 0.5496  loss_mask_4: 0.2003  loss_dice_4: 1.312  loss_ce_5: 0.5312  loss_mask_5: 0.1904  loss_dice_5: 1.295  loss_ce_6: 0.5144  loss_mask_6: 0.1907  loss_dice_6: 1.275  loss_ce_7: 0.5294  loss_mask_7: 0.19  loss_dice_7: 1.286  loss_ce_8: 0.4995  loss_mask_8: 0.1897  loss_dice_8: 1.252    time: 1.0649  last_time: 1.0725  data_time: 0.0753  last_data_time: 0.0805   lr: 0.0001  max_mem: 32772M
[10/09 21:56:14] d2.utils.events INFO:  eta: 0:00:42  iter: 2959  total_loss: 18.1  loss_ce: 0.3868  loss_mask: 0.147  loss_dice: 1.155  loss_ce_0: 0.5254  loss_mask_0: 0.1752  loss_dice_0: 1.4  loss_ce_1: 0.544  loss_mask_1: 0.1637  loss_dice_1: 1.319  loss_ce_2: 0.4711  loss_mask_2: 0.1535  loss_dice_2: 1.215  loss_ce_3: 0.4297  loss_mask_3: 0.1505  loss_dice_3: 1.18  loss_ce_4: 0.408  loss_mask_4: 0.1505  loss_dice_4: 1.211  loss_ce_5: 0.4129  loss_mask_5: 0.1495  loss_dice_5: 1.193  loss_ce_6: 0.3948  loss_mask_6: 0.1481  loss_dice_6: 1.163  loss_ce_7: 0.4193  loss_mask_7: 0.1465  loss_dice_7: 1.19  loss_ce_8: 0.3774  loss_mask_8: 0.1465  loss_dice_8: 1.16    time: 1.0737  last_time: 1.0384  data_time: 0.0795  last_data_time: 0.0659   lr: 0.0001  max_mem: 33192M
[10/09 21:56:14] d2.utils.events INFO:  eta: 0:44:33  iter: 479  total_loss: 21.22  loss_ce: 0.5015  loss_mask: 0.1873  loss_dice: 1.283  loss_ce_0: 0.6283  loss_mask_0: 0.2174  loss_dice_0: 1.529  loss_ce_1: 0.6781  loss_mask_1: 0.2033  loss_dice_1: 1.424  loss_ce_2: 0.6207  loss_mask_2: 0.1925  loss_dice_2: 1.348  loss_ce_3: 0.5836  loss_mask_3: 0.1911  loss_dice_3: 1.294  loss_ce_4: 0.5691  loss_mask_4: 0.1936  loss_dice_4: 1.317  loss_ce_5: 0.5226  loss_mask_5: 0.1897  loss_dice_5: 1.309  loss_ce_6: 0.542  loss_mask_6: 0.1901  loss_dice_6: 1.289  loss_ce_7: 0.5174  loss_mask_7: 0.1879  loss_dice_7: 1.291  loss_ce_8: 0.5156  loss_mask_8: 0.1898  loss_dice_8: 1.293    time: 1.0654  last_time: 1.0064  data_time: 0.0773  last_data_time: 0.0653   lr: 0.0001  max_mem: 32772M
[10/09 21:56:36] d2.utils.events INFO:  eta: 0:00:21  iter: 2979  total_loss: 17.73  loss_ce: 0.3846  loss_mask: 0.1522  loss_dice: 1.127  loss_ce_0: 0.5166  loss_mask_0: 0.1784  loss_dice_0: 1.351  loss_ce_1: 0.5252  loss_mask_1: 0.1676  loss_dice_1: 1.241  loss_ce_2: 0.487  loss_mask_2: 0.1555  loss_dice_2: 1.192  loss_ce_3: 0.4383  loss_mask_3: 0.1556  loss_dice_3: 1.14  loss_ce_4: 0.3908  loss_mask_4: 0.152  loss_dice_4: 1.173  loss_ce_5: 0.3966  loss_mask_5: 0.151  loss_dice_5: 1.173  loss_ce_6: 0.3716  loss_mask_6: 0.1531  loss_dice_6: 1.136  loss_ce_7: 0.3671  loss_mask_7: 0.1524  loss_dice_7: 1.171  loss_ce_8: 0.3651  loss_mask_8: 0.1526  loss_dice_8: 1.157    time: 1.0737  last_time: 1.0514  data_time: 0.0731  last_data_time: 0.0836   lr: 0.0001  max_mem: 33192M
[10/09 21:56:36] d2.utils.events INFO:  eta: 0:44:15  iter: 499  total_loss: 21.39  loss_ce: 0.549  loss_mask: 0.1953  loss_dice: 1.261  loss_ce_0: 0.615  loss_mask_0: 0.2256  loss_dice_0: 1.502  loss_ce_1: 0.7094  loss_mask_1: 0.2147  loss_dice_1: 1.418  loss_ce_2: 0.6429  loss_mask_2: 0.2026  loss_dice_2: 1.34  loss_ce_3: 0.5899  loss_mask_3: 0.2018  loss_dice_3: 1.307  loss_ce_4: 0.5502  loss_mask_4: 0.2035  loss_dice_4: 1.323  loss_ce_5: 0.5483  loss_mask_5: 0.2  loss_dice_5: 1.302  loss_ce_6: 0.5099  loss_mask_6: 0.1955  loss_dice_6: 1.292  loss_ce_7: 0.5244  loss_mask_7: 0.1967  loss_dice_7: 1.272  loss_ce_8: 0.5429  loss_mask_8: 0.1965  loss_dice_8: 1.248    time: 1.0661  last_time: 1.1252  data_time: 0.0752  last_data_time: 0.0730   lr: 0.0001  max_mem: 32772M
[10/09 21:56:57] fvcore.common.checkpoint INFO: Saving checkpoint to /tsi/hi-paris/GB/segmentation/results/In_vocab/r50_008_3000_19_a_decoder/model_final.pth
[10/09 21:56:58] d2.utils.events INFO:  eta: 0:43:57  iter: 519  total_loss: 21.59  loss_ce: 0.5362  loss_mask: 0.1758  loss_dice: 1.315  loss_ce_0: 0.6509  loss_mask_0: 0.1979  loss_dice_0: 1.594  loss_ce_1: 0.7049  loss_mask_1: 0.1876  loss_dice_1: 1.511  loss_ce_2: 0.6415  loss_mask_2: 0.1789  loss_dice_2: 1.448  loss_ce_3: 0.5836  loss_mask_3: 0.1758  loss_dice_3: 1.395  loss_ce_4: 0.5866  loss_mask_4: 0.177  loss_dice_4: 1.381  loss_ce_5: 0.5479  loss_mask_5: 0.1781  loss_dice_5: 1.347  loss_ce_6: 0.545  loss_mask_6: 0.1771  loss_dice_6: 1.366  loss_ce_7: 0.5504  loss_mask_7: 0.1746  loss_dice_7: 1.349  loss_ce_8: 0.5682  loss_mask_8: 0.1759  loss_dice_8: 1.338    time: 1.0677  last_time: 1.0500  data_time: 0.0808  last_data_time: 0.0777   lr: 0.0001  max_mem: 32772M
[10/09 21:57:00] d2.utils.events INFO:  eta: 0:00:00  iter: 2999  total_loss: 18.57  loss_ce: 0.4202  loss_mask: 0.1571  loss_dice: 1.141  loss_ce_0: 0.5445  loss_mask_0: 0.1733  loss_dice_0: 1.347  loss_ce_1: 0.5775  loss_mask_1: 0.1649  loss_dice_1: 1.252  loss_ce_2: 0.5335  loss_mask_2: 0.1585  loss_dice_2: 1.228  loss_ce_3: 0.4888  loss_mask_3: 0.1608  loss_dice_3: 1.156  loss_ce_4: 0.4932  loss_mask_4: 0.157  loss_dice_4: 1.14  loss_ce_5: 0.4657  loss_mask_5: 0.1554  loss_dice_5: 1.184  loss_ce_6: 0.4398  loss_mask_6: 0.1552  loss_dice_6: 1.156  loss_ce_7: 0.4475  loss_mask_7: 0.1564  loss_dice_7: 1.153  loss_ce_8: 0.4574  loss_mask_8: 0.1545  loss_dice_8: 1.136    time: 1.0737  last_time: 1.1406  data_time: 0.0740  last_data_time: 0.0804   lr: 0.0001  max_mem: 33192M
[10/09 21:57:00] d2.engine.hooks INFO: Overall training speed: 2998 iterations in 0:53:39 (1.0737 s / it)
[10/09 21:57:00] d2.engine.hooks INFO: Total training time: 0:53:52 (0:00:13 on hooks)
[10/09 21:57:00] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/09 21:57:00] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/09 21:57:00] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/09 21:57:00] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/09 21:57:00] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/09 21:57:00] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/09 21:57:03] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0042 s/iter. Inference: 0.1338 s/iter. Eval: 0.0726 s/iter. Total: 0.2106 s/iter. ETA=0:01:42
[10/09 21:57:09] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0048 s/iter. Inference: 0.1358 s/iter. Eval: 0.0730 s/iter. Total: 0.2137 s/iter. ETA=0:01:39
[10/09 21:57:14] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0050 s/iter. Inference: 0.1370 s/iter. Eval: 0.0695 s/iter. Total: 0.2116 s/iter. ETA=0:01:33
[10/09 21:57:19] d2.evaluation.evaluator INFO: Inference done 82/500. Dataloading: 0.0050 s/iter. Inference: 0.1382 s/iter. Eval: 0.0702 s/iter. Total: 0.2135 s/iter. ETA=0:01:29
[10/09 21:57:21] d2.utils.events INFO:  eta: 0:43:37  iter: 539  total_loss: 21.15  loss_ce: 0.5445  loss_mask: 0.1761  loss_dice: 1.296  loss_ce_0: 0.6828  loss_mask_0: 0.204  loss_dice_0: 1.49  loss_ce_1: 0.7211  loss_mask_1: 0.1857  loss_dice_1: 1.466  loss_ce_2: 0.6524  loss_mask_2: 0.1804  loss_dice_2: 1.385  loss_ce_3: 0.6103  loss_mask_3: 0.1812  loss_dice_3: 1.308  loss_ce_4: 0.5685  loss_mask_4: 0.1802  loss_dice_4: 1.314  loss_ce_5: 0.5651  loss_mask_5: 0.1801  loss_dice_5: 1.333  loss_ce_6: 0.5554  loss_mask_6: 0.1774  loss_dice_6: 1.307  loss_ce_7: 0.5331  loss_mask_7: 0.1782  loss_dice_7: 1.293  loss_ce_8: 0.5222  loss_mask_8: 0.179  loss_dice_8: 1.318    time: 1.0685  last_time: 1.1441  data_time: 0.0742  last_data_time: 0.0911   lr: 0.0001  max_mem: 32772M
[10/09 21:57:24] d2.evaluation.evaluator INFO: Inference done 106/500. Dataloading: 0.0050 s/iter. Inference: 0.1377 s/iter. Eval: 0.0706 s/iter. Total: 0.2134 s/iter. ETA=0:01:24
[10/09 21:57:29] d2.evaluation.evaluator INFO: Inference done 130/500. Dataloading: 0.0050 s/iter. Inference: 0.1372 s/iter. Eval: 0.0710 s/iter. Total: 0.2133 s/iter. ETA=0:01:18
[10/09 21:57:34] d2.evaluation.evaluator INFO: Inference done 154/500. Dataloading: 0.0051 s/iter. Inference: 0.1369 s/iter. Eval: 0.0711 s/iter. Total: 0.2131 s/iter. ETA=0:01:13
[10/09 21:57:39] d2.evaluation.evaluator INFO: Inference done 178/500. Dataloading: 0.0051 s/iter. Inference: 0.1368 s/iter. Eval: 0.0711 s/iter. Total: 0.2131 s/iter. ETA=0:01:08
[10/09 21:57:43] d2.utils.events INFO:  eta: 0:43:17  iter: 559  total_loss: 20.5  loss_ce: 0.4925  loss_mask: 0.1749  loss_dice: 1.247  loss_ce_0: 0.5647  loss_mask_0: 0.2003  loss_dice_0: 1.454  loss_ce_1: 0.6772  loss_mask_1: 0.19  loss_dice_1: 1.359  loss_ce_2: 0.5755  loss_mask_2: 0.1845  loss_dice_2: 1.317  loss_ce_3: 0.5477  loss_mask_3: 0.1785  loss_dice_3: 1.283  loss_ce_4: 0.5164  loss_mask_4: 0.1803  loss_dice_4: 1.272  loss_ce_5: 0.5098  loss_mask_5: 0.1785  loss_dice_5: 1.288  loss_ce_6: 0.4959  loss_mask_6: 0.1755  loss_dice_6: 1.25  loss_ce_7: 0.4681  loss_mask_7: 0.1788  loss_dice_7: 1.253  loss_ce_8: 0.4983  loss_mask_8: 0.1769  loss_dice_8: 1.262    time: 1.0690  last_time: 1.1107  data_time: 0.0767  last_data_time: 0.0875   lr: 0.0001  max_mem: 32772M
[10/09 21:57:44] d2.evaluation.evaluator INFO: Inference done 202/500. Dataloading: 0.0051 s/iter. Inference: 0.1368 s/iter. Eval: 0.0711 s/iter. Total: 0.2131 s/iter. ETA=0:01:03
[10/09 21:57:49] d2.evaluation.evaluator INFO: Inference done 226/500. Dataloading: 0.0051 s/iter. Inference: 0.1371 s/iter. Eval: 0.0708 s/iter. Total: 0.2131 s/iter. ETA=0:00:58
[10/09 21:57:54] d2.evaluation.evaluator INFO: Inference done 250/500. Dataloading: 0.0051 s/iter. Inference: 0.1368 s/iter. Eval: 0.0707 s/iter. Total: 0.2127 s/iter. ETA=0:00:53
[10/09 21:57:59] d2.evaluation.evaluator INFO: Inference done 274/500. Dataloading: 0.0052 s/iter. Inference: 0.1364 s/iter. Eval: 0.0709 s/iter. Total: 0.2124 s/iter. ETA=0:00:48
[10/09 21:58:04] d2.evaluation.evaluator INFO: Inference done 298/500. Dataloading: 0.0052 s/iter. Inference: 0.1360 s/iter. Eval: 0.0710 s/iter. Total: 0.2123 s/iter. ETA=0:00:42
[10/09 21:58:05] d2.utils.events INFO:  eta: 0:42:58  iter: 579  total_loss: 20.88  loss_ce: 0.5193  loss_mask: 0.174  loss_dice: 1.296  loss_ce_0: 0.613  loss_mask_0: 0.2031  loss_dice_0: 1.515  loss_ce_1: 0.6887  loss_mask_1: 0.1842  loss_dice_1: 1.461  loss_ce_2: 0.6348  loss_mask_2: 0.1752  loss_dice_2: 1.41  loss_ce_3: 0.5834  loss_mask_3: 0.1777  loss_dice_3: 1.337  loss_ce_4: 0.5482  loss_mask_4: 0.1737  loss_dice_4: 1.338  loss_ce_5: 0.5391  loss_mask_5: 0.1729  loss_dice_5: 1.332  loss_ce_6: 0.5377  loss_mask_6: 0.1743  loss_dice_6: 1.251  loss_ce_7: 0.5335  loss_mask_7: 0.1745  loss_dice_7: 1.323  loss_ce_8: 0.5159  loss_mask_8: 0.1738  loss_dice_8: 1.291    time: 1.0702  last_time: 1.1367  data_time: 0.0835  last_data_time: 0.0904   lr: 0.0001  max_mem: 32772M
[10/09 21:58:09] d2.evaluation.evaluator INFO: Inference done 322/500. Dataloading: 0.0052 s/iter. Inference: 0.1357 s/iter. Eval: 0.0712 s/iter. Total: 0.2121 s/iter. ETA=0:00:37
[10/09 21:58:14] d2.evaluation.evaluator INFO: Inference done 346/500. Dataloading: 0.0052 s/iter. Inference: 0.1356 s/iter. Eval: 0.0714 s/iter. Total: 0.2122 s/iter. ETA=0:00:32
[10/09 21:58:20] d2.evaluation.evaluator INFO: Inference done 370/500. Dataloading: 0.0052 s/iter. Inference: 0.1355 s/iter. Eval: 0.0715 s/iter. Total: 0.2122 s/iter. ETA=0:00:27
[10/09 21:58:25] d2.evaluation.evaluator INFO: Inference done 394/500. Dataloading: 0.0052 s/iter. Inference: 0.1356 s/iter. Eval: 0.0716 s/iter. Total: 0.2124 s/iter. ETA=0:00:22
[10/09 21:58:27] d2.utils.events INFO:  eta: 0:42:37  iter: 599  total_loss: 19.69  loss_ce: 0.4977  loss_mask: 0.181  loss_dice: 1.166  loss_ce_0: 0.5696  loss_mask_0: 0.2056  loss_dice_0: 1.445  loss_ce_1: 0.6449  loss_mask_1: 0.1939  loss_dice_1: 1.317  loss_ce_2: 0.5873  loss_mask_2: 0.1837  loss_dice_2: 1.264  loss_ce_3: 0.5865  loss_mask_3: 0.1841  loss_dice_3: 1.244  loss_ce_4: 0.5485  loss_mask_4: 0.1847  loss_dice_4: 1.198  loss_ce_5: 0.5164  loss_mask_5: 0.1826  loss_dice_5: 1.233  loss_ce_6: 0.5002  loss_mask_6: 0.1813  loss_dice_6: 1.2  loss_ce_7: 0.4969  loss_mask_7: 0.1789  loss_dice_7: 1.183  loss_ce_8: 0.4799  loss_mask_8: 0.1805  loss_dice_8: 1.217    time: 1.0703  last_time: 1.0930  data_time: 0.0799  last_data_time: 0.0922   lr: 0.0001  max_mem: 32772M
[10/09 21:58:30] d2.evaluation.evaluator INFO: Inference done 418/500. Dataloading: 0.0052 s/iter. Inference: 0.1354 s/iter. Eval: 0.0716 s/iter. Total: 0.2123 s/iter. ETA=0:00:17
[10/09 21:58:35] d2.evaluation.evaluator INFO: Inference done 442/500. Dataloading: 0.0052 s/iter. Inference: 0.1353 s/iter. Eval: 0.0717 s/iter. Total: 0.2122 s/iter. ETA=0:00:12
[10/09 21:58:40] d2.evaluation.evaluator INFO: Inference done 466/500. Dataloading: 0.0052 s/iter. Inference: 0.1352 s/iter. Eval: 0.0717 s/iter. Total: 0.2122 s/iter. ETA=0:00:07
[10/09 21:58:45] d2.evaluation.evaluator INFO: Inference done 490/500. Dataloading: 0.0052 s/iter. Inference: 0.1352 s/iter. Eval: 0.0717 s/iter. Total: 0.2122 s/iter. ETA=0:00:02
[10/09 21:58:47] d2.evaluation.evaluator INFO: Total inference time: 0:01:45.113270 (0.212350 s / iter per device, on 1 devices)
[10/09 21:58:47] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.135147 s / iter per device, on 1 devices)
[10/09 21:58:47] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evaldwmtokzd ...
[10/09 21:58:48] d2.utils.events INFO:  eta: 0:42:17  iter: 619  total_loss: 20.05  loss_ce: 0.5254  loss_mask: 0.1724  loss_dice: 1.207  loss_ce_0: 0.5922  loss_mask_0: 0.2085  loss_dice_0: 1.468  loss_ce_1: 0.6679  loss_mask_1: 0.1877  loss_dice_1: 1.345  loss_ce_2: 0.6135  loss_mask_2: 0.1831  loss_dice_2: 1.3  loss_ce_3: 0.5772  loss_mask_3: 0.1766  loss_dice_3: 1.238  loss_ce_4: 0.5209  loss_mask_4: 0.1776  loss_dice_4: 1.24  loss_ce_5: 0.543  loss_mask_5: 0.1779  loss_dice_5: 1.245  loss_ce_6: 0.531  loss_mask_6: 0.1751  loss_dice_6: 1.201  loss_ce_7: 0.5327  loss_mask_7: 0.1744  loss_dice_7: 1.195  loss_ce_8: 0.5427  loss_mask_8: 0.174  loss_dice_8: 1.201    time: 1.0705  last_time: 1.0593  data_time: 0.0775  last_data_time: 0.0687   lr: 0.0001  max_mem: 32772M
[10/09 21:59:10] d2.utils.events INFO:  eta: 0:41:59  iter: 639  total_loss: 21.38  loss_ce: 0.5703  loss_mask: 0.1775  loss_dice: 1.281  loss_ce_0: 0.6385  loss_mask_0: 0.2129  loss_dice_0: 1.541  loss_ce_1: 0.6964  loss_mask_1: 0.2028  loss_dice_1: 1.474  loss_ce_2: 0.6824  loss_mask_2: 0.188  loss_dice_2: 1.356  loss_ce_3: 0.6113  loss_mask_3: 0.1833  loss_dice_3: 1.332  loss_ce_4: 0.6021  loss_mask_4: 0.1817  loss_dice_4: 1.318  loss_ce_5: 0.5618  loss_mask_5: 0.1775  loss_dice_5: 1.31  loss_ce_6: 0.5816  loss_mask_6: 0.1764  loss_dice_6: 1.264  loss_ce_7: 0.552  loss_mask_7: 0.1776  loss_dice_7: 1.283  loss_ce_8: 0.5636  loss_mask_8: 0.1769  loss_dice_8: 1.292    time: 1.0712  last_time: 1.0918  data_time: 0.0810  last_data_time: 0.0874   lr: 0.0001  max_mem: 32772M
[10/09 21:59:12] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 57.611 | 79.963 | 70.963 |      19       |
| Things | 48.873 | 79.361 | 61.582 |       8       |
| Stuff  | 63.967 | 80.400 | 77.786 |      11       |
[10/09 21:59:12] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 97.286 | 97.691 | 99.586 |     Stuff     |
| class_8  | 73.234 | 83.320 | 87.895 |     Stuff     |
| class_11 | 86.818 | 88.807 | 97.760 |     Stuff     |
| class_12 | 42.696 | 77.181 | 55.319 |     Stuff     |
| class_13 | 35.839 | 74.829 | 47.895 |     Stuff     |
| class_17 | 43.877 | 63.169 | 69.459 |     Stuff     |
| class_19 | 44.831 | 67.131 | 66.781 |     Stuff     |
| class_20 | 66.422 | 76.748 | 86.545 |     Stuff     |
| class_21 | 88.200 | 89.300 | 98.768 |     Stuff     |
| class_22 | 38.027 | 75.583 | 50.312 |     Stuff     |
| class_23 | 86.403 | 90.641 | 95.325 |     Stuff     |
| class_24 | 49.743 | 74.581 | 66.696 |    Things     |
| class_25 | 48.433 | 72.498 | 66.806 |    Things     |
| class_26 | 63.643 | 81.665 | 77.932 |    Things     |
| class_27 | 52.633 | 87.543 | 60.123 |    Things     |
| class_28 | 55.851 | 87.331 | 63.953 |    Things     |
| class_31 | 43.915 | 87.831 | 50.000 |    Things     |
| class_32 | 37.250 | 73.241 | 50.859 |    Things     |
| class_33 | 39.513 | 70.201 | 56.285 |    Things     |
[10/09 21:59:12] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/09 21:59:12] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/09 21:59:12] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/09 21:59:12] d2.evaluation.testing INFO: copypaste: 57.6113,79.9627,70.9631,48.8726,79.3612,61.5818,63.9667,80.4002,77.7858,97.2864,97.6909,99.5859,73.2345,83.3201,87.8953,86.8178,88.8074,97.7597,42.6961,77.1814,55.3191,35.8392,74.8292,47.8947,43.8765,63.1693,69.4586,44.8306,67.1310,66.7808,66.4216,76.7484,86.5447,88.2001,89.3003,98.7680,38.0273,75.5832,50.3119,86.4032,90.6407,95.3250,49.7429,74.5814,66.6961,48.4327,72.4978,66.8058,63.6433,81.6648,77.9323,52.6331,87.5428,60.1227,55.8513,87.3311,63.9535,43.9153,87.8305,50.0000,37.2496,73.2407,50.8591,39.5125,70.2005,56.2852
[10/09 21:59:32] d2.utils.events INFO:  eta: 0:41:39  iter: 659  total_loss: 20.79  loss_ce: 0.522  loss_mask: 0.1724  loss_dice: 1.297  loss_ce_0: 0.6  loss_mask_0: 0.2004  loss_dice_0: 1.462  loss_ce_1: 0.6673  loss_mask_1: 0.1842  loss_dice_1: 1.457  loss_ce_2: 0.5827  loss_mask_2: 0.1755  loss_dice_2: 1.364  loss_ce_3: 0.5806  loss_mask_3: 0.1742  loss_dice_3: 1.342  loss_ce_4: 0.5708  loss_mask_4: 0.1756  loss_dice_4: 1.341  loss_ce_5: 0.5879  loss_mask_5: 0.1724  loss_dice_5: 1.311  loss_ce_6: 0.5354  loss_mask_6: 0.1698  loss_dice_6: 1.332  loss_ce_7: 0.5206  loss_mask_7: 0.1728  loss_dice_7: 1.288  loss_ce_8: 0.5349  loss_mask_8: 0.1728  loss_dice_8: 1.299    time: 1.0718  last_time: 1.0900  data_time: 0.0808  last_data_time: 0.0885   lr: 0.0001  max_mem: 32772M
[10/09 21:59:54] d2.utils.events INFO:  eta: 0:41:19  iter: 679  total_loss: 20.76  loss_ce: 0.5286  loss_mask: 0.1595  loss_dice: 1.232  loss_ce_0: 0.5724  loss_mask_0: 0.1945  loss_dice_0: 1.435  loss_ce_1: 0.6578  loss_mask_1: 0.1768  loss_dice_1: 1.399  loss_ce_2: 0.6013  loss_mask_2: 0.164  loss_dice_2: 1.317  loss_ce_3: 0.5853  loss_mask_3: 0.1666  loss_dice_3: 1.296  loss_ce_4: 0.5647  loss_mask_4: 0.1657  loss_dice_4: 1.285  loss_ce_5: 0.5776  loss_mask_5: 0.1622  loss_dice_5: 1.257  loss_ce_6: 0.5742  loss_mask_6: 0.1609  loss_dice_6: 1.239  loss_ce_7: 0.5407  loss_mask_7: 0.1617  loss_dice_7: 1.23  loss_ce_8: 0.5201  loss_mask_8: 0.1593  loss_dice_8: 1.222    time: 1.0719  last_time: 1.0916  data_time: 0.0801  last_data_time: 0.0844   lr: 0.0001  max_mem: 32772M
[10/09 22:00:16] d2.utils.events INFO:  eta: 0:40:58  iter: 699  total_loss: 21.08  loss_ce: 0.5317  loss_mask: 0.171  loss_dice: 1.267  loss_ce_0: 0.6042  loss_mask_0: 0.1943  loss_dice_0: 1.523  loss_ce_1: 0.6515  loss_mask_1: 0.1789  loss_dice_1: 1.426  loss_ce_2: 0.5951  loss_mask_2: 0.1738  loss_dice_2: 1.345  loss_ce_3: 0.5617  loss_mask_3: 0.1739  loss_dice_3: 1.326  loss_ce_4: 0.5501  loss_mask_4: 0.1719  loss_dice_4: 1.312  loss_ce_5: 0.5549  loss_mask_5: 0.1719  loss_dice_5: 1.293  loss_ce_6: 0.5416  loss_mask_6: 0.1712  loss_dice_6: 1.3  loss_ce_7: 0.5402  loss_mask_7: 0.1727  loss_dice_7: 1.297  loss_ce_8: 0.4983  loss_mask_8: 0.1726  loss_dice_8: 1.243    time: 1.0724  last_time: 1.0210  data_time: 0.0815  last_data_time: 0.0671   lr: 0.0001  max_mem: 32772M
[10/09 22:00:37] d2.utils.events INFO:  eta: 0:40:36  iter: 719  total_loss: 20.61  loss_ce: 0.5067  loss_mask: 0.1884  loss_dice: 1.261  loss_ce_0: 0.5739  loss_mask_0: 0.2178  loss_dice_0: 1.513  loss_ce_1: 0.6461  loss_mask_1: 0.2051  loss_dice_1: 1.36  loss_ce_2: 0.6301  loss_mask_2: 0.1934  loss_dice_2: 1.375  loss_ce_3: 0.57  loss_mask_3: 0.1943  loss_dice_3: 1.303  loss_ce_4: 0.5306  loss_mask_4: 0.1912  loss_dice_4: 1.309  loss_ce_5: 0.5214  loss_mask_5: 0.1908  loss_dice_5: 1.327  loss_ce_6: 0.5575  loss_mask_6: 0.1909  loss_dice_6: 1.257  loss_ce_7: 0.5443  loss_mask_7: 0.1905  loss_dice_7: 1.255  loss_ce_8: 0.5276  loss_mask_8: 0.1907  loss_dice_8: 1.285    time: 1.0723  last_time: 1.0589  data_time: 0.0779  last_data_time: 0.0847   lr: 0.0001  max_mem: 32772M
[10/09 22:00:59] d2.utils.events INFO:  eta: 0:40:16  iter: 739  total_loss: 20.76  loss_ce: 0.5114  loss_mask: 0.1781  loss_dice: 1.269  loss_ce_0: 0.5754  loss_mask_0: 0.1978  loss_dice_0: 1.473  loss_ce_1: 0.6542  loss_mask_1: 0.1912  loss_dice_1: 1.39  loss_ce_2: 0.5728  loss_mask_2: 0.1822  loss_dice_2: 1.316  loss_ce_3: 0.5403  loss_mask_3: 0.1828  loss_dice_3: 1.312  loss_ce_4: 0.5781  loss_mask_4: 0.1797  loss_dice_4: 1.299  loss_ce_5: 0.5324  loss_mask_5: 0.1787  loss_dice_5: 1.289  loss_ce_6: 0.5144  loss_mask_6: 0.1802  loss_dice_6: 1.261  loss_ce_7: 0.5032  loss_mask_7: 0.1787  loss_dice_7: 1.257  loss_ce_8: 0.4992  loss_mask_8: 0.1772  loss_dice_8: 1.258    time: 1.0729  last_time: 1.0902  data_time: 0.0868  last_data_time: 0.0900   lr: 0.0001  max_mem: 32772M
[10/09 22:01:21] d2.utils.events INFO:  eta: 0:39:57  iter: 759  total_loss: 20.72  loss_ce: 0.5357  loss_mask: 0.1542  loss_dice: 1.241  loss_ce_0: 0.6203  loss_mask_0: 0.1915  loss_dice_0: 1.447  loss_ce_1: 0.6202  loss_mask_1: 0.1735  loss_dice_1: 1.418  loss_ce_2: 0.5981  loss_mask_2: 0.1576  loss_dice_2: 1.331  loss_ce_3: 0.5472  loss_mask_3: 0.1569  loss_dice_3: 1.287  loss_ce_4: 0.5445  loss_mask_4: 0.1586  loss_dice_4: 1.246  loss_ce_5: 0.5281  loss_mask_5: 0.1555  loss_dice_5: 1.27  loss_ce_6: 0.4983  loss_mask_6: 0.1559  loss_dice_6: 1.254  loss_ce_7: 0.5074  loss_mask_7: 0.1543  loss_dice_7: 1.254  loss_ce_8: 0.5031  loss_mask_8: 0.1534  loss_dice_8: 1.27    time: 1.0741  last_time: 1.2349  data_time: 0.0853  last_data_time: 0.1185   lr: 0.0001  max_mem: 32772M
[10/09 22:01:44] d2.utils.events INFO:  eta: 0:39:37  iter: 779  total_loss: 20.99  loss_ce: 0.5151  loss_mask: 0.1547  loss_dice: 1.275  loss_ce_0: 0.657  loss_mask_0: 0.1837  loss_dice_0: 1.528  loss_ce_1: 0.6473  loss_mask_1: 0.1697  loss_dice_1: 1.453  loss_ce_2: 0.6449  loss_mask_2: 0.1605  loss_dice_2: 1.383  loss_ce_3: 0.5712  loss_mask_3: 0.158  loss_dice_3: 1.33  loss_ce_4: 0.5521  loss_mask_4: 0.1561  loss_dice_4: 1.31  loss_ce_5: 0.5254  loss_mask_5: 0.1547  loss_dice_5: 1.31  loss_ce_6: 0.5201  loss_mask_6: 0.1574  loss_dice_6: 1.318  loss_ce_7: 0.5089  loss_mask_7: 0.1546  loss_dice_7: 1.302  loss_ce_8: 0.4939  loss_mask_8: 0.1548  loss_dice_8: 1.315    time: 1.0751  last_time: 1.1014  data_time: 0.0893  last_data_time: 0.0944   lr: 0.0001  max_mem: 32772M
[10/09 22:02:06] d2.utils.events INFO:  eta: 0:39:17  iter: 799  total_loss: 19.95  loss_ce: 0.5062  loss_mask: 0.176  loss_dice: 1.218  loss_ce_0: 0.6188  loss_mask_0: 0.2048  loss_dice_0: 1.386  loss_ce_1: 0.6359  loss_mask_1: 0.1936  loss_dice_1: 1.316  loss_ce_2: 0.6012  loss_mask_2: 0.1843  loss_dice_2: 1.28  loss_ce_3: 0.56  loss_mask_3: 0.1773  loss_dice_3: 1.261  loss_ce_4: 0.5084  loss_mask_4: 0.1805  loss_dice_4: 1.247  loss_ce_5: 0.5231  loss_mask_5: 0.1794  loss_dice_5: 1.201  loss_ce_6: 0.5127  loss_mask_6: 0.1797  loss_dice_6: 1.212  loss_ce_7: 0.5157  loss_mask_7: 0.178  loss_dice_7: 1.222  loss_ce_8: 0.5237  loss_mask_8: 0.1782  loss_dice_8: 1.214    time: 1.0756  last_time: 1.0566  data_time: 0.0863  last_data_time: 0.1110   lr: 0.0001  max_mem: 32772M
[10/09 22:02:27] d2.utils.events INFO:  eta: 0:38:55  iter: 819  total_loss: 19.53  loss_ce: 0.5393  loss_mask: 0.1827  loss_dice: 1.178  loss_ce_0: 0.5523  loss_mask_0: 0.2053  loss_dice_0: 1.321  loss_ce_1: 0.6223  loss_mask_1: 0.1935  loss_dice_1: 1.331  loss_ce_2: 0.6093  loss_mask_2: 0.1839  loss_dice_2: 1.268  loss_ce_3: 0.5708  loss_mask_3: 0.1814  loss_dice_3: 1.182  loss_ce_4: 0.5182  loss_mask_4: 0.1825  loss_dice_4: 1.185  loss_ce_5: 0.565  loss_mask_5: 0.1855  loss_dice_5: 1.197  loss_ce_6: 0.5103  loss_mask_6: 0.1854  loss_dice_6: 1.189  loss_ce_7: 0.5186  loss_mask_7: 0.1843  loss_dice_7: 1.182  loss_ce_8: 0.4891  loss_mask_8: 0.1841  loss_dice_8: 1.172    time: 1.0754  last_time: 1.1127  data_time: 0.0747  last_data_time: 0.0602   lr: 0.0001  max_mem: 32772M
[10/09 22:02:49] d2.utils.events INFO:  eta: 0:38:34  iter: 839  total_loss: 20.87  loss_ce: 0.5064  loss_mask: 0.1782  loss_dice: 1.274  loss_ce_0: 0.5992  loss_mask_0: 0.2017  loss_dice_0: 1.493  loss_ce_1: 0.6771  loss_mask_1: 0.2022  loss_dice_1: 1.413  loss_ce_2: 0.6383  loss_mask_2: 0.1854  loss_dice_2: 1.342  loss_ce_3: 0.5626  loss_mask_3: 0.1785  loss_dice_3: 1.318  loss_ce_4: 0.5283  loss_mask_4: 0.1785  loss_dice_4: 1.27  loss_ce_5: 0.517  loss_mask_5: 0.1786  loss_dice_5: 1.286  loss_ce_6: 0.5017  loss_mask_6: 0.1782  loss_dice_6: 1.292  loss_ce_7: 0.4952  loss_mask_7: 0.18  loss_dice_7: 1.281  loss_ce_8: 0.5059  loss_mask_8: 0.1773  loss_dice_8: 1.31    time: 1.0759  last_time: 1.1363  data_time: 0.0813  last_data_time: 0.0813   lr: 0.0001  max_mem: 32772M
[10/09 22:03:11] d2.utils.events INFO:  eta: 0:38:12  iter: 859  total_loss: 20.2  loss_ce: 0.4698  loss_mask: 0.1726  loss_dice: 1.243  loss_ce_0: 0.6106  loss_mask_0: 0.2028  loss_dice_0: 1.457  loss_ce_1: 0.6157  loss_mask_1: 0.1938  loss_dice_1: 1.372  loss_ce_2: 0.5735  loss_mask_2: 0.1765  loss_dice_2: 1.362  loss_ce_3: 0.554  loss_mask_3: 0.1726  loss_dice_3: 1.288  loss_ce_4: 0.534  loss_mask_4: 0.1728  loss_dice_4: 1.289  loss_ce_5: 0.542  loss_mask_5: 0.1717  loss_dice_5: 1.28  loss_ce_6: 0.4806  loss_mask_6: 0.1696  loss_dice_6: 1.289  loss_ce_7: 0.4869  loss_mask_7: 0.1705  loss_dice_7: 1.269  loss_ce_8: 0.5143  loss_mask_8: 0.1719  loss_dice_8: 1.262    time: 1.0758  last_time: 1.0635  data_time: 0.0774  last_data_time: 0.0755   lr: 0.0001  max_mem: 32772M
[10/09 22:03:33] d2.utils.events INFO:  eta: 0:37:51  iter: 879  total_loss: 19.68  loss_ce: 0.4785  loss_mask: 0.1728  loss_dice: 1.23  loss_ce_0: 0.5817  loss_mask_0: 0.1961  loss_dice_0: 1.461  loss_ce_1: 0.6326  loss_mask_1: 0.1882  loss_dice_1: 1.382  loss_ce_2: 0.5898  loss_mask_2: 0.1773  loss_dice_2: 1.3  loss_ce_3: 0.533  loss_mask_3: 0.1748  loss_dice_3: 1.255  loss_ce_4: 0.5088  loss_mask_4: 0.1723  loss_dice_4: 1.265  loss_ce_5: 0.5055  loss_mask_5: 0.1747  loss_dice_5: 1.224  loss_ce_6: 0.5051  loss_mask_6: 0.1725  loss_dice_6: 1.25  loss_ce_7: 0.4729  loss_mask_7: 0.1746  loss_dice_7: 1.223  loss_ce_8: 0.5012  loss_mask_8: 0.1767  loss_dice_8: 1.211    time: 1.0759  last_time: 1.1103  data_time: 0.0830  last_data_time: 0.0931   lr: 0.0001  max_mem: 32772M
[10/09 22:03:55] d2.utils.events INFO:  eta: 0:37:31  iter: 899  total_loss: 19.78  loss_ce: 0.4589  loss_mask: 0.1746  loss_dice: 1.224  loss_ce_0: 0.5575  loss_mask_0: 0.2105  loss_dice_0: 1.425  loss_ce_1: 0.6224  loss_mask_1: 0.1845  loss_dice_1: 1.326  loss_ce_2: 0.5842  loss_mask_2: 0.1772  loss_dice_2: 1.277  loss_ce_3: 0.5185  loss_mask_3: 0.1789  loss_dice_3: 1.254  loss_ce_4: 0.4892  loss_mask_4: 0.1782  loss_dice_4: 1.257  loss_ce_5: 0.4886  loss_mask_5: 0.1768  loss_dice_5: 1.243  loss_ce_6: 0.4675  loss_mask_6: 0.1767  loss_dice_6: 1.208  loss_ce_7: 0.4622  loss_mask_7: 0.1763  loss_dice_7: 1.21  loss_ce_8: 0.4461  loss_mask_8: 0.1764  loss_dice_8: 1.255    time: 1.0763  last_time: 1.0797  data_time: 0.0853  last_data_time: 0.0908   lr: 0.0001  max_mem: 32772M
[10/09 22:04:17] d2.utils.events INFO:  eta: 0:37:10  iter: 919  total_loss: 19.6  loss_ce: 0.5144  loss_mask: 0.1693  loss_dice: 1.234  loss_ce_0: 0.601  loss_mask_0: 0.1953  loss_dice_0: 1.432  loss_ce_1: 0.6464  loss_mask_1: 0.1908  loss_dice_1: 1.362  loss_ce_2: 0.624  loss_mask_2: 0.1757  loss_dice_2: 1.271  loss_ce_3: 0.5439  loss_mask_3: 0.1737  loss_dice_3: 1.246  loss_ce_4: 0.5167  loss_mask_4: 0.1751  loss_dice_4: 1.218  loss_ce_5: 0.5204  loss_mask_5: 0.176  loss_dice_5: 1.264  loss_ce_6: 0.4651  loss_mask_6: 0.173  loss_dice_6: 1.221  loss_ce_7: 0.476  loss_mask_7: 0.172  loss_dice_7: 1.222  loss_ce_8: 0.4798  loss_mask_8: 0.1681  loss_dice_8: 1.228    time: 1.0770  last_time: 1.0901  data_time: 0.0920  last_data_time: 0.0902   lr: 0.0001  max_mem: 32772M
[10/09 22:04:38] d2.utils.events INFO:  eta: 0:36:49  iter: 939  total_loss: 19.85  loss_ce: 0.4812  loss_mask: 0.1713  loss_dice: 1.233  loss_ce_0: 0.5624  loss_mask_0: 0.1883  loss_dice_0: 1.439  loss_ce_1: 0.6081  loss_mask_1: 0.183  loss_dice_1: 1.326  loss_ce_2: 0.5823  loss_mask_2: 0.1764  loss_dice_2: 1.293  loss_ce_3: 0.4978  loss_mask_3: 0.1745  loss_dice_3: 1.264  loss_ce_4: 0.4951  loss_mask_4: 0.1751  loss_dice_4: 1.295  loss_ce_5: 0.4915  loss_mask_5: 0.1725  loss_dice_5: 1.27  loss_ce_6: 0.5107  loss_mask_6: 0.172  loss_dice_6: 1.254  loss_ce_7: 0.4648  loss_mask_7: 0.1723  loss_dice_7: 1.221  loss_ce_8: 0.4739  loss_mask_8: 0.1715  loss_dice_8: 1.251    time: 1.0770  last_time: 1.0421  data_time: 0.0772  last_data_time: 0.0739   lr: 0.0001  max_mem: 32772M
[10/09 22:05:01] d2.utils.events INFO:  eta: 0:36:29  iter: 959  total_loss: 20.12  loss_ce: 0.4766  loss_mask: 0.1745  loss_dice: 1.271  loss_ce_0: 0.5746  loss_mask_0: 0.2034  loss_dice_0: 1.489  loss_ce_1: 0.6263  loss_mask_1: 0.1937  loss_dice_1: 1.432  loss_ce_2: 0.5414  loss_mask_2: 0.1795  loss_dice_2: 1.388  loss_ce_3: 0.5147  loss_mask_3: 0.1766  loss_dice_3: 1.283  loss_ce_4: 0.4904  loss_mask_4: 0.1767  loss_dice_4: 1.327  loss_ce_5: 0.481  loss_mask_5: 0.1766  loss_dice_5: 1.318  loss_ce_6: 0.4751  loss_mask_6: 0.1756  loss_dice_6: 1.293  loss_ce_7: 0.4813  loss_mask_7: 0.1743  loss_dice_7: 1.261  loss_ce_8: 0.471  loss_mask_8: 0.1754  loss_dice_8: 1.268    time: 1.0776  last_time: 1.1893  data_time: 0.0793  last_data_time: 0.0768   lr: 0.0001  max_mem: 32772M
[10/09 22:05:23] d2.utils.events INFO:  eta: 0:36:07  iter: 979  total_loss: 20.48  loss_ce: 0.5265  loss_mask: 0.1723  loss_dice: 1.25  loss_ce_0: 0.5807  loss_mask_0: 0.2026  loss_dice_0: 1.494  loss_ce_1: 0.6343  loss_mask_1: 0.1844  loss_dice_1: 1.389  loss_ce_2: 0.5847  loss_mask_2: 0.1833  loss_dice_2: 1.31  loss_ce_3: 0.5652  loss_mask_3: 0.1796  loss_dice_3: 1.291  loss_ce_4: 0.5472  loss_mask_4: 0.177  loss_dice_4: 1.294  loss_ce_5: 0.5554  loss_mask_5: 0.1763  loss_dice_5: 1.269  loss_ce_6: 0.5182  loss_mask_6: 0.176  loss_dice_6: 1.235  loss_ce_7: 0.5022  loss_mask_7: 0.1745  loss_dice_7: 1.258  loss_ce_8: 0.5226  loss_mask_8: 0.1741  loss_dice_8: 1.264    time: 1.0779  last_time: 1.0920  data_time: 0.0834  last_data_time: 0.0876   lr: 0.0001  max_mem: 32772M
[10/09 22:05:45] d2.utils.events INFO:  eta: 0:35:47  iter: 999  total_loss: 20.23  loss_ce: 0.4992  loss_mask: 0.1695  loss_dice: 1.253  loss_ce_0: 0.5739  loss_mask_0: 0.1945  loss_dice_0: 1.469  loss_ce_1: 0.6447  loss_mask_1: 0.1764  loss_dice_1: 1.376  loss_ce_2: 0.5778  loss_mask_2: 0.1698  loss_dice_2: 1.377  loss_ce_3: 0.5424  loss_mask_3: 0.1713  loss_dice_3: 1.278  loss_ce_4: 0.5451  loss_mask_4: 0.1707  loss_dice_4: 1.303  loss_ce_5: 0.4986  loss_mask_5: 0.1665  loss_dice_5: 1.286  loss_ce_6: 0.4912  loss_mask_6: 0.1701  loss_dice_6: 1.261  loss_ce_7: 0.5168  loss_mask_7: 0.1657  loss_dice_7: 1.269  loss_ce_8: 0.4931  loss_mask_8: 0.1676  loss_dice_8: 1.286    time: 1.0784  last_time: 1.0868  data_time: 0.0837  last_data_time: 0.0687   lr: 0.0001  max_mem: 32772M
[10/09 22:06:07] d2.utils.events INFO:  eta: 0:35:26  iter: 1019  total_loss: 20.16  loss_ce: 0.4801  loss_mask: 0.1534  loss_dice: 1.233  loss_ce_0: 0.5997  loss_mask_0: 0.1834  loss_dice_0: 1.477  loss_ce_1: 0.6586  loss_mask_1: 0.1628  loss_dice_1: 1.397  loss_ce_2: 0.5902  loss_mask_2: 0.1569  loss_dice_2: 1.344  loss_ce_3: 0.5481  loss_mask_3: 0.1589  loss_dice_3: 1.271  loss_ce_4: 0.5023  loss_mask_4: 0.16  loss_dice_4: 1.299  loss_ce_5: 0.495  loss_mask_5: 0.1558  loss_dice_5: 1.26  loss_ce_6: 0.4722  loss_mask_6: 0.1556  loss_dice_6: 1.289  loss_ce_7: 0.4755  loss_mask_7: 0.1557  loss_dice_7: 1.265  loss_ce_8: 0.4893  loss_mask_8: 0.1556  loss_dice_8: 1.25    time: 1.0788  last_time: 1.0639  data_time: 0.0794  last_data_time: 0.0627   lr: 0.0001  max_mem: 32772M
[10/09 22:06:28] d2.utils.events INFO:  eta: 0:35:06  iter: 1039  total_loss: 19.35  loss_ce: 0.4788  loss_mask: 0.1797  loss_dice: 1.151  loss_ce_0: 0.6074  loss_mask_0: 0.2118  loss_dice_0: 1.375  loss_ce_1: 0.6387  loss_mask_1: 0.1902  loss_dice_1: 1.295  loss_ce_2: 0.5965  loss_mask_2: 0.1841  loss_dice_2: 1.218  loss_ce_3: 0.5266  loss_mask_3: 0.1803  loss_dice_3: 1.161  loss_ce_4: 0.4992  loss_mask_4: 0.1791  loss_dice_4: 1.145  loss_ce_5: 0.5144  loss_mask_5: 0.1808  loss_dice_5: 1.168  loss_ce_6: 0.4802  loss_mask_6: 0.1798  loss_dice_6: 1.134  loss_ce_7: 0.4732  loss_mask_7: 0.1813  loss_dice_7: 1.148  loss_ce_8: 0.4684  loss_mask_8: 0.1806  loss_dice_8: 1.173    time: 1.0784  last_time: 1.0848  data_time: 0.0701  last_data_time: 0.0937   lr: 0.0001  max_mem: 32772M
[10/09 22:06:49] d2.utils.events INFO:  eta: 0:34:45  iter: 1059  total_loss: 20.1  loss_ce: 0.4964  loss_mask: 0.1699  loss_dice: 1.204  loss_ce_0: 0.6002  loss_mask_0: 0.2101  loss_dice_0: 1.358  loss_ce_1: 0.675  loss_mask_1: 0.187  loss_dice_1: 1.308  loss_ce_2: 0.5849  loss_mask_2: 0.1744  loss_dice_2: 1.257  loss_ce_3: 0.5467  loss_mask_3: 0.178  loss_dice_3: 1.236  loss_ce_4: 0.5224  loss_mask_4: 0.1743  loss_dice_4: 1.204  loss_ce_5: 0.5001  loss_mask_5: 0.1745  loss_dice_5: 1.211  loss_ce_6: 0.513  loss_mask_6: 0.1709  loss_dice_6: 1.19  loss_ce_7: 0.4734  loss_mask_7: 0.1725  loss_dice_7: 1.179  loss_ce_8: 0.5008  loss_mask_8: 0.17  loss_dice_8: 1.207    time: 1.0782  last_time: 1.0737  data_time: 0.0782  last_data_time: 0.0998   lr: 0.0001  max_mem: 32772M
[10/09 22:07:11] d2.utils.events INFO:  eta: 0:34:25  iter: 1079  total_loss: 19.83  loss_ce: 0.4983  loss_mask: 0.16  loss_dice: 1.219  loss_ce_0: 0.5764  loss_mask_0: 0.197  loss_dice_0: 1.431  loss_ce_1: 0.6197  loss_mask_1: 0.1714  loss_dice_1: 1.36  loss_ce_2: 0.5564  loss_mask_2: 0.162  loss_dice_2: 1.281  loss_ce_3: 0.5384  loss_mask_3: 0.1631  loss_dice_3: 1.244  loss_ce_4: 0.5193  loss_mask_4: 0.1633  loss_dice_4: 1.263  loss_ce_5: 0.4837  loss_mask_5: 0.1606  loss_dice_5: 1.258  loss_ce_6: 0.4933  loss_mask_6: 0.1611  loss_dice_6: 1.192  loss_ce_7: 0.4831  loss_mask_7: 0.164  loss_dice_7: 1.226  loss_ce_8: 0.4772  loss_mask_8: 0.1619  loss_dice_8: 1.206    time: 1.0784  last_time: 1.0432  data_time: 0.0842  last_data_time: 0.0571   lr: 0.0001  max_mem: 32772M
[10/09 22:07:33] d2.utils.events INFO:  eta: 0:34:04  iter: 1099  total_loss: 20.22  loss_ce: 0.5133  loss_mask: 0.1635  loss_dice: 1.269  loss_ce_0: 0.576  loss_mask_0: 0.1807  loss_dice_0: 1.462  loss_ce_1: 0.6419  loss_mask_1: 0.1704  loss_dice_1: 1.396  loss_ce_2: 0.6132  loss_mask_2: 0.1613  loss_dice_2: 1.344  loss_ce_3: 0.5493  loss_mask_3: 0.1647  loss_dice_3: 1.297  loss_ce_4: 0.5117  loss_mask_4: 0.161  loss_dice_4: 1.283  loss_ce_5: 0.523  loss_mask_5: 0.1637  loss_dice_5: 1.314  loss_ce_6: 0.5123  loss_mask_6: 0.1633  loss_dice_6: 1.286  loss_ce_7: 0.4858  loss_mask_7: 0.1647  loss_dice_7: 1.268  loss_ce_8: 0.5028  loss_mask_8: 0.164  loss_dice_8: 1.308    time: 1.0782  last_time: 1.0669  data_time: 0.0712  last_data_time: 0.0753   lr: 0.0001  max_mem: 32772M
[10/09 22:07:54] d2.utils.events INFO:  eta: 0:33:43  iter: 1119  total_loss: 19.84  loss_ce: 0.45  loss_mask: 0.1658  loss_dice: 1.277  loss_ce_0: 0.5593  loss_mask_0: 0.1997  loss_dice_0: 1.448  loss_ce_1: 0.6187  loss_mask_1: 0.1806  loss_dice_1: 1.37  loss_ce_2: 0.5858  loss_mask_2: 0.1727  loss_dice_2: 1.35  loss_ce_3: 0.525  loss_mask_3: 0.1767  loss_dice_3: 1.235  loss_ce_4: 0.4783  loss_mask_4: 0.172  loss_dice_4: 1.289  loss_ce_5: 0.4538  loss_mask_5: 0.1667  loss_dice_5: 1.28  loss_ce_6: 0.5084  loss_mask_6: 0.1679  loss_dice_6: 1.258  loss_ce_7: 0.4515  loss_mask_7: 0.1678  loss_dice_7: 1.207  loss_ce_8: 0.4367  loss_mask_8: 0.1661  loss_dice_8: 1.243    time: 1.0779  last_time: 1.1026  data_time: 0.0696  last_data_time: 0.0792   lr: 0.0001  max_mem: 32772M
[10/09 22:08:16] d2.utils.events INFO:  eta: 0:33:22  iter: 1139  total_loss: 19.75  loss_ce: 0.4499  loss_mask: 0.1713  loss_dice: 1.16  loss_ce_0: 0.5845  loss_mask_0: 0.1962  loss_dice_0: 1.39  loss_ce_1: 0.6232  loss_mask_1: 0.182  loss_dice_1: 1.319  loss_ce_2: 0.5499  loss_mask_2: 0.1752  loss_dice_2: 1.278  loss_ce_3: 0.5281  loss_mask_3: 0.172  loss_dice_3: 1.225  loss_ce_4: 0.4704  loss_mask_4: 0.1708  loss_dice_4: 1.214  loss_ce_5: 0.474  loss_mask_5: 0.1718  loss_dice_5: 1.2  loss_ce_6: 0.4784  loss_mask_6: 0.1713  loss_dice_6: 1.184  loss_ce_7: 0.4524  loss_mask_7: 0.1729  loss_dice_7: 1.189  loss_ce_8: 0.457  loss_mask_8: 0.1717  loss_dice_8: 1.194    time: 1.0780  last_time: 1.0615  data_time: 0.0745  last_data_time: 0.0731   lr: 0.0001  max_mem: 32772M
[10/09 22:08:37] d2.utils.events INFO:  eta: 0:33:02  iter: 1159  total_loss: 19.25  loss_ce: 0.4355  loss_mask: 0.1717  loss_dice: 1.205  loss_ce_0: 0.5774  loss_mask_0: 0.2064  loss_dice_0: 1.404  loss_ce_1: 0.6161  loss_mask_1: 0.1838  loss_dice_1: 1.381  loss_ce_2: 0.5558  loss_mask_2: 0.1745  loss_dice_2: 1.292  loss_ce_3: 0.5084  loss_mask_3: 0.1738  loss_dice_3: 1.267  loss_ce_4: 0.4597  loss_mask_4: 0.1743  loss_dice_4: 1.218  loss_ce_5: 0.4699  loss_mask_5: 0.1708  loss_dice_5: 1.246  loss_ce_6: 0.4296  loss_mask_6: 0.1701  loss_dice_6: 1.209  loss_ce_7: 0.4403  loss_mask_7: 0.1711  loss_dice_7: 1.235  loss_ce_8: 0.4405  loss_mask_8: 0.171  loss_dice_8: 1.221    time: 1.0778  last_time: 0.9913  data_time: 0.0713  last_data_time: 0.0655   lr: 0.0001  max_mem: 32772M
[10/09 22:08:58] d2.utils.events INFO:  eta: 0:32:41  iter: 1179  total_loss: 19.97  loss_ce: 0.4559  loss_mask: 0.1589  loss_dice: 1.19  loss_ce_0: 0.5693  loss_mask_0: 0.1896  loss_dice_0: 1.437  loss_ce_1: 0.6394  loss_mask_1: 0.172  loss_dice_1: 1.356  loss_ce_2: 0.585  loss_mask_2: 0.162  loss_dice_2: 1.276  loss_ce_3: 0.5405  loss_mask_3: 0.1597  loss_dice_3: 1.282  loss_ce_4: 0.5025  loss_mask_4: 0.1582  loss_dice_4: 1.256  loss_ce_5: 0.49  loss_mask_5: 0.1586  loss_dice_5: 1.23  loss_ce_6: 0.4832  loss_mask_6: 0.1578  loss_dice_6: 1.231  loss_ce_7: 0.4764  loss_mask_7: 0.159  loss_dice_7: 1.244  loss_ce_8: 0.4511  loss_mask_8: 0.1595  loss_dice_8: 1.216    time: 1.0775  last_time: 1.0432  data_time: 0.0721  last_data_time: 0.0563   lr: 0.0001  max_mem: 32772M
[10/09 22:09:20] d2.utils.events INFO:  eta: 0:32:19  iter: 1199  total_loss: 19.95  loss_ce: 0.4895  loss_mask: 0.1703  loss_dice: 1.173  loss_ce_0: 0.5878  loss_mask_0: 0.1962  loss_dice_0: 1.448  loss_ce_1: 0.6179  loss_mask_1: 0.1887  loss_dice_1: 1.33  loss_ce_2: 0.6009  loss_mask_2: 0.1729  loss_dice_2: 1.299  loss_ce_3: 0.5418  loss_mask_3: 0.1714  loss_dice_3: 1.25  loss_ce_4: 0.52  loss_mask_4: 0.1702  loss_dice_4: 1.255  loss_ce_5: 0.5049  loss_mask_5: 0.1711  loss_dice_5: 1.228  loss_ce_6: 0.4897  loss_mask_6: 0.1703  loss_dice_6: 1.242  loss_ce_7: 0.4669  loss_mask_7: 0.1694  loss_dice_7: 1.222  loss_ce_8: 0.4599  loss_mask_8: 0.1676  loss_dice_8: 1.21    time: 1.0775  last_time: 1.0738  data_time: 0.0756  last_data_time: 0.0835   lr: 0.0001  max_mem: 32993M
[10/09 22:09:42] d2.utils.events INFO:  eta: 0:31:58  iter: 1219  total_loss: 20.04  loss_ce: 0.5028  loss_mask: 0.1638  loss_dice: 1.217  loss_ce_0: 0.607  loss_mask_0: 0.1915  loss_dice_0: 1.436  loss_ce_1: 0.6649  loss_mask_1: 0.1751  loss_dice_1: 1.373  loss_ce_2: 0.6063  loss_mask_2: 0.1699  loss_dice_2: 1.353  loss_ce_3: 0.5488  loss_mask_3: 0.1682  loss_dice_3: 1.258  loss_ce_4: 0.529  loss_mask_4: 0.1664  loss_dice_4: 1.281  loss_ce_5: 0.517  loss_mask_5: 0.167  loss_dice_5: 1.236  loss_ce_6: 0.4954  loss_mask_6: 0.1651  loss_dice_6: 1.215  loss_ce_7: 0.4754  loss_mask_7: 0.1618  loss_dice_7: 1.231  loss_ce_8: 0.4848  loss_mask_8: 0.1624  loss_dice_8: 1.25    time: 1.0775  last_time: 1.0560  data_time: 0.0754  last_data_time: 0.0920   lr: 0.0001  max_mem: 32993M
[10/09 22:10:03] d2.utils.events INFO:  eta: 0:31:37  iter: 1239  total_loss: 18.6  loss_ce: 0.446  loss_mask: 0.1691  loss_dice: 1.184  loss_ce_0: 0.5473  loss_mask_0: 0.2  loss_dice_0: 1.344  loss_ce_1: 0.6061  loss_mask_1: 0.1777  loss_dice_1: 1.295  loss_ce_2: 0.5594  loss_mask_2: 0.1734  loss_dice_2: 1.249  loss_ce_3: 0.5118  loss_mask_3: 0.1691  loss_dice_3: 1.177  loss_ce_4: 0.481  loss_mask_4: 0.1684  loss_dice_4: 1.181  loss_ce_5: 0.4581  loss_mask_5: 0.167  loss_dice_5: 1.17  loss_ce_6: 0.4782  loss_mask_6: 0.1671  loss_dice_6: 1.183  loss_ce_7: 0.4536  loss_mask_7: 0.1684  loss_dice_7: 1.172  loss_ce_8: 0.4567  loss_mask_8: 0.1678  loss_dice_8: 1.18    time: 1.0773  last_time: 1.0641  data_time: 0.0704  last_data_time: 0.0772   lr: 0.0001  max_mem: 32993M
[10/09 22:10:24] d2.utils.events INFO:  eta: 0:31:15  iter: 1259  total_loss: 19.73  loss_ce: 0.4825  loss_mask: 0.1836  loss_dice: 1.264  loss_ce_0: 0.5423  loss_mask_0: 0.2053  loss_dice_0: 1.425  loss_ce_1: 0.6175  loss_mask_1: 0.1953  loss_dice_1: 1.365  loss_ce_2: 0.5561  loss_mask_2: 0.1889  loss_dice_2: 1.333  loss_ce_3: 0.4839  loss_mask_3: 0.1887  loss_dice_3: 1.329  loss_ce_4: 0.4683  loss_mask_4: 0.1862  loss_dice_4: 1.284  loss_ce_5: 0.4681  loss_mask_5: 0.1852  loss_dice_5: 1.297  loss_ce_6: 0.479  loss_mask_6: 0.1861  loss_dice_6: 1.3  loss_ce_7: 0.4749  loss_mask_7: 0.1826  loss_dice_7: 1.215  loss_ce_8: 0.4455  loss_mask_8: 0.1822  loss_dice_8: 1.274    time: 1.0772  last_time: 1.1251  data_time: 0.0754  last_data_time: 0.0758   lr: 0.0001  max_mem: 32993M
[10/09 22:10:46] d2.utils.events INFO:  eta: 0:30:54  iter: 1279  total_loss: 19.88  loss_ce: 0.5301  loss_mask: 0.1592  loss_dice: 1.185  loss_ce_0: 0.6117  loss_mask_0: 0.1815  loss_dice_0: 1.439  loss_ce_1: 0.6569  loss_mask_1: 0.177  loss_dice_1: 1.336  loss_ce_2: 0.6173  loss_mask_2: 0.1675  loss_dice_2: 1.293  loss_ce_3: 0.5597  loss_mask_3: 0.1683  loss_dice_3: 1.226  loss_ce_4: 0.5276  loss_mask_4: 0.1652  loss_dice_4: 1.245  loss_ce_5: 0.5218  loss_mask_5: 0.1642  loss_dice_5: 1.208  loss_ce_6: 0.5083  loss_mask_6: 0.1604  loss_dice_6: 1.199  loss_ce_7: 0.5089  loss_mask_7: 0.1598  loss_dice_7: 1.182  loss_ce_8: 0.4974  loss_mask_8: 0.1577  loss_dice_8: 1.213    time: 1.0773  last_time: 1.1001  data_time: 0.0763  last_data_time: 0.0868   lr: 0.0001  max_mem: 32993M
[10/09 22:11:08] d2.utils.events INFO:  eta: 0:30:34  iter: 1299  total_loss: 20.14  loss_ce: 0.4747  loss_mask: 0.1638  loss_dice: 1.201  loss_ce_0: 0.5054  loss_mask_0: 0.1873  loss_dice_0: 1.483  loss_ce_1: 0.6148  loss_mask_1: 0.1755  loss_dice_1: 1.34  loss_ce_2: 0.5736  loss_mask_2: 0.169  loss_dice_2: 1.287  loss_ce_3: 0.5423  loss_mask_3: 0.1683  loss_dice_3: 1.238  loss_ce_4: 0.5117  loss_mask_4: 0.1664  loss_dice_4: 1.245  loss_ce_5: 0.504  loss_mask_5: 0.1659  loss_dice_5: 1.262  loss_ce_6: 0.4835  loss_mask_6: 0.1664  loss_dice_6: 1.265  loss_ce_7: 0.4755  loss_mask_7: 0.1647  loss_dice_7: 1.265  loss_ce_8: 0.4735  loss_mask_8: 0.1632  loss_dice_8: 1.211    time: 1.0777  last_time: 1.0514  data_time: 0.0812  last_data_time: 0.0683   lr: 0.0001  max_mem: 32993M
[10/09 22:11:30] d2.utils.events INFO:  eta: 0:30:14  iter: 1319  total_loss: 19.32  loss_ce: 0.4894  loss_mask: 0.167  loss_dice: 1.201  loss_ce_0: 0.5806  loss_mask_0: 0.1851  loss_dice_0: 1.442  loss_ce_1: 0.6492  loss_mask_1: 0.1762  loss_dice_1: 1.322  loss_ce_2: 0.6042  loss_mask_2: 0.166  loss_dice_2: 1.254  loss_ce_3: 0.5502  loss_mask_3: 0.165  loss_dice_3: 1.193  loss_ce_4: 0.5326  loss_mask_4: 0.1669  loss_dice_4: 1.205  loss_ce_5: 0.4934  loss_mask_5: 0.1646  loss_dice_5: 1.217  loss_ce_6: 0.4853  loss_mask_6: 0.1642  loss_dice_6: 1.206  loss_ce_7: 0.4698  loss_mask_7: 0.1663  loss_dice_7: 1.164  loss_ce_8: 0.4866  loss_mask_8: 0.1634  loss_dice_8: 1.169    time: 1.0779  last_time: 1.0883  data_time: 0.0803  last_data_time: 0.0919   lr: 0.0001  max_mem: 32993M
[10/09 22:11:52] d2.utils.events INFO:  eta: 0:29:52  iter: 1339  total_loss: 19.51  loss_ce: 0.5017  loss_mask: 0.1699  loss_dice: 1.143  loss_ce_0: 0.5891  loss_mask_0: 0.1813  loss_dice_0: 1.367  loss_ce_1: 0.6414  loss_mask_1: 0.1723  loss_dice_1: 1.318  loss_ce_2: 0.594  loss_mask_2: 0.1623  loss_dice_2: 1.246  loss_ce_3: 0.5475  loss_mask_3: 0.164  loss_dice_3: 1.197  loss_ce_4: 0.527  loss_mask_4: 0.1629  loss_dice_4: 1.213  loss_ce_5: 0.4982  loss_mask_5: 0.1663  loss_dice_5: 1.226  loss_ce_6: 0.5079  loss_mask_6: 0.1629  loss_dice_6: 1.186  loss_ce_7: 0.5056  loss_mask_7: 0.1676  loss_dice_7: 1.188  loss_ce_8: 0.4746  loss_mask_8: 0.164  loss_dice_8: 1.193    time: 1.0778  last_time: 1.1144  data_time: 0.0746  last_data_time: 0.0657   lr: 0.0001  max_mem: 32993M
[10/09 22:12:13] d2.utils.events INFO:  eta: 0:29:31  iter: 1359  total_loss: 20.48  loss_ce: 0.4918  loss_mask: 0.1539  loss_dice: 1.3  loss_ce_0: 0.6102  loss_mask_0: 0.1803  loss_dice_0: 1.479  loss_ce_1: 0.6826  loss_mask_1: 0.177  loss_dice_1: 1.404  loss_ce_2: 0.5988  loss_mask_2: 0.1672  loss_dice_2: 1.329  loss_ce_3: 0.5532  loss_mask_3: 0.1613  loss_dice_3: 1.305  loss_ce_4: 0.5308  loss_mask_4: 0.1605  loss_dice_4: 1.283  loss_ce_5: 0.5083  loss_mask_5: 0.1574  loss_dice_5: 1.259  loss_ce_6: 0.5238  loss_mask_6: 0.1597  loss_dice_6: 1.251  loss_ce_7: 0.4911  loss_mask_7: 0.1588  loss_dice_7: 1.322  loss_ce_8: 0.5029  loss_mask_8: 0.1556  loss_dice_8: 1.294    time: 1.0780  last_time: 1.0736  data_time: 0.0812  last_data_time: 0.0660   lr: 0.0001  max_mem: 32993M
[10/09 22:12:35] d2.utils.events INFO:  eta: 0:29:09  iter: 1379  total_loss: 20.39  loss_ce: 0.4694  loss_mask: 0.1596  loss_dice: 1.222  loss_ce_0: 0.5531  loss_mask_0: 0.1816  loss_dice_0: 1.44  loss_ce_1: 0.6721  loss_mask_1: 0.1691  loss_dice_1: 1.392  loss_ce_2: 0.6015  loss_mask_2: 0.1616  loss_dice_2: 1.328  loss_ce_3: 0.5319  loss_mask_3: 0.1561  loss_dice_3: 1.257  loss_ce_4: 0.5156  loss_mask_4: 0.1574  loss_dice_4: 1.279  loss_ce_5: 0.4825  loss_mask_5: 0.1546  loss_dice_5: 1.284  loss_ce_6: 0.4878  loss_mask_6: 0.1559  loss_dice_6: 1.251  loss_ce_7: 0.4835  loss_mask_7: 0.159  loss_dice_7: 1.266  loss_ce_8: 0.4918  loss_mask_8: 0.1585  loss_dice_8: 1.234    time: 1.0781  last_time: 1.0880  data_time: 0.0778  last_data_time: 0.0816   lr: 0.0001  max_mem: 32993M
[10/09 22:12:57] d2.utils.events INFO:  eta: 0:28:47  iter: 1399  total_loss: 20.4  loss_ce: 0.487  loss_mask: 0.167  loss_dice: 1.203  loss_ce_0: 0.5828  loss_mask_0: 0.1832  loss_dice_0: 1.456  loss_ce_1: 0.626  loss_mask_1: 0.181  loss_dice_1: 1.368  loss_ce_2: 0.5957  loss_mask_2: 0.1738  loss_dice_2: 1.327  loss_ce_3: 0.5283  loss_mask_3: 0.1703  loss_dice_3: 1.274  loss_ce_4: 0.5413  loss_mask_4: 0.1699  loss_dice_4: 1.26  loss_ce_5: 0.5176  loss_mask_5: 0.1696  loss_dice_5: 1.252  loss_ce_6: 0.4706  loss_mask_6: 0.1712  loss_dice_6: 1.226  loss_ce_7: 0.5031  loss_mask_7: 0.1709  loss_dice_7: 1.228  loss_ce_8: 0.4808  loss_mask_8: 0.1676  loss_dice_8: 1.227    time: 1.0782  last_time: 1.1013  data_time: 0.0786  last_data_time: 0.0640   lr: 0.0001  max_mem: 32993M
[10/09 22:13:19] d2.utils.events INFO:  eta: 0:28:27  iter: 1419  total_loss: 19.98  loss_ce: 0.4557  loss_mask: 0.1733  loss_dice: 1.268  loss_ce_0: 0.5035  loss_mask_0: 0.1963  loss_dice_0: 1.459  loss_ce_1: 0.6297  loss_mask_1: 0.1808  loss_dice_1: 1.35  loss_ce_2: 0.5642  loss_mask_2: 0.173  loss_dice_2: 1.333  loss_ce_3: 0.5167  loss_mask_3: 0.1715  loss_dice_3: 1.274  loss_ce_4: 0.4949  loss_mask_4: 0.1732  loss_dice_4: 1.275  loss_ce_5: 0.4957  loss_mask_5: 0.171  loss_dice_5: 1.26  loss_ce_6: 0.4718  loss_mask_6: 0.1703  loss_dice_6: 1.245  loss_ce_7: 0.4797  loss_mask_7: 0.1713  loss_dice_7: 1.247  loss_ce_8: 0.4472  loss_mask_8: 0.1706  loss_dice_8: 1.266    time: 1.0785  last_time: 1.0677  data_time: 0.0804  last_data_time: 0.0801   lr: 0.0001  max_mem: 32993M
[10/09 22:13:41] d2.utils.events INFO:  eta: 0:28:05  iter: 1439  total_loss: 18.82  loss_ce: 0.4659  loss_mask: 0.1801  loss_dice: 1.138  loss_ce_0: 0.5639  loss_mask_0: 0.2065  loss_dice_0: 1.372  loss_ce_1: 0.6352  loss_mask_1: 0.1898  loss_dice_1: 1.276  loss_ce_2: 0.5635  loss_mask_2: 0.1798  loss_dice_2: 1.206  loss_ce_3: 0.5436  loss_mask_3: 0.1806  loss_dice_3: 1.177  loss_ce_4: 0.5081  loss_mask_4: 0.1823  loss_dice_4: 1.171  loss_ce_5: 0.4784  loss_mask_5: 0.1829  loss_dice_5: 1.171  loss_ce_6: 0.4743  loss_mask_6: 0.1801  loss_dice_6: 1.116  loss_ce_7: 0.462  loss_mask_7: 0.1809  loss_dice_7: 1.149  loss_ce_8: 0.4747  loss_mask_8: 0.1809  loss_dice_8: 1.148    time: 1.0784  last_time: 1.0629  data_time: 0.0760  last_data_time: 0.0778   lr: 0.0001  max_mem: 32993M
[10/09 22:14:02] d2.utils.events INFO:  eta: 0:27:44  iter: 1459  total_loss: 19.79  loss_ce: 0.4651  loss_mask: 0.1648  loss_dice: 1.217  loss_ce_0: 0.5372  loss_mask_0: 0.198  loss_dice_0: 1.45  loss_ce_1: 0.6564  loss_mask_1: 0.1817  loss_dice_1: 1.373  loss_ce_2: 0.5652  loss_mask_2: 0.169  loss_dice_2: 1.33  loss_ce_3: 0.5312  loss_mask_3: 0.1687  loss_dice_3: 1.301  loss_ce_4: 0.5082  loss_mask_4: 0.1657  loss_dice_4: 1.29  loss_ce_5: 0.5106  loss_mask_5: 0.1652  loss_dice_5: 1.283  loss_ce_6: 0.4604  loss_mask_6: 0.1657  loss_dice_6: 1.251  loss_ce_7: 0.4756  loss_mask_7: 0.1654  loss_dice_7: 1.221  loss_ce_8: 0.4872  loss_mask_8: 0.1664  loss_dice_8: 1.218    time: 1.0783  last_time: 1.0658  data_time: 0.0758  last_data_time: 0.0624   lr: 0.0001  max_mem: 32993M
[10/09 22:14:24] d2.utils.events INFO:  eta: 0:27:23  iter: 1479  total_loss: 20.07  loss_ce: 0.5172  loss_mask: 0.1616  loss_dice: 1.215  loss_ce_0: 0.574  loss_mask_0: 0.1847  loss_dice_0: 1.429  loss_ce_1: 0.6874  loss_mask_1: 0.1803  loss_dice_1: 1.345  loss_ce_2: 0.5839  loss_mask_2: 0.1751  loss_dice_2: 1.296  loss_ce_3: 0.5713  loss_mask_3: 0.1689  loss_dice_3: 1.256  loss_ce_4: 0.5534  loss_mask_4: 0.1663  loss_dice_4: 1.271  loss_ce_5: 0.5423  loss_mask_5: 0.1669  loss_dice_5: 1.234  loss_ce_6: 0.5098  loss_mask_6: 0.1679  loss_dice_6: 1.228  loss_ce_7: 0.5013  loss_mask_7: 0.1672  loss_dice_7: 1.252  loss_ce_8: 0.504  loss_mask_8: 0.1622  loss_dice_8: 1.249    time: 1.0785  last_time: 1.0678  data_time: 0.0811  last_data_time: 0.0916   lr: 0.0001  max_mem: 32993M
[10/09 22:14:46] d2.utils.events INFO:  eta: 0:27:01  iter: 1499  total_loss: 19.18  loss_ce: 0.4634  loss_mask: 0.1609  loss_dice: 1.221  loss_ce_0: 0.5301  loss_mask_0: 0.188  loss_dice_0: 1.419  loss_ce_1: 0.5805  loss_mask_1: 0.1776  loss_dice_1: 1.329  loss_ce_2: 0.5531  loss_mask_2: 0.1704  loss_dice_2: 1.282  loss_ce_3: 0.5121  loss_mask_3: 0.1674  loss_dice_3: 1.254  loss_ce_4: 0.4826  loss_mask_4: 0.1653  loss_dice_4: 1.267  loss_ce_5: 0.485  loss_mask_5: 0.1655  loss_dice_5: 1.266  loss_ce_6: 0.4414  loss_mask_6: 0.1617  loss_dice_6: 1.194  loss_ce_7: 0.4418  loss_mask_7: 0.1621  loss_dice_7: 1.172  loss_ce_8: 0.4698  loss_mask_8: 0.1608  loss_dice_8: 1.177    time: 1.0785  last_time: 1.0883  data_time: 0.0770  last_data_time: 0.0765   lr: 0.0001  max_mem: 32993M
[10/09 22:15:07] d2.utils.events INFO:  eta: 0:26:38  iter: 1519  total_loss: 19.73  loss_ce: 0.4686  loss_mask: 0.1694  loss_dice: 1.166  loss_ce_0: 0.549  loss_mask_0: 0.1972  loss_dice_0: 1.381  loss_ce_1: 0.6137  loss_mask_1: 0.1764  loss_dice_1: 1.325  loss_ce_2: 0.5724  loss_mask_2: 0.1713  loss_dice_2: 1.295  loss_ce_3: 0.5296  loss_mask_3: 0.1701  loss_dice_3: 1.233  loss_ce_4: 0.4936  loss_mask_4: 0.1713  loss_dice_4: 1.231  loss_ce_5: 0.4852  loss_mask_5: 0.1676  loss_dice_5: 1.188  loss_ce_6: 0.4898  loss_mask_6: 0.1708  loss_dice_6: 1.201  loss_ce_7: 0.4774  loss_mask_7: 0.169  loss_dice_7: 1.201  loss_ce_8: 0.4804  loss_mask_8: 0.1692  loss_dice_8: 1.168    time: 1.0784  last_time: 1.0742  data_time: 0.0753  last_data_time: 0.1010   lr: 0.0001  max_mem: 32993M
[10/09 22:15:28] d2.utils.events INFO:  eta: 0:26:15  iter: 1539  total_loss: 18.91  loss_ce: 0.4461  loss_mask: 0.1724  loss_dice: 1.197  loss_ce_0: 0.5269  loss_mask_0: 0.1892  loss_dice_0: 1.389  loss_ce_1: 0.6289  loss_mask_1: 0.1766  loss_dice_1: 1.346  loss_ce_2: 0.5622  loss_mask_2: 0.1764  loss_dice_2: 1.276  loss_ce_3: 0.5367  loss_mask_3: 0.1727  loss_dice_3: 1.203  loss_ce_4: 0.4923  loss_mask_4: 0.1747  loss_dice_4: 1.209  loss_ce_5: 0.5018  loss_mask_5: 0.1679  loss_dice_5: 1.205  loss_ce_6: 0.4401  loss_mask_6: 0.1721  loss_dice_6: 1.209  loss_ce_7: 0.4471  loss_mask_7: 0.1719  loss_dice_7: 1.178  loss_ce_8: 0.4545  loss_mask_8: 0.1703  loss_dice_8: 1.17    time: 1.0781  last_time: 1.0447  data_time: 0.0688  last_data_time: 0.0589   lr: 0.0001  max_mem: 32993M
[10/09 22:15:50] d2.utils.events INFO:  eta: 0:25:53  iter: 1559  total_loss: 19.4  loss_ce: 0.4295  loss_mask: 0.171  loss_dice: 1.159  loss_ce_0: 0.5472  loss_mask_0: 0.1928  loss_dice_0: 1.405  loss_ce_1: 0.567  loss_mask_1: 0.1839  loss_dice_1: 1.299  loss_ce_2: 0.5271  loss_mask_2: 0.1747  loss_dice_2: 1.236  loss_ce_3: 0.5054  loss_mask_3: 0.1748  loss_dice_3: 1.232  loss_ce_4: 0.462  loss_mask_4: 0.174  loss_dice_4: 1.225  loss_ce_5: 0.4822  loss_mask_5: 0.1716  loss_dice_5: 1.222  loss_ce_6: 0.4772  loss_mask_6: 0.1706  loss_dice_6: 1.206  loss_ce_7: 0.4611  loss_mask_7: 0.1729  loss_dice_7: 1.203  loss_ce_8: 0.4446  loss_mask_8: 0.1696  loss_dice_8: 1.184    time: 1.0780  last_time: 1.0875  data_time: 0.0701  last_data_time: 0.0845   lr: 0.0001  max_mem: 32993M
[10/09 22:16:12] d2.utils.events INFO:  eta: 0:25:32  iter: 1579  total_loss: 19.54  loss_ce: 0.4494  loss_mask: 0.1672  loss_dice: 1.245  loss_ce_0: 0.5722  loss_mask_0: 0.1912  loss_dice_0: 1.443  loss_ce_1: 0.6205  loss_mask_1: 0.181  loss_dice_1: 1.362  loss_ce_2: 0.545  loss_mask_2: 0.1716  loss_dice_2: 1.3  loss_ce_3: 0.5226  loss_mask_3: 0.1705  loss_dice_3: 1.241  loss_ce_4: 0.4598  loss_mask_4: 0.1673  loss_dice_4: 1.252  loss_ce_5: 0.4488  loss_mask_5: 0.1692  loss_dice_5: 1.306  loss_ce_6: 0.4509  loss_mask_6: 0.1669  loss_dice_6: 1.209  loss_ce_7: 0.4573  loss_mask_7: 0.167  loss_dice_7: 1.218  loss_ce_8: 0.4642  loss_mask_8: 0.1676  loss_dice_8: 1.222    time: 1.0783  last_time: 1.1013  data_time: 0.0810  last_data_time: 0.0811   lr: 0.0001  max_mem: 32993M
[10/09 22:16:34] d2.utils.events INFO:  eta: 0:25:12  iter: 1599  total_loss: 19.74  loss_ce: 0.4558  loss_mask: 0.1496  loss_dice: 1.24  loss_ce_0: 0.5267  loss_mask_0: 0.1874  loss_dice_0: 1.5  loss_ce_1: 0.6113  loss_mask_1: 0.1676  loss_dice_1: 1.384  loss_ce_2: 0.5588  loss_mask_2: 0.1571  loss_dice_2: 1.343  loss_ce_3: 0.5259  loss_mask_3: 0.1623  loss_dice_3: 1.263  loss_ce_4: 0.5142  loss_mask_4: 0.1566  loss_dice_4: 1.232  loss_ce_5: 0.4927  loss_mask_5: 0.1528  loss_dice_5: 1.215  loss_ce_6: 0.4496  loss_mask_6: 0.1505  loss_dice_6: 1.228  loss_ce_7: 0.4735  loss_mask_7: 0.1514  loss_dice_7: 1.258  loss_ce_8: 0.4677  loss_mask_8: 0.1487  loss_dice_8: 1.229    time: 1.0784  last_time: 1.1041  data_time: 0.0788  last_data_time: 0.0580   lr: 0.0001  max_mem: 32993M
[10/09 22:16:56] d2.utils.events INFO:  eta: 0:24:51  iter: 1619  total_loss: 20.69  loss_ce: 0.5169  loss_mask: 0.1503  loss_dice: 1.253  loss_ce_0: 0.5791  loss_mask_0: 0.1818  loss_dice_0: 1.499  loss_ce_1: 0.6397  loss_mask_1: 0.1674  loss_dice_1: 1.372  loss_ce_2: 0.5836  loss_mask_2: 0.1568  loss_dice_2: 1.322  loss_ce_3: 0.5727  loss_mask_3: 0.1517  loss_dice_3: 1.293  loss_ce_4: 0.5048  loss_mask_4: 0.1536  loss_dice_4: 1.283  loss_ce_5: 0.4905  loss_mask_5: 0.154  loss_dice_5: 1.258  loss_ce_6: 0.4978  loss_mask_6: 0.1542  loss_dice_6: 1.268  loss_ce_7: 0.4873  loss_mask_7: 0.1534  loss_dice_7: 1.237  loss_ce_8: 0.4675  loss_mask_8: 0.1516  loss_dice_8: 1.258    time: 1.0787  last_time: 1.1462  data_time: 0.0789  last_data_time: 0.0895   lr: 0.0001  max_mem: 32993M
[10/09 22:17:18] d2.utils.events INFO:  eta: 0:24:29  iter: 1639  total_loss: 19.99  loss_ce: 0.4615  loss_mask: 0.1564  loss_dice: 1.218  loss_ce_0: 0.5751  loss_mask_0: 0.1799  loss_dice_0: 1.416  loss_ce_1: 0.6563  loss_mask_1: 0.1667  loss_dice_1: 1.365  loss_ce_2: 0.579  loss_mask_2: 0.1591  loss_dice_2: 1.302  loss_ce_3: 0.5318  loss_mask_3: 0.1573  loss_dice_3: 1.251  loss_ce_4: 0.5085  loss_mask_4: 0.1587  loss_dice_4: 1.25  loss_ce_5: 0.5173  loss_mask_5: 0.1568  loss_dice_5: 1.227  loss_ce_6: 0.4825  loss_mask_6: 0.1549  loss_dice_6: 1.226  loss_ce_7: 0.4994  loss_mask_7: 0.1568  loss_dice_7: 1.246  loss_ce_8: 0.4856  loss_mask_8: 0.1547  loss_dice_8: 1.226    time: 1.0788  last_time: 1.0438  data_time: 0.0796  last_data_time: 0.0821   lr: 0.0001  max_mem: 32993M
[10/09 22:17:39] d2.utils.events INFO:  eta: 0:24:06  iter: 1659  total_loss: 19.5  loss_ce: 0.4171  loss_mask: 0.1703  loss_dice: 1.233  loss_ce_0: 0.5667  loss_mask_0: 0.1994  loss_dice_0: 1.375  loss_ce_1: 0.5856  loss_mask_1: 0.1833  loss_dice_1: 1.322  loss_ce_2: 0.5526  loss_mask_2: 0.1807  loss_dice_2: 1.314  loss_ce_3: 0.4919  loss_mask_3: 0.1742  loss_dice_3: 1.259  loss_ce_4: 0.4645  loss_mask_4: 0.1712  loss_dice_4: 1.263  loss_ce_5: 0.4741  loss_mask_5: 0.1731  loss_dice_5: 1.256  loss_ce_6: 0.4192  loss_mask_6: 0.1726  loss_dice_6: 1.245  loss_ce_7: 0.4295  loss_mask_7: 0.1732  loss_dice_7: 1.235  loss_ce_8: 0.4163  loss_mask_8: 0.1709  loss_dice_8: 1.209    time: 1.0788  last_time: 1.0463  data_time: 0.0776  last_data_time: 0.0831   lr: 0.0001  max_mem: 32993M
[10/09 22:18:01] d2.utils.events INFO:  eta: 0:23:45  iter: 1679  total_loss: 19.16  loss_ce: 0.4481  loss_mask: 0.1691  loss_dice: 1.213  loss_ce_0: 0.5125  loss_mask_0: 0.1942  loss_dice_0: 1.402  loss_ce_1: 0.5899  loss_mask_1: 0.183  loss_dice_1: 1.346  loss_ce_2: 0.5298  loss_mask_2: 0.1747  loss_dice_2: 1.3  loss_ce_3: 0.5178  loss_mask_3: 0.1735  loss_dice_3: 1.237  loss_ce_4: 0.4429  loss_mask_4: 0.1744  loss_dice_4: 1.257  loss_ce_5: 0.4603  loss_mask_5: 0.1775  loss_dice_5: 1.238  loss_ce_6: 0.4372  loss_mask_6: 0.171  loss_dice_6: 1.216  loss_ce_7: 0.4027  loss_mask_7: 0.173  loss_dice_7: 1.243  loss_ce_8: 0.4066  loss_mask_8: 0.1711  loss_dice_8: 1.25    time: 1.0787  last_time: 0.9867  data_time: 0.0782  last_data_time: 0.0535   lr: 0.0001  max_mem: 32993M
[10/09 22:18:22] d2.utils.events INFO:  eta: 0:23:23  iter: 1699  total_loss: 19.5  loss_ce: 0.4326  loss_mask: 0.1646  loss_dice: 1.24  loss_ce_0: 0.5613  loss_mask_0: 0.194  loss_dice_0: 1.424  loss_ce_1: 0.6078  loss_mask_1: 0.18  loss_dice_1: 1.412  loss_ce_2: 0.5039  loss_mask_2: 0.1751  loss_dice_2: 1.309  loss_ce_3: 0.4978  loss_mask_3: 0.1669  loss_dice_3: 1.288  loss_ce_4: 0.4745  loss_mask_4: 0.1618  loss_dice_4: 1.262  loss_ce_5: 0.4478  loss_mask_5: 0.1633  loss_dice_5: 1.297  loss_ce_6: 0.4554  loss_mask_6: 0.1649  loss_dice_6: 1.27  loss_ce_7: 0.4461  loss_mask_7: 0.1661  loss_dice_7: 1.254  loss_ce_8: 0.4567  loss_mask_8: 0.1656  loss_dice_8: 1.238    time: 1.0787  last_time: 1.0898  data_time: 0.0754  last_data_time: 0.0804   lr: 0.0001  max_mem: 32993M
[10/09 22:18:44] d2.utils.events INFO:  eta: 0:23:02  iter: 1719  total_loss: 19.29  loss_ce: 0.4537  loss_mask: 0.1639  loss_dice: 1.199  loss_ce_0: 0.5117  loss_mask_0: 0.1958  loss_dice_0: 1.432  loss_ce_1: 0.6  loss_mask_1: 0.1805  loss_dice_1: 1.381  loss_ce_2: 0.5175  loss_mask_2: 0.1628  loss_dice_2: 1.326  loss_ce_3: 0.4884  loss_mask_3: 0.1637  loss_dice_3: 1.24  loss_ce_4: 0.4744  loss_mask_4: 0.1683  loss_dice_4: 1.256  loss_ce_5: 0.4424  loss_mask_5: 0.1643  loss_dice_5: 1.235  loss_ce_6: 0.4118  loss_mask_6: 0.1614  loss_dice_6: 1.231  loss_ce_7: 0.4111  loss_mask_7: 0.1629  loss_dice_7: 1.238  loss_ce_8: 0.4327  loss_mask_8: 0.1618  loss_dice_8: 1.233    time: 1.0786  last_time: 1.0676  data_time: 0.0749  last_data_time: 0.0725   lr: 0.0001  max_mem: 32993M
[10/09 22:19:05] d2.utils.events INFO:  eta: 0:22:39  iter: 1739  total_loss: 18.75  loss_ce: 0.4288  loss_mask: 0.1656  loss_dice: 1.149  loss_ce_0: 0.5437  loss_mask_0: 0.198  loss_dice_0: 1.355  loss_ce_1: 0.6325  loss_mask_1: 0.1752  loss_dice_1: 1.268  loss_ce_2: 0.5538  loss_mask_2: 0.1706  loss_dice_2: 1.221  loss_ce_3: 0.4951  loss_mask_3: 0.17  loss_dice_3: 1.167  loss_ce_4: 0.4782  loss_mask_4: 0.1682  loss_dice_4: 1.17  loss_ce_5: 0.4514  loss_mask_5: 0.1674  loss_dice_5: 1.188  loss_ce_6: 0.4597  loss_mask_6: 0.1664  loss_dice_6: 1.165  loss_ce_7: 0.4518  loss_mask_7: 0.165  loss_dice_7: 1.182  loss_ce_8: 0.4603  loss_mask_8: 0.1665  loss_dice_8: 1.167    time: 1.0785  last_time: 1.0327  data_time: 0.0764  last_data_time: 0.0614   lr: 0.0001  max_mem: 32993M
[10/09 22:19:27] d2.utils.events INFO:  eta: 0:22:16  iter: 1759  total_loss: 20.09  loss_ce: 0.4728  loss_mask: 0.1625  loss_dice: 1.22  loss_ce_0: 0.5984  loss_mask_0: 0.1975  loss_dice_0: 1.401  loss_ce_1: 0.6841  loss_mask_1: 0.1816  loss_dice_1: 1.351  loss_ce_2: 0.6142  loss_mask_2: 0.1687  loss_dice_2: 1.301  loss_ce_3: 0.5749  loss_mask_3: 0.1661  loss_dice_3: 1.248  loss_ce_4: 0.5454  loss_mask_4: 0.1649  loss_dice_4: 1.229  loss_ce_5: 0.5252  loss_mask_5: 0.163  loss_dice_5: 1.234  loss_ce_6: 0.5097  loss_mask_6: 0.1624  loss_dice_6: 1.201  loss_ce_7: 0.5301  loss_mask_7: 0.1615  loss_dice_7: 1.201  loss_ce_8: 0.4988  loss_mask_8: 0.1622  loss_dice_8: 1.206    time: 1.0784  last_time: 1.0554  data_time: 0.0783  last_data_time: 0.0770   lr: 0.0001  max_mem: 32993M
[10/09 22:19:48] d2.utils.events INFO:  eta: 0:21:54  iter: 1779  total_loss: 19.02  loss_ce: 0.4018  loss_mask: 0.1608  loss_dice: 1.226  loss_ce_0: 0.5314  loss_mask_0: 0.1902  loss_dice_0: 1.46  loss_ce_1: 0.5982  loss_mask_1: 0.1721  loss_dice_1: 1.36  loss_ce_2: 0.5496  loss_mask_2: 0.1633  loss_dice_2: 1.306  loss_ce_3: 0.5024  loss_mask_3: 0.1647  loss_dice_3: 1.252  loss_ce_4: 0.4934  loss_mask_4: 0.1651  loss_dice_4: 1.3  loss_ce_5: 0.4439  loss_mask_5: 0.1623  loss_dice_5: 1.267  loss_ce_6: 0.4184  loss_mask_6: 0.1623  loss_dice_6: 1.255  loss_ce_7: 0.4352  loss_mask_7: 0.1602  loss_dice_7: 1.251  loss_ce_8: 0.4205  loss_mask_8: 0.1597  loss_dice_8: 1.239    time: 1.0783  last_time: 1.0650  data_time: 0.0732  last_data_time: 0.0676   lr: 0.0001  max_mem: 32993M
[10/09 22:20:10] d2.utils.events INFO:  eta: 0:21:32  iter: 1799  total_loss: 19.65  loss_ce: 0.4316  loss_mask: 0.1689  loss_dice: 1.242  loss_ce_0: 0.5698  loss_mask_0: 0.1893  loss_dice_0: 1.45  loss_ce_1: 0.637  loss_mask_1: 0.1866  loss_dice_1: 1.338  loss_ce_2: 0.5537  loss_mask_2: 0.1732  loss_dice_2: 1.341  loss_ce_3: 0.5209  loss_mask_3: 0.17  loss_dice_3: 1.253  loss_ce_4: 0.4887  loss_mask_4: 0.168  loss_dice_4: 1.281  loss_ce_5: 0.4917  loss_mask_5: 0.1673  loss_dice_5: 1.257  loss_ce_6: 0.4367  loss_mask_6: 0.1683  loss_dice_6: 1.262  loss_ce_7: 0.4661  loss_mask_7: 0.1679  loss_dice_7: 1.232  loss_ce_8: 0.4641  loss_mask_8: 0.1692  loss_dice_8: 1.251    time: 1.0782  last_time: 1.0489  data_time: 0.0753  last_data_time: 0.0834   lr: 0.0001  max_mem: 32993M
[10/09 22:20:31] d2.utils.events INFO:  eta: 0:21:11  iter: 1819  total_loss: 20.59  loss_ce: 0.4848  loss_mask: 0.1559  loss_dice: 1.304  loss_ce_0: 0.5902  loss_mask_0: 0.178  loss_dice_0: 1.487  loss_ce_1: 0.6394  loss_mask_1: 0.166  loss_dice_1: 1.42  loss_ce_2: 0.5905  loss_mask_2: 0.1556  loss_dice_2: 1.401  loss_ce_3: 0.5099  loss_mask_3: 0.1576  loss_dice_3: 1.334  loss_ce_4: 0.4886  loss_mask_4: 0.1585  loss_dice_4: 1.316  loss_ce_5: 0.5016  loss_mask_5: 0.1552  loss_dice_5: 1.342  loss_ce_6: 0.4827  loss_mask_6: 0.154  loss_dice_6: 1.291  loss_ce_7: 0.4869  loss_mask_7: 0.1553  loss_dice_7: 1.31  loss_ce_8: 0.4685  loss_mask_8: 0.1541  loss_dice_8: 1.286    time: 1.0782  last_time: 1.1256  data_time: 0.0760  last_data_time: 0.0886   lr: 0.0001  max_mem: 32993M
[10/09 22:20:53] d2.utils.events INFO:  eta: 0:20:49  iter: 1839  total_loss: 20.05  loss_ce: 0.4457  loss_mask: 0.1655  loss_dice: 1.225  loss_ce_0: 0.5405  loss_mask_0: 0.1926  loss_dice_0: 1.478  loss_ce_1: 0.5964  loss_mask_1: 0.1764  loss_dice_1: 1.386  loss_ce_2: 0.5722  loss_mask_2: 0.1741  loss_dice_2: 1.318  loss_ce_3: 0.5318  loss_mask_3: 0.1717  loss_dice_3: 1.292  loss_ce_4: 0.5105  loss_mask_4: 0.168  loss_dice_4: 1.262  loss_ce_5: 0.4648  loss_mask_5: 0.1672  loss_dice_5: 1.248  loss_ce_6: 0.4711  loss_mask_6: 0.1629  loss_dice_6: 1.243  loss_ce_7: 0.4801  loss_mask_7: 0.1631  loss_dice_7: 1.252  loss_ce_8: 0.4833  loss_mask_8: 0.1627  loss_dice_8: 1.231    time: 1.0782  last_time: 1.1034  data_time: 0.0733  last_data_time: 0.0864   lr: 0.0001  max_mem: 32993M
[10/09 22:21:15] d2.utils.events INFO:  eta: 0:20:28  iter: 1859  total_loss: 20.5  loss_ce: 0.4443  loss_mask: 0.1626  loss_dice: 1.284  loss_ce_0: 0.5766  loss_mask_0: 0.1908  loss_dice_0: 1.484  loss_ce_1: 0.6343  loss_mask_1: 0.1714  loss_dice_1: 1.396  loss_ce_2: 0.5943  loss_mask_2: 0.1681  loss_dice_2: 1.375  loss_ce_3: 0.5626  loss_mask_3: 0.1613  loss_dice_3: 1.311  loss_ce_4: 0.5315  loss_mask_4: 0.1614  loss_dice_4: 1.316  loss_ce_5: 0.5014  loss_mask_5: 0.1599  loss_dice_5: 1.303  loss_ce_6: 0.4673  loss_mask_6: 0.1629  loss_dice_6: 1.294  loss_ce_7: 0.484  loss_mask_7: 0.1635  loss_dice_7: 1.288  loss_ce_8: 0.4841  loss_mask_8: 0.1637  loss_dice_8: 1.29    time: 1.0783  last_time: 1.0488  data_time: 0.0796  last_data_time: 0.0609   lr: 0.0001  max_mem: 32993M
[10/09 22:21:36] d2.utils.events INFO:  eta: 0:20:06  iter: 1879  total_loss: 19.42  loss_ce: 0.4516  loss_mask: 0.1675  loss_dice: 1.223  loss_ce_0: 0.5895  loss_mask_0: 0.2028  loss_dice_0: 1.43  loss_ce_1: 0.6291  loss_mask_1: 0.1844  loss_dice_1: 1.339  loss_ce_2: 0.59  loss_mask_2: 0.1727  loss_dice_2: 1.298  loss_ce_3: 0.4861  loss_mask_3: 0.172  loss_dice_3: 1.257  loss_ce_4: 0.4867  loss_mask_4: 0.1718  loss_dice_4: 1.245  loss_ce_5: 0.461  loss_mask_5: 0.1704  loss_dice_5: 1.245  loss_ce_6: 0.4384  loss_mask_6: 0.1697  loss_dice_6: 1.222  loss_ce_7: 0.4422  loss_mask_7: 0.1692  loss_dice_7: 1.215  loss_ce_8: 0.4547  loss_mask_8: 0.1688  loss_dice_8: 1.212    time: 1.0782  last_time: 1.0438  data_time: 0.0740  last_data_time: 0.0751   lr: 0.0001  max_mem: 32993M
[10/09 22:21:58] d2.utils.events INFO:  eta: 0:19:44  iter: 1899  total_loss: 18.22  loss_ce: 0.4285  loss_mask: 0.1499  loss_dice: 1.189  loss_ce_0: 0.5248  loss_mask_0: 0.1837  loss_dice_0: 1.364  loss_ce_1: 0.6074  loss_mask_1: 0.1684  loss_dice_1: 1.295  loss_ce_2: 0.5544  loss_mask_2: 0.1539  loss_dice_2: 1.259  loss_ce_3: 0.4783  loss_mask_3: 0.1563  loss_dice_3: 1.209  loss_ce_4: 0.4581  loss_mask_4: 0.1543  loss_dice_4: 1.212  loss_ce_5: 0.4402  loss_mask_5: 0.1526  loss_dice_5: 1.164  loss_ce_6: 0.4567  loss_mask_6: 0.1511  loss_dice_6: 1.165  loss_ce_7: 0.4722  loss_mask_7: 0.1515  loss_dice_7: 1.192  loss_ce_8: 0.4478  loss_mask_8: 0.1528  loss_dice_8: 1.148    time: 1.0782  last_time: 1.0541  data_time: 0.0766  last_data_time: 0.0856   lr: 0.0001  max_mem: 32993M
[10/09 22:22:19] d2.utils.events INFO:  eta: 0:19:21  iter: 1919  total_loss: 19.29  loss_ce: 0.4696  loss_mask: 0.1657  loss_dice: 1.184  loss_ce_0: 0.5188  loss_mask_0: 0.1961  loss_dice_0: 1.418  loss_ce_1: 0.5879  loss_mask_1: 0.1807  loss_dice_1: 1.371  loss_ce_2: 0.5612  loss_mask_2: 0.1682  loss_dice_2: 1.273  loss_ce_3: 0.513  loss_mask_3: 0.1684  loss_dice_3: 1.218  loss_ce_4: 0.4611  loss_mask_4: 0.1673  loss_dice_4: 1.222  loss_ce_5: 0.472  loss_mask_5: 0.1656  loss_dice_5: 1.227  loss_ce_6: 0.4812  loss_mask_6: 0.1646  loss_dice_6: 1.22  loss_ce_7: 0.4753  loss_mask_7: 0.1632  loss_dice_7: 1.203  loss_ce_8: 0.4741  loss_mask_8: 0.1634  loss_dice_8: 1.218    time: 1.0781  last_time: 1.1357  data_time: 0.0741  last_data_time: 0.0687   lr: 0.0001  max_mem: 32993M
[10/09 22:22:41] d2.utils.events INFO:  eta: 0:19:00  iter: 1939  total_loss: 18.87  loss_ce: 0.4258  loss_mask: 0.1594  loss_dice: 1.183  loss_ce_0: 0.5551  loss_mask_0: 0.1904  loss_dice_0: 1.385  loss_ce_1: 0.599  loss_mask_1: 0.1724  loss_dice_1: 1.317  loss_ce_2: 0.5453  loss_mask_2: 0.1638  loss_dice_2: 1.279  loss_ce_3: 0.5026  loss_mask_3: 0.1638  loss_dice_3: 1.206  loss_ce_4: 0.4835  loss_mask_4: 0.1598  loss_dice_4: 1.188  loss_ce_5: 0.4949  loss_mask_5: 0.1602  loss_dice_5: 1.183  loss_ce_6: 0.4451  loss_mask_6: 0.16  loss_dice_6: 1.2  loss_ce_7: 0.4579  loss_mask_7: 0.1575  loss_dice_7: 1.186  loss_ce_8: 0.451  loss_mask_8: 0.158  loss_dice_8: 1.181    time: 1.0781  last_time: 1.0739  data_time: 0.0776  last_data_time: 0.0709   lr: 0.0001  max_mem: 32993M
[10/09 22:23:02] d2.utils.events INFO:  eta: 0:18:38  iter: 1959  total_loss: 19.04  loss_ce: 0.4012  loss_mask: 0.1571  loss_dice: 1.208  loss_ce_0: 0.512  loss_mask_0: 0.1867  loss_dice_0: 1.402  loss_ce_1: 0.5625  loss_mask_1: 0.1678  loss_dice_1: 1.38  loss_ce_2: 0.5183  loss_mask_2: 0.162  loss_dice_2: 1.289  loss_ce_3: 0.4783  loss_mask_3: 0.1571  loss_dice_3: 1.251  loss_ce_4: 0.4761  loss_mask_4: 0.1573  loss_dice_4: 1.207  loss_ce_5: 0.4809  loss_mask_5: 0.1552  loss_dice_5: 1.26  loss_ce_6: 0.4523  loss_mask_6: 0.1571  loss_dice_6: 1.222  loss_ce_7: 0.431  loss_mask_7: 0.1546  loss_dice_7: 1.175  loss_ce_8: 0.4382  loss_mask_8: 0.1574  loss_dice_8: 1.2    time: 1.0779  last_time: 1.0553  data_time: 0.0721  last_data_time: 0.0839   lr: 0.0001  max_mem: 32993M
[10/09 22:23:24] d2.utils.events INFO:  eta: 0:18:16  iter: 1979  total_loss: 19.16  loss_ce: 0.4227  loss_mask: 0.1707  loss_dice: 1.231  loss_ce_0: 0.5283  loss_mask_0: 0.1977  loss_dice_0: 1.404  loss_ce_1: 0.5846  loss_mask_1: 0.1786  loss_dice_1: 1.303  loss_ce_2: 0.5098  loss_mask_2: 0.1752  loss_dice_2: 1.28  loss_ce_3: 0.4792  loss_mask_3: 0.1749  loss_dice_3: 1.238  loss_ce_4: 0.4513  loss_mask_4: 0.1755  loss_dice_4: 1.213  loss_ce_5: 0.4528  loss_mask_5: 0.1723  loss_dice_5: 1.216  loss_ce_6: 0.4462  loss_mask_6: 0.1715  loss_dice_6: 1.231  loss_ce_7: 0.4202  loss_mask_7: 0.1708  loss_dice_7: 1.19  loss_ce_8: 0.4224  loss_mask_8: 0.1725  loss_dice_8: 1.213    time: 1.0779  last_time: 1.0608  data_time: 0.0725  last_data_time: 0.0702   lr: 0.0001  max_mem: 32993M
[10/09 22:23:45] d2.utils.events INFO:  eta: 0:17:53  iter: 1999  total_loss: 20.48  loss_ce: 0.4685  loss_mask: 0.1639  loss_dice: 1.255  loss_ce_0: 0.576  loss_mask_0: 0.197  loss_dice_0: 1.445  loss_ce_1: 0.6221  loss_mask_1: 0.1806  loss_dice_1: 1.39  loss_ce_2: 0.6004  loss_mask_2: 0.1777  loss_dice_2: 1.31  loss_ce_3: 0.5253  loss_mask_3: 0.1722  loss_dice_3: 1.267  loss_ce_4: 0.4908  loss_mask_4: 0.1702  loss_dice_4: 1.261  loss_ce_5: 0.4758  loss_mask_5: 0.1695  loss_dice_5: 1.291  loss_ce_6: 0.4647  loss_mask_6: 0.1642  loss_dice_6: 1.291  loss_ce_7: 0.4732  loss_mask_7: 0.1634  loss_dice_7: 1.22  loss_ce_8: 0.4409  loss_mask_8: 0.1631  loss_dice_8: 1.265    time: 1.0780  last_time: 1.0725  data_time: 0.0766  last_data_time: 0.0833   lr: 0.0001  max_mem: 32993M
[10/09 22:24:07] d2.utils.events INFO:  eta: 0:17:32  iter: 2019  total_loss: 19.22  loss_ce: 0.4551  loss_mask: 0.1578  loss_dice: 1.151  loss_ce_0: 0.4976  loss_mask_0: 0.1921  loss_dice_0: 1.482  loss_ce_1: 0.5794  loss_mask_1: 0.171  loss_dice_1: 1.314  loss_ce_2: 0.5491  loss_mask_2: 0.166  loss_dice_2: 1.257  loss_ce_3: 0.4938  loss_mask_3: 0.1613  loss_dice_3: 1.217  loss_ce_4: 0.4791  loss_mask_4: 0.1607  loss_dice_4: 1.212  loss_ce_5: 0.4663  loss_mask_5: 0.1578  loss_dice_5: 1.196  loss_ce_6: 0.4523  loss_mask_6: 0.1604  loss_dice_6: 1.169  loss_ce_7: 0.4668  loss_mask_7: 0.1593  loss_dice_7: 1.169  loss_ce_8: 0.4716  loss_mask_8: 0.1595  loss_dice_8: 1.224    time: 1.0780  last_time: 1.1575  data_time: 0.0729  last_data_time: 0.0949   lr: 0.0001  max_mem: 32993M
[10/09 22:24:29] d2.utils.events INFO:  eta: 0:17:11  iter: 2039  total_loss: 20.24  loss_ce: 0.453  loss_mask: 0.1646  loss_dice: 1.289  loss_ce_0: 0.5316  loss_mask_0: 0.1879  loss_dice_0: 1.528  loss_ce_1: 0.5896  loss_mask_1: 0.1764  loss_dice_1: 1.442  loss_ce_2: 0.5782  loss_mask_2: 0.169  loss_dice_2: 1.376  loss_ce_3: 0.5091  loss_mask_3: 0.1688  loss_dice_3: 1.341  loss_ce_4: 0.4934  loss_mask_4: 0.1672  loss_dice_4: 1.326  loss_ce_5: 0.4543  loss_mask_5: 0.1681  loss_dice_5: 1.357  loss_ce_6: 0.4463  loss_mask_6: 0.1636  loss_dice_6: 1.287  loss_ce_7: 0.4474  loss_mask_7: 0.1646  loss_dice_7: 1.301  loss_ce_8: 0.4303  loss_mask_8: 0.1648  loss_dice_8: 1.315    time: 1.0783  last_time: 1.1134  data_time: 0.0782  last_data_time: 0.0984   lr: 0.0001  max_mem: 32993M
[10/09 22:24:51] d2.utils.events INFO:  eta: 0:16:50  iter: 2059  total_loss: 18.92  loss_ce: 0.4211  loss_mask: 0.1649  loss_dice: 1.179  loss_ce_0: 0.5207  loss_mask_0: 0.1912  loss_dice_0: 1.435  loss_ce_1: 0.564  loss_mask_1: 0.173  loss_dice_1: 1.335  loss_ce_2: 0.5542  loss_mask_2: 0.1669  loss_dice_2: 1.257  loss_ce_3: 0.4944  loss_mask_3: 0.1665  loss_dice_3: 1.261  loss_ce_4: 0.4663  loss_mask_4: 0.1668  loss_dice_4: 1.239  loss_ce_5: 0.4544  loss_mask_5: 0.1647  loss_dice_5: 1.228  loss_ce_6: 0.4379  loss_mask_6: 0.167  loss_dice_6: 1.206  loss_ce_7: 0.4494  loss_mask_7: 0.1652  loss_dice_7: 1.18  loss_ce_8: 0.4346  loss_mask_8: 0.1671  loss_dice_8: 1.208    time: 1.0784  last_time: 1.1117  data_time: 0.0763  last_data_time: 0.0958   lr: 0.0001  max_mem: 32993M
[10/09 22:25:13] d2.utils.events INFO:  eta: 0:16:29  iter: 2079  total_loss: 20.07  loss_ce: 0.423  loss_mask: 0.1731  loss_dice: 1.215  loss_ce_0: 0.5266  loss_mask_0: 0.2012  loss_dice_0: 1.446  loss_ce_1: 0.5794  loss_mask_1: 0.1897  loss_dice_1: 1.341  loss_ce_2: 0.5404  loss_mask_2: 0.1786  loss_dice_2: 1.3  loss_ce_3: 0.5054  loss_mask_3: 0.1798  loss_dice_3: 1.26  loss_ce_4: 0.4759  loss_mask_4: 0.1759  loss_dice_4: 1.244  loss_ce_5: 0.4601  loss_mask_5: 0.1727  loss_dice_5: 1.285  loss_ce_6: 0.4616  loss_mask_6: 0.1741  loss_dice_6: 1.23  loss_ce_7: 0.4424  loss_mask_7: 0.1753  loss_dice_7: 1.242  loss_ce_8: 0.4422  loss_mask_8: 0.1741  loss_dice_8: 1.255    time: 1.0785  last_time: 1.0881  data_time: 0.0756  last_data_time: 0.0931   lr: 0.0001  max_mem: 32993M
[10/09 22:25:35] d2.utils.events INFO:  eta: 0:16:08  iter: 2099  total_loss: 19.07  loss_ce: 0.4588  loss_mask: 0.1551  loss_dice: 1.157  loss_ce_0: 0.5439  loss_mask_0: 0.1831  loss_dice_0: 1.435  loss_ce_1: 0.5989  loss_mask_1: 0.1653  loss_dice_1: 1.327  loss_ce_2: 0.5815  loss_mask_2: 0.1628  loss_dice_2: 1.252  loss_ce_3: 0.4731  loss_mask_3: 0.1567  loss_dice_3: 1.214  loss_ce_4: 0.4628  loss_mask_4: 0.1574  loss_dice_4: 1.209  loss_ce_5: 0.4774  loss_mask_5: 0.1564  loss_dice_5: 1.2  loss_ce_6: 0.471  loss_mask_6: 0.1581  loss_dice_6: 1.164  loss_ce_7: 0.448  loss_mask_7: 0.1557  loss_dice_7: 1.172  loss_ce_8: 0.448  loss_mask_8: 0.1551  loss_dice_8: 1.186    time: 1.0786  last_time: 1.0758  data_time: 0.0762  last_data_time: 0.0621   lr: 0.0001  max_mem: 32993M
[10/09 22:25:57] d2.utils.events INFO:  eta: 0:15:46  iter: 2119  total_loss: 19.87  loss_ce: 0.4899  loss_mask: 0.16  loss_dice: 1.226  loss_ce_0: 0.5836  loss_mask_0: 0.1839  loss_dice_0: 1.43  loss_ce_1: 0.6466  loss_mask_1: 0.1684  loss_dice_1: 1.345  loss_ce_2: 0.6087  loss_mask_2: 0.1591  loss_dice_2: 1.298  loss_ce_3: 0.5367  loss_mask_3: 0.162  loss_dice_3: 1.226  loss_ce_4: 0.5035  loss_mask_4: 0.1604  loss_dice_4: 1.227  loss_ce_5: 0.5034  loss_mask_5: 0.1638  loss_dice_5: 1.242  loss_ce_6: 0.4814  loss_mask_6: 0.1613  loss_dice_6: 1.206  loss_ce_7: 0.502  loss_mask_7: 0.1605  loss_dice_7: 1.222  loss_ce_8: 0.5072  loss_mask_8: 0.1621  loss_dice_8: 1.232    time: 1.0787  last_time: 1.0947  data_time: 0.0820  last_data_time: 0.0827   lr: 0.0001  max_mem: 32993M
[10/09 22:26:19] d2.utils.events INFO:  eta: 0:15:25  iter: 2139  total_loss: 19.44  loss_ce: 0.4736  loss_mask: 0.1491  loss_dice: 1.179  loss_ce_0: 0.5999  loss_mask_0: 0.1788  loss_dice_0: 1.442  loss_ce_1: 0.6351  loss_mask_1: 0.1614  loss_dice_1: 1.373  loss_ce_2: 0.5771  loss_mask_2: 0.1554  loss_dice_2: 1.312  loss_ce_3: 0.5178  loss_mask_3: 0.1532  loss_dice_3: 1.217  loss_ce_4: 0.5227  loss_mask_4: 0.156  loss_dice_4: 1.234  loss_ce_5: 0.4993  loss_mask_5: 0.1503  loss_dice_5: 1.224  loss_ce_6: 0.4717  loss_mask_6: 0.1525  loss_dice_6: 1.224  loss_ce_7: 0.4608  loss_mask_7: 0.1495  loss_dice_7: 1.226  loss_ce_8: 0.4616  loss_mask_8: 0.1481  loss_dice_8: 1.229    time: 1.0789  last_time: 1.0336  data_time: 0.0794  last_data_time: 0.0798   lr: 0.0001  max_mem: 32993M
[10/09 22:26:41] d2.utils.events INFO:  eta: 0:15:04  iter: 2159  total_loss: 19.38  loss_ce: 0.4463  loss_mask: 0.1589  loss_dice: 1.214  loss_ce_0: 0.5359  loss_mask_0: 0.1896  loss_dice_0: 1.397  loss_ce_1: 0.6609  loss_mask_1: 0.1753  loss_dice_1: 1.372  loss_ce_2: 0.5533  loss_mask_2: 0.164  loss_dice_2: 1.294  loss_ce_3: 0.4881  loss_mask_3: 0.1638  loss_dice_3: 1.266  loss_ce_4: 0.4679  loss_mask_4: 0.1641  loss_dice_4: 1.24  loss_ce_5: 0.4599  loss_mask_5: 0.1641  loss_dice_5: 1.236  loss_ce_6: 0.4181  loss_mask_6: 0.1604  loss_dice_6: 1.244  loss_ce_7: 0.4251  loss_mask_7: 0.1593  loss_dice_7: 1.22  loss_ce_8: 0.4322  loss_mask_8: 0.16  loss_dice_8: 1.209    time: 1.0791  last_time: 1.1363  data_time: 0.0796  last_data_time: 0.0895   lr: 0.0001  max_mem: 32993M
[10/09 22:27:02] d2.utils.events INFO:  eta: 0:14:43  iter: 2179  total_loss: 18.86  loss_ce: 0.4288  loss_mask: 0.1598  loss_dice: 1.187  loss_ce_0: 0.5714  loss_mask_0: 0.1877  loss_dice_0: 1.377  loss_ce_1: 0.624  loss_mask_1: 0.1752  loss_dice_1: 1.313  loss_ce_2: 0.5313  loss_mask_2: 0.1634  loss_dice_2: 1.261  loss_ce_3: 0.4688  loss_mask_3: 0.1625  loss_dice_3: 1.232  loss_ce_4: 0.5051  loss_mask_4: 0.1618  loss_dice_4: 1.203  loss_ce_5: 0.4599  loss_mask_5: 0.1628  loss_dice_5: 1.201  loss_ce_6: 0.4445  loss_mask_6: 0.1612  loss_dice_6: 1.177  loss_ce_7: 0.4676  loss_mask_7: 0.1599  loss_dice_7: 1.185  loss_ce_8: 0.4202  loss_mask_8: 0.1592  loss_dice_8: 1.177    time: 1.0790  last_time: 1.0976  data_time: 0.0759  last_data_time: 0.0704   lr: 0.0001  max_mem: 32993M
[10/09 22:27:24] d2.utils.events INFO:  eta: 0:14:22  iter: 2199  total_loss: 19.25  loss_ce: 0.4291  loss_mask: 0.1595  loss_dice: 1.202  loss_ce_0: 0.5458  loss_mask_0: 0.1808  loss_dice_0: 1.38  loss_ce_1: 0.5865  loss_mask_1: 0.1696  loss_dice_1: 1.337  loss_ce_2: 0.5641  loss_mask_2: 0.1615  loss_dice_2: 1.267  loss_ce_3: 0.4934  loss_mask_3: 0.1651  loss_dice_3: 1.235  loss_ce_4: 0.4428  loss_mask_4: 0.1649  loss_dice_4: 1.238  loss_ce_5: 0.4452  loss_mask_5: 0.1629  loss_dice_5: 1.253  loss_ce_6: 0.4282  loss_mask_6: 0.1627  loss_dice_6: 1.208  loss_ce_7: 0.4352  loss_mask_7: 0.1619  loss_dice_7: 1.163  loss_ce_8: 0.4231  loss_mask_8: 0.1647  loss_dice_8: 1.208    time: 1.0789  last_time: 1.0373  data_time: 0.0776  last_data_time: 0.0693   lr: 0.0001  max_mem: 32993M
[10/09 22:27:46] d2.utils.events INFO:  eta: 0:14:00  iter: 2219  total_loss: 18.75  loss_ce: 0.4833  loss_mask: 0.1532  loss_dice: 1.167  loss_ce_0: 0.5553  loss_mask_0: 0.1766  loss_dice_0: 1.351  loss_ce_1: 0.6319  loss_mask_1: 0.166  loss_dice_1: 1.269  loss_ce_2: 0.5622  loss_mask_2: 0.16  loss_dice_2: 1.259  loss_ce_3: 0.5483  loss_mask_3: 0.1582  loss_dice_3: 1.219  loss_ce_4: 0.5138  loss_mask_4: 0.1591  loss_dice_4: 1.218  loss_ce_5: 0.4523  loss_mask_5: 0.1573  loss_dice_5: 1.189  loss_ce_6: 0.4639  loss_mask_6: 0.1555  loss_dice_6: 1.195  loss_ce_7: 0.4571  loss_mask_7: 0.1563  loss_dice_7: 1.169  loss_ce_8: 0.4705  loss_mask_8: 0.1567  loss_dice_8: 1.159    time: 1.0790  last_time: 1.0226  data_time: 0.0802  last_data_time: 0.0657   lr: 0.0001  max_mem: 32993M
[10/09 22:28:08] d2.utils.events INFO:  eta: 0:13:39  iter: 2239  total_loss: 19.16  loss_ce: 0.4118  loss_mask: 0.1605  loss_dice: 1.235  loss_ce_0: 0.5262  loss_mask_0: 0.1819  loss_dice_0: 1.41  loss_ce_1: 0.6067  loss_mask_1: 0.1712  loss_dice_1: 1.373  loss_ce_2: 0.5596  loss_mask_2: 0.1599  loss_dice_2: 1.317  loss_ce_3: 0.5015  loss_mask_3: 0.1595  loss_dice_3: 1.234  loss_ce_4: 0.4768  loss_mask_4: 0.1589  loss_dice_4: 1.235  loss_ce_5: 0.46  loss_mask_5: 0.1568  loss_dice_5: 1.209  loss_ce_6: 0.4578  loss_mask_6: 0.1603  loss_dice_6: 1.182  loss_ce_7: 0.4415  loss_mask_7: 0.1627  loss_dice_7: 1.191  loss_ce_8: 0.4494  loss_mask_8: 0.159  loss_dice_8: 1.182    time: 1.0792  last_time: 1.1322  data_time: 0.0786  last_data_time: 0.0866   lr: 0.0001  max_mem: 32993M
[10/09 22:28:30] d2.utils.events INFO:  eta: 0:13:18  iter: 2259  total_loss: 18.75  loss_ce: 0.4144  loss_mask: 0.1614  loss_dice: 1.207  loss_ce_0: 0.5232  loss_mask_0: 0.1842  loss_dice_0: 1.402  loss_ce_1: 0.5393  loss_mask_1: 0.1694  loss_dice_1: 1.318  loss_ce_2: 0.5302  loss_mask_2: 0.1656  loss_dice_2: 1.295  loss_ce_3: 0.4511  loss_mask_3: 0.162  loss_dice_3: 1.236  loss_ce_4: 0.4467  loss_mask_4: 0.1626  loss_dice_4: 1.223  loss_ce_5: 0.4283  loss_mask_5: 0.161  loss_dice_5: 1.224  loss_ce_6: 0.407  loss_mask_6: 0.1631  loss_dice_6: 1.186  loss_ce_7: 0.3839  loss_mask_7: 0.1597  loss_dice_7: 1.228  loss_ce_8: 0.3898  loss_mask_8: 0.162  loss_dice_8: 1.21    time: 1.0793  last_time: 1.0424  data_time: 0.0781  last_data_time: 0.0575   lr: 0.0001  max_mem: 32993M
[10/09 22:28:51] d2.utils.events INFO:  eta: 0:12:56  iter: 2279  total_loss: 18.96  loss_ce: 0.4622  loss_mask: 0.1642  loss_dice: 1.186  loss_ce_0: 0.5634  loss_mask_0: 0.1888  loss_dice_0: 1.403  loss_ce_1: 0.6055  loss_mask_1: 0.1719  loss_dice_1: 1.339  loss_ce_2: 0.5721  loss_mask_2: 0.1676  loss_dice_2: 1.275  loss_ce_3: 0.5174  loss_mask_3: 0.1669  loss_dice_3: 1.209  loss_ce_4: 0.4795  loss_mask_4: 0.1656  loss_dice_4: 1.22  loss_ce_5: 0.4679  loss_mask_5: 0.1667  loss_dice_5: 1.195  loss_ce_6: 0.4702  loss_mask_6: 0.1635  loss_dice_6: 1.177  loss_ce_7: 0.481  loss_mask_7: 0.1622  loss_dice_7: 1.169  loss_ce_8: 0.4667  loss_mask_8: 0.1629  loss_dice_8: 1.179    time: 1.0792  last_time: 1.0502  data_time: 0.0780  last_data_time: 0.0822   lr: 0.0001  max_mem: 32993M
[10/09 22:29:13] d2.utils.events INFO:  eta: 0:12:34  iter: 2299  total_loss: 19.41  loss_ce: 0.4392  loss_mask: 0.1584  loss_dice: 1.255  loss_ce_0: 0.5253  loss_mask_0: 0.1837  loss_dice_0: 1.436  loss_ce_1: 0.603  loss_mask_1: 0.1694  loss_dice_1: 1.373  loss_ce_2: 0.5472  loss_mask_2: 0.1615  loss_dice_2: 1.336  loss_ce_3: 0.4932  loss_mask_3: 0.1607  loss_dice_3: 1.256  loss_ce_4: 0.4873  loss_mask_4: 0.16  loss_dice_4: 1.275  loss_ce_5: 0.4763  loss_mask_5: 0.1591  loss_dice_5: 1.26  loss_ce_6: 0.4621  loss_mask_6: 0.1577  loss_dice_6: 1.258  loss_ce_7: 0.4477  loss_mask_7: 0.1562  loss_dice_7: 1.264  loss_ce_8: 0.4516  loss_mask_8: 0.1571  loss_dice_8: 1.264    time: 1.0793  last_time: 1.1036  data_time: 0.0770  last_data_time: 0.0637   lr: 0.0001  max_mem: 32993M
[10/09 22:29:35] d2.utils.events INFO:  eta: 0:12:12  iter: 2319  total_loss: 18.32  loss_ce: 0.3926  loss_mask: 0.1611  loss_dice: 1.207  loss_ce_0: 0.4975  loss_mask_0: 0.183  loss_dice_0: 1.337  loss_ce_1: 0.5301  loss_mask_1: 0.1784  loss_dice_1: 1.304  loss_ce_2: 0.5437  loss_mask_2: 0.1679  loss_dice_2: 1.24  loss_ce_3: 0.4943  loss_mask_3: 0.1645  loss_dice_3: 1.203  loss_ce_4: 0.4208  loss_mask_4: 0.1651  loss_dice_4: 1.184  loss_ce_5: 0.4423  loss_mask_5: 0.1625  loss_dice_5: 1.198  loss_ce_6: 0.3916  loss_mask_6: 0.1606  loss_dice_6: 1.212  loss_ce_7: 0.382  loss_mask_7: 0.1615  loss_dice_7: 1.163  loss_ce_8: 0.4094  loss_mask_8: 0.1602  loss_dice_8: 1.176    time: 1.0794  last_time: 1.1148  data_time: 0.0812  last_data_time: 0.0928   lr: 0.0001  max_mem: 32993M
[10/09 22:29:56] d2.utils.events INFO:  eta: 0:11:50  iter: 2339  total_loss: 18.77  loss_ce: 0.4279  loss_mask: 0.1566  loss_dice: 1.168  loss_ce_0: 0.5275  loss_mask_0: 0.1874  loss_dice_0: 1.402  loss_ce_1: 0.5497  loss_mask_1: 0.1695  loss_dice_1: 1.322  loss_ce_2: 0.5255  loss_mask_2: 0.1612  loss_dice_2: 1.302  loss_ce_3: 0.5083  loss_mask_3: 0.1581  loss_dice_3: 1.23  loss_ce_4: 0.4572  loss_mask_4: 0.1593  loss_dice_4: 1.225  loss_ce_5: 0.4629  loss_mask_5: 0.1583  loss_dice_5: 1.192  loss_ce_6: 0.4352  loss_mask_6: 0.1568  loss_dice_6: 1.177  loss_ce_7: 0.427  loss_mask_7: 0.1568  loss_dice_7: 1.181  loss_ce_8: 0.4059  loss_mask_8: 0.1581  loss_dice_8: 1.194    time: 1.0792  last_time: 1.0966  data_time: 0.0753  last_data_time: 0.0754   lr: 0.0001  max_mem: 32993M
[10/09 22:30:18] d2.utils.events INFO:  eta: 0:11:29  iter: 2359  total_loss: 18.81  loss_ce: 0.4406  loss_mask: 0.1559  loss_dice: 1.151  loss_ce_0: 0.5727  loss_mask_0: 0.187  loss_dice_0: 1.38  loss_ce_1: 0.5899  loss_mask_1: 0.1731  loss_dice_1: 1.269  loss_ce_2: 0.5326  loss_mask_2: 0.1583  loss_dice_2: 1.269  loss_ce_3: 0.5069  loss_mask_3: 0.1589  loss_dice_3: 1.216  loss_ce_4: 0.4934  loss_mask_4: 0.1588  loss_dice_4: 1.21  loss_ce_5: 0.4782  loss_mask_5: 0.1575  loss_dice_5: 1.182  loss_ce_6: 0.4596  loss_mask_6: 0.1558  loss_dice_6: 1.152  loss_ce_7: 0.451  loss_mask_7: 0.1566  loss_dice_7: 1.171  loss_ce_8: 0.4493  loss_mask_8: 0.1581  loss_dice_8: 1.187    time: 1.0793  last_time: 1.1337  data_time: 0.0799  last_data_time: 0.0791   lr: 0.0001  max_mem: 32993M
[10/09 22:30:40] d2.utils.events INFO:  eta: 0:11:07  iter: 2379  total_loss: 18.36  loss_ce: 0.4276  loss_mask: 0.1683  loss_dice: 1.167  loss_ce_0: 0.5537  loss_mask_0: 0.1969  loss_dice_0: 1.351  loss_ce_1: 0.5604  loss_mask_1: 0.1823  loss_dice_1: 1.287  loss_ce_2: 0.5266  loss_mask_2: 0.1694  loss_dice_2: 1.251  loss_ce_3: 0.4813  loss_mask_3: 0.1697  loss_dice_3: 1.199  loss_ce_4: 0.4799  loss_mask_4: 0.171  loss_dice_4: 1.193  loss_ce_5: 0.4635  loss_mask_5: 0.1725  loss_dice_5: 1.16  loss_ce_6: 0.4529  loss_mask_6: 0.1688  loss_dice_6: 1.126  loss_ce_7: 0.4609  loss_mask_7: 0.1706  loss_dice_7: 1.134  loss_ce_8: 0.423  loss_mask_8: 0.172  loss_dice_8: 1.185    time: 1.0793  last_time: 1.0713  data_time: 0.0762  last_data_time: 0.0879   lr: 0.0001  max_mem: 32993M
[10/09 22:31:02] d2.utils.events INFO:  eta: 0:10:46  iter: 2399  total_loss: 18.37  loss_ce: 0.4453  loss_mask: 0.1571  loss_dice: 1.147  loss_ce_0: 0.544  loss_mask_0: 0.1906  loss_dice_0: 1.363  loss_ce_1: 0.5994  loss_mask_1: 0.1727  loss_dice_1: 1.287  loss_ce_2: 0.5463  loss_mask_2: 0.162  loss_dice_2: 1.233  loss_ce_3: 0.4613  loss_mask_3: 0.1627  loss_dice_3: 1.207  loss_ce_4: 0.4544  loss_mask_4: 0.1607  loss_dice_4: 1.189  loss_ce_5: 0.4015  loss_mask_5: 0.1574  loss_dice_5: 1.156  loss_ce_6: 0.4477  loss_mask_6: 0.1569  loss_dice_6: 1.173  loss_ce_7: 0.4324  loss_mask_7: 0.1573  loss_dice_7: 1.138  loss_ce_8: 0.4454  loss_mask_8: 0.156  loss_dice_8: 1.146    time: 1.0794  last_time: 1.0849  data_time: 0.0791  last_data_time: 0.0624   lr: 0.0001  max_mem: 32993M
[10/09 22:31:23] d2.utils.events INFO:  eta: 0:10:24  iter: 2419  total_loss: 18.76  loss_ce: 0.4236  loss_mask: 0.1648  loss_dice: 1.134  loss_ce_0: 0.5773  loss_mask_0: 0.1922  loss_dice_0: 1.336  loss_ce_1: 0.5965  loss_mask_1: 0.1809  loss_dice_1: 1.28  loss_ce_2: 0.5673  loss_mask_2: 0.1717  loss_dice_2: 1.22  loss_ce_3: 0.5368  loss_mask_3: 0.168  loss_dice_3: 1.203  loss_ce_4: 0.4947  loss_mask_4: 0.1664  loss_dice_4: 1.186  loss_ce_5: 0.459  loss_mask_5: 0.1655  loss_dice_5: 1.212  loss_ce_6: 0.4412  loss_mask_6: 0.1671  loss_dice_6: 1.171  loss_ce_7: 0.4358  loss_mask_7: 0.1668  loss_dice_7: 1.138  loss_ce_8: 0.4195  loss_mask_8: 0.1666  loss_dice_8: 1.17    time: 1.0794  last_time: 1.0819  data_time: 0.0780  last_data_time: 0.0893   lr: 0.0001  max_mem: 32993M
[10/09 22:31:45] d2.utils.events INFO:  eta: 0:10:03  iter: 2439  total_loss: 18.78  loss_ce: 0.4378  loss_mask: 0.1611  loss_dice: 1.186  loss_ce_0: 0.5399  loss_mask_0: 0.1819  loss_dice_0: 1.366  loss_ce_1: 0.5694  loss_mask_1: 0.1749  loss_dice_1: 1.334  loss_ce_2: 0.519  loss_mask_2: 0.1746  loss_dice_2: 1.246  loss_ce_3: 0.4796  loss_mask_3: 0.1676  loss_dice_3: 1.218  loss_ce_4: 0.454  loss_mask_4: 0.1682  loss_dice_4: 1.246  loss_ce_5: 0.466  loss_mask_5: 0.1641  loss_dice_5: 1.206  loss_ce_6: 0.4347  loss_mask_6: 0.1627  loss_dice_6: 1.189  loss_ce_7: 0.4468  loss_mask_7: 0.1636  loss_dice_7: 1.222  loss_ce_8: 0.4201  loss_mask_8: 0.161  loss_dice_8: 1.224    time: 1.0794  last_time: 1.1052  data_time: 0.0768  last_data_time: 0.0700   lr: 0.0001  max_mem: 32993M
[10/09 22:32:07] d2.utils.events INFO:  eta: 0:09:41  iter: 2459  total_loss: 19.45  loss_ce: 0.4352  loss_mask: 0.1477  loss_dice: 1.24  loss_ce_0: 0.5282  loss_mask_0: 0.1721  loss_dice_0: 1.454  loss_ce_1: 0.605  loss_mask_1: 0.157  loss_dice_1: 1.378  loss_ce_2: 0.5384  loss_mask_2: 0.1508  loss_dice_2: 1.342  loss_ce_3: 0.4966  loss_mask_3: 0.1465  loss_dice_3: 1.286  loss_ce_4: 0.4719  loss_mask_4: 0.151  loss_dice_4: 1.274  loss_ce_5: 0.4618  loss_mask_5: 0.1495  loss_dice_5: 1.261  loss_ce_6: 0.4182  loss_mask_6: 0.1513  loss_dice_6: 1.233  loss_ce_7: 0.4435  loss_mask_7: 0.1484  loss_dice_7: 1.263  loss_ce_8: 0.4432  loss_mask_8: 0.1478  loss_dice_8: 1.219    time: 1.0794  last_time: 1.0849  data_time: 0.0773  last_data_time: 0.0945   lr: 0.0001  max_mem: 32993M
[10/09 22:32:29] d2.utils.events INFO:  eta: 0:09:20  iter: 2479  total_loss: 19.81  loss_ce: 0.4486  loss_mask: 0.15  loss_dice: 1.244  loss_ce_0: 0.5401  loss_mask_0: 0.1692  loss_dice_0: 1.46  loss_ce_1: 0.6076  loss_mask_1: 0.1627  loss_dice_1: 1.383  loss_ce_2: 0.5836  loss_mask_2: 0.1501  loss_dice_2: 1.32  loss_ce_3: 0.5506  loss_mask_3: 0.1467  loss_dice_3: 1.293  loss_ce_4: 0.4991  loss_mask_4: 0.1473  loss_dice_4: 1.281  loss_ce_5: 0.4722  loss_mask_5: 0.1492  loss_dice_5: 1.267  loss_ce_6: 0.4928  loss_mask_6: 0.1497  loss_dice_6: 1.242  loss_ce_7: 0.4946  loss_mask_7: 0.149  loss_dice_7: 1.22  loss_ce_8: 0.5016  loss_mask_8: 0.1478  loss_dice_8: 1.252    time: 1.0798  last_time: 1.1114  data_time: 0.0922  last_data_time: 0.0890   lr: 0.0001  max_mem: 32993M
[10/09 22:32:51] d2.utils.events INFO:  eta: 0:08:59  iter: 2499  total_loss: 18.85  loss_ce: 0.4589  loss_mask: 0.1613  loss_dice: 1.145  loss_ce_0: 0.5382  loss_mask_0: 0.1835  loss_dice_0: 1.33  loss_ce_1: 0.6337  loss_mask_1: 0.1714  loss_dice_1: 1.268  loss_ce_2: 0.5688  loss_mask_2: 0.1614  loss_dice_2: 1.24  loss_ce_3: 0.5295  loss_mask_3: 0.1608  loss_dice_3: 1.188  loss_ce_4: 0.5197  loss_mask_4: 0.1633  loss_dice_4: 1.194  loss_ce_5: 0.48  loss_mask_5: 0.161  loss_dice_5: 1.173  loss_ce_6: 0.4772  loss_mask_6: 0.1621  loss_dice_6: 1.163  loss_ce_7: 0.4813  loss_mask_7: 0.1611  loss_dice_7: 1.168  loss_ce_8: 0.4976  loss_mask_8: 0.1601  loss_dice_8: 1.179    time: 1.0798  last_time: 1.0383  data_time: 0.0808  last_data_time: 0.0609   lr: 0.0001  max_mem: 32993M
[10/09 22:33:13] d2.utils.events INFO:  eta: 0:08:38  iter: 2519  total_loss: 18.52  loss_ce: 0.4413  loss_mask: 0.157  loss_dice: 1.148  loss_ce_0: 0.5304  loss_mask_0: 0.1835  loss_dice_0: 1.349  loss_ce_1: 0.5225  loss_mask_1: 0.172  loss_dice_1: 1.269  loss_ce_2: 0.503  loss_mask_2: 0.1668  loss_dice_2: 1.218  loss_ce_3: 0.4796  loss_mask_3: 0.1628  loss_dice_3: 1.183  loss_ce_4: 0.4507  loss_mask_4: 0.1614  loss_dice_4: 1.172  loss_ce_5: 0.4267  loss_mask_5: 0.1579  loss_dice_5: 1.151  loss_ce_6: 0.4404  loss_mask_6: 0.1594  loss_dice_6: 1.177  loss_ce_7: 0.4173  loss_mask_7: 0.1593  loss_dice_7: 1.13  loss_ce_8: 0.4163  loss_mask_8: 0.1579  loss_dice_8: 1.175    time: 1.0798  last_time: 1.0289  data_time: 0.0776  last_data_time: 0.0570   lr: 0.0001  max_mem: 32993M
[10/09 22:33:34] d2.utils.events INFO:  eta: 0:08:16  iter: 2539  total_loss: 19.09  loss_ce: 0.4519  loss_mask: 0.1565  loss_dice: 1.216  loss_ce_0: 0.5221  loss_mask_0: 0.1949  loss_dice_0: 1.413  loss_ce_1: 0.6391  loss_mask_1: 0.1673  loss_dice_1: 1.323  loss_ce_2: 0.566  loss_mask_2: 0.1631  loss_dice_2: 1.259  loss_ce_3: 0.513  loss_mask_3: 0.1604  loss_dice_3: 1.221  loss_ce_4: 0.4758  loss_mask_4: 0.1601  loss_dice_4: 1.224  loss_ce_5: 0.4873  loss_mask_5: 0.1554  loss_dice_5: 1.239  loss_ce_6: 0.4439  loss_mask_6: 0.1585  loss_dice_6: 1.206  loss_ce_7: 0.4534  loss_mask_7: 0.1594  loss_dice_7: 1.217  loss_ce_8: 0.4709  loss_mask_8: 0.1577  loss_dice_8: 1.188    time: 1.0798  last_time: 1.0926  data_time: 0.0761  last_data_time: 0.0679   lr: 0.0001  max_mem: 32993M
[10/09 22:33:56] d2.utils.events INFO:  eta: 0:07:55  iter: 2559  total_loss: 19.05  loss_ce: 0.406  loss_mask: 0.1651  loss_dice: 1.198  loss_ce_0: 0.539  loss_mask_0: 0.1934  loss_dice_0: 1.38  loss_ce_1: 0.5984  loss_mask_1: 0.1776  loss_dice_1: 1.316  loss_ce_2: 0.5687  loss_mask_2: 0.1671  loss_dice_2: 1.264  loss_ce_3: 0.5376  loss_mask_3: 0.1642  loss_dice_3: 1.203  loss_ce_4: 0.474  loss_mask_4: 0.1649  loss_dice_4: 1.222  loss_ce_5: 0.448  loss_mask_5: 0.1651  loss_dice_5: 1.202  loss_ce_6: 0.4399  loss_mask_6: 0.1638  loss_dice_6: 1.181  loss_ce_7: 0.4295  loss_mask_7: 0.1664  loss_dice_7: 1.207  loss_ce_8: 0.4184  loss_mask_8: 0.1641  loss_dice_8: 1.191    time: 1.0798  last_time: 1.0594  data_time: 0.0883  last_data_time: 0.0818   lr: 0.0001  max_mem: 32993M
[10/09 22:34:18] d2.utils.events INFO:  eta: 0:07:33  iter: 2579  total_loss: 18.49  loss_ce: 0.4239  loss_mask: 0.1615  loss_dice: 1.198  loss_ce_0: 0.5231  loss_mask_0: 0.1961  loss_dice_0: 1.389  loss_ce_1: 0.5915  loss_mask_1: 0.1811  loss_dice_1: 1.345  loss_ce_2: 0.5491  loss_mask_2: 0.1702  loss_dice_2: 1.27  loss_ce_3: 0.5018  loss_mask_3: 0.1666  loss_dice_3: 1.178  loss_ce_4: 0.4586  loss_mask_4: 0.1661  loss_dice_4: 1.206  loss_ce_5: 0.475  loss_mask_5: 0.1632  loss_dice_5: 1.201  loss_ce_6: 0.4313  loss_mask_6: 0.1655  loss_dice_6: 1.163  loss_ce_7: 0.4216  loss_mask_7: 0.1659  loss_dice_7: 1.156  loss_ce_8: 0.426  loss_mask_8: 0.1651  loss_dice_8: 1.159    time: 1.0798  last_time: 1.0676  data_time: 0.0786  last_data_time: 0.0771   lr: 0.0001  max_mem: 32993M
[10/09 22:34:40] d2.utils.events INFO:  eta: 0:07:11  iter: 2599  total_loss: 19.11  loss_ce: 0.4532  loss_mask: 0.1642  loss_dice: 1.199  loss_ce_0: 0.5382  loss_mask_0: 0.1877  loss_dice_0: 1.375  loss_ce_1: 0.6164  loss_mask_1: 0.1784  loss_dice_1: 1.351  loss_ce_2: 0.5891  loss_mask_2: 0.1739  loss_dice_2: 1.227  loss_ce_3: 0.5219  loss_mask_3: 0.1666  loss_dice_3: 1.237  loss_ce_4: 0.5185  loss_mask_4: 0.1647  loss_dice_4: 1.202  loss_ce_5: 0.4865  loss_mask_5: 0.1635  loss_dice_5: 1.194  loss_ce_6: 0.4857  loss_mask_6: 0.164  loss_dice_6: 1.21  loss_ce_7: 0.4649  loss_mask_7: 0.1623  loss_dice_7: 1.215  loss_ce_8: 0.4667  loss_mask_8: 0.1616  loss_dice_8: 1.167    time: 1.0800  last_time: 1.0682  data_time: 0.0845  last_data_time: 0.0693   lr: 0.0001  max_mem: 32993M
[10/09 22:35:01] d2.utils.events INFO:  eta: 0:06:50  iter: 2619  total_loss: 18.99  loss_ce: 0.4171  loss_mask: 0.1616  loss_dice: 1.136  loss_ce_0: 0.5371  loss_mask_0: 0.1896  loss_dice_0: 1.374  loss_ce_1: 0.5692  loss_mask_1: 0.176  loss_dice_1: 1.32  loss_ce_2: 0.5462  loss_mask_2: 0.169  loss_dice_2: 1.258  loss_ce_3: 0.4835  loss_mask_3: 0.1678  loss_dice_3: 1.177  loss_ce_4: 0.4561  loss_mask_4: 0.1662  loss_dice_4: 1.236  loss_ce_5: 0.4483  loss_mask_5: 0.1631  loss_dice_5: 1.186  loss_ce_6: 0.4398  loss_mask_6: 0.1639  loss_dice_6: 1.213  loss_ce_7: 0.4444  loss_mask_7: 0.1629  loss_dice_7: 1.171  loss_ce_8: 0.4288  loss_mask_8: 0.1623  loss_dice_8: 1.218    time: 1.0800  last_time: 1.0622  data_time: 0.0833  last_data_time: 0.0846   lr: 0.0001  max_mem: 32993M
[10/09 22:35:23] d2.utils.events INFO:  eta: 0:06:28  iter: 2639  total_loss: 18.73  loss_ce: 0.4171  loss_mask: 0.1583  loss_dice: 1.133  loss_ce_0: 0.5526  loss_mask_0: 0.1926  loss_dice_0: 1.336  loss_ce_1: 0.6485  loss_mask_1: 0.171  loss_dice_1: 1.303  loss_ce_2: 0.5457  loss_mask_2: 0.1645  loss_dice_2: 1.237  loss_ce_3: 0.5055  loss_mask_3: 0.1649  loss_dice_3: 1.191  loss_ce_4: 0.4981  loss_mask_4: 0.1639  loss_dice_4: 1.182  loss_ce_5: 0.4524  loss_mask_5: 0.1622  loss_dice_5: 1.16  loss_ce_6: 0.4593  loss_mask_6: 0.1589  loss_dice_6: 1.179  loss_ce_7: 0.4345  loss_mask_7: 0.1615  loss_dice_7: 1.169  loss_ce_8: 0.4552  loss_mask_8: 0.1591  loss_dice_8: 1.156    time: 1.0801  last_time: 1.1012  data_time: 0.0811  last_data_time: 0.1001   lr: 0.0001  max_mem: 32993M
[10/09 22:35:45] d2.utils.events INFO:  eta: 0:06:06  iter: 2659  total_loss: 18.18  loss_ce: 0.4214  loss_mask: 0.1583  loss_dice: 1.103  loss_ce_0: 0.5196  loss_mask_0: 0.1922  loss_dice_0: 1.338  loss_ce_1: 0.5803  loss_mask_1: 0.1749  loss_dice_1: 1.274  loss_ce_2: 0.5062  loss_mask_2: 0.1746  loss_dice_2: 1.232  loss_ce_3: 0.4744  loss_mask_3: 0.1652  loss_dice_3: 1.159  loss_ce_4: 0.4537  loss_mask_4: 0.1599  loss_dice_4: 1.168  loss_ce_5: 0.4493  loss_mask_5: 0.1564  loss_dice_5: 1.166  loss_ce_6: 0.4239  loss_mask_6: 0.1562  loss_dice_6: 1.14  loss_ce_7: 0.4188  loss_mask_7: 0.1587  loss_dice_7: 1.153  loss_ce_8: 0.4234  loss_mask_8: 0.1566  loss_dice_8: 1.152    time: 1.0800  last_time: 1.0531  data_time: 0.0749  last_data_time: 0.0796   lr: 0.0001  max_mem: 32993M
[10/09 22:36:06] d2.utils.events INFO:  eta: 0:05:45  iter: 2679  total_loss: 19.07  loss_ce: 0.4425  loss_mask: 0.1704  loss_dice: 1.204  loss_ce_0: 0.534  loss_mask_0: 0.1888  loss_dice_0: 1.418  loss_ce_1: 0.5948  loss_mask_1: 0.1869  loss_dice_1: 1.32  loss_ce_2: 0.5431  loss_mask_2: 0.176  loss_dice_2: 1.271  loss_ce_3: 0.5151  loss_mask_3: 0.1732  loss_dice_3: 1.222  loss_ce_4: 0.4539  loss_mask_4: 0.1713  loss_dice_4: 1.213  loss_ce_5: 0.4438  loss_mask_5: 0.174  loss_dice_5: 1.214  loss_ce_6: 0.44  loss_mask_6: 0.1723  loss_dice_6: 1.186  loss_ce_7: 0.447  loss_mask_7: 0.172  loss_dice_7: 1.182  loss_ce_8: 0.4432  loss_mask_8: 0.1707  loss_dice_8: 1.215    time: 1.0800  last_time: 1.0570  data_time: 0.0769  last_data_time: 0.0584   lr: 0.0001  max_mem: 32993M
[10/09 22:36:28] d2.utils.events INFO:  eta: 0:05:23  iter: 2699  total_loss: 17.69  loss_ce: 0.4011  loss_mask: 0.1538  loss_dice: 1.111  loss_ce_0: 0.5265  loss_mask_0: 0.1828  loss_dice_0: 1.302  loss_ce_1: 0.5793  loss_mask_1: 0.1698  loss_dice_1: 1.25  loss_ce_2: 0.5485  loss_mask_2: 0.1594  loss_dice_2: 1.172  loss_ce_3: 0.4702  loss_mask_3: 0.159  loss_dice_3: 1.158  loss_ce_4: 0.4512  loss_mask_4: 0.1573  loss_dice_4: 1.144  loss_ce_5: 0.4368  loss_mask_5: 0.1564  loss_dice_5: 1.123  loss_ce_6: 0.4392  loss_mask_6: 0.1542  loss_dice_6: 1.14  loss_ce_7: 0.4117  loss_mask_7: 0.1546  loss_dice_7: 1.128  loss_ce_8: 0.4092  loss_mask_8: 0.1534  loss_dice_8: 1.138    time: 1.0801  last_time: 1.1563  data_time: 0.0858  last_data_time: 0.1641   lr: 0.0001  max_mem: 32993M
[10/09 22:36:50] d2.utils.events INFO:  eta: 0:05:02  iter: 2719  total_loss: 18.2  loss_ce: 0.3965  loss_mask: 0.1565  loss_dice: 1.141  loss_ce_0: 0.5352  loss_mask_0: 0.1937  loss_dice_0: 1.336  loss_ce_1: 0.5748  loss_mask_1: 0.1739  loss_dice_1: 1.296  loss_ce_2: 0.5103  loss_mask_2: 0.1629  loss_dice_2: 1.205  loss_ce_3: 0.4903  loss_mask_3: 0.1605  loss_dice_3: 1.193  loss_ce_4: 0.4202  loss_mask_4: 0.1594  loss_dice_4: 1.206  loss_ce_5: 0.3892  loss_mask_5: 0.1591  loss_dice_5: 1.166  loss_ce_6: 0.3927  loss_mask_6: 0.1564  loss_dice_6: 1.139  loss_ce_7: 0.4146  loss_mask_7: 0.1571  loss_dice_7: 1.136  loss_ce_8: 0.4277  loss_mask_8: 0.1555  loss_dice_8: 1.13    time: 1.0801  last_time: 1.0858  data_time: 0.0785  last_data_time: 0.0771   lr: 0.0001  max_mem: 32993M
[10/09 22:37:12] d2.utils.events INFO:  eta: 0:04:40  iter: 2739  total_loss: 18.54  loss_ce: 0.4299  loss_mask: 0.1601  loss_dice: 1.162  loss_ce_0: 0.5451  loss_mask_0: 0.1804  loss_dice_0: 1.379  loss_ce_1: 0.5879  loss_mask_1: 0.1685  loss_dice_1: 1.31  loss_ce_2: 0.5765  loss_mask_2: 0.1639  loss_dice_2: 1.261  loss_ce_3: 0.5029  loss_mask_3: 0.1629  loss_dice_3: 1.19  loss_ce_4: 0.4597  loss_mask_4: 0.162  loss_dice_4: 1.193  loss_ce_5: 0.4395  loss_mask_5: 0.16  loss_dice_5: 1.181  loss_ce_6: 0.4385  loss_mask_6: 0.1587  loss_dice_6: 1.172  loss_ce_7: 0.4365  loss_mask_7: 0.1617  loss_dice_7: 1.169  loss_ce_8: 0.4347  loss_mask_8: 0.1606  loss_dice_8: 1.164    time: 1.0802  last_time: 1.0833  data_time: 0.0795  last_data_time: 0.0598   lr: 0.0001  max_mem: 32993M
[10/09 22:37:34] d2.utils.events INFO:  eta: 0:04:19  iter: 2759  total_loss: 17.52  loss_ce: 0.3746  loss_mask: 0.1578  loss_dice: 1.129  loss_ce_0: 0.5455  loss_mask_0: 0.1812  loss_dice_0: 1.362  loss_ce_1: 0.5378  loss_mask_1: 0.1674  loss_dice_1: 1.251  loss_ce_2: 0.5317  loss_mask_2: 0.1619  loss_dice_2: 1.166  loss_ce_3: 0.4687  loss_mask_3: 0.1592  loss_dice_3: 1.15  loss_ce_4: 0.4607  loss_mask_4: 0.1615  loss_dice_4: 1.151  loss_ce_5: 0.4108  loss_mask_5: 0.1564  loss_dice_5: 1.132  loss_ce_6: 0.3985  loss_mask_6: 0.1557  loss_dice_6: 1.13  loss_ce_7: 0.4009  loss_mask_7: 0.1555  loss_dice_7: 1.106  loss_ce_8: 0.4061  loss_mask_8: 0.1568  loss_dice_8: 1.064    time: 1.0803  last_time: 1.0885  data_time: 0.0847  last_data_time: 0.0868   lr: 0.0001  max_mem: 32993M
[10/09 22:37:55] d2.utils.events INFO:  eta: 0:03:57  iter: 2779  total_loss: 18.9  loss_ce: 0.4276  loss_mask: 0.1562  loss_dice: 1.145  loss_ce_0: 0.5419  loss_mask_0: 0.1803  loss_dice_0: 1.355  loss_ce_1: 0.6193  loss_mask_1: 0.167  loss_dice_1: 1.294  loss_ce_2: 0.5792  loss_mask_2: 0.1594  loss_dice_2: 1.235  loss_ce_3: 0.5041  loss_mask_3: 0.1571  loss_dice_3: 1.196  loss_ce_4: 0.4542  loss_mask_4: 0.156  loss_dice_4: 1.198  loss_ce_5: 0.4539  loss_mask_5: 0.1557  loss_dice_5: 1.19  loss_ce_6: 0.4329  loss_mask_6: 0.1551  loss_dice_6: 1.167  loss_ce_7: 0.4381  loss_mask_7: 0.1555  loss_dice_7: 1.176  loss_ce_8: 0.4589  loss_mask_8: 0.1559  loss_dice_8: 1.158    time: 1.0802  last_time: 1.1245  data_time: 0.0751  last_data_time: 0.0712   lr: 0.0001  max_mem: 32993M
[10/09 22:38:17] d2.utils.events INFO:  eta: 0:03:36  iter: 2799  total_loss: 18.89  loss_ce: 0.4322  loss_mask: 0.1442  loss_dice: 1.182  loss_ce_0: 0.5658  loss_mask_0: 0.1746  loss_dice_0: 1.42  loss_ce_1: 0.6018  loss_mask_1: 0.1619  loss_dice_1: 1.338  loss_ce_2: 0.5086  loss_mask_2: 0.154  loss_dice_2: 1.281  loss_ce_3: 0.4624  loss_mask_3: 0.1493  loss_dice_3: 1.232  loss_ce_4: 0.4634  loss_mask_4: 0.1485  loss_dice_4: 1.201  loss_ce_5: 0.4311  loss_mask_5: 0.146  loss_dice_5: 1.201  loss_ce_6: 0.4057  loss_mask_6: 0.1483  loss_dice_6: 1.227  loss_ce_7: 0.4307  loss_mask_7: 0.1471  loss_dice_7: 1.208  loss_ce_8: 0.4126  loss_mask_8: 0.1436  loss_dice_8: 1.217    time: 1.0803  last_time: 1.1084  data_time: 0.0787  last_data_time: 0.1073   lr: 0.0001  max_mem: 32993M
[10/09 22:38:39] d2.utils.events INFO:  eta: 0:03:14  iter: 2819  total_loss: 19.28  loss_ce: 0.4239  loss_mask: 0.1683  loss_dice: 1.204  loss_ce_0: 0.5436  loss_mask_0: 0.1873  loss_dice_0: 1.389  loss_ce_1: 0.5787  loss_mask_1: 0.1766  loss_dice_1: 1.337  loss_ce_2: 0.5204  loss_mask_2: 0.1704  loss_dice_2: 1.293  loss_ce_3: 0.4435  loss_mask_3: 0.1709  loss_dice_3: 1.218  loss_ce_4: 0.4431  loss_mask_4: 0.172  loss_dice_4: 1.229  loss_ce_5: 0.4505  loss_mask_5: 0.1676  loss_dice_5: 1.22  loss_ce_6: 0.4368  loss_mask_6: 0.167  loss_dice_6: 1.202  loss_ce_7: 0.4469  loss_mask_7: 0.1684  loss_dice_7: 1.174  loss_ce_8: 0.4288  loss_mask_8: 0.168  loss_dice_8: 1.171    time: 1.0803  last_time: 1.0544  data_time: 0.0814  last_data_time: 0.0790   lr: 0.0001  max_mem: 32993M
[10/09 22:39:01] d2.utils.events INFO:  eta: 0:02:52  iter: 2839  total_loss: 18.18  loss_ce: 0.374  loss_mask: 0.1431  loss_dice: 1.134  loss_ce_0: 0.5588  loss_mask_0: 0.1637  loss_dice_0: 1.345  loss_ce_1: 0.5841  loss_mask_1: 0.1561  loss_dice_1: 1.279  loss_ce_2: 0.5193  loss_mask_2: 0.1484  loss_dice_2: 1.203  loss_ce_3: 0.4495  loss_mask_3: 0.1461  loss_dice_3: 1.206  loss_ce_4: 0.4146  loss_mask_4: 0.1443  loss_dice_4: 1.179  loss_ce_5: 0.4051  loss_mask_5: 0.1452  loss_dice_5: 1.167  loss_ce_6: 0.4217  loss_mask_6: 0.1426  loss_dice_6: 1.119  loss_ce_7: 0.4267  loss_mask_7: 0.1439  loss_dice_7: 1.112  loss_ce_8: 0.4059  loss_mask_8: 0.1444  loss_dice_8: 1.147    time: 1.0804  last_time: 1.0869  data_time: 0.0786  last_data_time: 0.0713   lr: 0.0001  max_mem: 32993M
[10/09 22:39:23] d2.utils.events INFO:  eta: 0:02:31  iter: 2859  total_loss: 16.99  loss_ce: 0.3549  loss_mask: 0.156  loss_dice: 1.082  loss_ce_0: 0.4919  loss_mask_0: 0.1755  loss_dice_0: 1.259  loss_ce_1: 0.5228  loss_mask_1: 0.1656  loss_dice_1: 1.204  loss_ce_2: 0.4785  loss_mask_2: 0.1576  loss_dice_2: 1.142  loss_ce_3: 0.4832  loss_mask_3: 0.1593  loss_dice_3: 1.113  loss_ce_4: 0.4277  loss_mask_4: 0.1579  loss_dice_4: 1.084  loss_ce_5: 0.3946  loss_mask_5: 0.1556  loss_dice_5: 1.07  loss_ce_6: 0.3945  loss_mask_6: 0.1556  loss_dice_6: 1.042  loss_ce_7: 0.4021  loss_mask_7: 0.1545  loss_dice_7: 1.057  loss_ce_8: 0.3431  loss_mask_8: 0.1542  loss_dice_8: 1.039    time: 1.0804  last_time: 1.1017  data_time: 0.0818  last_data_time: 0.0849   lr: 0.0001  max_mem: 32993M
[10/09 22:39:45] d2.utils.events INFO:  eta: 0:02:09  iter: 2879  total_loss: 19.28  loss_ce: 0.4366  loss_mask: 0.1546  loss_dice: 1.211  loss_ce_0: 0.5628  loss_mask_0: 0.1836  loss_dice_0: 1.407  loss_ce_1: 0.6167  loss_mask_1: 0.172  loss_dice_1: 1.345  loss_ce_2: 0.5223  loss_mask_2: 0.1595  loss_dice_2: 1.286  loss_ce_3: 0.4912  loss_mask_3: 0.1615  loss_dice_3: 1.226  loss_ce_4: 0.4656  loss_mask_4: 0.1585  loss_dice_4: 1.25  loss_ce_5: 0.4674  loss_mask_5: 0.1552  loss_dice_5: 1.195  loss_ce_6: 0.4512  loss_mask_6: 0.1571  loss_dice_6: 1.219  loss_ce_7: 0.451  loss_mask_7: 0.1549  loss_dice_7: 1.211  loss_ce_8: 0.4654  loss_mask_8: 0.1567  loss_dice_8: 1.195    time: 1.0805  last_time: 1.1007  data_time: 0.0871  last_data_time: 0.1047   lr: 0.0001  max_mem: 32993M
[10/09 22:40:06] d2.utils.events INFO:  eta: 0:01:48  iter: 2899  total_loss: 19.24  loss_ce: 0.4067  loss_mask: 0.1624  loss_dice: 1.237  loss_ce_0: 0.578  loss_mask_0: 0.1877  loss_dice_0: 1.442  loss_ce_1: 0.5873  loss_mask_1: 0.1711  loss_dice_1: 1.4  loss_ce_2: 0.5644  loss_mask_2: 0.1606  loss_dice_2: 1.323  loss_ce_3: 0.505  loss_mask_3: 0.1606  loss_dice_3: 1.278  loss_ce_4: 0.4695  loss_mask_4: 0.1583  loss_dice_4: 1.24  loss_ce_5: 0.4605  loss_mask_5: 0.1609  loss_dice_5: 1.28  loss_ce_6: 0.4572  loss_mask_6: 0.1598  loss_dice_6: 1.215  loss_ce_7: 0.4239  loss_mask_7: 0.1597  loss_dice_7: 1.22  loss_ce_8: 0.4069  loss_mask_8: 0.1588  loss_dice_8: 1.227    time: 1.0805  last_time: 1.0564  data_time: 0.0851  last_data_time: 0.0780   lr: 0.0001  max_mem: 32993M
[10/09 22:40:28] d2.utils.events INFO:  eta: 0:01:26  iter: 2919  total_loss: 19.48  loss_ce: 0.468  loss_mask: 0.1493  loss_dice: 1.206  loss_ce_0: 0.5268  loss_mask_0: 0.1806  loss_dice_0: 1.438  loss_ce_1: 0.6092  loss_mask_1: 0.1594  loss_dice_1: 1.385  loss_ce_2: 0.5457  loss_mask_2: 0.1491  loss_dice_2: 1.286  loss_ce_3: 0.5095  loss_mask_3: 0.1495  loss_dice_3: 1.249  loss_ce_4: 0.4785  loss_mask_4: 0.1504  loss_dice_4: 1.245  loss_ce_5: 0.4711  loss_mask_5: 0.1503  loss_dice_5: 1.24  loss_ce_6: 0.4655  loss_mask_6: 0.1499  loss_dice_6: 1.187  loss_ce_7: 0.4432  loss_mask_7: 0.152  loss_dice_7: 1.194  loss_ce_8: 0.466  loss_mask_8: 0.1506  loss_dice_8: 1.191    time: 1.0806  last_time: 1.0563  data_time: 0.0866  last_data_time: 0.0670   lr: 0.0001  max_mem: 32993M
[10/09 22:40:50] d2.utils.events INFO:  eta: 0:01:04  iter: 2939  total_loss: 19.69  loss_ce: 0.4487  loss_mask: 0.1562  loss_dice: 1.261  loss_ce_0: 0.5186  loss_mask_0: 0.172  loss_dice_0: 1.431  loss_ce_1: 0.591  loss_mask_1: 0.1613  loss_dice_1: 1.387  loss_ce_2: 0.5893  loss_mask_2: 0.1554  loss_dice_2: 1.341  loss_ce_3: 0.5295  loss_mask_3: 0.1586  loss_dice_3: 1.275  loss_ce_4: 0.4689  loss_mask_4: 0.1561  loss_dice_4: 1.278  loss_ce_5: 0.459  loss_mask_5: 0.1561  loss_dice_5: 1.264  loss_ce_6: 0.4827  loss_mask_6: 0.1587  loss_dice_6: 1.249  loss_ce_7: 0.4132  loss_mask_7: 0.1561  loss_dice_7: 1.23  loss_ce_8: 0.4484  loss_mask_8: 0.1561  loss_dice_8: 1.248    time: 1.0807  last_time: 1.1259  data_time: 0.0853  last_data_time: 0.0690   lr: 0.0001  max_mem: 32993M
[10/09 22:41:13] d2.utils.events INFO:  eta: 0:00:43  iter: 2959  total_loss: 20.38  loss_ce: 0.4592  loss_mask: 0.158  loss_dice: 1.249  loss_ce_0: 0.5641  loss_mask_0: 0.1791  loss_dice_0: 1.439  loss_ce_1: 0.628  loss_mask_1: 0.1675  loss_dice_1: 1.42  loss_ce_2: 0.5977  loss_mask_2: 0.1574  loss_dice_2: 1.309  loss_ce_3: 0.5332  loss_mask_3: 0.1567  loss_dice_3: 1.276  loss_ce_4: 0.4863  loss_mask_4: 0.1611  loss_dice_4: 1.279  loss_ce_5: 0.4964  loss_mask_5: 0.156  loss_dice_5: 1.283  loss_ce_6: 0.4896  loss_mask_6: 0.159  loss_dice_6: 1.246  loss_ce_7: 0.4737  loss_mask_7: 0.1587  loss_dice_7: 1.25  loss_ce_8: 0.4862  loss_mask_8: 0.1585  loss_dice_8: 1.258    time: 1.0810  last_time: 1.2180  data_time: 0.0866  last_data_time: 0.0789   lr: 0.0001  max_mem: 32993M
[10/09 22:41:34] d2.utils.events INFO:  eta: 0:00:21  iter: 2979  total_loss: 19.91  loss_ce: 0.4313  loss_mask: 0.1549  loss_dice: 1.223  loss_ce_0: 0.5578  loss_mask_0: 0.1799  loss_dice_0: 1.439  loss_ce_1: 0.6117  loss_mask_1: 0.1682  loss_dice_1: 1.362  loss_ce_2: 0.6035  loss_mask_2: 0.159  loss_dice_2: 1.294  loss_ce_3: 0.4877  loss_mask_3: 0.1593  loss_dice_3: 1.237  loss_ce_4: 0.4448  loss_mask_4: 0.1572  loss_dice_4: 1.274  loss_ce_5: 0.4468  loss_mask_5: 0.1557  loss_dice_5: 1.217  loss_ce_6: 0.4854  loss_mask_6: 0.1548  loss_dice_6: 1.188  loss_ce_7: 0.4549  loss_mask_7: 0.1548  loss_dice_7: 1.167  loss_ce_8: 0.4945  loss_mask_8: 0.1532  loss_dice_8: 1.224    time: 1.0809  last_time: 1.0612  data_time: 0.0760  last_data_time: 0.0838   lr: 0.0001  max_mem: 32993M
[10/09 22:41:56] fvcore.common.checkpoint INFO: Saving checkpoint to /tsi/hi-paris/GB/segmentation/results/In_vocab/r50_008_3000_19_a_decoder/model_final.pth
[10/09 22:41:59] d2.utils.events INFO:  eta: 0:00:00  iter: 2999  total_loss: 18.09  loss_ce: 0.3978  loss_mask: 0.1566  loss_dice: 1.143  loss_ce_0: 0.5471  loss_mask_0: 0.1842  loss_dice_0: 1.351  loss_ce_1: 0.5774  loss_mask_1: 0.1659  loss_dice_1: 1.249  loss_ce_2: 0.5294  loss_mask_2: 0.1605  loss_dice_2: 1.225  loss_ce_3: 0.4929  loss_mask_3: 0.1574  loss_dice_3: 1.138  loss_ce_4: 0.4421  loss_mask_4: 0.1565  loss_dice_4: 1.183  loss_ce_5: 0.4321  loss_mask_5: 0.1549  loss_dice_5: 1.173  loss_ce_6: 0.4121  loss_mask_6: 0.1542  loss_dice_6: 1.141  loss_ce_7: 0.4058  loss_mask_7: 0.1566  loss_dice_7: 1.127  loss_ce_8: 0.4027  loss_mask_8: 0.155  loss_dice_8: 1.134    time: 1.0808  last_time: 1.0952  data_time: 0.0723  last_data_time: 0.0694   lr: 0.0001  max_mem: 32993M
[10/09 22:41:59] d2.engine.hooks INFO: Overall training speed: 2998 iterations in 0:54:00 (1.0809 s / it)
[10/09 22:41:59] d2.engine.hooks INFO: Total training time: 0:54:15 (0:00:15 on hooks)
[10/09 22:41:59] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/09 22:41:59] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/09 22:41:59] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/09 22:41:59] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/09 22:41:59] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/09 22:41:59] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/09 22:42:03] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0041 s/iter. Inference: 0.1770 s/iter. Eval: 0.0667 s/iter. Total: 0.2478 s/iter. ETA=0:02:01
[10/09 22:42:08] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0047 s/iter. Inference: 0.1445 s/iter. Eval: 0.0694 s/iter. Total: 0.2187 s/iter. ETA=0:01:41
[10/09 22:42:13] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0048 s/iter. Inference: 0.1432 s/iter. Eval: 0.0699 s/iter. Total: 0.2179 s/iter. ETA=0:01:36
[10/09 22:42:18] d2.evaluation.evaluator INFO: Inference done 83/500. Dataloading: 0.0048 s/iter. Inference: 0.1417 s/iter. Eval: 0.0703 s/iter. Total: 0.2168 s/iter. ETA=0:01:30
[10/09 22:42:23] d2.evaluation.evaluator INFO: Inference done 107/500. Dataloading: 0.0048 s/iter. Inference: 0.1408 s/iter. Eval: 0.0705 s/iter. Total: 0.2161 s/iter. ETA=0:01:24
[10/09 22:42:28] d2.evaluation.evaluator INFO: Inference done 130/500. Dataloading: 0.0048 s/iter. Inference: 0.1417 s/iter. Eval: 0.0704 s/iter. Total: 0.2171 s/iter. ETA=0:01:20
[10/09 22:42:33] d2.evaluation.evaluator INFO: Inference done 153/500. Dataloading: 0.0049 s/iter. Inference: 0.1419 s/iter. Eval: 0.0706 s/iter. Total: 0.2174 s/iter. ETA=0:01:15
[10/09 22:42:38] d2.evaluation.evaluator INFO: Inference done 177/500. Dataloading: 0.0049 s/iter. Inference: 0.1409 s/iter. Eval: 0.0708 s/iter. Total: 0.2166 s/iter. ETA=0:01:09
[10/09 22:42:44] d2.evaluation.evaluator INFO: Inference done 200/500. Dataloading: 0.0049 s/iter. Inference: 0.1414 s/iter. Eval: 0.0707 s/iter. Total: 0.2171 s/iter. ETA=0:01:05
[10/09 22:42:49] d2.evaluation.evaluator INFO: Inference done 224/500. Dataloading: 0.0050 s/iter. Inference: 0.1408 s/iter. Eval: 0.0706 s/iter. Total: 0.2165 s/iter. ETA=0:00:59
[10/09 22:42:54] d2.evaluation.evaluator INFO: Inference done 248/500. Dataloading: 0.0050 s/iter. Inference: 0.1404 s/iter. Eval: 0.0708 s/iter. Total: 0.2162 s/iter. ETA=0:00:54
[10/09 22:42:59] d2.evaluation.evaluator INFO: Inference done 272/500. Dataloading: 0.0050 s/iter. Inference: 0.1399 s/iter. Eval: 0.0709 s/iter. Total: 0.2158 s/iter. ETA=0:00:49
[10/09 22:43:04] d2.evaluation.evaluator INFO: Inference done 295/500. Dataloading: 0.0050 s/iter. Inference: 0.1406 s/iter. Eval: 0.0707 s/iter. Total: 0.2163 s/iter. ETA=0:00:44
[10/09 22:43:09] d2.evaluation.evaluator INFO: Inference done 322/500. Dataloading: 0.0050 s/iter. Inference: 0.1397 s/iter. Eval: 0.0695 s/iter. Total: 0.2142 s/iter. ETA=0:00:38
[10/09 22:43:14] d2.evaluation.evaluator INFO: Inference done 350/500. Dataloading: 0.0050 s/iter. Inference: 0.1389 s/iter. Eval: 0.0679 s/iter. Total: 0.2119 s/iter. ETA=0:00:31
[10/09 22:43:19] d2.evaluation.evaluator INFO: Inference done 376/500. Dataloading: 0.0049 s/iter. Inference: 0.1387 s/iter. Eval: 0.0670 s/iter. Total: 0.2108 s/iter. ETA=0:00:26
[10/09 22:43:24] d2.evaluation.evaluator INFO: Inference done 399/500. Dataloading: 0.0050 s/iter. Inference: 0.1390 s/iter. Eval: 0.0673 s/iter. Total: 0.2113 s/iter. ETA=0:00:21
[10/09 22:43:30] d2.evaluation.evaluator INFO: Inference done 422/500. Dataloading: 0.0050 s/iter. Inference: 0.1394 s/iter. Eval: 0.0675 s/iter. Total: 0.2120 s/iter. ETA=0:00:16
[10/09 22:43:35] d2.evaluation.evaluator INFO: Inference done 443/500. Dataloading: 0.0050 s/iter. Inference: 0.1407 s/iter. Eval: 0.0676 s/iter. Total: 0.2133 s/iter. ETA=0:00:12
[10/09 22:43:40] d2.evaluation.evaluator INFO: Inference done 467/500. Dataloading: 0.0049 s/iter. Inference: 0.1405 s/iter. Eval: 0.0678 s/iter. Total: 0.2134 s/iter. ETA=0:00:07
[10/09 22:43:45] d2.evaluation.evaluator INFO: Inference done 490/500. Dataloading: 0.0049 s/iter. Inference: 0.1408 s/iter. Eval: 0.0682 s/iter. Total: 0.2140 s/iter. ETA=0:00:02
[10/09 22:43:47] d2.evaluation.evaluator INFO: Total inference time: 0:01:46.133920 (0.214412 s / iter per device, on 1 devices)
[10/09 22:43:47] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:09 (0.140991 s / iter per device, on 1 devices)
[10/09 22:43:47] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_eval6m033zes ...
[10/09 22:44:12] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 58.013 | 79.796 | 71.586 |      19       |
| Things | 50.214 | 79.101 | 63.460 |       8       |
| Stuff  | 63.685 | 80.301 | 77.496 |      11       |
[10/09 22:44:12] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 97.067 | 97.369 | 99.690 |     Stuff     |
| class_8  | 73.007 | 83.620 | 87.309 |     Stuff     |
| class_11 | 86.283 | 88.741 | 97.231 |     Stuff     |
| class_12 | 43.372 | 78.069 | 55.556 |     Stuff     |
| class_13 | 38.094 | 74.985 | 50.802 |     Stuff     |
| class_17 | 43.159 | 62.876 | 68.641 |     Stuff     |
| class_19 | 44.127 | 67.692 | 65.188 |     Stuff     |
| class_20 | 65.776 | 76.767 | 85.683 |     Stuff     |
| class_21 | 87.920 | 89.019 | 98.765 |     Stuff     |
| class_22 | 35.607 | 73.906 | 48.178 |     Stuff     |
| class_23 | 86.126 | 90.267 | 95.413 |     Stuff     |
| class_24 | 51.361 | 75.190 | 68.308 |    Things     |
| class_25 | 49.188 | 72.424 | 67.917 |    Things     |
| class_26 | 63.679 | 81.781 | 77.866 |    Things     |
| class_27 | 51.369 | 88.221 | 58.228 |    Things     |
| class_28 | 52.591 | 89.645 | 58.667 |    Things     |
| class_31 | 54.654 | 81.982 | 66.667 |    Things     |
| class_32 | 36.772 | 73.002 | 50.370 |    Things     |
| class_33 | 42.096 | 70.562 | 59.657 |    Things     |
[10/09 22:44:12] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/09 22:44:12] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/09 22:44:12] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/09 22:44:12] d2.evaluation.testing INFO: copypaste: 58.0131,79.7956,71.5860,50.2137,79.1008,63.4599,63.6853,80.3010,77.4960,97.0673,97.3693,99.6898,73.0074,83.6200,87.3085,86.2832,88.7407,97.2308,43.3719,78.0695,55.5556,38.0937,74.9845,50.8021,43.1588,62.8757,68.6415,44.1269,67.6921,65.1877,65.7761,76.7665,85.6833,87.9202,89.0192,98.7654,35.6067,73.9063,48.1781,86.1265,90.2672,95.4128,51.3608,75.1904,68.3077,49.1878,72.4238,67.9167,63.6791,81.7805,77.8658,51.3690,88.2207,58.2278,52.5915,89.6446,58.6667,54.6544,81.9815,66.6667,36.7716,73.0024,50.3704,42.0955,70.5623,59.6572
[10/13 14:41:02] detectron2 INFO: Rank of current process: 0. World size: 1
[10/13 14:41:03] detectron2 INFO: Environment info:
-------------------------------  -------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:47:35) [GCC 12.3.0]
numpy                            1.24.4
detectron2                       0.6 @/home/ids/gbrison/segmentation/segmentation/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    CUDA 12.5
detectron2 arch flags            8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.0+cu121 @/home/ids/gbrison/segmentation/miniconda3/envs/fc/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA L40S (arch=8.9)
Driver version                   555.42.06
CUDA_HOME                        /usr/local/cuda
Pillow                           9.4.0
torchvision                      0.19.0+cu121 @/home/ids/gbrison/segmentation/miniconda3/envs/fc/lib/python3.8/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.10.0
-------------------------------  -------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[10/13 14:41:03] detectron2 INFO: Command line arguments: Namespace(config_file='configs/coco/panoptic-segmentation/fcclip/r50_exp_3000_a_decoder.yaml', dist_url='tcp://127.0.0.1:51163', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[10/13 14:41:03] detectron2 INFO: Contents of args.config_file=configs/coco/panoptic-segmentation/fcclip/r50_exp_3000_a_decoder.yaml:
_BASE_: ./fcclip_convnext_large_eval_ade20k_r50.yaml

INPUT:
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TEST: 2560

MODEL:
  SEM_SEG_HEAD:
    NUM_CLASSES: 19
  WEIGHTS: /tsi/hi-paris/GB/segmentation/models/fcclip_cocopan_r50.pth
OUTPUT_DIR: /tsi/hi-paris/GB/segmentation/results/In_vocab/r50_008_3000_19_a_decoder
DATASETS:
  TRAIN: ("openvocab_cityscapes_fine_panoptic_train",)
  TEST: ("openvocab_cityscapes_fine_panoptic_val",)
SOLVER:
  IMS_PER_BATCH: 8
  MAX_ITER: 3000
TEST:
  EVAL_PERIOD: 3000


[10/13 14:41:03] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - openvocab_cityscapes_fine_panoptic_val
  TRAIN:
  - openvocab_cityscapes_fine_panoptic_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    MINIMUM_INST_AREA: 1
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_panoptic_lsj
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 1024
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: -1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: CLIP
  DEVICE: cuda
  FC_CLIP:
    CLIP_MODEL_NAME: RN50
    CLIP_PRETRAINED_WEIGHTS: openai
    EMBED_DIM: 1024
    ENSEMBLE_ON_VALID_MASK: true
    GEOMETRIC_ENSEMBLE_ALPHA: 0.4
    GEOMETRIC_ENSEMBLE_BETA: 0.8
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 250
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.0
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: true
      SEMANTIC_ON: true
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: FCCLIP
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.32316305
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 1
    - 1
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: basic
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: FCCLIPHead
    NORM: GN
    NUM_CLASSES: 19
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: /tsi/hi-paris/GB/segmentation/models/fcclip_cocopan_r50.pth
OUTPUT_DIR: /tsi/hi-paris/GB/segmentation/results/In_vocab/r50_008_3000_19_a_decoder
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 3000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 3000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[10/13 14:41:03] detectron2 INFO: Full config saved to /tsi/hi-paris/GB/segmentation/results/In_vocab/r50_008_3000_19_a_decoder/config.yaml
[10/13 14:41:03] d2.utils.env INFO: Using a generated random seed 4921253
[10/13 14:41:07] d2.engine.defaults INFO: Model:
FCCLIP(
  (backbone): CLIP(
    (clip_model): CLIP(
      (visual): ModifiedResNet(
        (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (layer1): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer2): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer3): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (layer4): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
            (downsample): Sequential(
              (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act1): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act2): ReLU(inplace=True)
            (avgpool): Identity()
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act3): ReLU(inplace=True)
          )
        )
        (attnpool): AttentionPool2d(
          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (c_proj): Linear(in_features=2048, out_features=1024, bias=True)
        )
      )
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ls_1): Identity()
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ls_2): Identity()
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (sem_seg_head): FCCLIPHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(250, 256)
      (query_embed): Embedding(250, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (mask_pooling): MaskPooling()
      (_mask_pooling_proj): Sequential(
        (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
      )
      (class_embed): MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=1024, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 19
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU()
  (mask_pooling): MaskPooling()
  (decoder_adapter): DecoderAdapter(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (conv2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (norm1): LayerNorm((64, 1, 1), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((256, 1, 1), eps=1e-05, elementwise_affine=True)
    (relu): ReLU()
  )
  (void_embedding): Embedding(1, 1024)
)
[10/13 14:41:07] fcclip.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerPanopticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1333, sample_style='choice'), RandomFlip()]
[10/13 14:41:07] fcclip.data.datasets.register_cityscapes_panoptic INFO: 18 cities found in 'datasets/cityscapes/leftImg8bit/train'.
[10/13 14:41:07] d2.data.build INFO: Using training sampler TrainingSampler
[10/13 14:41:07] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 14:41:07] d2.data.common INFO: Serializing 2975 elements to byte tensors and concatenating them all ...
[10/13 14:41:07] d2.data.common INFO: Serialized dataset takes 4.12 MiB
[10/13 14:41:07] d2.data.build INFO: Making batched data loader with batch_size=8
[10/13 14:41:07] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[10/13 14:41:07] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /tsi/hi-paris/GB/segmentation/models/fcclip_cocopan_r50.pth ...
[10/13 14:41:07] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /tsi/hi-paris/GB/segmentation/models/fcclip_cocopan_r50.pth ...
[10/13 14:41:10] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (134,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.
[10/13 14:41:10] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.clip_model.ln_final.{bias, weight}
backbone.clip_model.token_embedding.weight
backbone.clip_model.transformer.resblocks.0.attn.out_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}
backbone.clip_model.transformer.resblocks.0.ln_1.{bias, weight}
backbone.clip_model.transformer.resblocks.0.ln_2.{bias, weight}
backbone.clip_model.transformer.resblocks.0.mlp.c_fc.{bias, weight}
backbone.clip_model.transformer.resblocks.0.mlp.c_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.1.attn.out_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}
backbone.clip_model.transformer.resblocks.1.ln_1.{bias, weight}
backbone.clip_model.transformer.resblocks.1.ln_2.{bias, weight}
backbone.clip_model.transformer.resblocks.1.mlp.c_fc.{bias, weight}
backbone.clip_model.transformer.resblocks.1.mlp.c_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.10.attn.out_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}
backbone.clip_model.transformer.resblocks.10.ln_1.{bias, weight}
backbone.clip_model.transformer.resblocks.10.ln_2.{bias, weight}
backbone.clip_model.transformer.resblocks.10.mlp.c_fc.{bias, weight}
backbone.clip_model.transformer.resblocks.10.mlp.c_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.11.attn.out_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}
backbone.clip_model.transformer.resblocks.11.ln_1.{bias, weight}
backbone.clip_model.transformer.resblocks.11.ln_2.{bias, weight}
backbone.clip_model.transformer.resblocks.11.mlp.c_fc.{bias, weight}
backbone.clip_model.transformer.resblocks.11.mlp.c_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.2.attn.out_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}
backbone.clip_model.transformer.resblocks.2.ln_1.{bias, weight}
backbone.clip_model.transformer.resblocks.2.ln_2.{bias, weight}
backbone.clip_model.transformer.resblocks.2.mlp.c_fc.{bias, weight}
backbone.clip_model.transformer.resblocks.2.mlp.c_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.3.attn.out_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}
backbone.clip_model.transformer.resblocks.3.ln_1.{bias, weight}
backbone.clip_model.transformer.resblocks.3.ln_2.{bias, weight}
backbone.clip_model.transformer.resblocks.3.mlp.c_fc.{bias, weight}
backbone.clip_model.transformer.resblocks.3.mlp.c_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.4.attn.out_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}
backbone.clip_model.transformer.resblocks.4.ln_1.{bias, weight}
backbone.clip_model.transformer.resblocks.4.ln_2.{bias, weight}
backbone.clip_model.transformer.resblocks.4.mlp.c_fc.{bias, weight}
backbone.clip_model.transformer.resblocks.4.mlp.c_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.5.attn.out_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}
backbone.clip_model.transformer.resblocks.5.ln_1.{bias, weight}
backbone.clip_model.transformer.resblocks.5.ln_2.{bias, weight}
backbone.clip_model.transformer.resblocks.5.mlp.c_fc.{bias, weight}
backbone.clip_model.transformer.resblocks.5.mlp.c_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.6.attn.out_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}
backbone.clip_model.transformer.resblocks.6.ln_1.{bias, weight}
backbone.clip_model.transformer.resblocks.6.ln_2.{bias, weight}
backbone.clip_model.transformer.resblocks.6.mlp.c_fc.{bias, weight}
backbone.clip_model.transformer.resblocks.6.mlp.c_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.7.attn.out_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}
backbone.clip_model.transformer.resblocks.7.ln_1.{bias, weight}
backbone.clip_model.transformer.resblocks.7.ln_2.{bias, weight}
backbone.clip_model.transformer.resblocks.7.mlp.c_fc.{bias, weight}
backbone.clip_model.transformer.resblocks.7.mlp.c_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.8.attn.out_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}
backbone.clip_model.transformer.resblocks.8.ln_1.{bias, weight}
backbone.clip_model.transformer.resblocks.8.ln_2.{bias, weight}
backbone.clip_model.transformer.resblocks.8.mlp.c_fc.{bias, weight}
backbone.clip_model.transformer.resblocks.8.mlp.c_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.9.attn.out_proj.{bias, weight}
backbone.clip_model.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}
backbone.clip_model.transformer.resblocks.9.ln_1.{bias, weight}
backbone.clip_model.transformer.resblocks.9.ln_2.{bias, weight}
backbone.clip_model.transformer.resblocks.9.mlp.c_fc.{bias, weight}
backbone.clip_model.transformer.resblocks.9.mlp.c_proj.{bias, weight}
backbone.clip_model.visual.attnpool.c_proj.{bias, weight}
backbone.clip_model.visual.attnpool.k_proj.{bias, weight}
backbone.clip_model.visual.attnpool.positional_embedding
backbone.clip_model.visual.attnpool.q_proj.{bias, weight}
backbone.clip_model.visual.attnpool.v_proj.{bias, weight}
backbone.clip_model.visual.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.conv1.weight
backbone.clip_model.visual.conv2.weight
backbone.clip_model.visual.conv3.weight
backbone.clip_model.visual.layer1.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer1.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer1.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer1.0.conv1.weight
backbone.clip_model.visual.layer1.0.conv2.weight
backbone.clip_model.visual.layer1.0.conv3.weight
backbone.clip_model.visual.layer1.0.downsample.0.weight
backbone.clip_model.visual.layer1.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer1.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer1.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer1.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer1.1.conv1.weight
backbone.clip_model.visual.layer1.1.conv2.weight
backbone.clip_model.visual.layer1.1.conv3.weight
backbone.clip_model.visual.layer1.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer1.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer1.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer1.2.conv1.weight
backbone.clip_model.visual.layer1.2.conv2.weight
backbone.clip_model.visual.layer1.2.conv3.weight
backbone.clip_model.visual.layer2.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer2.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer2.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer2.0.conv1.weight
backbone.clip_model.visual.layer2.0.conv2.weight
backbone.clip_model.visual.layer2.0.conv3.weight
backbone.clip_model.visual.layer2.0.downsample.0.weight
backbone.clip_model.visual.layer2.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer2.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer2.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer2.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer2.1.conv1.weight
backbone.clip_model.visual.layer2.1.conv2.weight
backbone.clip_model.visual.layer2.1.conv3.weight
backbone.clip_model.visual.layer2.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer2.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer2.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer2.2.conv1.weight
backbone.clip_model.visual.layer2.2.conv2.weight
backbone.clip_model.visual.layer2.2.conv3.weight
backbone.clip_model.visual.layer2.3.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer2.3.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer2.3.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer2.3.conv1.weight
backbone.clip_model.visual.layer2.3.conv2.weight
backbone.clip_model.visual.layer2.3.conv3.weight
backbone.clip_model.visual.layer3.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.0.conv1.weight
backbone.clip_model.visual.layer3.0.conv2.weight
backbone.clip_model.visual.layer3.0.conv3.weight
backbone.clip_model.visual.layer3.0.downsample.0.weight
backbone.clip_model.visual.layer3.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.1.conv1.weight
backbone.clip_model.visual.layer3.1.conv2.weight
backbone.clip_model.visual.layer3.1.conv3.weight
backbone.clip_model.visual.layer3.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.2.conv1.weight
backbone.clip_model.visual.layer3.2.conv2.weight
backbone.clip_model.visual.layer3.2.conv3.weight
backbone.clip_model.visual.layer3.3.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.3.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.3.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.3.conv1.weight
backbone.clip_model.visual.layer3.3.conv2.weight
backbone.clip_model.visual.layer3.3.conv3.weight
backbone.clip_model.visual.layer3.4.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.4.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.4.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.4.conv1.weight
backbone.clip_model.visual.layer3.4.conv2.weight
backbone.clip_model.visual.layer3.4.conv3.weight
backbone.clip_model.visual.layer3.5.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.5.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.5.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer3.5.conv1.weight
backbone.clip_model.visual.layer3.5.conv2.weight
backbone.clip_model.visual.layer3.5.conv3.weight
backbone.clip_model.visual.layer4.0.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer4.0.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer4.0.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer4.0.conv1.weight
backbone.clip_model.visual.layer4.0.conv2.weight
backbone.clip_model.visual.layer4.0.conv3.weight
backbone.clip_model.visual.layer4.0.downsample.0.weight
backbone.clip_model.visual.layer4.0.downsample.1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer4.1.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer4.1.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer4.1.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer4.1.conv1.weight
backbone.clip_model.visual.layer4.1.conv2.weight
backbone.clip_model.visual.layer4.1.conv3.weight
backbone.clip_model.visual.layer4.2.bn1.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer4.2.bn2.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer4.2.bn3.{bias, num_batches_tracked, running_mean, running_var, weight}
backbone.clip_model.visual.layer4.2.conv1.weight
backbone.clip_model.visual.layer4.2.conv2.weight
backbone.clip_model.visual.layer4.2.conv3.weight
backbone.clip_model.{logit_scale, positional_embedding, text_projection}
bn1.{bias, running_mean, running_var, weight}
bn2.{bias, running_mean, running_var, weight}
conv1.{bias, weight}
conv2.{bias, weight}
criterion.empty_weight
decoder_adapter.conv1.{bias, weight}
decoder_adapter.conv2.{bias, weight}
decoder_adapter.norm1.{bias, weight}
decoder_adapter.norm2.{bias, weight}
[10/13 14:41:10] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[10/13 14:41:14] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 14:41:14] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 14:41:14] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 14:41:14] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 14:41:14] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 14:41:14] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 14:41:17] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0041 s/iter. Inference: 0.1291 s/iter. Eval: 0.0662 s/iter. Total: 0.1995 s/iter. ETA=0:01:37
[10/13 14:41:22] d2.evaluation.evaluator INFO: Inference done 36/500. Dataloading: 0.0049 s/iter. Inference: 0.1293 s/iter. Eval: 0.0693 s/iter. Total: 0.2035 s/iter. ETA=0:01:34
[10/13 14:41:27] d2.evaluation.evaluator INFO: Inference done 61/500. Dataloading: 0.0048 s/iter. Inference: 0.1287 s/iter. Eval: 0.0709 s/iter. Total: 0.2045 s/iter. ETA=0:01:29
[10/13 14:41:32] d2.evaluation.evaluator INFO: Inference done 86/500. Dataloading: 0.0048 s/iter. Inference: 0.1285 s/iter. Eval: 0.0717 s/iter. Total: 0.2050 s/iter. ETA=0:01:24
[10/13 14:41:38] d2.evaluation.evaluator INFO: Inference done 111/500. Dataloading: 0.0048 s/iter. Inference: 0.1282 s/iter. Eval: 0.0721 s/iter. Total: 0.2052 s/iter. ETA=0:01:19
[10/13 14:41:43] d2.evaluation.evaluator INFO: Inference done 136/500. Dataloading: 0.0047 s/iter. Inference: 0.1282 s/iter. Eval: 0.0724 s/iter. Total: 0.2054 s/iter. ETA=0:01:14
[10/13 14:41:48] d2.evaluation.evaluator INFO: Inference done 161/500. Dataloading: 0.0047 s/iter. Inference: 0.1280 s/iter. Eval: 0.0725 s/iter. Total: 0.2053 s/iter. ETA=0:01:09
[10/13 14:41:53] d2.evaluation.evaluator INFO: Inference done 186/500. Dataloading: 0.0047 s/iter. Inference: 0.1280 s/iter. Eval: 0.0726 s/iter. Total: 0.2054 s/iter. ETA=0:01:04
[10/13 14:41:58] d2.evaluation.evaluator INFO: Inference done 211/500. Dataloading: 0.0047 s/iter. Inference: 0.1279 s/iter. Eval: 0.0726 s/iter. Total: 0.2053 s/iter. ETA=0:00:59
[10/13 14:42:03] d2.evaluation.evaluator INFO: Inference done 236/500. Dataloading: 0.0047 s/iter. Inference: 0.1279 s/iter. Eval: 0.0727 s/iter. Total: 0.2054 s/iter. ETA=0:00:54
[10/13 14:42:08] d2.evaluation.evaluator INFO: Inference done 261/500. Dataloading: 0.0047 s/iter. Inference: 0.1279 s/iter. Eval: 0.0728 s/iter. Total: 0.2055 s/iter. ETA=0:00:49
[10/13 14:42:14] d2.evaluation.evaluator INFO: Inference done 286/500. Dataloading: 0.0047 s/iter. Inference: 0.1278 s/iter. Eval: 0.0728 s/iter. Total: 0.2054 s/iter. ETA=0:00:43
[10/13 14:42:19] d2.evaluation.evaluator INFO: Inference done 311/500. Dataloading: 0.0048 s/iter. Inference: 0.1277 s/iter. Eval: 0.0727 s/iter. Total: 0.2051 s/iter. ETA=0:00:38
[10/13 14:42:24] d2.evaluation.evaluator INFO: Inference done 338/500. Dataloading: 0.0048 s/iter. Inference: 0.1276 s/iter. Eval: 0.0711 s/iter. Total: 0.2037 s/iter. ETA=0:00:32
[10/13 14:42:29] d2.evaluation.evaluator INFO: Inference done 366/500. Dataloading: 0.0049 s/iter. Inference: 0.1277 s/iter. Eval: 0.0694 s/iter. Total: 0.2021 s/iter. ETA=0:00:27
[10/13 14:42:34] d2.evaluation.evaluator INFO: Inference done 394/500. Dataloading: 0.0050 s/iter. Inference: 0.1278 s/iter. Eval: 0.0680 s/iter. Total: 0.2008 s/iter. ETA=0:00:21
[10/13 14:42:39] d2.evaluation.evaluator INFO: Inference done 422/500. Dataloading: 0.0050 s/iter. Inference: 0.1279 s/iter. Eval: 0.0667 s/iter. Total: 0.1996 s/iter. ETA=0:00:15
[10/13 14:42:44] d2.evaluation.evaluator INFO: Inference done 450/500. Dataloading: 0.0051 s/iter. Inference: 0.1279 s/iter. Eval: 0.0656 s/iter. Total: 0.1986 s/iter. ETA=0:00:09
[10/13 14:42:49] d2.evaluation.evaluator INFO: Inference done 477/500. Dataloading: 0.0051 s/iter. Inference: 0.1279 s/iter. Eval: 0.0651 s/iter. Total: 0.1981 s/iter. ETA=0:00:04
[10/13 14:42:54] d2.evaluation.evaluator INFO: Total inference time: 0:01:38.304827 (0.198596 s / iter per device, on 1 devices)
[10/13 14:42:54] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:03 (0.127918 s / iter per device, on 1 devices)
[10/13 14:42:54] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalnd11jw1f ...
[10/13 14:43:17] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 40.181 | 66.136 | 49.238 |      19       |
| Things | 29.166 | 59.253 | 36.909 |       8       |
| Stuff  | 48.191 | 71.141 | 58.204 |      11       |
[10/13 14:43:17] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 93.497 | 96.437 | 96.951 |     Stuff     |
| class_8  | 62.278 | 78.563 | 79.271 |     Stuff     |
| class_11 | 80.155 | 84.618 | 94.726 |     Stuff     |
| class_12 | 33.000 | 80.667 | 40.909 |     Stuff     |
| class_13 | 30.218 | 72.940 | 41.429 |     Stuff     |
| class_17 | 0.000  | 0.000  | 0.000  |     Stuff     |
| class_19 | 32.904 | 65.807 | 50.000 |     Stuff     |
| class_20 | 1.794  | 59.657 | 3.008  |     Stuff     |
| class_21 | 84.764 | 86.010 | 98.551 |     Stuff     |
| class_22 | 29.566 | 69.798 | 42.359 |     Stuff     |
| class_23 | 81.929 | 88.053 | 93.044 |     Stuff     |
| class_24 | 20.554 | 79.003 | 26.017 |    Things     |
| class_25 | 0.000  | 0.000  | 0.000  |    Things     |
| class_26 | 56.638 | 80.126 | 70.687 |    Things     |
| class_27 | 29.211 | 85.056 | 34.343 |    Things     |
| class_28 | 54.322 | 89.170 | 60.920 |    Things     |
| class_31 | 0.000  | 0.000  | 0.000  |    Things     |
| class_32 | 35.556 | 71.736 | 49.565 |    Things     |
| class_33 | 37.048 | 68.937 | 53.741 |    Things     |
[10/13 14:43:17] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 14:43:17] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 14:43:17] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 14:43:17] d2.evaluation.testing INFO: copypaste: 40.1807,66.1357,49.2379,29.1662,59.2535,36.9092,48.1912,71.1410,58.2043,93.4966,96.4374,96.9506,62.2778,78.5631,79.2711,80.1548,84.6176,94.7260,33.0002,80.6672,40.9091,30.2181,72.9402,41.4286,0.0000,0.0000,0.0000,32.9035,65.8070,50.0000,1.7942,59.6571,3.0075,84.7637,86.0102,98.5507,29.5659,69.7979,42.3592,81.9287,88.0533,93.0445,20.5542,79.0028,26.0171,0.0000,0.0000,0.0000,56.6384,80.1256,70.6870,29.2113,85.0563,34.3434,54.3220,89.1701,60.9195,0.0000,0.0000,0.0000,35.5562,71.7362,49.5652,37.0476,68.9367,53.7415
[10/13 14:43:28] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 14:43:28] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 14:43:28] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 14:43:28] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 14:43:28] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 14:43:28] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 14:43:30] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0045 s/iter. Inference: 0.1307 s/iter. Eval: 0.0538 s/iter. Total: 0.1890 s/iter. ETA=0:01:32
[10/13 14:43:35] d2.evaluation.evaluator INFO: Inference done 36/500. Dataloading: 0.0050 s/iter. Inference: 0.1330 s/iter. Eval: 0.0626 s/iter. Total: 0.2007 s/iter. ETA=0:01:33
[10/13 14:43:41] d2.evaluation.evaluator INFO: Inference done 61/500. Dataloading: 0.0050 s/iter. Inference: 0.1333 s/iter. Eval: 0.0655 s/iter. Total: 0.2039 s/iter. ETA=0:01:29
[10/13 14:43:46] d2.evaluation.evaluator INFO: Inference done 85/500. Dataloading: 0.0049 s/iter. Inference: 0.1333 s/iter. Eval: 0.0675 s/iter. Total: 0.2058 s/iter. ETA=0:01:25
[10/13 14:43:51] d2.evaluation.evaluator INFO: Inference done 109/500. Dataloading: 0.0048 s/iter. Inference: 0.1331 s/iter. Eval: 0.0687 s/iter. Total: 0.2066 s/iter. ETA=0:01:20
[10/13 14:43:56] d2.evaluation.evaluator INFO: Inference done 133/500. Dataloading: 0.0048 s/iter. Inference: 0.1330 s/iter. Eval: 0.0694 s/iter. Total: 0.2072 s/iter. ETA=0:01:16
[10/13 14:44:01] d2.evaluation.evaluator INFO: Inference done 157/500. Dataloading: 0.0048 s/iter. Inference: 0.1328 s/iter. Eval: 0.0699 s/iter. Total: 0.2075 s/iter. ETA=0:01:11
[10/13 14:44:06] d2.evaluation.evaluator INFO: Inference done 181/500. Dataloading: 0.0048 s/iter. Inference: 0.1327 s/iter. Eval: 0.0702 s/iter. Total: 0.2077 s/iter. ETA=0:01:06
[10/13 14:44:11] d2.evaluation.evaluator INFO: Inference done 205/500. Dataloading: 0.0047 s/iter. Inference: 0.1326 s/iter. Eval: 0.0705 s/iter. Total: 0.2078 s/iter. ETA=0:01:01
[10/13 14:44:16] d2.evaluation.evaluator INFO: Inference done 229/500. Dataloading: 0.0047 s/iter. Inference: 0.1326 s/iter. Eval: 0.0706 s/iter. Total: 0.2079 s/iter. ETA=0:00:56
[10/13 14:44:21] d2.evaluation.evaluator INFO: Inference done 253/500. Dataloading: 0.0047 s/iter. Inference: 0.1326 s/iter. Eval: 0.0707 s/iter. Total: 0.2080 s/iter. ETA=0:00:51
[10/13 14:44:26] d2.evaluation.evaluator INFO: Inference done 277/500. Dataloading: 0.0047 s/iter. Inference: 0.1325 s/iter. Eval: 0.0709 s/iter. Total: 0.2081 s/iter. ETA=0:00:46
[10/13 14:44:31] d2.evaluation.evaluator INFO: Inference done 304/500. Dataloading: 0.0048 s/iter. Inference: 0.1321 s/iter. Eval: 0.0697 s/iter. Total: 0.2066 s/iter. ETA=0:00:40
[10/13 14:44:36] d2.evaluation.evaluator INFO: Inference done 332/500. Dataloading: 0.0048 s/iter. Inference: 0.1318 s/iter. Eval: 0.0679 s/iter. Total: 0.2047 s/iter. ETA=0:00:34
[10/13 14:44:41] d2.evaluation.evaluator INFO: Inference done 359/500. Dataloading: 0.0049 s/iter. Inference: 0.1319 s/iter. Eval: 0.0666 s/iter. Total: 0.2034 s/iter. ETA=0:00:28
[10/13 14:44:46] d2.evaluation.evaluator INFO: Inference done 386/500. Dataloading: 0.0050 s/iter. Inference: 0.1319 s/iter. Eval: 0.0654 s/iter. Total: 0.2023 s/iter. ETA=0:00:23
[10/13 14:44:51] d2.evaluation.evaluator INFO: Inference done 413/500. Dataloading: 0.0050 s/iter. Inference: 0.1319 s/iter. Eval: 0.0643 s/iter. Total: 0.2013 s/iter. ETA=0:00:17
[10/13 14:44:56] d2.evaluation.evaluator INFO: Inference done 440/500. Dataloading: 0.0051 s/iter. Inference: 0.1319 s/iter. Eval: 0.0634 s/iter. Total: 0.2004 s/iter. ETA=0:00:12
[10/13 14:45:01] d2.evaluation.evaluator INFO: Inference done 467/500. Dataloading: 0.0051 s/iter. Inference: 0.1318 s/iter. Eval: 0.0625 s/iter. Total: 0.1995 s/iter. ETA=0:00:06
[10/13 14:45:06] d2.evaluation.evaluator INFO: Inference done 494/500. Dataloading: 0.0051 s/iter. Inference: 0.1318 s/iter. Eval: 0.0618 s/iter. Total: 0.1988 s/iter. ETA=0:00:01
[10/13 14:45:08] d2.evaluation.evaluator INFO: Total inference time: 0:01:38.360980 (0.198709 s / iter per device, on 1 devices)
[10/13 14:45:08] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:05 (0.131731 s / iter per device, on 1 devices)
[10/13 14:45:08] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_eval03my2jb5 ...
[10/13 14:45:30] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 42.986 | 66.521 | 52.964 |      19       |
| Things | 32.064 | 58.707 | 40.933 |       8       |
| Stuff  | 50.929 | 72.205 | 61.713 |      11       |
[10/13 14:45:30] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 91.358 | 93.804 | 97.393 |     Stuff     |
| class_8  | 65.314 | 79.878 | 81.768 |     Stuff     |
| class_11 | 82.655 | 86.218 | 95.868 |     Stuff     |
| class_12 | 33.988 | 78.659 | 43.210 |     Stuff     |
| class_13 | 28.337 | 73.531 | 38.538 |     Stuff     |
| class_17 | 0.000  | 0.000  | 0.000  |     Stuff     |
| class_19 | 32.214 | 66.820 | 48.211 |     Stuff     |
| class_20 | 26.356 | 67.833 | 38.854 |     Stuff     |
| class_21 | 85.962 | 87.218 | 98.560 |     Stuff     |
| class_22 | 31.055 | 70.470 | 44.068 |     Stuff     |
| class_23 | 82.978 | 89.826 | 92.377 |     Stuff     |
| class_24 | 41.449 | 73.738 | 56.211 |    Things     |
| class_25 | 0.000  | 0.000  | 0.000  |    Things     |
| class_26 | 56.564 | 80.369 | 70.381 |    Things     |
| class_27 | 38.836 | 86.347 | 44.976 |    Things     |
| class_28 | 49.302 | 90.201 | 54.658 |    Things     |
| class_31 | 0.000  | 0.000  | 0.000  |    Things     |
| class_32 | 34.316 | 69.505 | 49.372 |    Things     |
| class_33 | 36.043 | 69.492 | 51.866 |    Things     |
[10/13 14:45:30] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 14:45:30] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 14:45:30] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 14:45:30] d2.evaluation.testing INFO: copypaste: 42.9857,66.5214,52.9637,32.0637,58.7065,40.9330,50.9289,72.2050,61.7133,91.3583,93.8036,97.3931,65.3144,79.8777,81.7680,82.6555,86.2182,95.8678,33.9885,78.6591,43.2099,28.3374,73.5306,38.5382,0.0000,0.0000,0.0000,32.2144,66.8198,48.2109,26.3559,67.8327,38.8543,85.9617,87.2179,98.5597,31.0545,70.4698,44.0678,82.9778,89.8255,92.3767,41.4490,73.7378,56.2113,0.0000,0.0000,0.0000,56.5639,80.3687,70.3805,38.8356,86.3473,44.9761,49.3024,90.2009,54.6584,0.0000,0.0000,0.0000,34.3165,69.5054,49.3724,36.0426,69.4921,51.8657
[10/13 14:45:41] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 14:45:41] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 14:45:41] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 14:45:41] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 14:45:41] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 14:45:41] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 14:45:43] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0045 s/iter. Inference: 0.1313 s/iter. Eval: 0.0495 s/iter. Total: 0.1854 s/iter. ETA=0:01:30
[10/13 14:45:48] d2.evaluation.evaluator INFO: Inference done 36/500. Dataloading: 0.0056 s/iter. Inference: 0.1319 s/iter. Eval: 0.0622 s/iter. Total: 0.1997 s/iter. ETA=0:01:32
[10/13 14:45:53] d2.evaluation.evaluator INFO: Inference done 60/500. Dataloading: 0.0052 s/iter. Inference: 0.1335 s/iter. Eval: 0.0660 s/iter. Total: 0.2047 s/iter. ETA=0:01:30
[10/13 14:45:58] d2.evaluation.evaluator INFO: Inference done 84/500. Dataloading: 0.0051 s/iter. Inference: 0.1340 s/iter. Eval: 0.0671 s/iter. Total: 0.2063 s/iter. ETA=0:01:25
[10/13 14:46:03] d2.evaluation.evaluator INFO: Inference done 108/500. Dataloading: 0.0050 s/iter. Inference: 0.1345 s/iter. Eval: 0.0681 s/iter. Total: 0.2077 s/iter. ETA=0:01:21
[10/13 14:46:09] d2.evaluation.evaluator INFO: Inference done 132/500. Dataloading: 0.0049 s/iter. Inference: 0.1344 s/iter. Eval: 0.0688 s/iter. Total: 0.2082 s/iter. ETA=0:01:16
[10/13 14:46:14] d2.evaluation.evaluator INFO: Inference done 156/500. Dataloading: 0.0049 s/iter. Inference: 0.1345 s/iter. Eval: 0.0687 s/iter. Total: 0.2082 s/iter. ETA=0:01:11
[10/13 14:46:19] d2.evaluation.evaluator INFO: Inference done 180/500. Dataloading: 0.0049 s/iter. Inference: 0.1343 s/iter. Eval: 0.0691 s/iter. Total: 0.2084 s/iter. ETA=0:01:06
[10/13 14:46:24] d2.evaluation.evaluator INFO: Inference done 205/500. Dataloading: 0.0049 s/iter. Inference: 0.1343 s/iter. Eval: 0.0689 s/iter. Total: 0.2082 s/iter. ETA=0:01:01
[10/13 14:46:29] d2.evaluation.evaluator INFO: Inference done 229/500. Dataloading: 0.0049 s/iter. Inference: 0.1344 s/iter. Eval: 0.0691 s/iter. Total: 0.2085 s/iter. ETA=0:00:56
[10/13 14:46:34] d2.evaluation.evaluator INFO: Inference done 253/500. Dataloading: 0.0049 s/iter. Inference: 0.1344 s/iter. Eval: 0.0691 s/iter. Total: 0.2085 s/iter. ETA=0:00:51
[10/13 14:46:39] d2.evaluation.evaluator INFO: Inference done 277/500. Dataloading: 0.0049 s/iter. Inference: 0.1344 s/iter. Eval: 0.0693 s/iter. Total: 0.2087 s/iter. ETA=0:00:46
[10/13 14:46:44] d2.evaluation.evaluator INFO: Inference done 301/500. Dataloading: 0.0049 s/iter. Inference: 0.1343 s/iter. Eval: 0.0696 s/iter. Total: 0.2088 s/iter. ETA=0:00:41
[10/13 14:46:49] d2.evaluation.evaluator INFO: Inference done 326/500. Dataloading: 0.0049 s/iter. Inference: 0.1339 s/iter. Eval: 0.0698 s/iter. Total: 0.2087 s/iter. ETA=0:00:36
[10/13 14:46:54] d2.evaluation.evaluator INFO: Inference done 350/500. Dataloading: 0.0049 s/iter. Inference: 0.1339 s/iter. Eval: 0.0700 s/iter. Total: 0.2088 s/iter. ETA=0:00:31
[10/13 14:46:59] d2.evaluation.evaluator INFO: Inference done 374/500. Dataloading: 0.0049 s/iter. Inference: 0.1339 s/iter. Eval: 0.0701 s/iter. Total: 0.2089 s/iter. ETA=0:00:26
[10/13 14:47:04] d2.evaluation.evaluator INFO: Inference done 398/500. Dataloading: 0.0048 s/iter. Inference: 0.1340 s/iter. Eval: 0.0702 s/iter. Total: 0.2091 s/iter. ETA=0:00:21
[10/13 14:47:09] d2.evaluation.evaluator INFO: Inference done 422/500. Dataloading: 0.0048 s/iter. Inference: 0.1340 s/iter. Eval: 0.0703 s/iter. Total: 0.2092 s/iter. ETA=0:00:16
[10/13 14:47:14] d2.evaluation.evaluator INFO: Inference done 446/500. Dataloading: 0.0048 s/iter. Inference: 0.1340 s/iter. Eval: 0.0704 s/iter. Total: 0.2092 s/iter. ETA=0:00:11
[10/13 14:47:19] d2.evaluation.evaluator INFO: Inference done 470/500. Dataloading: 0.0048 s/iter. Inference: 0.1340 s/iter. Eval: 0.0704 s/iter. Total: 0.2093 s/iter. ETA=0:00:06
[10/13 14:47:24] d2.evaluation.evaluator INFO: Inference done 494/500. Dataloading: 0.0048 s/iter. Inference: 0.1339 s/iter. Eval: 0.0705 s/iter. Total: 0.2093 s/iter. ETA=0:00:01
[10/13 14:47:26] d2.evaluation.evaluator INFO: Total inference time: 0:01:43.665427 (0.209425 s / iter per device, on 1 devices)
[10/13 14:47:26] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.133906 s / iter per device, on 1 devices)
[10/13 14:47:26] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evall9nbn3jw ...
[10/13 14:47:49] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 43.777 | 70.602 | 53.405 |      19       |
| Things | 33.391 | 59.530 | 42.116 |       8       |
| Stuff  | 51.330 | 78.655 | 61.615 |      11       |
[10/13 14:47:49] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 95.616 | 96.013 | 99.586 |     Stuff     |
| class_8  | 65.661 | 79.391 | 82.705 |     Stuff     |
| class_11 | 83.566 | 86.024 | 97.143 |     Stuff     |
| class_12 | 32.188 | 77.140 | 41.727 |     Stuff     |
| class_13 | 26.734 | 74.049 | 36.103 |     Stuff     |
| class_17 | 10.020 | 62.507 | 16.031 |     Stuff     |
| class_19 | 17.348 | 69.393 | 25.000 |     Stuff     |
| class_20 | 33.950 | 71.078 | 47.765 |     Stuff     |
| class_21 | 86.820 | 88.267 | 98.361 |     Stuff     |
| class_22 | 29.084 | 70.545 | 41.228 |     Stuff     |
| class_23 | 83.642 | 90.800 | 92.117 |     Stuff     |
| class_24 | 44.774 | 73.774 | 60.691 |    Things     |
| class_25 | 0.000  | 0.000  | 0.000  |    Things     |
| class_26 | 55.733 | 80.579 | 69.166 |    Things     |
| class_27 | 42.974 | 88.852 | 48.366 |    Things     |
| class_28 | 49.702 | 90.735 | 54.777 |    Things     |
| class_31 | 0.000  | 0.000  | 0.000  |    Things     |
| class_32 | 37.333 | 71.838 | 51.969 |    Things     |
| class_33 | 36.611 | 70.462 | 51.958 |    Things     |
[10/13 14:47:49] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 14:47:49] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 14:47:49] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 14:47:49] d2.evaluation.testing INFO: copypaste: 43.7766,70.6025,53.4048,33.3909,59.5300,42.1158,51.3299,78.6552,61.6150,95.6156,96.0132,99.5859,65.6607,79.3914,82.7051,83.5658,86.0236,97.1429,32.1881,77.1405,41.7266,26.7341,74.0493,36.1032,10.0202,62.5069,16.0305,17.3483,69.3933,25.0000,33.9503,71.0779,47.7650,86.8195,88.2665,98.3607,29.0843,70.5450,41.2281,83.6421,90.7997,92.1171,44.7740,73.7736,60.6911,0.0000,0.0000,0.0000,55.7329,80.5790,69.1655,42.9741,88.8518,48.3660,49.7022,90.7354,54.7771,0.0000,0.0000,0.0000,37.3329,71.8376,51.9685,36.6111,70.4625,51.9584
[10/13 14:48:00] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 14:48:00] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 14:48:00] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 14:48:00] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 14:48:00] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 14:48:00] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 14:48:03] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0038 s/iter. Inference: 0.1323 s/iter. Eval: 0.0723 s/iter. Total: 0.2085 s/iter. ETA=0:01:41
[10/13 14:48:08] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0045 s/iter. Inference: 0.1321 s/iter. Eval: 0.0726 s/iter. Total: 0.2093 s/iter. ETA=0:01:37
[10/13 14:48:13] d2.evaluation.evaluator INFO: Inference done 60/500. Dataloading: 0.0048 s/iter. Inference: 0.1326 s/iter. Eval: 0.0709 s/iter. Total: 0.2084 s/iter. ETA=0:01:31
[10/13 14:48:18] d2.evaluation.evaluator INFO: Inference done 84/500. Dataloading: 0.0048 s/iter. Inference: 0.1336 s/iter. Eval: 0.0711 s/iter. Total: 0.2095 s/iter. ETA=0:01:27
[10/13 14:48:23] d2.evaluation.evaluator INFO: Inference done 108/500. Dataloading: 0.0048 s/iter. Inference: 0.1334 s/iter. Eval: 0.0714 s/iter. Total: 0.2096 s/iter. ETA=0:01:22
[10/13 14:48:28] d2.evaluation.evaluator INFO: Inference done 132/500. Dataloading: 0.0048 s/iter. Inference: 0.1333 s/iter. Eval: 0.0716 s/iter. Total: 0.2097 s/iter. ETA=0:01:17
[10/13 14:48:33] d2.evaluation.evaluator INFO: Inference done 157/500. Dataloading: 0.0048 s/iter. Inference: 0.1331 s/iter. Eval: 0.0712 s/iter. Total: 0.2091 s/iter. ETA=0:01:11
[10/13 14:48:38] d2.evaluation.evaluator INFO: Inference done 181/500. Dataloading: 0.0048 s/iter. Inference: 0.1331 s/iter. Eval: 0.0713 s/iter. Total: 0.2092 s/iter. ETA=0:01:06
[10/13 14:48:43] d2.evaluation.evaluator INFO: Inference done 205/500. Dataloading: 0.0048 s/iter. Inference: 0.1334 s/iter. Eval: 0.0713 s/iter. Total: 0.2094 s/iter. ETA=0:01:01
[10/13 14:48:48] d2.evaluation.evaluator INFO: Inference done 230/500. Dataloading: 0.0048 s/iter. Inference: 0.1334 s/iter. Eval: 0.0707 s/iter. Total: 0.2090 s/iter. ETA=0:00:56
[10/13 14:48:54] d2.evaluation.evaluator INFO: Inference done 255/500. Dataloading: 0.0049 s/iter. Inference: 0.1334 s/iter. Eval: 0.0699 s/iter. Total: 0.2082 s/iter. ETA=0:00:51
[10/13 14:48:59] d2.evaluation.evaluator INFO: Inference done 280/500. Dataloading: 0.0049 s/iter. Inference: 0.1334 s/iter. Eval: 0.0696 s/iter. Total: 0.2079 s/iter. ETA=0:00:45
[10/13 14:49:04] d2.evaluation.evaluator INFO: Inference done 305/500. Dataloading: 0.0049 s/iter. Inference: 0.1329 s/iter. Eval: 0.0699 s/iter. Total: 0.2078 s/iter. ETA=0:00:40
[10/13 14:49:09] d2.evaluation.evaluator INFO: Inference done 330/500. Dataloading: 0.0049 s/iter. Inference: 0.1327 s/iter. Eval: 0.0701 s/iter. Total: 0.2077 s/iter. ETA=0:00:35
[10/13 14:49:14] d2.evaluation.evaluator INFO: Inference done 354/500. Dataloading: 0.0049 s/iter. Inference: 0.1327 s/iter. Eval: 0.0703 s/iter. Total: 0.2079 s/iter. ETA=0:00:30
[10/13 14:49:19] d2.evaluation.evaluator INFO: Inference done 378/500. Dataloading: 0.0049 s/iter. Inference: 0.1327 s/iter. Eval: 0.0704 s/iter. Total: 0.2080 s/iter. ETA=0:00:25
[10/13 14:49:24] d2.evaluation.evaluator INFO: Inference done 402/500. Dataloading: 0.0048 s/iter. Inference: 0.1329 s/iter. Eval: 0.0704 s/iter. Total: 0.2082 s/iter. ETA=0:00:20
[10/13 14:49:29] d2.evaluation.evaluator INFO: Inference done 426/500. Dataloading: 0.0048 s/iter. Inference: 0.1330 s/iter. Eval: 0.0705 s/iter. Total: 0.2084 s/iter. ETA=0:00:15
[10/13 14:49:34] d2.evaluation.evaluator INFO: Inference done 450/500. Dataloading: 0.0048 s/iter. Inference: 0.1329 s/iter. Eval: 0.0706 s/iter. Total: 0.2084 s/iter. ETA=0:00:10
[10/13 14:49:39] d2.evaluation.evaluator INFO: Inference done 474/500. Dataloading: 0.0048 s/iter. Inference: 0.1331 s/iter. Eval: 0.0706 s/iter. Total: 0.2086 s/iter. ETA=0:00:05
[10/13 14:49:44] d2.evaluation.evaluator INFO: Inference done 498/500. Dataloading: 0.0048 s/iter. Inference: 0.1330 s/iter. Eval: 0.0707 s/iter. Total: 0.2086 s/iter. ETA=0:00:00
[10/13 14:49:45] d2.evaluation.evaluator INFO: Total inference time: 0:01:43.341078 (0.208770 s / iter per device, on 1 devices)
[10/13 14:49:45] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:05 (0.133021 s / iter per device, on 1 devices)
[10/13 14:49:45] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalf6_2nj8j ...
[10/13 14:50:08] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 46.088 | 70.755 | 56.457 |      19       |
| Things | 34.855 | 59.654 | 43.832 |       8       |
| Stuff  | 54.258 | 78.828 | 65.638 |      11       |
[10/13 14:50:08] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 95.923 | 96.423 | 99.482 |     Stuff     |
| class_8  | 67.666 | 81.959 | 82.561 |     Stuff     |
| class_11 | 84.096 | 86.212 | 97.546 |     Stuff     |
| class_12 | 33.054 | 80.641 | 40.989 |     Stuff     |
| class_13 | 28.045 | 73.738 | 38.033 |     Stuff     |
| class_17 | 24.263 | 61.412 | 39.509 |     Stuff     |
| class_19 | 18.943 | 66.019 | 28.694 |     Stuff     |
| class_20 | 44.934 | 72.259 | 62.185 |     Stuff     |
| class_21 | 87.158 | 88.335 | 98.667 |     Stuff     |
| class_22 | 29.216 | 69.794 | 41.860 |     Stuff     |
| class_23 | 83.540 | 90.316 | 92.497 |     Stuff     |
| class_24 | 43.763 | 74.717 | 58.571 |    Things     |
| class_25 | 0.000  | 0.000  | 0.000  |    Things     |
| class_26 | 59.831 | 81.467 | 73.442 |    Things     |
| class_27 | 43.521 | 88.597 | 49.123 |    Things     |
| class_28 | 52.486 | 89.897 | 58.385 |    Things     |
| class_31 | 0.000  | 0.000  | 0.000  |    Things     |
| class_32 | 41.015 | 72.541 | 56.540 |    Things     |
| class_33 | 38.225 | 70.017 | 54.593 |    Things     |
[10/13 14:50:08] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 14:50:08] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 14:50:08] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 14:50:08] d2.evaluation.testing INFO: copypaste: 46.0883,70.7549,56.4567,34.8551,59.6544,43.8318,54.2580,78.8279,65.6384,95.9229,96.4225,99.4819,67.6659,81.9590,82.5607,84.0964,86.2120,97.5460,33.0544,80.6413,40.9894,28.0445,73.7378,38.0328,24.2631,61.4117,39.5089,18.9434,66.0191,28.6938,44.9340,72.2587,62.1849,87.1575,88.3353,98.6667,29.2159,69.7935,41.8605,83.5398,90.3161,92.4972,43.7627,74.7171,58.5712,0.0000,0.0000,0.0000,59.8307,81.4666,73.4420,43.5212,88.5968,49.1228,52.4862,89.8965,58.3851,0.0000,0.0000,0.0000,41.0148,72.5411,56.5401,38.2249,70.0174,54.5935
[10/13 14:50:19] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 14:50:19] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 14:50:19] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 14:50:19] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 14:50:19] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 14:50:19] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 14:50:22] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0037 s/iter. Inference: 0.1362 s/iter. Eval: 0.0709 s/iter. Total: 0.2108 s/iter. ETA=0:01:43
[10/13 14:50:27] d2.evaluation.evaluator INFO: Inference done 36/500. Dataloading: 0.0047 s/iter. Inference: 0.1318 s/iter. Eval: 0.0693 s/iter. Total: 0.2058 s/iter. ETA=0:01:35
[10/13 14:50:32] d2.evaluation.evaluator INFO: Inference done 60/500. Dataloading: 0.0047 s/iter. Inference: 0.1328 s/iter. Eval: 0.0701 s/iter. Total: 0.2077 s/iter. ETA=0:01:31
[10/13 14:50:37] d2.evaluation.evaluator INFO: Inference done 84/500. Dataloading: 0.0048 s/iter. Inference: 0.1343 s/iter. Eval: 0.0702 s/iter. Total: 0.2094 s/iter. ETA=0:01:27
[10/13 14:50:42] d2.evaluation.evaluator INFO: Inference done 108/500. Dataloading: 0.0048 s/iter. Inference: 0.1349 s/iter. Eval: 0.0704 s/iter. Total: 0.2101 s/iter. ETA=0:01:22
[10/13 14:50:47] d2.evaluation.evaluator INFO: Inference done 132/500. Dataloading: 0.0048 s/iter. Inference: 0.1349 s/iter. Eval: 0.0708 s/iter. Total: 0.2105 s/iter. ETA=0:01:17
[10/13 14:50:52] d2.evaluation.evaluator INFO: Inference done 156/500. Dataloading: 0.0048 s/iter. Inference: 0.1349 s/iter. Eval: 0.0708 s/iter. Total: 0.2105 s/iter. ETA=0:01:12
[10/13 14:50:57] d2.evaluation.evaluator INFO: Inference done 180/500. Dataloading: 0.0047 s/iter. Inference: 0.1348 s/iter. Eval: 0.0709 s/iter. Total: 0.2105 s/iter. ETA=0:01:07
[10/13 14:51:02] d2.evaluation.evaluator INFO: Inference done 204/500. Dataloading: 0.0047 s/iter. Inference: 0.1349 s/iter. Eval: 0.0709 s/iter. Total: 0.2106 s/iter. ETA=0:01:02
[10/13 14:51:07] d2.evaluation.evaluator INFO: Inference done 228/500. Dataloading: 0.0047 s/iter. Inference: 0.1348 s/iter. Eval: 0.0710 s/iter. Total: 0.2105 s/iter. ETA=0:00:57
[10/13 14:51:12] d2.evaluation.evaluator INFO: Inference done 252/500. Dataloading: 0.0047 s/iter. Inference: 0.1346 s/iter. Eval: 0.0711 s/iter. Total: 0.2104 s/iter. ETA=0:00:52
[10/13 14:51:17] d2.evaluation.evaluator INFO: Inference done 276/500. Dataloading: 0.0047 s/iter. Inference: 0.1344 s/iter. Eval: 0.0712 s/iter. Total: 0.2103 s/iter. ETA=0:00:47
[10/13 14:51:22] d2.evaluation.evaluator INFO: Inference done 301/500. Dataloading: 0.0047 s/iter. Inference: 0.1340 s/iter. Eval: 0.0711 s/iter. Total: 0.2098 s/iter. ETA=0:00:41
[10/13 14:51:27] d2.evaluation.evaluator INFO: Inference done 325/500. Dataloading: 0.0047 s/iter. Inference: 0.1339 s/iter. Eval: 0.0711 s/iter. Total: 0.2098 s/iter. ETA=0:00:36
[10/13 14:51:32] d2.evaluation.evaluator INFO: Inference done 349/500. Dataloading: 0.0047 s/iter. Inference: 0.1339 s/iter. Eval: 0.0712 s/iter. Total: 0.2098 s/iter. ETA=0:00:31
[10/13 14:51:37] d2.evaluation.evaluator INFO: Inference done 373/500. Dataloading: 0.0047 s/iter. Inference: 0.1339 s/iter. Eval: 0.0712 s/iter. Total: 0.2099 s/iter. ETA=0:00:26
[10/13 14:51:43] d2.evaluation.evaluator INFO: Inference done 397/500. Dataloading: 0.0047 s/iter. Inference: 0.1340 s/iter. Eval: 0.0712 s/iter. Total: 0.2100 s/iter. ETA=0:00:21
[10/13 14:51:48] d2.evaluation.evaluator INFO: Inference done 421/500. Dataloading: 0.0047 s/iter. Inference: 0.1340 s/iter. Eval: 0.0712 s/iter. Total: 0.2100 s/iter. ETA=0:00:16
[10/13 14:51:53] d2.evaluation.evaluator INFO: Inference done 445/500. Dataloading: 0.0047 s/iter. Inference: 0.1339 s/iter. Eval: 0.0713 s/iter. Total: 0.2100 s/iter. ETA=0:00:11
[10/13 14:51:58] d2.evaluation.evaluator INFO: Inference done 469/500. Dataloading: 0.0047 s/iter. Inference: 0.1339 s/iter. Eval: 0.0714 s/iter. Total: 0.2100 s/iter. ETA=0:00:06
[10/13 14:52:03] d2.evaluation.evaluator INFO: Inference done 493/500. Dataloading: 0.0047 s/iter. Inference: 0.1340 s/iter. Eval: 0.0714 s/iter. Total: 0.2101 s/iter. ETA=0:00:01
[10/13 14:52:04] d2.evaluation.evaluator INFO: Total inference time: 0:01:44.070839 (0.210244 s / iter per device, on 1 devices)
[10/13 14:52:04] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.133940 s / iter per device, on 1 devices)
[10/13 14:52:04] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalxdmc8rtt ...
[10/13 14:52:28] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 47.175 | 73.399 | 58.237 |      19       |
| Things | 34.876 | 66.407 | 44.386 |       8       |
| Stuff  | 56.119 | 78.484 | 68.311 |      11       |
[10/13 14:52:28] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.459 | 96.961 | 99.482 |     Stuff     |
| class_8  | 69.012 | 82.178 | 83.978 |     Stuff     |
| class_11 | 84.078 | 86.655 | 97.026 |     Stuff     |
| class_12 | 40.691 | 78.685 | 51.713 |     Stuff     |
| class_13 | 29.350 | 72.458 | 40.506 |     Stuff     |
| class_17 | 25.704 | 61.064 | 42.094 |     Stuff     |
| class_19 | 22.811 | 64.894 | 35.152 |     Stuff     |
| class_20 | 47.127 | 72.131 | 65.335 |     Stuff     |
| class_21 | 87.294 | 88.387 | 98.763 |     Stuff     |
| class_22 | 31.000 | 69.751 | 44.444 |     Stuff     |
| class_23 | 83.787 | 90.162 | 92.929 |     Stuff     |
| class_24 | 44.866 | 74.665 | 60.089 |    Things     |
| class_25 | 0.000  | 0.000  | 0.000  |    Things     |
| class_26 | 59.830 | 81.448 | 73.457 |    Things     |
| class_27 | 44.417 | 87.750 | 50.617 |    Things     |
| class_28 | 45.553 | 89.995 | 50.617 |    Things     |
| class_31 | 4.586  | 55.032 | 8.333  |    Things     |
| class_32 | 42.052 | 72.317 | 58.150 |    Things     |
| class_33 | 37.701 | 70.047 | 53.823 |    Things     |
[10/13 14:52:28] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 14:52:28] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 14:52:28] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 14:52:28] d2.evaluation.testing INFO: copypaste: 47.1745,73.3989,58.2373,34.8755,66.4067,44.3859,56.1193,78.4842,68.3111,96.4587,96.9611,99.4819,69.0117,82.1784,83.9779,84.0778,86.6552,97.0256,40.6907,78.6851,51.7134,29.3499,72.4577,40.5063,25.7040,61.0636,42.0938,22.8112,64.8940,35.1515,47.1270,72.1314,65.3349,87.2939,88.3874,98.7629,31.0003,69.7507,44.4444,83.7869,90.1620,92.9293,44.8659,74.6653,60.0894,0.0000,0.0000,0.0000,59.8295,81.4481,73.4572,44.4166,87.7500,50.6173,45.5528,89.9946,50.6173,4.5860,55.0318,8.3333,42.0519,72.3166,58.1498,37.7015,70.0472,53.8229
[10/13 14:52:38] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 14:52:38] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 14:52:38] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 14:52:38] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 14:52:38] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 14:52:38] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 14:52:41] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0037 s/iter. Inference: 0.1354 s/iter. Eval: 0.0672 s/iter. Total: 0.2063 s/iter. ETA=0:01:40
[10/13 14:52:46] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0046 s/iter. Inference: 0.1337 s/iter. Eval: 0.0703 s/iter. Total: 0.2087 s/iter. ETA=0:01:37
[10/13 14:52:51] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0047 s/iter. Inference: 0.1348 s/iter. Eval: 0.0706 s/iter. Total: 0.2102 s/iter. ETA=0:01:32
[10/13 14:52:56] d2.evaluation.evaluator INFO: Inference done 83/500. Dataloading: 0.0047 s/iter. Inference: 0.1350 s/iter. Eval: 0.0708 s/iter. Total: 0.2105 s/iter. ETA=0:01:27
[10/13 14:53:01] d2.evaluation.evaluator INFO: Inference done 107/500. Dataloading: 0.0047 s/iter. Inference: 0.1346 s/iter. Eval: 0.0711 s/iter. Total: 0.2105 s/iter. ETA=0:01:22
[10/13 14:53:06] d2.evaluation.evaluator INFO: Inference done 131/500. Dataloading: 0.0047 s/iter. Inference: 0.1345 s/iter. Eval: 0.0712 s/iter. Total: 0.2105 s/iter. ETA=0:01:17
[10/13 14:53:11] d2.evaluation.evaluator INFO: Inference done 155/500. Dataloading: 0.0047 s/iter. Inference: 0.1341 s/iter. Eval: 0.0714 s/iter. Total: 0.2102 s/iter. ETA=0:01:12
[10/13 14:53:16] d2.evaluation.evaluator INFO: Inference done 179/500. Dataloading: 0.0047 s/iter. Inference: 0.1341 s/iter. Eval: 0.0714 s/iter. Total: 0.2102 s/iter. ETA=0:01:07
[10/13 14:53:21] d2.evaluation.evaluator INFO: Inference done 203/500. Dataloading: 0.0047 s/iter. Inference: 0.1342 s/iter. Eval: 0.0714 s/iter. Total: 0.2103 s/iter. ETA=0:01:02
[10/13 14:53:26] d2.evaluation.evaluator INFO: Inference done 227/500. Dataloading: 0.0047 s/iter. Inference: 0.1341 s/iter. Eval: 0.0714 s/iter. Total: 0.2103 s/iter. ETA=0:00:57
[10/13 14:53:31] d2.evaluation.evaluator INFO: Inference done 251/500. Dataloading: 0.0047 s/iter. Inference: 0.1340 s/iter. Eval: 0.0715 s/iter. Total: 0.2102 s/iter. ETA=0:00:52
[10/13 14:53:36] d2.evaluation.evaluator INFO: Inference done 275/500. Dataloading: 0.0047 s/iter. Inference: 0.1340 s/iter. Eval: 0.0713 s/iter. Total: 0.2101 s/iter. ETA=0:00:47
[10/13 14:53:42] d2.evaluation.evaluator INFO: Inference done 300/500. Dataloading: 0.0047 s/iter. Inference: 0.1336 s/iter. Eval: 0.0709 s/iter. Total: 0.2093 s/iter. ETA=0:00:41
[10/13 14:53:47] d2.evaluation.evaluator INFO: Inference done 325/500. Dataloading: 0.0047 s/iter. Inference: 0.1332 s/iter. Eval: 0.0711 s/iter. Total: 0.2091 s/iter. ETA=0:00:36
[10/13 14:53:52] d2.evaluation.evaluator INFO: Inference done 349/500. Dataloading: 0.0047 s/iter. Inference: 0.1334 s/iter. Eval: 0.0711 s/iter. Total: 0.2093 s/iter. ETA=0:00:31
[10/13 14:53:57] d2.evaluation.evaluator INFO: Inference done 373/500. Dataloading: 0.0047 s/iter. Inference: 0.1335 s/iter. Eval: 0.0712 s/iter. Total: 0.2094 s/iter. ETA=0:00:26
[10/13 14:54:02] d2.evaluation.evaluator INFO: Inference done 397/500. Dataloading: 0.0047 s/iter. Inference: 0.1335 s/iter. Eval: 0.0712 s/iter. Total: 0.2095 s/iter. ETA=0:00:21
[10/13 14:54:07] d2.evaluation.evaluator INFO: Inference done 421/500. Dataloading: 0.0047 s/iter. Inference: 0.1336 s/iter. Eval: 0.0712 s/iter. Total: 0.2096 s/iter. ETA=0:00:16
[10/13 14:54:12] d2.evaluation.evaluator INFO: Inference done 445/500. Dataloading: 0.0047 s/iter. Inference: 0.1336 s/iter. Eval: 0.0713 s/iter. Total: 0.2096 s/iter. ETA=0:00:11
[10/13 14:54:17] d2.evaluation.evaluator INFO: Inference done 469/500. Dataloading: 0.0047 s/iter. Inference: 0.1336 s/iter. Eval: 0.0713 s/iter. Total: 0.2097 s/iter. ETA=0:00:06
[10/13 14:54:22] d2.evaluation.evaluator INFO: Inference done 493/500. Dataloading: 0.0047 s/iter. Inference: 0.1337 s/iter. Eval: 0.0713 s/iter. Total: 0.2098 s/iter. ETA=0:00:01
[10/13 14:54:24] d2.evaluation.evaluator INFO: Total inference time: 0:01:43.879448 (0.209857 s / iter per device, on 1 devices)
[10/13 14:54:24] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.133661 s / iter per device, on 1 devices)
[10/13 14:54:24] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evald3jiaz6z ...
[10/13 14:54:47] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 49.416 | 74.313 | 61.206 |      19       |
| Things | 39.543 | 68.837 | 50.118 |       8       |
| Stuff  | 56.596 | 78.296 | 69.269 |      11       |
[10/13 14:54:47] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 95.417 | 95.914 | 99.482 |     Stuff     |
| class_8  | 68.992 | 82.030 | 84.106 |     Stuff     |
| class_11 | 83.903 | 87.020 | 96.418 |     Stuff     |
| class_12 | 38.106 | 77.089 | 49.432 |     Stuff     |
| class_13 | 30.063 | 71.889 | 41.818 |     Stuff     |
| class_17 | 25.863 | 60.665 | 42.633 |     Stuff     |
| class_19 | 29.505 | 64.884 | 45.474 |     Stuff     |
| class_20 | 49.523 | 72.662 | 68.155 |     Stuff     |
| class_21 | 87.382 | 88.565 | 98.664 |     Stuff     |
| class_22 | 30.192 | 70.714 | 42.697 |     Stuff     |
| class_23 | 83.613 | 89.829 | 93.080 |     Stuff     |
| class_24 | 44.040 | 74.221 | 59.336 |    Things     |
| class_25 | 0.000  | 0.000  | 0.000  |    Things     |
| class_26 | 58.847 | 80.542 | 73.064 |    Things     |
| class_27 | 46.591 | 86.775 | 53.691 |    Things     |
| class_28 | 52.271 | 89.202 | 58.599 |    Things     |
| class_31 | 42.287 | 80.731 | 52.381 |    Things     |
| class_32 | 35.483 | 69.622 | 50.965 |    Things     |
| class_33 | 36.826 | 69.599 | 52.912 |    Things     |
[10/13 14:54:47] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 14:54:47] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 14:54:47] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 14:54:47] d2.evaluation.testing INFO: copypaste: 49.4161,74.3133,61.2056,39.5432,68.8366,50.1185,56.5963,78.2964,69.2689,95.4171,95.9141,99.4819,68.9918,82.0296,84.1060,83.9025,87.0199,96.4176,38.1063,77.0886,49.4318,30.0629,71.8894,41.8182,25.8634,60.6648,42.6332,29.5054,64.8845,45.4737,49.5225,72.6615,68.1551,87.3820,88.5653,98.6639,30.1924,70.7139,42.6966,83.6135,89.8293,93.0804,44.0397,74.2212,59.3357,0.0000,0.0000,0.0000,58.8472,80.5424,73.0636,46.5906,86.7750,53.6913,52.2714,89.2023,58.5987,42.2875,80.7307,52.3810,35.4831,69.6222,50.9653,36.8263,69.5989,52.9121
[10/13 14:54:58] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 14:54:58] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 14:54:58] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 14:54:58] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 14:54:58] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 14:54:58] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 14:55:01] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0043 s/iter. Inference: 0.1354 s/iter. Eval: 0.0633 s/iter. Total: 0.2029 s/iter. ETA=0:01:39
[10/13 14:55:06] d2.evaluation.evaluator INFO: Inference done 36/500. Dataloading: 0.0049 s/iter. Inference: 0.1336 s/iter. Eval: 0.0669 s/iter. Total: 0.2054 s/iter. ETA=0:01:35
[10/13 14:55:11] d2.evaluation.evaluator INFO: Inference done 60/500. Dataloading: 0.0049 s/iter. Inference: 0.1350 s/iter. Eval: 0.0686 s/iter. Total: 0.2086 s/iter. ETA=0:01:31
[10/13 14:55:16] d2.evaluation.evaluator INFO: Inference done 84/500. Dataloading: 0.0049 s/iter. Inference: 0.1353 s/iter. Eval: 0.0693 s/iter. Total: 0.2096 s/iter. ETA=0:01:27
[10/13 14:55:21] d2.evaluation.evaluator INFO: Inference done 108/500. Dataloading: 0.0048 s/iter. Inference: 0.1354 s/iter. Eval: 0.0698 s/iter. Total: 0.2100 s/iter. ETA=0:01:22
[10/13 14:55:26] d2.evaluation.evaluator INFO: Inference done 132/500. Dataloading: 0.0050 s/iter. Inference: 0.1354 s/iter. Eval: 0.0695 s/iter. Total: 0.2099 s/iter. ETA=0:01:17
[10/13 14:55:31] d2.evaluation.evaluator INFO: Inference done 156/500. Dataloading: 0.0049 s/iter. Inference: 0.1354 s/iter. Eval: 0.0697 s/iter. Total: 0.2101 s/iter. ETA=0:01:12
[10/13 14:55:36] d2.evaluation.evaluator INFO: Inference done 180/500. Dataloading: 0.0049 s/iter. Inference: 0.1354 s/iter. Eval: 0.0699 s/iter. Total: 0.2102 s/iter. ETA=0:01:07
[10/13 14:55:41] d2.evaluation.evaluator INFO: Inference done 204/500. Dataloading: 0.0049 s/iter. Inference: 0.1355 s/iter. Eval: 0.0700 s/iter. Total: 0.2104 s/iter. ETA=0:01:02
[10/13 14:55:46] d2.evaluation.evaluator INFO: Inference done 229/500. Dataloading: 0.0049 s/iter. Inference: 0.1356 s/iter. Eval: 0.0695 s/iter. Total: 0.2101 s/iter. ETA=0:00:56
[10/13 14:55:52] d2.evaluation.evaluator INFO: Inference done 254/500. Dataloading: 0.0049 s/iter. Inference: 0.1352 s/iter. Eval: 0.0696 s/iter. Total: 0.2098 s/iter. ETA=0:00:51
[10/13 14:55:57] d2.evaluation.evaluator INFO: Inference done 278/500. Dataloading: 0.0049 s/iter. Inference: 0.1350 s/iter. Eval: 0.0698 s/iter. Total: 0.2098 s/iter. ETA=0:00:46
[10/13 14:56:02] d2.evaluation.evaluator INFO: Inference done 302/500. Dataloading: 0.0049 s/iter. Inference: 0.1347 s/iter. Eval: 0.0701 s/iter. Total: 0.2098 s/iter. ETA=0:00:41
[10/13 14:56:07] d2.evaluation.evaluator INFO: Inference done 327/500. Dataloading: 0.0049 s/iter. Inference: 0.1344 s/iter. Eval: 0.0701 s/iter. Total: 0.2095 s/iter. ETA=0:00:36
[10/13 14:56:12] d2.evaluation.evaluator INFO: Inference done 351/500. Dataloading: 0.0049 s/iter. Inference: 0.1346 s/iter. Eval: 0.0700 s/iter. Total: 0.2096 s/iter. ETA=0:00:31
[10/13 14:56:17] d2.evaluation.evaluator INFO: Inference done 375/500. Dataloading: 0.0049 s/iter. Inference: 0.1348 s/iter. Eval: 0.0700 s/iter. Total: 0.2097 s/iter. ETA=0:00:26
[10/13 14:56:22] d2.evaluation.evaluator INFO: Inference done 399/500. Dataloading: 0.0049 s/iter. Inference: 0.1352 s/iter. Eval: 0.0699 s/iter. Total: 0.2101 s/iter. ETA=0:00:21
[10/13 14:56:27] d2.evaluation.evaluator INFO: Inference done 423/500. Dataloading: 0.0049 s/iter. Inference: 0.1354 s/iter. Eval: 0.0699 s/iter. Total: 0.2102 s/iter. ETA=0:00:16
[10/13 14:56:32] d2.evaluation.evaluator INFO: Inference done 447/500. Dataloading: 0.0049 s/iter. Inference: 0.1353 s/iter. Eval: 0.0700 s/iter. Total: 0.2102 s/iter. ETA=0:00:11
[10/13 14:56:37] d2.evaluation.evaluator INFO: Inference done 471/500. Dataloading: 0.0048 s/iter. Inference: 0.1353 s/iter. Eval: 0.0700 s/iter. Total: 0.2102 s/iter. ETA=0:00:06
[10/13 14:56:42] d2.evaluation.evaluator INFO: Inference done 495/500. Dataloading: 0.0048 s/iter. Inference: 0.1352 s/iter. Eval: 0.0702 s/iter. Total: 0.2102 s/iter. ETA=0:00:01
[10/13 14:56:43] d2.evaluation.evaluator INFO: Total inference time: 0:01:44.105710 (0.210315 s / iter per device, on 1 devices)
[10/13 14:56:43] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.135110 s / iter per device, on 1 devices)
[10/13 14:56:43] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalxgjbz0xx ...
[10/13 14:57:06] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 49.041 | 77.984 | 60.732 |      19       |
| Things | 37.832 | 77.376 | 48.065 |       8       |
| Stuff  | 57.193 | 78.427 | 69.944 |      11       |
[10/13 14:57:06] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.612 | 97.014 | 99.586 |     Stuff     |
| class_8  | 68.994 | 81.805 | 84.340 |     Stuff     |
| class_11 | 85.023 | 87.815 | 96.821 |     Stuff     |
| class_12 | 38.370 | 77.180 | 49.714 |     Stuff     |
| class_13 | 29.431 | 72.054 | 40.845 |     Stuff     |
| class_17 | 26.647 | 60.660 | 43.928 |     Stuff     |
| class_19 | 32.940 | 64.881 | 50.769 |     Stuff     |
| class_20 | 49.957 | 71.413 | 69.954 |     Stuff     |
| class_21 | 87.419 | 88.603 | 98.664 |     Stuff     |
| class_22 | 29.654 | 70.676 | 41.958 |     Stuff     |
| class_23 | 84.079 | 90.593 | 92.809 |     Stuff     |
| class_24 | 43.496 | 74.192 | 58.627 |    Things     |
| class_25 | 0.250  | 68.126 | 0.367  |    Things     |
| class_26 | 59.760 | 81.332 | 73.476 |    Things     |
| class_27 | 41.665 | 85.934 | 48.485 |    Things     |
| class_28 | 46.981 | 89.488 | 52.500 |    Things     |
| class_31 | 37.396 | 79.108 | 47.273 |    Things     |
| class_32 | 37.774 | 71.168 | 53.077 |    Things     |
| class_33 | 35.331 | 69.661 | 50.719 |    Things     |
[10/13 14:57:06] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 14:57:06] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 14:57:06] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 14:57:06] d2.evaluation.testing INFO: copypaste: 49.0410,77.9844,60.7322,37.8317,77.3761,48.0654,57.1932,78.4268,69.9444,96.6121,97.0138,99.5859,68.9941,81.8046,84.3400,85.0234,87.8155,96.8205,38.3697,77.1804,49.7143,29.4307,72.0544,40.8451,26.6469,60.6602,43.9282,32.9396,64.8810,50.7692,49.9566,71.4133,69.9541,87.4189,88.6027,98.6639,29.6541,70.6756,41.9580,84.0788,90.5934,92.8090,43.4962,74.1920,58.6266,0.2500,68.1258,0.3670,59.7596,81.3319,73.4762,41.6652,85.9344,48.4848,46.9811,89.4878,52.5000,37.3964,79.1077,47.2727,37.7736,71.1677,53.0769,35.3312,69.6612,50.7186
[10/13 14:57:17] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 14:57:17] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 14:57:17] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 14:57:17] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 14:57:17] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 14:57:17] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 14:57:20] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0037 s/iter. Inference: 0.1304 s/iter. Eval: 0.0763 s/iter. Total: 0.2104 s/iter. ETA=0:01:42
[10/13 14:57:25] d2.evaluation.evaluator INFO: Inference done 34/500. Dataloading: 0.0049 s/iter. Inference: 0.1389 s/iter. Eval: 0.0749 s/iter. Total: 0.2188 s/iter. ETA=0:01:41
[10/13 14:57:30] d2.evaluation.evaluator INFO: Inference done 58/500. Dataloading: 0.0051 s/iter. Inference: 0.1373 s/iter. Eval: 0.0748 s/iter. Total: 0.2173 s/iter. ETA=0:01:36
[10/13 14:57:35] d2.evaluation.evaluator INFO: Inference done 81/500. Dataloading: 0.0052 s/iter. Inference: 0.1386 s/iter. Eval: 0.0742 s/iter. Total: 0.2181 s/iter. ETA=0:01:31
[10/13 14:57:41] d2.evaluation.evaluator INFO: Inference done 104/500. Dataloading: 0.0052 s/iter. Inference: 0.1404 s/iter. Eval: 0.0740 s/iter. Total: 0.2198 s/iter. ETA=0:01:27
[10/13 14:57:46] d2.evaluation.evaluator INFO: Inference done 127/500. Dataloading: 0.0052 s/iter. Inference: 0.1397 s/iter. Eval: 0.0744 s/iter. Total: 0.2194 s/iter. ETA=0:01:21
[10/13 14:57:51] d2.evaluation.evaluator INFO: Inference done 150/500. Dataloading: 0.0052 s/iter. Inference: 0.1396 s/iter. Eval: 0.0743 s/iter. Total: 0.2191 s/iter. ETA=0:01:16
[10/13 14:57:56] d2.evaluation.evaluator INFO: Inference done 174/500. Dataloading: 0.0052 s/iter. Inference: 0.1389 s/iter. Eval: 0.0741 s/iter. Total: 0.2183 s/iter. ETA=0:01:11
[10/13 14:58:01] d2.evaluation.evaluator INFO: Inference done 198/500. Dataloading: 0.0051 s/iter. Inference: 0.1384 s/iter. Eval: 0.0739 s/iter. Total: 0.2175 s/iter. ETA=0:01:05
[10/13 14:58:06] d2.evaluation.evaluator INFO: Inference done 222/500. Dataloading: 0.0051 s/iter. Inference: 0.1382 s/iter. Eval: 0.0738 s/iter. Total: 0.2172 s/iter. ETA=0:01:00
[10/13 14:58:11] d2.evaluation.evaluator INFO: Inference done 246/500. Dataloading: 0.0051 s/iter. Inference: 0.1380 s/iter. Eval: 0.0736 s/iter. Total: 0.2167 s/iter. ETA=0:00:55
[10/13 14:58:16] d2.evaluation.evaluator INFO: Inference done 270/500. Dataloading: 0.0050 s/iter. Inference: 0.1375 s/iter. Eval: 0.0735 s/iter. Total: 0.2161 s/iter. ETA=0:00:49
[10/13 14:58:21] d2.evaluation.evaluator INFO: Inference done 295/500. Dataloading: 0.0050 s/iter. Inference: 0.1369 s/iter. Eval: 0.0735 s/iter. Total: 0.2154 s/iter. ETA=0:00:44
[10/13 14:58:26] d2.evaluation.evaluator INFO: Inference done 319/500. Dataloading: 0.0050 s/iter. Inference: 0.1364 s/iter. Eval: 0.0734 s/iter. Total: 0.2149 s/iter. ETA=0:00:38
[10/13 14:58:31] d2.evaluation.evaluator INFO: Inference done 343/500. Dataloading: 0.0050 s/iter. Inference: 0.1363 s/iter. Eval: 0.0733 s/iter. Total: 0.2146 s/iter. ETA=0:00:33
[10/13 14:58:36] d2.evaluation.evaluator INFO: Inference done 367/500. Dataloading: 0.0049 s/iter. Inference: 0.1361 s/iter. Eval: 0.0732 s/iter. Total: 0.2144 s/iter. ETA=0:00:28
[10/13 14:58:42] d2.evaluation.evaluator INFO: Inference done 391/500. Dataloading: 0.0049 s/iter. Inference: 0.1361 s/iter. Eval: 0.0732 s/iter. Total: 0.2142 s/iter. ETA=0:00:23
[10/13 14:58:47] d2.evaluation.evaluator INFO: Inference done 415/500. Dataloading: 0.0049 s/iter. Inference: 0.1360 s/iter. Eval: 0.0731 s/iter. Total: 0.2141 s/iter. ETA=0:00:18
[10/13 14:58:52] d2.evaluation.evaluator INFO: Inference done 439/500. Dataloading: 0.0049 s/iter. Inference: 0.1358 s/iter. Eval: 0.0731 s/iter. Total: 0.2138 s/iter. ETA=0:00:13
[10/13 14:58:57] d2.evaluation.evaluator INFO: Inference done 463/500. Dataloading: 0.0049 s/iter. Inference: 0.1356 s/iter. Eval: 0.0730 s/iter. Total: 0.2136 s/iter. ETA=0:00:07
[10/13 14:59:02] d2.evaluation.evaluator INFO: Inference done 487/500. Dataloading: 0.0048 s/iter. Inference: 0.1357 s/iter. Eval: 0.0729 s/iter. Total: 0.2135 s/iter. ETA=0:00:02
[10/13 14:59:04] d2.evaluation.evaluator INFO: Total inference time: 0:01:45.672259 (0.213479 s / iter per device, on 1 devices)
[10/13 14:59:04] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:07 (0.135548 s / iter per device, on 1 devices)
[10/13 14:59:04] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_eval78lbzcr5 ...
[10/13 14:59:28] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 47.896 | 74.795 | 59.235 |      19       |
| Things | 35.422 | 69.714 | 44.993 |       8       |
| Stuff  | 56.968 | 78.491 | 69.593 |      11       |
[10/13 14:59:28] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 95.949 | 96.248 | 99.690 |     Stuff     |
| class_8  | 68.892 | 81.607 | 84.420 |     Stuff     |
| class_11 | 85.408 | 87.552 | 97.551 |     Stuff     |
| class_12 | 36.370 | 77.231 | 47.093 |     Stuff     |
| class_13 | 30.329 | 72.700 | 41.718 |     Stuff     |
| class_17 | 24.060 | 60.530 | 39.749 |     Stuff     |
| class_19 | 34.075 | 64.616 | 52.734 |     Stuff     |
| class_20 | 49.933 | 72.190 | 69.170 |     Stuff     |
| class_21 | 87.589 | 88.772 | 98.667 |     Stuff     |
| class_22 | 30.059 | 71.140 | 42.254 |     Stuff     |
| class_23 | 83.986 | 90.815 | 92.480 |     Stuff     |
| class_24 | 44.811 | 74.670 | 60.012 |    Things     |
| class_25 | 0.000  | 0.000  | 0.000  |    Things     |
| class_26 | 60.444 | 81.376 | 74.278 |    Things     |
| class_27 | 25.496 | 89.235 | 28.571 |    Things     |
| class_28 | 39.810 | 89.916 | 44.275 |    Things     |
| class_31 | 38.776 | 82.839 | 46.809 |    Things     |
| class_32 | 38.327 | 70.365 | 54.468 |    Things     |
| class_33 | 35.716 | 69.309 | 51.531 |    Things     |
[10/13 14:59:28] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 14:59:28] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 14:59:28] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 14:59:28] d2.evaluation.testing INFO: copypaste: 47.8964,74.7954,59.2352,35.4224,69.7138,44.9930,56.9683,78.4911,69.5932,95.9495,96.2481,99.6898,68.8922,81.6066,84.4199,85.4077,87.5518,97.5510,36.3704,77.2309,47.0930,30.3290,72.7004,41.7178,24.0602,60.5305,39.7490,34.0747,64.6158,52.7344,49.9335,72.1900,69.1695,87.5889,88.7725,98.6667,30.0590,71.1397,42.2535,83.9863,90.8153,92.4804,44.8114,74.6702,60.0124,0.0000,0.0000,0.0000,60.4440,81.3759,74.2776,25.4956,89.2346,28.5714,39.8103,89.9164,44.2748,38.7759,82.8394,46.8085,38.3265,70.3651,54.4681,35.7158,69.3091,51.5312
[10/13 14:59:38] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 14:59:38] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 14:59:38] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 14:59:38] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 14:59:38] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 14:59:38] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 14:59:41] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0038 s/iter. Inference: 0.1310 s/iter. Eval: 0.0731 s/iter. Total: 0.2079 s/iter. ETA=0:01:41
[10/13 14:59:46] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0048 s/iter. Inference: 0.1361 s/iter. Eval: 0.0727 s/iter. Total: 0.2136 s/iter. ETA=0:01:39
[10/13 14:59:51] d2.evaluation.evaluator INFO: Inference done 58/500. Dataloading: 0.0049 s/iter. Inference: 0.1403 s/iter. Eval: 0.0716 s/iter. Total: 0.2168 s/iter. ETA=0:01:35
[10/13 14:59:56] d2.evaluation.evaluator INFO: Inference done 81/500. Dataloading: 0.0049 s/iter. Inference: 0.1411 s/iter. Eval: 0.0722 s/iter. Total: 0.2182 s/iter. ETA=0:01:31
[10/13 15:00:01] d2.evaluation.evaluator INFO: Inference done 104/500. Dataloading: 0.0049 s/iter. Inference: 0.1407 s/iter. Eval: 0.0725 s/iter. Total: 0.2181 s/iter. ETA=0:01:26
[10/13 15:00:07] d2.evaluation.evaluator INFO: Inference done 127/500. Dataloading: 0.0049 s/iter. Inference: 0.1410 s/iter. Eval: 0.0727 s/iter. Total: 0.2187 s/iter. ETA=0:01:21
[10/13 15:00:12] d2.evaluation.evaluator INFO: Inference done 150/500. Dataloading: 0.0049 s/iter. Inference: 0.1414 s/iter. Eval: 0.0729 s/iter. Total: 0.2193 s/iter. ETA=0:01:16
[10/13 15:00:17] d2.evaluation.evaluator INFO: Inference done 173/500. Dataloading: 0.0050 s/iter. Inference: 0.1410 s/iter. Eval: 0.0732 s/iter. Total: 0.2193 s/iter. ETA=0:01:11
[10/13 15:00:22] d2.evaluation.evaluator INFO: Inference done 196/500. Dataloading: 0.0050 s/iter. Inference: 0.1411 s/iter. Eval: 0.0735 s/iter. Total: 0.2197 s/iter. ETA=0:01:06
[10/13 15:00:27] d2.evaluation.evaluator INFO: Inference done 220/500. Dataloading: 0.0050 s/iter. Inference: 0.1408 s/iter. Eval: 0.0734 s/iter. Total: 0.2192 s/iter. ETA=0:01:01
[10/13 15:00:32] d2.evaluation.evaluator INFO: Inference done 244/500. Dataloading: 0.0050 s/iter. Inference: 0.1399 s/iter. Eval: 0.0737 s/iter. Total: 0.2186 s/iter. ETA=0:00:55
[10/13 15:00:37] d2.evaluation.evaluator INFO: Inference done 267/500. Dataloading: 0.0050 s/iter. Inference: 0.1400 s/iter. Eval: 0.0737 s/iter. Total: 0.2187 s/iter. ETA=0:00:50
[10/13 15:00:42] d2.evaluation.evaluator INFO: Inference done 290/500. Dataloading: 0.0050 s/iter. Inference: 0.1399 s/iter. Eval: 0.0738 s/iter. Total: 0.2187 s/iter. ETA=0:00:45
[10/13 15:00:47] d2.evaluation.evaluator INFO: Inference done 312/500. Dataloading: 0.0050 s/iter. Inference: 0.1404 s/iter. Eval: 0.0740 s/iter. Total: 0.2194 s/iter. ETA=0:00:41
[10/13 15:00:52] d2.evaluation.evaluator INFO: Inference done 334/500. Dataloading: 0.0050 s/iter. Inference: 0.1406 s/iter. Eval: 0.0744 s/iter. Total: 0.2201 s/iter. ETA=0:00:36
[10/13 15:00:57] d2.evaluation.evaluator INFO: Inference done 356/500. Dataloading: 0.0050 s/iter. Inference: 0.1416 s/iter. Eval: 0.0743 s/iter. Total: 0.2210 s/iter. ETA=0:00:31
[10/13 15:01:03] d2.evaluation.evaluator INFO: Inference done 379/500. Dataloading: 0.0050 s/iter. Inference: 0.1420 s/iter. Eval: 0.0743 s/iter. Total: 0.2214 s/iter. ETA=0:00:26
[10/13 15:01:08] d2.evaluation.evaluator INFO: Inference done 402/500. Dataloading: 0.0050 s/iter. Inference: 0.1422 s/iter. Eval: 0.0743 s/iter. Total: 0.2216 s/iter. ETA=0:00:21
[10/13 15:01:13] d2.evaluation.evaluator INFO: Inference done 425/500. Dataloading: 0.0050 s/iter. Inference: 0.1421 s/iter. Eval: 0.0745 s/iter. Total: 0.2216 s/iter. ETA=0:00:16
[10/13 15:01:18] d2.evaluation.evaluator INFO: Inference done 448/500. Dataloading: 0.0050 s/iter. Inference: 0.1421 s/iter. Eval: 0.0745 s/iter. Total: 0.2216 s/iter. ETA=0:00:11
[10/13 15:01:23] d2.evaluation.evaluator INFO: Inference done 471/500. Dataloading: 0.0050 s/iter. Inference: 0.1419 s/iter. Eval: 0.0745 s/iter. Total: 0.2215 s/iter. ETA=0:00:06
[10/13 15:01:28] d2.evaluation.evaluator INFO: Inference done 494/500. Dataloading: 0.0050 s/iter. Inference: 0.1419 s/iter. Eval: 0.0746 s/iter. Total: 0.2215 s/iter. ETA=0:00:01
[10/13 15:01:30] d2.evaluation.evaluator INFO: Total inference time: 0:01:49.807043 (0.221832 s / iter per device, on 1 devices)
[10/13 15:01:30] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:10 (0.141783 s / iter per device, on 1 devices)
[10/13 15:01:30] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evaltfp_98s4 ...
[10/13 15:01:53] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 49.910 | 78.384 | 61.551 |      19       |
| Things | 39.750 | 78.212 | 49.790 |       8       |
| Stuff  | 57.300 | 78.508 | 70.104 |      11       |
[10/13 15:01:53] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.340 | 96.842 | 99.482 |     Stuff     |
| class_8  | 69.659 | 81.600 | 85.366 |     Stuff     |
| class_11 | 84.518 | 86.649 | 97.541 |     Stuff     |
| class_12 | 36.644 | 78.122 | 46.906 |     Stuff     |
| class_13 | 29.146 | 71.773 | 40.609 |     Stuff     |
| class_17 | 26.216 | 60.528 | 43.312 |     Stuff     |
| class_19 | 34.963 | 65.288 | 53.552 |     Stuff     |
| class_20 | 51.281 | 72.552 | 70.682 |     Stuff     |
| class_21 | 87.548 | 88.640 | 98.768 |     Stuff     |
| class_22 | 29.659 | 71.183 | 41.667 |     Stuff     |
| class_23 | 84.320 | 90.416 | 93.258 |     Stuff     |
| class_24 | 42.899 | 74.426 | 57.640 |    Things     |
| class_25 | 0.255  | 69.610 | 0.367  |    Things     |
| class_26 | 60.820 | 81.260 | 74.846 |    Things     |
| class_27 | 48.433 | 88.173 | 54.930 |    Things     |
| class_28 | 60.331 | 88.380 | 68.263 |    Things     |
| class_31 | 33.082 | 82.706 | 40.000 |    Things     |
| class_32 | 36.529 | 71.536 | 51.064 |    Things     |
| class_33 | 35.647 | 69.606 | 51.212 |    Things     |
[10/13 15:01:53] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:01:53] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:01:53] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:01:53] d2.evaluation.testing INFO: copypaste: 49.9101,78.3837,61.5508,39.7497,78.2122,49.7903,57.2996,78.5085,70.1038,96.3403,96.8420,99.4819,69.6589,81.6004,85.3659,84.5180,86.6487,97.5410,36.6437,78.1223,46.9055,29.1463,71.7727,40.6091,26.2161,60.5284,43.3121,34.9631,65.2883,53.5519,51.2814,72.5525,70.6818,87.5479,88.6399,98.7680,29.6595,71.1827,41.6667,84.3201,90.4155,93.2584,42.8994,74.4258,57.6404,0.2554,69.6097,0.3670,60.8195,81.2598,74.8458,48.4332,88.1733,54.9296,60.3315,88.3803,68.2635,33.0823,82.7057,40.0000,36.5291,71.5362,51.0638,35.6470,69.6065,51.2121
[10/13 15:02:04] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 15:02:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 15:02:04] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 15:02:04] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 15:02:04] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 15:02:04] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 15:02:07] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0034 s/iter. Inference: 0.1329 s/iter. Eval: 0.0679 s/iter. Total: 0.2042 s/iter. ETA=0:01:39
[10/13 15:02:12] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0046 s/iter. Inference: 0.1325 s/iter. Eval: 0.0720 s/iter. Total: 0.2091 s/iter. ETA=0:01:37
[10/13 15:02:17] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0047 s/iter. Inference: 0.1338 s/iter. Eval: 0.0711 s/iter. Total: 0.2097 s/iter. ETA=0:01:32
[10/13 15:02:22] d2.evaluation.evaluator INFO: Inference done 83/500. Dataloading: 0.0047 s/iter. Inference: 0.1344 s/iter. Eval: 0.0715 s/iter. Total: 0.2106 s/iter. ETA=0:01:27
[10/13 15:02:27] d2.evaluation.evaluator INFO: Inference done 107/500. Dataloading: 0.0047 s/iter. Inference: 0.1349 s/iter. Eval: 0.0721 s/iter. Total: 0.2118 s/iter. ETA=0:01:23
[10/13 15:02:32] d2.evaluation.evaluator INFO: Inference done 131/500. Dataloading: 0.0048 s/iter. Inference: 0.1350 s/iter. Eval: 0.0722 s/iter. Total: 0.2120 s/iter. ETA=0:01:18
[10/13 15:02:37] d2.evaluation.evaluator INFO: Inference done 155/500. Dataloading: 0.0049 s/iter. Inference: 0.1350 s/iter. Eval: 0.0720 s/iter. Total: 0.2119 s/iter. ETA=0:01:13
[10/13 15:02:42] d2.evaluation.evaluator INFO: Inference done 179/500. Dataloading: 0.0049 s/iter. Inference: 0.1353 s/iter. Eval: 0.0719 s/iter. Total: 0.2121 s/iter. ETA=0:01:08
[10/13 15:02:48] d2.evaluation.evaluator INFO: Inference done 202/500. Dataloading: 0.0049 s/iter. Inference: 0.1364 s/iter. Eval: 0.0722 s/iter. Total: 0.2135 s/iter. ETA=0:01:03
[10/13 15:02:53] d2.evaluation.evaluator INFO: Inference done 226/500. Dataloading: 0.0049 s/iter. Inference: 0.1364 s/iter. Eval: 0.0724 s/iter. Total: 0.2136 s/iter. ETA=0:00:58
[10/13 15:02:58] d2.evaluation.evaluator INFO: Inference done 250/500. Dataloading: 0.0049 s/iter. Inference: 0.1362 s/iter. Eval: 0.0726 s/iter. Total: 0.2137 s/iter. ETA=0:00:53
[10/13 15:03:03] d2.evaluation.evaluator INFO: Inference done 274/500. Dataloading: 0.0049 s/iter. Inference: 0.1360 s/iter. Eval: 0.0728 s/iter. Total: 0.2137 s/iter. ETA=0:00:48
[10/13 15:03:08] d2.evaluation.evaluator INFO: Inference done 298/500. Dataloading: 0.0049 s/iter. Inference: 0.1354 s/iter. Eval: 0.0732 s/iter. Total: 0.2135 s/iter. ETA=0:00:43
[10/13 15:03:13] d2.evaluation.evaluator INFO: Inference done 322/500. Dataloading: 0.0049 s/iter. Inference: 0.1348 s/iter. Eval: 0.0735 s/iter. Total: 0.2133 s/iter. ETA=0:00:37
[10/13 15:03:18] d2.evaluation.evaluator INFO: Inference done 346/500. Dataloading: 0.0049 s/iter. Inference: 0.1346 s/iter. Eval: 0.0737 s/iter. Total: 0.2132 s/iter. ETA=0:00:32
[10/13 15:03:23] d2.evaluation.evaluator INFO: Inference done 370/500. Dataloading: 0.0049 s/iter. Inference: 0.1344 s/iter. Eval: 0.0738 s/iter. Total: 0.2132 s/iter. ETA=0:00:27
[10/13 15:03:28] d2.evaluation.evaluator INFO: Inference done 394/500. Dataloading: 0.0049 s/iter. Inference: 0.1344 s/iter. Eval: 0.0739 s/iter. Total: 0.2132 s/iter. ETA=0:00:22
[10/13 15:03:33] d2.evaluation.evaluator INFO: Inference done 418/500. Dataloading: 0.0049 s/iter. Inference: 0.1342 s/iter. Eval: 0.0741 s/iter. Total: 0.2132 s/iter. ETA=0:00:17
[10/13 15:03:39] d2.evaluation.evaluator INFO: Inference done 442/500. Dataloading: 0.0049 s/iter. Inference: 0.1341 s/iter. Eval: 0.0742 s/iter. Total: 0.2131 s/iter. ETA=0:00:12
[10/13 15:03:44] d2.evaluation.evaluator INFO: Inference done 466/500. Dataloading: 0.0049 s/iter. Inference: 0.1339 s/iter. Eval: 0.0743 s/iter. Total: 0.2131 s/iter. ETA=0:00:07
[10/13 15:03:49] d2.evaluation.evaluator INFO: Inference done 490/500. Dataloading: 0.0049 s/iter. Inference: 0.1338 s/iter. Eval: 0.0743 s/iter. Total: 0.2130 s/iter. ETA=0:00:02
[10/13 15:03:51] d2.evaluation.evaluator INFO: Total inference time: 0:01:45.509775 (0.213151 s / iter per device, on 1 devices)
[10/13 15:03:51] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.133729 s / iter per device, on 1 devices)
[10/13 15:03:51] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalt_js2cei ...
[10/13 15:04:15] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 51.207 | 78.846 | 63.036 |      19       |
| Things | 42.091 | 78.697 | 52.678 |       8       |
| Stuff  | 57.836 | 78.954 | 70.570 |      11       |
[10/13 15:04:15] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 95.879 | 96.278 | 99.586 |     Stuff     |
| class_8  | 69.259 | 81.974 | 84.488 |     Stuff     |
| class_11 | 84.679 | 87.175 | 97.137 |     Stuff     |
| class_12 | 37.358 | 79.260 | 47.134 |     Stuff     |
| class_13 | 29.097 | 73.309 | 39.691 |     Stuff     |
| class_17 | 27.770 | 61.108 | 45.445 |     Stuff     |
| class_19 | 38.131 | 66.604 | 57.250 |     Stuff     |
| class_20 | 51.782 | 72.944 | 70.990 |     Stuff     |
| class_21 | 87.617 | 88.712 | 98.765 |     Stuff     |
| class_22 | 29.346 | 70.642 | 41.542 |     Stuff     |
| class_23 | 85.275 | 90.489 | 94.237 |     Stuff     |
| class_24 | 46.412 | 74.913 | 61.955 |    Things     |
| class_25 | 8.164  | 71.748 | 11.379 |    Things     |
| class_26 | 60.803 | 81.339 | 74.753 |    Things     |
| class_27 | 47.032 | 86.226 | 54.545 |    Things     |
| class_28 | 57.559 | 90.367 | 63.694 |    Things     |
| class_31 | 46.104 | 82.602 | 55.814 |    Things     |
| class_32 | 35.545 | 72.596 | 48.963 |    Things     |
| class_33 | 35.113 | 69.782 | 50.318 |    Things     |
[10/13 15:04:15] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:04:15] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:04:15] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:04:15] d2.evaluation.testing INFO: copypaste: 51.2066,78.8456,63.0361,42.0915,78.6967,52.6776,57.8357,78.9539,70.5696,95.8789,96.2775,99.5859,69.2587,81.9741,84.4884,84.6791,87.1749,97.1370,37.3582,79.2599,47.1338,29.0970,73.3094,39.6907,27.7703,61.1075,45.4450,38.1309,66.6037,57.2505,51.7825,72.9436,70.9898,87.6166,88.7118,98.7654,29.3458,70.6416,41.5418,85.2747,90.4893,94.2373,46.4120,74.9126,61.9548,8.1644,71.7481,11.3793,60.8031,81.3391,74.7525,47.0321,86.2256,54.5455,57.5586,90.3670,63.6943,46.1036,82.6022,55.8140,35.5451,72.5964,48.9627,35.1130,69.7824,50.3179
[10/13 15:04:25] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 15:04:25] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 15:04:25] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 15:04:25] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 15:04:25] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 15:04:25] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 15:04:28] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0037 s/iter. Inference: 0.1315 s/iter. Eval: 0.0724 s/iter. Total: 0.2076 s/iter. ETA=0:01:41
[10/13 15:04:33] d2.evaluation.evaluator INFO: Inference done 36/500. Dataloading: 0.0051 s/iter. Inference: 0.1314 s/iter. Eval: 0.0667 s/iter. Total: 0.2032 s/iter. ETA=0:01:34
[10/13 15:04:38] d2.evaluation.evaluator INFO: Inference done 61/500. Dataloading: 0.0054 s/iter. Inference: 0.1328 s/iter. Eval: 0.0649 s/iter. Total: 0.2031 s/iter. ETA=0:01:29
[10/13 15:04:43] d2.evaluation.evaluator INFO: Inference done 86/500. Dataloading: 0.0055 s/iter. Inference: 0.1337 s/iter. Eval: 0.0652 s/iter. Total: 0.2045 s/iter. ETA=0:01:24
[10/13 15:04:49] d2.evaluation.evaluator INFO: Inference done 110/500. Dataloading: 0.0054 s/iter. Inference: 0.1347 s/iter. Eval: 0.0664 s/iter. Total: 0.2065 s/iter. ETA=0:01:20
[10/13 15:04:54] d2.evaluation.evaluator INFO: Inference done 134/500. Dataloading: 0.0053 s/iter. Inference: 0.1351 s/iter. Eval: 0.0668 s/iter. Total: 0.2073 s/iter. ETA=0:01:15
[10/13 15:04:59] d2.evaluation.evaluator INFO: Inference done 159/500. Dataloading: 0.0052 s/iter. Inference: 0.1349 s/iter. Eval: 0.0673 s/iter. Total: 0.2075 s/iter. ETA=0:01:10
[10/13 15:05:04] d2.evaluation.evaluator INFO: Inference done 183/500. Dataloading: 0.0051 s/iter. Inference: 0.1348 s/iter. Eval: 0.0679 s/iter. Total: 0.2079 s/iter. ETA=0:01:05
[10/13 15:05:09] d2.evaluation.evaluator INFO: Inference done 207/500. Dataloading: 0.0051 s/iter. Inference: 0.1355 s/iter. Eval: 0.0681 s/iter. Total: 0.2087 s/iter. ETA=0:01:01
[10/13 15:05:14] d2.evaluation.evaluator INFO: Inference done 231/500. Dataloading: 0.0050 s/iter. Inference: 0.1356 s/iter. Eval: 0.0684 s/iter. Total: 0.2090 s/iter. ETA=0:00:56
[10/13 15:05:19] d2.evaluation.evaluator INFO: Inference done 255/500. Dataloading: 0.0050 s/iter. Inference: 0.1354 s/iter. Eval: 0.0687 s/iter. Total: 0.2091 s/iter. ETA=0:00:51
[10/13 15:05:24] d2.evaluation.evaluator INFO: Inference done 279/500. Dataloading: 0.0050 s/iter. Inference: 0.1350 s/iter. Eval: 0.0691 s/iter. Total: 0.2091 s/iter. ETA=0:00:46
[10/13 15:05:29] d2.evaluation.evaluator INFO: Inference done 304/500. Dataloading: 0.0050 s/iter. Inference: 0.1345 s/iter. Eval: 0.0694 s/iter. Total: 0.2089 s/iter. ETA=0:00:40
[10/13 15:05:34] d2.evaluation.evaluator INFO: Inference done 329/500. Dataloading: 0.0049 s/iter. Inference: 0.1341 s/iter. Eval: 0.0697 s/iter. Total: 0.2087 s/iter. ETA=0:00:35
[10/13 15:05:40] d2.evaluation.evaluator INFO: Inference done 353/500. Dataloading: 0.0049 s/iter. Inference: 0.1340 s/iter. Eval: 0.0698 s/iter. Total: 0.2088 s/iter. ETA=0:00:30
[10/13 15:05:45] d2.evaluation.evaluator INFO: Inference done 377/500. Dataloading: 0.0049 s/iter. Inference: 0.1339 s/iter. Eval: 0.0700 s/iter. Total: 0.2089 s/iter. ETA=0:00:25
[10/13 15:05:50] d2.evaluation.evaluator INFO: Inference done 401/500. Dataloading: 0.0049 s/iter. Inference: 0.1339 s/iter. Eval: 0.0701 s/iter. Total: 0.2090 s/iter. ETA=0:00:20
[10/13 15:05:55] d2.evaluation.evaluator INFO: Inference done 425/500. Dataloading: 0.0049 s/iter. Inference: 0.1338 s/iter. Eval: 0.0703 s/iter. Total: 0.2090 s/iter. ETA=0:00:15
[10/13 15:06:00] d2.evaluation.evaluator INFO: Inference done 450/500. Dataloading: 0.0049 s/iter. Inference: 0.1336 s/iter. Eval: 0.0704 s/iter. Total: 0.2090 s/iter. ETA=0:00:10
[10/13 15:06:05] d2.evaluation.evaluator INFO: Inference done 474/500. Dataloading: 0.0049 s/iter. Inference: 0.1336 s/iter. Eval: 0.0705 s/iter. Total: 0.2090 s/iter. ETA=0:00:05
[10/13 15:06:10] d2.evaluation.evaluator INFO: Inference done 498/500. Dataloading: 0.0049 s/iter. Inference: 0.1335 s/iter. Eval: 0.0706 s/iter. Total: 0.2090 s/iter. ETA=0:00:00
[10/13 15:06:10] d2.evaluation.evaluator INFO: Total inference time: 0:01:43.520557 (0.209132 s / iter per device, on 1 devices)
[10/13 15:06:10] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.133507 s / iter per device, on 1 devices)
[10/13 15:06:10] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalkt0kpb9e ...
[10/13 15:06:34] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 50.613 | 79.036 | 62.379 |      19       |
| Things | 39.820 | 78.826 | 50.018 |       8       |
| Stuff  | 58.463 | 79.189 | 71.370 |      11       |
[10/13 15:06:34] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.699 | 97.000 | 99.690 |     Stuff     |
| class_8  | 69.462 | 81.747 | 84.972 |     Stuff     |
| class_11 | 85.005 | 87.516 | 97.131 |     Stuff     |
| class_12 | 34.750 | 79.614 | 43.648 |     Stuff     |
| class_13 | 32.025 | 73.231 | 43.732 |     Stuff     |
| class_17 | 29.955 | 60.926 | 49.167 |     Stuff     |
| class_19 | 37.804 | 66.589 | 56.772 |     Stuff     |
| class_20 | 54.021 | 72.796 | 74.208 |     Stuff     |
| class_21 | 86.915 | 88.186 | 98.560 |     Stuff     |
| class_22 | 31.995 | 73.009 | 43.823 |     Stuff     |
| class_23 | 84.458 | 90.462 | 93.363 |     Stuff     |
| class_24 | 45.522 | 75.010 | 60.688 |    Things     |
| class_25 | 11.212 | 70.848 | 15.825 |    Things     |
| class_26 | 59.539 | 80.921 | 73.577 |    Things     |
| class_27 | 47.532 | 88.527 | 53.691 |    Things     |
| class_28 | 47.835 | 91.792 | 52.113 |    Things     |
| class_31 | 36.011 | 82.525 | 43.636 |    Things     |
| class_32 | 35.886 | 72.066 | 49.796 |    Things     |
| class_33 | 35.022 | 68.920 | 50.815 |    Things     |
[10/13 15:06:34] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:06:34] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:06:34] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:06:34] d2.evaluation.testing INFO: copypaste: 50.6129,79.0360,62.3792,39.8197,78.8261,50.0175,58.4626,79.1886,71.3696,96.6986,96.9995,99.6898,69.4616,81.7467,84.9718,85.0049,87.5156,97.1311,34.7501,79.6140,43.6482,32.0251,73.2308,43.7318,29.9554,60.9263,49.1667,37.8037,66.5889,56.7718,54.0207,72.7962,74.2081,86.9154,88.1856,98.5597,31.9948,73.0094,43.8228,84.4580,90.4616,93.3633,45.5219,75.0101,60.6877,11.2117,70.8482,15.8249,59.5388,80.9208,73.5765,47.5315,88.5274,53.6913,47.8350,91.7915,52.1127,36.0110,82.5252,43.6364,35.8859,72.0659,49.7959,35.0217,68.9200,50.8150
[10/13 15:07:27] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 15:07:27] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 15:07:27] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 15:07:27] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 15:07:27] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 15:07:27] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 15:07:29] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0035 s/iter. Inference: 0.1330 s/iter. Eval: 0.0731 s/iter. Total: 0.2097 s/iter. ETA=0:01:42
[10/13 15:07:34] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0045 s/iter. Inference: 0.1331 s/iter. Eval: 0.0724 s/iter. Total: 0.2101 s/iter. ETA=0:01:37
[10/13 15:07:39] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0047 s/iter. Inference: 0.1347 s/iter. Eval: 0.0714 s/iter. Total: 0.2109 s/iter. ETA=0:01:32
[10/13 15:07:45] d2.evaluation.evaluator INFO: Inference done 83/500. Dataloading: 0.0047 s/iter. Inference: 0.1348 s/iter. Eval: 0.0715 s/iter. Total: 0.2110 s/iter. ETA=0:01:27
[10/13 15:07:50] d2.evaluation.evaluator INFO: Inference done 107/500. Dataloading: 0.0047 s/iter. Inference: 0.1346 s/iter. Eval: 0.0721 s/iter. Total: 0.2114 s/iter. ETA=0:01:23
[10/13 15:07:55] d2.evaluation.evaluator INFO: Inference done 131/500. Dataloading: 0.0047 s/iter. Inference: 0.1345 s/iter. Eval: 0.0721 s/iter. Total: 0.2113 s/iter. ETA=0:01:17
[10/13 15:08:00] d2.evaluation.evaluator INFO: Inference done 155/500. Dataloading: 0.0046 s/iter. Inference: 0.1345 s/iter. Eval: 0.0720 s/iter. Total: 0.2112 s/iter. ETA=0:01:12
[10/13 15:08:05] d2.evaluation.evaluator INFO: Inference done 179/500. Dataloading: 0.0046 s/iter. Inference: 0.1344 s/iter. Eval: 0.0719 s/iter. Total: 0.2110 s/iter. ETA=0:01:07
[10/13 15:08:10] d2.evaluation.evaluator INFO: Inference done 203/500. Dataloading: 0.0046 s/iter. Inference: 0.1348 s/iter. Eval: 0.0717 s/iter. Total: 0.2112 s/iter. ETA=0:01:02
[10/13 15:08:15] d2.evaluation.evaluator INFO: Inference done 227/500. Dataloading: 0.0046 s/iter. Inference: 0.1348 s/iter. Eval: 0.0717 s/iter. Total: 0.2112 s/iter. ETA=0:00:57
[10/13 15:08:20] d2.evaluation.evaluator INFO: Inference done 251/500. Dataloading: 0.0046 s/iter. Inference: 0.1349 s/iter. Eval: 0.0716 s/iter. Total: 0.2112 s/iter. ETA=0:00:52
[10/13 15:08:25] d2.evaluation.evaluator INFO: Inference done 275/500. Dataloading: 0.0047 s/iter. Inference: 0.1349 s/iter. Eval: 0.0716 s/iter. Total: 0.2112 s/iter. ETA=0:00:47
[10/13 15:08:30] d2.evaluation.evaluator INFO: Inference done 300/500. Dataloading: 0.0047 s/iter. Inference: 0.1344 s/iter. Eval: 0.0717 s/iter. Total: 0.2109 s/iter. ETA=0:00:42
[10/13 15:08:35] d2.evaluation.evaluator INFO: Inference done 325/500. Dataloading: 0.0047 s/iter. Inference: 0.1340 s/iter. Eval: 0.0718 s/iter. Total: 0.2105 s/iter. ETA=0:00:36
[10/13 15:08:40] d2.evaluation.evaluator INFO: Inference done 349/500. Dataloading: 0.0047 s/iter. Inference: 0.1343 s/iter. Eval: 0.0715 s/iter. Total: 0.2105 s/iter. ETA=0:00:31
[10/13 15:08:46] d2.evaluation.evaluator INFO: Inference done 373/500. Dataloading: 0.0047 s/iter. Inference: 0.1345 s/iter. Eval: 0.0715 s/iter. Total: 0.2107 s/iter. ETA=0:00:26
[10/13 15:08:51] d2.evaluation.evaluator INFO: Inference done 397/500. Dataloading: 0.0047 s/iter. Inference: 0.1347 s/iter. Eval: 0.0714 s/iter. Total: 0.2109 s/iter. ETA=0:00:21
[10/13 15:08:56] d2.evaluation.evaluator INFO: Inference done 421/500. Dataloading: 0.0047 s/iter. Inference: 0.1348 s/iter. Eval: 0.0714 s/iter. Total: 0.2110 s/iter. ETA=0:00:16
[10/13 15:09:01] d2.evaluation.evaluator INFO: Inference done 445/500. Dataloading: 0.0048 s/iter. Inference: 0.1347 s/iter. Eval: 0.0714 s/iter. Total: 0.2109 s/iter. ETA=0:00:11
[10/13 15:09:06] d2.evaluation.evaluator INFO: Inference done 470/500. Dataloading: 0.0048 s/iter. Inference: 0.1346 s/iter. Eval: 0.0713 s/iter. Total: 0.2108 s/iter. ETA=0:00:06
[10/13 15:09:11] d2.evaluation.evaluator INFO: Inference done 494/500. Dataloading: 0.0048 s/iter. Inference: 0.1347 s/iter. Eval: 0.0713 s/iter. Total: 0.2108 s/iter. ETA=0:00:01
[10/13 15:09:12] d2.evaluation.evaluator INFO: Total inference time: 0:01:44.387617 (0.210884 s / iter per device, on 1 devices)
[10/13 15:09:12] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.134608 s / iter per device, on 1 devices)
[10/13 15:09:12] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalk6fzx09p ...
[10/13 15:09:36] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 52.547 | 78.997 | 64.848 |      19       |
| Things | 43.179 | 78.520 | 54.653 |       8       |
| Stuff  | 59.360 | 79.343 | 72.263 |      11       |
[10/13 15:09:36] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.432 | 96.732 | 99.690 |     Stuff     |
| class_8  | 70.629 | 82.430 | 85.683 |     Stuff     |
| class_11 | 85.652 | 88.187 | 97.125 |     Stuff     |
| class_12 | 36.753 | 77.925 | 47.164 |     Stuff     |
| class_13 | 30.040 | 73.297 | 40.984 |     Stuff     |
| class_17 | 28.208 | 61.526 | 45.846 |     Stuff     |
| class_19 | 39.994 | 66.861 | 59.817 |     Stuff     |
| class_20 | 57.970 | 73.879 | 78.467 |     Stuff     |
| class_21 | 87.068 | 88.432 | 98.458 |     Stuff     |
| class_22 | 33.445 | 72.943 | 45.852 |     Stuff     |
| class_23 | 86.772 | 90.567 | 95.810 |     Stuff     |
| class_24 | 48.757 | 75.102 | 64.921 |    Things     |
| class_25 | 34.685 | 72.386 | 47.917 |    Things     |
| class_26 | 61.337 | 81.178 | 75.559 |    Things     |
| class_27 | 47.696 | 90.092 | 52.941 |    Things     |
| class_28 | 55.642 | 90.997 | 61.146 |    Things     |
| class_31 | 26.827 | 77.799 | 34.483 |    Things     |
| class_32 | 35.721 | 70.909 | 50.376 |    Things     |
| class_33 | 34.763 | 69.695 | 49.879 |    Things     |
[10/13 15:09:36] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:09:36] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:09:36] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:09:36] d2.evaluation.testing INFO: copypaste: 52.5469,78.9966,64.8483,43.1785,78.5197,54.6528,59.3602,79.3435,72.2632,96.4319,96.7320,99.6898,70.6286,82.4301,85.6831,85.6522,88.1873,97.1253,36.7525,77.9246,47.1642,30.0396,73.2967,40.9836,28.2077,61.5264,45.8465,39.9939,66.8610,59.8165,57.9704,73.8789,78.4667,87.0683,88.4316,98.4584,33.4453,72.9427,45.8515,86.7717,90.5667,95.8097,48.7570,75.1017,64.9213,34.6850,72.3861,47.9167,61.3370,81.1780,75.5586,47.6959,90.0923,52.9412,55.6417,90.9974,61.1465,26.8271,77.7986,34.4828,35.7212,70.9092,50.3759,34.7633,69.6947,49.8794
[10/13 15:10:29] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 15:10:29] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 15:10:29] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 15:10:29] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 15:10:29] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 15:10:29] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 15:10:31] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0035 s/iter. Inference: 0.1311 s/iter. Eval: 0.0726 s/iter. Total: 0.2071 s/iter. ETA=0:01:41
[10/13 15:10:36] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0048 s/iter. Inference: 0.1325 s/iter. Eval: 0.0709 s/iter. Total: 0.2082 s/iter. ETA=0:01:36
[10/13 15:10:41] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0048 s/iter. Inference: 0.1340 s/iter. Eval: 0.0708 s/iter. Total: 0.2096 s/iter. ETA=0:01:32
[10/13 15:10:46] d2.evaluation.evaluator INFO: Inference done 83/500. Dataloading: 0.0050 s/iter. Inference: 0.1354 s/iter. Eval: 0.0693 s/iter. Total: 0.2097 s/iter. ETA=0:01:27
[10/13 15:10:51] d2.evaluation.evaluator INFO: Inference done 107/500. Dataloading: 0.0050 s/iter. Inference: 0.1354 s/iter. Eval: 0.0693 s/iter. Total: 0.2098 s/iter. ETA=0:01:22
[10/13 15:10:57] d2.evaluation.evaluator INFO: Inference done 132/500. Dataloading: 0.0051 s/iter. Inference: 0.1352 s/iter. Eval: 0.0684 s/iter. Total: 0.2088 s/iter. ETA=0:01:16
[10/13 15:11:02] d2.evaluation.evaluator INFO: Inference done 156/500. Dataloading: 0.0051 s/iter. Inference: 0.1356 s/iter. Eval: 0.0688 s/iter. Total: 0.2096 s/iter. ETA=0:01:12
[10/13 15:11:07] d2.evaluation.evaluator INFO: Inference done 179/500. Dataloading: 0.0052 s/iter. Inference: 0.1373 s/iter. Eval: 0.0687 s/iter. Total: 0.2112 s/iter. ETA=0:01:07
[10/13 15:11:12] d2.evaluation.evaluator INFO: Inference done 202/500. Dataloading: 0.0052 s/iter. Inference: 0.1385 s/iter. Eval: 0.0686 s/iter. Total: 0.2123 s/iter. ETA=0:01:03
[10/13 15:11:17] d2.evaluation.evaluator INFO: Inference done 226/500. Dataloading: 0.0052 s/iter. Inference: 0.1382 s/iter. Eval: 0.0688 s/iter. Total: 0.2122 s/iter. ETA=0:00:58
[10/13 15:11:22] d2.evaluation.evaluator INFO: Inference done 251/500. Dataloading: 0.0052 s/iter. Inference: 0.1378 s/iter. Eval: 0.0688 s/iter. Total: 0.2118 s/iter. ETA=0:00:52
[10/13 15:11:27] d2.evaluation.evaluator INFO: Inference done 276/500. Dataloading: 0.0051 s/iter. Inference: 0.1374 s/iter. Eval: 0.0688 s/iter. Total: 0.2114 s/iter. ETA=0:00:47
[10/13 15:11:32] d2.evaluation.evaluator INFO: Inference done 300/500. Dataloading: 0.0051 s/iter. Inference: 0.1370 s/iter. Eval: 0.0691 s/iter. Total: 0.2113 s/iter. ETA=0:00:42
[10/13 15:11:38] d2.evaluation.evaluator INFO: Inference done 325/500. Dataloading: 0.0051 s/iter. Inference: 0.1363 s/iter. Eval: 0.0693 s/iter. Total: 0.2108 s/iter. ETA=0:00:36
[10/13 15:11:43] d2.evaluation.evaluator INFO: Inference done 349/500. Dataloading: 0.0051 s/iter. Inference: 0.1361 s/iter. Eval: 0.0695 s/iter. Total: 0.2108 s/iter. ETA=0:00:31
[10/13 15:11:48] d2.evaluation.evaluator INFO: Inference done 373/500. Dataloading: 0.0051 s/iter. Inference: 0.1359 s/iter. Eval: 0.0696 s/iter. Total: 0.2107 s/iter. ETA=0:00:26
[10/13 15:11:53] d2.evaluation.evaluator INFO: Inference done 397/500. Dataloading: 0.0051 s/iter. Inference: 0.1361 s/iter. Eval: 0.0696 s/iter. Total: 0.2108 s/iter. ETA=0:00:21
[10/13 15:11:58] d2.evaluation.evaluator INFO: Inference done 422/500. Dataloading: 0.0051 s/iter. Inference: 0.1360 s/iter. Eval: 0.0694 s/iter. Total: 0.2106 s/iter. ETA=0:00:16
[10/13 15:12:03] d2.evaluation.evaluator INFO: Inference done 446/500. Dataloading: 0.0051 s/iter. Inference: 0.1359 s/iter. Eval: 0.0696 s/iter. Total: 0.2105 s/iter. ETA=0:00:11
[10/13 15:12:08] d2.evaluation.evaluator INFO: Inference done 470/500. Dataloading: 0.0051 s/iter. Inference: 0.1358 s/iter. Eval: 0.0696 s/iter. Total: 0.2105 s/iter. ETA=0:00:06
[10/13 15:12:13] d2.evaluation.evaluator INFO: Inference done 494/500. Dataloading: 0.0051 s/iter. Inference: 0.1357 s/iter. Eval: 0.0696 s/iter. Total: 0.2105 s/iter. ETA=0:00:01
[10/13 15:12:14] d2.evaluation.evaluator INFO: Total inference time: 0:01:44.224437 (0.210554 s / iter per device, on 1 devices)
[10/13 15:12:14] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:07 (0.135634 s / iter per device, on 1 devices)
[10/13 15:12:14] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_eval5_hb8ios ...
[10/13 15:12:38] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 54.001 | 79.657 | 66.310 |      19       |
| Things | 46.880 | 79.790 | 58.545 |       8       |
| Stuff  | 59.181 | 79.560 | 71.956 |      11       |
[10/13 15:12:38] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 95.819 | 96.928 | 98.855 |     Stuff     |
| class_8  | 70.473 | 82.435 | 85.489 |     Stuff     |
| class_11 | 84.446 | 88.078 | 95.876 |     Stuff     |
| class_12 | 38.253 | 78.485 | 48.739 |     Stuff     |
| class_13 | 32.093 | 74.884 | 42.857 |     Stuff     |
| class_17 | 27.341 | 61.775 | 44.259 |     Stuff     |
| class_19 | 40.308 | 66.519 | 60.595 |     Stuff     |
| class_20 | 56.756 | 73.654 | 77.058 |     Stuff     |
| class_21 | 86.695 | 88.055 | 98.455 |     Stuff     |
| class_22 | 32.703 | 73.661 | 44.397 |     Stuff     |
| class_23 | 86.101 | 90.692 | 94.938 |     Stuff     |
| class_24 | 49.781 | 75.684 | 65.774 |    Things     |
| class_25 | 41.613 | 73.394 | 56.699 |    Things     |
| class_26 | 61.540 | 81.942 | 75.102 |    Things     |
| class_27 | 44.873 | 89.140 | 50.340 |    Things     |
| class_28 | 62.290 | 90.703 | 68.675 |    Things     |
| class_31 | 42.635 | 85.271 | 50.000 |    Things     |
| class_32 | 35.065 | 72.143 | 48.606 |    Things     |
| class_33 | 37.239 | 70.042 | 53.167 |    Things     |
[10/13 15:12:38] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:12:38] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:12:38] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:12:38] d2.evaluation.testing INFO: copypaste: 54.0013,79.6571,66.3096,46.8796,79.7899,58.5452,59.1807,79.5605,71.9564,95.8185,96.9280,98.8554,70.4730,82.4349,85.4893,84.4460,88.0781,95.8763,38.2531,78.4849,48.7395,32.0930,74.8838,42.8571,27.3408,61.7748,44.2589,40.3075,66.5191,60.5954,56.7564,73.6540,77.0582,86.6947,88.0550,98.4552,32.7030,73.6611,44.3966,86.1012,90.6919,94.9381,49.7807,75.6844,65.7740,41.6132,73.3937,56.6986,61.5401,81.9423,75.1017,44.8731,89.1398,50.3401,62.2900,90.7030,68.6747,42.6354,85.2708,50.0000,35.0654,72.1428,48.6056,37.2392,70.0421,53.1670
[10/13 15:13:31] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 15:13:31] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 15:13:31] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 15:13:31] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 15:13:31] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 15:13:31] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 15:13:34] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0039 s/iter. Inference: 0.1305 s/iter. Eval: 0.0741 s/iter. Total: 0.2085 s/iter. ETA=0:01:41
[10/13 15:13:39] d2.evaluation.evaluator INFO: Inference done 36/500. Dataloading: 0.0045 s/iter. Inference: 0.1303 s/iter. Eval: 0.0732 s/iter. Total: 0.2081 s/iter. ETA=0:01:36
[10/13 15:13:44] d2.evaluation.evaluator INFO: Inference done 61/500. Dataloading: 0.0047 s/iter. Inference: 0.1312 s/iter. Eval: 0.0716 s/iter. Total: 0.2075 s/iter. ETA=0:01:31
[10/13 15:13:49] d2.evaluation.evaluator INFO: Inference done 86/500. Dataloading: 0.0048 s/iter. Inference: 0.1321 s/iter. Eval: 0.0693 s/iter. Total: 0.2063 s/iter. ETA=0:01:25
[10/13 15:13:54] d2.evaluation.evaluator INFO: Inference done 110/500. Dataloading: 0.0049 s/iter. Inference: 0.1323 s/iter. Eval: 0.0700 s/iter. Total: 0.2073 s/iter. ETA=0:01:20
[10/13 15:13:59] d2.evaluation.evaluator INFO: Inference done 135/500. Dataloading: 0.0050 s/iter. Inference: 0.1326 s/iter. Eval: 0.0696 s/iter. Total: 0.2073 s/iter. ETA=0:01:15
[10/13 15:14:04] d2.evaluation.evaluator INFO: Inference done 159/500. Dataloading: 0.0050 s/iter. Inference: 0.1332 s/iter. Eval: 0.0696 s/iter. Total: 0.2078 s/iter. ETA=0:01:10
[10/13 15:14:09] d2.evaluation.evaluator INFO: Inference done 183/500. Dataloading: 0.0050 s/iter. Inference: 0.1333 s/iter. Eval: 0.0699 s/iter. Total: 0.2082 s/iter. ETA=0:01:06
[10/13 15:14:14] d2.evaluation.evaluator INFO: Inference done 207/500. Dataloading: 0.0050 s/iter. Inference: 0.1334 s/iter. Eval: 0.0699 s/iter. Total: 0.2084 s/iter. ETA=0:01:01
[10/13 15:14:19] d2.evaluation.evaluator INFO: Inference done 231/500. Dataloading: 0.0050 s/iter. Inference: 0.1334 s/iter. Eval: 0.0700 s/iter. Total: 0.2084 s/iter. ETA=0:00:56
[10/13 15:14:25] d2.evaluation.evaluator INFO: Inference done 256/500. Dataloading: 0.0050 s/iter. Inference: 0.1335 s/iter. Eval: 0.0696 s/iter. Total: 0.2082 s/iter. ETA=0:00:50
[10/13 15:14:30] d2.evaluation.evaluator INFO: Inference done 281/500. Dataloading: 0.0051 s/iter. Inference: 0.1335 s/iter. Eval: 0.0695 s/iter. Total: 0.2081 s/iter. ETA=0:00:45
[10/13 15:14:35] d2.evaluation.evaluator INFO: Inference done 306/500. Dataloading: 0.0051 s/iter. Inference: 0.1331 s/iter. Eval: 0.0694 s/iter. Total: 0.2076 s/iter. ETA=0:00:40
[10/13 15:14:40] d2.evaluation.evaluator INFO: Inference done 331/500. Dataloading: 0.0051 s/iter. Inference: 0.1330 s/iter. Eval: 0.0694 s/iter. Total: 0.2075 s/iter. ETA=0:00:35
[10/13 15:14:45] d2.evaluation.evaluator INFO: Inference done 355/500. Dataloading: 0.0051 s/iter. Inference: 0.1331 s/iter. Eval: 0.0694 s/iter. Total: 0.2077 s/iter. ETA=0:00:30
[10/13 15:14:50] d2.evaluation.evaluator INFO: Inference done 379/500. Dataloading: 0.0051 s/iter. Inference: 0.1333 s/iter. Eval: 0.0695 s/iter. Total: 0.2079 s/iter. ETA=0:00:25
[10/13 15:14:55] d2.evaluation.evaluator INFO: Inference done 403/500. Dataloading: 0.0051 s/iter. Inference: 0.1334 s/iter. Eval: 0.0696 s/iter. Total: 0.2081 s/iter. ETA=0:00:20
[10/13 15:15:00] d2.evaluation.evaluator INFO: Inference done 427/500. Dataloading: 0.0051 s/iter. Inference: 0.1333 s/iter. Eval: 0.0697 s/iter. Total: 0.2082 s/iter. ETA=0:00:15
[10/13 15:15:05] d2.evaluation.evaluator INFO: Inference done 451/500. Dataloading: 0.0051 s/iter. Inference: 0.1332 s/iter. Eval: 0.0699 s/iter. Total: 0.2082 s/iter. ETA=0:00:10
[10/13 15:15:10] d2.evaluation.evaluator INFO: Inference done 475/500. Dataloading: 0.0051 s/iter. Inference: 0.1332 s/iter. Eval: 0.0700 s/iter. Total: 0.2083 s/iter. ETA=0:00:05
[10/13 15:15:15] d2.evaluation.evaluator INFO: Inference done 499/500. Dataloading: 0.0051 s/iter. Inference: 0.1332 s/iter. Eval: 0.0700 s/iter. Total: 0.2083 s/iter. ETA=0:00:00
[10/13 15:15:15] d2.evaluation.evaluator INFO: Total inference time: 0:01:43.207309 (0.208500 s / iter per device, on 1 devices)
[10/13 15:15:15] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:05 (0.133181 s / iter per device, on 1 devices)
[10/13 15:15:15] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalkjd2akrl ...
[10/13 15:15:39] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 54.349 | 79.698 | 66.747 |      19       |
| Things | 46.459 | 79.367 | 58.330 |       8       |
| Stuff  | 60.087 | 79.939 | 72.867 |      11       |
[10/13 15:15:39] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.682 | 96.983 | 99.690 |     Stuff     |
| class_8  | 70.393 | 81.852 | 86.000 |     Stuff     |
| class_11 | 85.973 | 88.507 | 97.137 |     Stuff     |
| class_12 | 38.022 | 79.793 | 47.651 |     Stuff     |
| class_13 | 30.728 | 73.785 | 41.645 |     Stuff     |
| class_17 | 31.857 | 62.295 | 51.139 |     Stuff     |
| class_19 | 40.061 | 67.722 | 59.155 |     Stuff     |
| class_20 | 60.837 | 74.567 | 81.588 |     Stuff     |
| class_21 | 87.317 | 88.497 | 98.667 |     Stuff     |
| class_22 | 32.481 | 74.332 | 43.697 |     Stuff     |
| class_23 | 86.603 | 90.995 | 95.172 |     Stuff     |
| class_24 | 49.275 | 75.155 | 65.565 |    Things     |
| class_25 | 39.612 | 73.634 | 53.797 |    Things     |
| class_26 | 62.977 | 81.602 | 77.176 |    Things     |
| class_27 | 44.739 | 88.268 | 50.685 |    Things     |
| class_28 | 54.816 | 90.945 | 60.274 |    Things     |
| class_31 | 48.849 | 82.155 | 59.459 |    Things     |
| class_32 | 37.413 | 73.535 | 50.877 |    Things     |
| class_33 | 33.991 | 69.639 | 48.811 |    Things     |
[10/13 15:15:39] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:15:39] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:15:39] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:15:39] d2.evaluation.testing INFO: copypaste: 54.3487,79.6980,66.7465,46.4590,79.3666,58.3304,60.0867,79.9390,72.8674,96.6817,96.9825,99.6898,70.3925,81.8518,86.0000,85.9730,88.5070,97.1370,38.0224,79.7934,47.6510,30.7281,73.7854,41.6452,31.8570,62.2953,51.1387,40.0610,67.7221,59.1549,60.8372,74.5667,81.5877,87.3167,88.4966,98.6667,32.4814,74.3325,43.6975,86.6025,90.9954,95.1724,49.2753,75.1550,65.5648,39.6124,73.6336,53.7967,62.9771,81.6023,77.1756,44.7386,88.2680,50.6849,54.8162,90.9450,60.2740,48.8488,82.1548,59.4595,37.4127,73.5354,50.8772,33.9912,69.6388,48.8107
[10/13 15:16:33] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 15:16:33] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 15:16:33] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 15:16:33] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 15:16:33] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 15:16:33] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 15:16:35] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0038 s/iter. Inference: 0.1302 s/iter. Eval: 0.0730 s/iter. Total: 0.2070 s/iter. ETA=0:01:41
[10/13 15:16:40] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0046 s/iter. Inference: 0.1304 s/iter. Eval: 0.0734 s/iter. Total: 0.2085 s/iter. ETA=0:01:36
[10/13 15:16:45] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0047 s/iter. Inference: 0.1310 s/iter. Eval: 0.0729 s/iter. Total: 0.2086 s/iter. ETA=0:01:31
[10/13 15:16:51] d2.evaluation.evaluator INFO: Inference done 84/500. Dataloading: 0.0050 s/iter. Inference: 0.1317 s/iter. Eval: 0.0714 s/iter. Total: 0.2082 s/iter. ETA=0:01:26
[10/13 15:16:56] d2.evaluation.evaluator INFO: Inference done 108/500. Dataloading: 0.0049 s/iter. Inference: 0.1322 s/iter. Eval: 0.0716 s/iter. Total: 0.2088 s/iter. ETA=0:01:21
[10/13 15:17:01] d2.evaluation.evaluator INFO: Inference done 132/500. Dataloading: 0.0049 s/iter. Inference: 0.1323 s/iter. Eval: 0.0719 s/iter. Total: 0.2092 s/iter. ETA=0:01:16
[10/13 15:17:06] d2.evaluation.evaluator INFO: Inference done 156/500. Dataloading: 0.0049 s/iter. Inference: 0.1322 s/iter. Eval: 0.0720 s/iter. Total: 0.2092 s/iter. ETA=0:01:11
[10/13 15:17:11] d2.evaluation.evaluator INFO: Inference done 180/500. Dataloading: 0.0049 s/iter. Inference: 0.1322 s/iter. Eval: 0.0720 s/iter. Total: 0.2092 s/iter. ETA=0:01:06
[10/13 15:17:16] d2.evaluation.evaluator INFO: Inference done 204/500. Dataloading: 0.0049 s/iter. Inference: 0.1323 s/iter. Eval: 0.0720 s/iter. Total: 0.2093 s/iter. ETA=0:01:01
[10/13 15:17:21] d2.evaluation.evaluator INFO: Inference done 228/500. Dataloading: 0.0049 s/iter. Inference: 0.1324 s/iter. Eval: 0.0720 s/iter. Total: 0.2093 s/iter. ETA=0:00:56
[10/13 15:17:26] d2.evaluation.evaluator INFO: Inference done 252/500. Dataloading: 0.0049 s/iter. Inference: 0.1324 s/iter. Eval: 0.0720 s/iter. Total: 0.2093 s/iter. ETA=0:00:51
[10/13 15:17:31] d2.evaluation.evaluator INFO: Inference done 277/500. Dataloading: 0.0049 s/iter. Inference: 0.1322 s/iter. Eval: 0.0718 s/iter. Total: 0.2089 s/iter. ETA=0:00:46
[10/13 15:17:36] d2.evaluation.evaluator INFO: Inference done 303/500. Dataloading: 0.0050 s/iter. Inference: 0.1320 s/iter. Eval: 0.0707 s/iter. Total: 0.2077 s/iter. ETA=0:00:40
[10/13 15:17:41] d2.evaluation.evaluator INFO: Inference done 328/500. Dataloading: 0.0050 s/iter. Inference: 0.1317 s/iter. Eval: 0.0708 s/iter. Total: 0.2075 s/iter. ETA=0:00:35
[10/13 15:17:46] d2.evaluation.evaluator INFO: Inference done 353/500. Dataloading: 0.0050 s/iter. Inference: 0.1318 s/iter. Eval: 0.0704 s/iter. Total: 0.2072 s/iter. ETA=0:00:30
[10/13 15:17:51] d2.evaluation.evaluator INFO: Inference done 378/500. Dataloading: 0.0050 s/iter. Inference: 0.1319 s/iter. Eval: 0.0700 s/iter. Total: 0.2070 s/iter. ETA=0:00:25
[10/13 15:17:56] d2.evaluation.evaluator INFO: Inference done 402/500. Dataloading: 0.0050 s/iter. Inference: 0.1322 s/iter. Eval: 0.0700 s/iter. Total: 0.2073 s/iter. ETA=0:00:20
[10/13 15:18:01] d2.evaluation.evaluator INFO: Inference done 426/500. Dataloading: 0.0050 s/iter. Inference: 0.1323 s/iter. Eval: 0.0700 s/iter. Total: 0.2074 s/iter. ETA=0:00:15
[10/13 15:18:06] d2.evaluation.evaluator INFO: Inference done 450/500. Dataloading: 0.0050 s/iter. Inference: 0.1323 s/iter. Eval: 0.0701 s/iter. Total: 0.2075 s/iter. ETA=0:00:10
[10/13 15:18:11] d2.evaluation.evaluator INFO: Inference done 474/500. Dataloading: 0.0050 s/iter. Inference: 0.1323 s/iter. Eval: 0.0702 s/iter. Total: 0.2076 s/iter. ETA=0:00:05
[10/13 15:18:17] d2.evaluation.evaluator INFO: Inference done 498/500. Dataloading: 0.0050 s/iter. Inference: 0.1324 s/iter. Eval: 0.0702 s/iter. Total: 0.2077 s/iter. ETA=0:00:00
[10/13 15:18:17] d2.evaluation.evaluator INFO: Total inference time: 0:01:42.882118 (0.207843 s / iter per device, on 1 devices)
[10/13 15:18:17] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:05 (0.132365 s / iter per device, on 1 devices)
[10/13 15:18:17] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evaloz5ven3p ...
[10/13 15:18:40] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 53.458 | 79.162 | 66.152 |      19       |
| Things | 44.856 | 79.205 | 56.643 |       8       |
| Stuff  | 59.715 | 79.132 | 73.068 |      11       |
[10/13 15:18:40] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.481 | 96.782 | 99.690 |     Stuff     |
| class_8  | 69.161 | 81.486 | 84.875 |     Stuff     |
| class_11 | 85.256 | 87.768 | 97.137 |     Stuff     |
| class_12 | 37.786 | 76.937 | 49.112 |     Stuff     |
| class_13 | 31.504 | 72.732 | 43.316 |     Stuff     |
| class_17 | 35.339 | 61.492 | 57.469 |     Stuff     |
| class_19 | 38.590 | 66.656 | 57.895 |     Stuff     |
| class_20 | 57.973 | 73.718 | 78.642 |     Stuff     |
| class_21 | 88.057 | 88.786 | 99.179 |     Stuff     |
| class_22 | 30.712 | 72.863 | 42.151 |     Stuff     |
| class_23 | 86.008 | 91.227 | 94.279 |     Stuff     |
| class_24 | 48.601 | 74.977 | 64.821 |    Things     |
| class_25 | 41.923 | 73.231 | 57.248 |    Things     |
| class_26 | 60.151 | 81.302 | 73.985 |    Things     |
| class_27 | 50.561 | 85.836 | 58.904 |    Things     |
| class_28 | 58.062 | 89.640 | 64.773 |    Things     |
| class_31 | 24.213 | 84.745 | 28.571 |    Things     |
| class_32 | 37.308 | 74.309 | 50.206 |    Things     |
| class_33 | 38.025 | 69.595 | 54.638 |    Things     |
[10/13 15:18:40] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:18:40] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:18:40] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:18:40] d2.evaluation.testing INFO: copypaste: 53.4585,79.1623,66.1520,44.8555,79.2045,56.6432,59.7152,79.1316,73.0676,96.4813,96.7816,99.6898,69.1610,81.4858,84.8749,85.2556,87.7684,97.1370,37.7857,76.9372,49.1124,31.5044,72.7324,43.3155,35.3387,61.4918,57.4689,38.5905,66.6563,57.8947,57.9728,73.7175,78.6418,88.0568,88.7860,99.1786,30.7123,72.8634,42.1505,86.0081,91.2271,94.2792,48.6008,74.9767,64.8212,41.9235,73.2312,57.2482,60.1510,81.3022,73.9845,50.5611,85.8362,58.9041,58.0625,89.6403,64.7727,24.2130,84.7454,28.5714,37.3076,74.3095,50.2058,38.0248,69.5946,54.6376
[10/13 15:19:33] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 15:19:33] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 15:19:33] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 15:19:33] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 15:19:33] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 15:19:33] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 15:19:36] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0047 s/iter. Inference: 0.1301 s/iter. Eval: 0.0574 s/iter. Total: 0.1922 s/iter. ETA=0:01:33
[10/13 15:19:41] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0050 s/iter. Inference: 0.1362 s/iter. Eval: 0.0672 s/iter. Total: 0.2085 s/iter. ETA=0:01:36
[10/13 15:19:46] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0050 s/iter. Inference: 0.1360 s/iter. Eval: 0.0692 s/iter. Total: 0.2103 s/iter. ETA=0:01:32
[10/13 15:19:51] d2.evaluation.evaluator INFO: Inference done 83/500. Dataloading: 0.0050 s/iter. Inference: 0.1358 s/iter. Eval: 0.0705 s/iter. Total: 0.2114 s/iter. ETA=0:01:28
[10/13 15:19:56] d2.evaluation.evaluator INFO: Inference done 106/500. Dataloading: 0.0052 s/iter. Inference: 0.1375 s/iter. Eval: 0.0702 s/iter. Total: 0.2130 s/iter. ETA=0:01:23
[10/13 15:20:02] d2.evaluation.evaluator INFO: Inference done 130/500. Dataloading: 0.0052 s/iter. Inference: 0.1369 s/iter. Eval: 0.0708 s/iter. Total: 0.2130 s/iter. ETA=0:01:18
[10/13 15:20:07] d2.evaluation.evaluator INFO: Inference done 154/500. Dataloading: 0.0052 s/iter. Inference: 0.1365 s/iter. Eval: 0.0711 s/iter. Total: 0.2128 s/iter. ETA=0:01:13
[10/13 15:20:12] d2.evaluation.evaluator INFO: Inference done 179/500. Dataloading: 0.0052 s/iter. Inference: 0.1360 s/iter. Eval: 0.0706 s/iter. Total: 0.2118 s/iter. ETA=0:01:07
[10/13 15:20:17] d2.evaluation.evaluator INFO: Inference done 202/500. Dataloading: 0.0052 s/iter. Inference: 0.1369 s/iter. Eval: 0.0705 s/iter. Total: 0.2126 s/iter. ETA=0:01:03
[10/13 15:20:22] d2.evaluation.evaluator INFO: Inference done 227/500. Dataloading: 0.0052 s/iter. Inference: 0.1365 s/iter. Eval: 0.0697 s/iter. Total: 0.2115 s/iter. ETA=0:00:57
[10/13 15:20:27] d2.evaluation.evaluator INFO: Inference done 251/500. Dataloading: 0.0052 s/iter. Inference: 0.1363 s/iter. Eval: 0.0699 s/iter. Total: 0.2114 s/iter. ETA=0:00:52
[10/13 15:20:32] d2.evaluation.evaluator INFO: Inference done 275/500. Dataloading: 0.0052 s/iter. Inference: 0.1359 s/iter. Eval: 0.0700 s/iter. Total: 0.2111 s/iter. ETA=0:00:47
[10/13 15:20:37] d2.evaluation.evaluator INFO: Inference done 299/500. Dataloading: 0.0051 s/iter. Inference: 0.1356 s/iter. Eval: 0.0702 s/iter. Total: 0.2110 s/iter. ETA=0:00:42
[10/13 15:20:42] d2.evaluation.evaluator INFO: Inference done 324/500. Dataloading: 0.0052 s/iter. Inference: 0.1355 s/iter. Eval: 0.0700 s/iter. Total: 0.2108 s/iter. ETA=0:00:37
[10/13 15:20:47] d2.evaluation.evaluator INFO: Inference done 349/500. Dataloading: 0.0052 s/iter. Inference: 0.1354 s/iter. Eval: 0.0700 s/iter. Total: 0.2106 s/iter. ETA=0:00:31
[10/13 15:20:53] d2.evaluation.evaluator INFO: Inference done 374/500. Dataloading: 0.0052 s/iter. Inference: 0.1353 s/iter. Eval: 0.0698 s/iter. Total: 0.2104 s/iter. ETA=0:00:26
[10/13 15:20:58] d2.evaluation.evaluator INFO: Inference done 398/500. Dataloading: 0.0052 s/iter. Inference: 0.1353 s/iter. Eval: 0.0699 s/iter. Total: 0.2105 s/iter. ETA=0:00:21
[10/13 15:21:03] d2.evaluation.evaluator INFO: Inference done 423/500. Dataloading: 0.0052 s/iter. Inference: 0.1351 s/iter. Eval: 0.0699 s/iter. Total: 0.2103 s/iter. ETA=0:00:16
[10/13 15:21:08] d2.evaluation.evaluator INFO: Inference done 447/500. Dataloading: 0.0052 s/iter. Inference: 0.1350 s/iter. Eval: 0.0699 s/iter. Total: 0.2102 s/iter. ETA=0:00:11
[10/13 15:21:13] d2.evaluation.evaluator INFO: Inference done 471/500. Dataloading: 0.0052 s/iter. Inference: 0.1350 s/iter. Eval: 0.0700 s/iter. Total: 0.2102 s/iter. ETA=0:00:06
[10/13 15:21:18] d2.evaluation.evaluator INFO: Inference done 495/500. Dataloading: 0.0052 s/iter. Inference: 0.1349 s/iter. Eval: 0.0701 s/iter. Total: 0.2102 s/iter. ETA=0:00:01
[10/13 15:21:19] d2.evaluation.evaluator INFO: Total inference time: 0:01:44.132532 (0.210369 s / iter per device, on 1 devices)
[10/13 15:21:19] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.134832 s / iter per device, on 1 devices)
[10/13 15:21:19] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalxpg7ad7v ...
[10/13 15:21:43] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 54.850 | 79.353 | 67.568 |      19       |
| Things | 47.715 | 78.731 | 60.364 |       8       |
| Stuff  | 60.039 | 79.805 | 72.808 |      11       |
[10/13 15:21:43] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.284 | 96.786 | 99.482 |     Stuff     |
| class_8  | 68.723 | 82.413 | 83.388 |     Stuff     |
| class_11 | 85.478 | 88.183 | 96.933 |     Stuff     |
| class_12 | 39.379 | 78.521 | 50.151 |     Stuff     |
| class_13 | 32.259 | 73.216 | 44.059 |     Stuff     |
| class_17 | 27.910 | 61.038 | 45.726 |     Stuff     |
| class_19 | 41.292 | 66.782 | 61.831 |     Stuff     |
| class_20 | 57.576 | 74.269 | 77.524 |     Stuff     |
| class_21 | 87.949 | 89.326 | 98.458 |     Stuff     |
| class_22 | 36.540 | 75.863 | 48.165 |     Stuff     |
| class_23 | 87.039 | 91.454 | 95.172 |     Stuff     |
| class_24 | 48.983 | 74.719 | 65.556 |    Things     |
| class_25 | 40.921 | 72.749 | 56.250 |    Things     |
| class_26 | 61.685 | 81.803 | 75.406 |    Things     |
| class_27 | 45.645 | 85.812 | 53.191 |    Things     |
| class_28 | 57.563 | 89.281 | 64.474 |    Things     |
| class_31 | 51.097 | 83.614 | 61.111 |    Things     |
| class_32 | 37.819 | 71.918 | 52.586 |    Things     |
| class_33 | 38.010 | 69.956 | 54.334 |    Things     |
[10/13 15:21:43] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:21:43] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:21:43] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:21:43] d2.evaluation.testing INFO: copypaste: 54.8501,79.3528,67.5684,47.7152,78.7314,60.3635,60.0390,79.8047,72.8082,96.2842,96.7857,99.4819,68.7229,82.4131,83.3883,85.4782,88.1832,96.9325,39.3789,78.5206,50.1511,32.2587,73.2164,44.0594,27.9102,61.0379,45.7261,41.2919,66.7821,61.8307,57.5763,74.2686,77.5244,87.9488,89.3259,98.4584,36.5397,75.8634,48.1651,87.0394,91.4544,95.1724,48.9825,74.7185,65.5560,40.9213,72.7490,56.2500,61.6848,81.8032,75.4063,45.6445,85.8117,53.1915,57.5627,89.2810,64.4737,51.0972,83.6136,61.1111,37.8192,71.9185,52.5862,38.0095,69.9560,54.3335
[10/13 15:22:36] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 15:22:36] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 15:22:36] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 15:22:36] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 15:22:36] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 15:22:36] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 15:22:38] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0037 s/iter. Inference: 0.1303 s/iter. Eval: 0.0729 s/iter. Total: 0.2069 s/iter. ETA=0:01:41
[10/13 15:22:43] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0046 s/iter. Inference: 0.1303 s/iter. Eval: 0.0733 s/iter. Total: 0.2083 s/iter. ETA=0:01:36
[10/13 15:22:49] d2.evaluation.evaluator INFO: Inference done 60/500. Dataloading: 0.0048 s/iter. Inference: 0.1315 s/iter. Eval: 0.0718 s/iter. Total: 0.2081 s/iter. ETA=0:01:31
[10/13 15:22:54] d2.evaluation.evaluator INFO: Inference done 84/500. Dataloading: 0.0048 s/iter. Inference: 0.1331 s/iter. Eval: 0.0714 s/iter. Total: 0.2094 s/iter. ETA=0:01:27
[10/13 15:22:59] d2.evaluation.evaluator INFO: Inference done 108/500. Dataloading: 0.0048 s/iter. Inference: 0.1330 s/iter. Eval: 0.0716 s/iter. Total: 0.2095 s/iter. ETA=0:01:22
[10/13 15:23:04] d2.evaluation.evaluator INFO: Inference done 132/500. Dataloading: 0.0048 s/iter. Inference: 0.1329 s/iter. Eval: 0.0717 s/iter. Total: 0.2094 s/iter. ETA=0:01:17
[10/13 15:23:09] d2.evaluation.evaluator INFO: Inference done 157/500. Dataloading: 0.0049 s/iter. Inference: 0.1329 s/iter. Eval: 0.0711 s/iter. Total: 0.2089 s/iter. ETA=0:01:11
[10/13 15:23:14] d2.evaluation.evaluator INFO: Inference done 182/500. Dataloading: 0.0049 s/iter. Inference: 0.1331 s/iter. Eval: 0.0701 s/iter. Total: 0.2082 s/iter. ETA=0:01:06
[10/13 15:23:19] d2.evaluation.evaluator INFO: Inference done 207/500. Dataloading: 0.0050 s/iter. Inference: 0.1334 s/iter. Eval: 0.0694 s/iter. Total: 0.2078 s/iter. ETA=0:01:00
[10/13 15:23:24] d2.evaluation.evaluator INFO: Inference done 231/500. Dataloading: 0.0050 s/iter. Inference: 0.1337 s/iter. Eval: 0.0696 s/iter. Total: 0.2083 s/iter. ETA=0:00:56
[10/13 15:23:29] d2.evaluation.evaluator INFO: Inference done 255/500. Dataloading: 0.0050 s/iter. Inference: 0.1337 s/iter. Eval: 0.0698 s/iter. Total: 0.2085 s/iter. ETA=0:00:51
[10/13 15:23:34] d2.evaluation.evaluator INFO: Inference done 279/500. Dataloading: 0.0050 s/iter. Inference: 0.1336 s/iter. Eval: 0.0700 s/iter. Total: 0.2086 s/iter. ETA=0:00:46
[10/13 15:23:39] d2.evaluation.evaluator INFO: Inference done 303/500. Dataloading: 0.0049 s/iter. Inference: 0.1335 s/iter. Eval: 0.0701 s/iter. Total: 0.2086 s/iter. ETA=0:00:41
[10/13 15:23:44] d2.evaluation.evaluator INFO: Inference done 327/500. Dataloading: 0.0049 s/iter. Inference: 0.1334 s/iter. Eval: 0.0703 s/iter. Total: 0.2086 s/iter. ETA=0:00:36
[10/13 15:23:49] d2.evaluation.evaluator INFO: Inference done 351/500. Dataloading: 0.0049 s/iter. Inference: 0.1333 s/iter. Eval: 0.0704 s/iter. Total: 0.2087 s/iter. ETA=0:00:31
[10/13 15:23:54] d2.evaluation.evaluator INFO: Inference done 375/500. Dataloading: 0.0049 s/iter. Inference: 0.1333 s/iter. Eval: 0.0705 s/iter. Total: 0.2088 s/iter. ETA=0:00:26
[10/13 15:23:59] d2.evaluation.evaluator INFO: Inference done 399/500. Dataloading: 0.0049 s/iter. Inference: 0.1335 s/iter. Eval: 0.0705 s/iter. Total: 0.2089 s/iter. ETA=0:00:21
[10/13 15:24:04] d2.evaluation.evaluator INFO: Inference done 423/500. Dataloading: 0.0049 s/iter. Inference: 0.1334 s/iter. Eval: 0.0706 s/iter. Total: 0.2090 s/iter. ETA=0:00:16
[10/13 15:24:09] d2.evaluation.evaluator INFO: Inference done 447/500. Dataloading: 0.0049 s/iter. Inference: 0.1333 s/iter. Eval: 0.0707 s/iter. Total: 0.2089 s/iter. ETA=0:00:11
[10/13 15:24:14] d2.evaluation.evaluator INFO: Inference done 471/500. Dataloading: 0.0049 s/iter. Inference: 0.1332 s/iter. Eval: 0.0708 s/iter. Total: 0.2089 s/iter. ETA=0:00:06
[10/13 15:24:19] d2.evaluation.evaluator INFO: Inference done 495/500. Dataloading: 0.0049 s/iter. Inference: 0.1332 s/iter. Eval: 0.0709 s/iter. Total: 0.2089 s/iter. ETA=0:00:01
[10/13 15:24:21] d2.evaluation.evaluator INFO: Total inference time: 0:01:43.491628 (0.209074 s / iter per device, on 1 devices)
[10/13 15:24:21] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:05 (0.133129 s / iter per device, on 1 devices)
[10/13 15:24:21] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalse27thdq ...
[10/13 15:24:44] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 56.459 | 79.662 | 69.437 |      19       |
| Things | 50.089 | 79.481 | 62.725 |       8       |
| Stuff  | 61.093 | 79.794 | 74.318 |      11       |
[10/13 15:24:44] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 95.960 | 96.460 | 99.482 |     Stuff     |
| class_8  | 70.759 | 82.672 | 85.590 |     Stuff     |
| class_11 | 86.243 | 88.503 | 97.446 |     Stuff     |
| class_12 | 38.294 | 78.479 | 48.795 |     Stuff     |
| class_13 | 33.743 | 74.152 | 45.506 |     Stuff     |
| class_17 | 31.922 | 61.929 | 51.546 |     Stuff     |
| class_19 | 42.838 | 66.598 | 64.323 |     Stuff     |
| class_20 | 59.974 | 74.242 | 80.782 |     Stuff     |
| class_21 | 88.308 | 89.041 | 99.177 |     Stuff     |
| class_22 | 36.465 | 74.245 | 49.115 |     Stuff     |
| class_23 | 87.512 | 91.413 | 95.732 |     Stuff     |
| class_24 | 50.404 | 75.193 | 67.033 |    Things     |
| class_25 | 42.872 | 73.558 | 58.283 |    Things     |
| class_26 | 63.977 | 81.823 | 78.190 |    Things     |
| class_27 | 51.609 | 88.742 | 58.156 |    Things     |
| class_28 | 62.095 | 91.001 | 68.235 |    Things     |
| class_31 | 51.716 | 81.883 | 63.158 |    Things     |
| class_32 | 38.672 | 73.677 | 52.489 |    Things     |
| class_33 | 39.366 | 69.973 | 56.260 |    Things     |
[10/13 15:24:44] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:24:44] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:24:44] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:24:44] d2.evaluation.testing INFO: copypaste: 56.4595,79.6623,69.4367,50.0889,79.4812,62.7254,61.0926,79.7940,74.3177,95.9603,96.4601,99.4819,70.7589,82.6724,85.5895,86.2432,88.5033,97.4464,38.2942,78.4795,48.7952,33.7434,74.1521,45.5056,31.9221,61.9289,51.5464,42.8380,66.5979,64.3234,59.9737,74.2416,80.7818,88.3078,89.0407,99.1770,36.4653,74.2446,49.1150,87.5120,91.4132,95.7324,50.4042,75.1928,67.0333,42.8719,73.5583,58.2830,63.9774,81.8234,78.1897,51.6086,88.7417,58.1560,62.0948,91.0011,68.2353,51.7155,81.8829,63.1579,38.6720,73.6768,52.4887,39.3663,69.9727,56.2595
[10/13 15:25:37] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 15:25:37] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 15:25:37] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 15:25:37] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 15:25:37] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 15:25:37] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 15:25:40] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0045 s/iter. Inference: 0.1412 s/iter. Eval: 0.0727 s/iter. Total: 0.2185 s/iter. ETA=0:01:46
[10/13 15:25:45] d2.evaluation.evaluator INFO: Inference done 34/500. Dataloading: 0.0049 s/iter. Inference: 0.1395 s/iter. Eval: 0.0766 s/iter. Total: 0.2210 s/iter. ETA=0:01:42
[10/13 15:25:50] d2.evaluation.evaluator INFO: Inference done 58/500. Dataloading: 0.0048 s/iter. Inference: 0.1389 s/iter. Eval: 0.0738 s/iter. Total: 0.2176 s/iter. ETA=0:01:36
[10/13 15:25:55] d2.evaluation.evaluator INFO: Inference done 82/500. Dataloading: 0.0049 s/iter. Inference: 0.1387 s/iter. Eval: 0.0732 s/iter. Total: 0.2168 s/iter. ETA=0:01:30
[10/13 15:26:01] d2.evaluation.evaluator INFO: Inference done 105/500. Dataloading: 0.0049 s/iter. Inference: 0.1391 s/iter. Eval: 0.0738 s/iter. Total: 0.2180 s/iter. ETA=0:01:26
[10/13 15:26:06] d2.evaluation.evaluator INFO: Inference done 128/500. Dataloading: 0.0049 s/iter. Inference: 0.1402 s/iter. Eval: 0.0735 s/iter. Total: 0.2187 s/iter. ETA=0:01:21
[10/13 15:26:11] d2.evaluation.evaluator INFO: Inference done 151/500. Dataloading: 0.0049 s/iter. Inference: 0.1414 s/iter. Eval: 0.0733 s/iter. Total: 0.2197 s/iter. ETA=0:01:16
[10/13 15:26:16] d2.evaluation.evaluator INFO: Inference done 174/500. Dataloading: 0.0050 s/iter. Inference: 0.1422 s/iter. Eval: 0.0733 s/iter. Total: 0.2205 s/iter. ETA=0:01:11
[10/13 15:26:21] d2.evaluation.evaluator INFO: Inference done 197/500. Dataloading: 0.0050 s/iter. Inference: 0.1429 s/iter. Eval: 0.0728 s/iter. Total: 0.2208 s/iter. ETA=0:01:06
[10/13 15:26:26] d2.evaluation.evaluator INFO: Inference done 219/500. Dataloading: 0.0050 s/iter. Inference: 0.1439 s/iter. Eval: 0.0729 s/iter. Total: 0.2219 s/iter. ETA=0:01:02
[10/13 15:26:31] d2.evaluation.evaluator INFO: Inference done 242/500. Dataloading: 0.0050 s/iter. Inference: 0.1436 s/iter. Eval: 0.0731 s/iter. Total: 0.2218 s/iter. ETA=0:00:57
[10/13 15:26:37] d2.evaluation.evaluator INFO: Inference done 265/500. Dataloading: 0.0050 s/iter. Inference: 0.1440 s/iter. Eval: 0.0733 s/iter. Total: 0.2223 s/iter. ETA=0:00:52
[10/13 15:26:42] d2.evaluation.evaluator INFO: Inference done 288/500. Dataloading: 0.0050 s/iter. Inference: 0.1439 s/iter. Eval: 0.0734 s/iter. Total: 0.2224 s/iter. ETA=0:00:47
[10/13 15:26:47] d2.evaluation.evaluator INFO: Inference done 312/500. Dataloading: 0.0050 s/iter. Inference: 0.1431 s/iter. Eval: 0.0738 s/iter. Total: 0.2219 s/iter. ETA=0:00:41
[10/13 15:26:52] d2.evaluation.evaluator INFO: Inference done 336/500. Dataloading: 0.0050 s/iter. Inference: 0.1424 s/iter. Eval: 0.0739 s/iter. Total: 0.2213 s/iter. ETA=0:00:36
[10/13 15:26:57] d2.evaluation.evaluator INFO: Inference done 359/500. Dataloading: 0.0050 s/iter. Inference: 0.1427 s/iter. Eval: 0.0736 s/iter. Total: 0.2213 s/iter. ETA=0:00:31
[10/13 15:27:02] d2.evaluation.evaluator INFO: Inference done 382/500. Dataloading: 0.0050 s/iter. Inference: 0.1430 s/iter. Eval: 0.0734 s/iter. Total: 0.2215 s/iter. ETA=0:00:26
[10/13 15:27:07] d2.evaluation.evaluator INFO: Inference done 405/500. Dataloading: 0.0050 s/iter. Inference: 0.1430 s/iter. Eval: 0.0735 s/iter. Total: 0.2217 s/iter. ETA=0:00:21
[10/13 15:27:12] d2.evaluation.evaluator INFO: Inference done 428/500. Dataloading: 0.0050 s/iter. Inference: 0.1427 s/iter. Eval: 0.0737 s/iter. Total: 0.2215 s/iter. ETA=0:00:15
[10/13 15:27:18] d2.evaluation.evaluator INFO: Inference done 452/500. Dataloading: 0.0050 s/iter. Inference: 0.1424 s/iter. Eval: 0.0736 s/iter. Total: 0.2211 s/iter. ETA=0:00:10
[10/13 15:27:23] d2.evaluation.evaluator INFO: Inference done 476/500. Dataloading: 0.0050 s/iter. Inference: 0.1425 s/iter. Eval: 0.0733 s/iter. Total: 0.2209 s/iter. ETA=0:00:05
[10/13 15:27:28] d2.evaluation.evaluator INFO: Inference done 499/500. Dataloading: 0.0051 s/iter. Inference: 0.1426 s/iter. Eval: 0.0733 s/iter. Total: 0.2210 s/iter. ETA=0:00:00
[10/13 15:27:28] d2.evaluation.evaluator INFO: Total inference time: 0:01:49.444576 (0.221100 s / iter per device, on 1 devices)
[10/13 15:27:28] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:10 (0.142543 s / iter per device, on 1 devices)
[10/13 15:27:28] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_eval1gyti1fb ...
[10/13 15:27:52] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 54.510 | 78.988 | 67.378 |      19       |
| Things | 46.482 | 77.989 | 59.234 |       8       |
| Stuff  | 60.349 | 79.714 | 73.301 |      11       |
[10/13 15:27:52] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.935 | 97.236 | 99.690 |     Stuff     |
| class_8  | 71.442 | 82.176 | 86.937 |     Stuff     |
| class_11 | 85.764 | 88.201 | 97.236 |     Stuff     |
| class_12 | 36.809 | 77.963 | 47.213 |     Stuff     |
| class_13 | 31.774 | 73.045 | 43.500 |     Stuff     |
| class_17 | 31.619 | 61.332 | 51.553 |     Stuff     |
| class_19 | 36.879 | 67.033 | 55.016 |     Stuff     |
| class_20 | 60.890 | 74.574 | 81.650 |     Stuff     |
| class_21 | 88.012 | 88.834 | 99.075 |     Stuff     |
| class_22 | 37.421 | 75.529 | 49.545 |     Stuff     |
| class_23 | 86.290 | 90.934 | 94.892 |     Stuff     |
| class_24 | 47.538 | 74.858 | 63.504 |    Things     |
| class_25 | 41.035 | 71.554 | 57.348 |    Things     |
| class_26 | 59.877 | 81.642 | 73.341 |    Things     |
| class_27 | 51.944 | 86.976 | 59.722 |    Things     |
| class_28 | 61.504 | 87.997 | 69.892 |    Things     |
| class_31 | 34.528 | 78.921 | 43.750 |    Things     |
| class_32 | 37.544 | 72.367 | 51.880 |    Things     |
| class_33 | 37.886 | 69.595 | 54.438 |    Things     |
[10/13 15:27:52] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:27:52] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:27:52] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:27:52] d2.evaluation.testing INFO: copypaste: 54.5099,78.9878,67.3781,46.4819,77.9888,59.2345,60.3485,79.7144,73.3008,96.9345,97.2362,99.6898,71.4416,82.1759,86.9374,85.7635,88.2010,97.2364,36.8088,77.9631,47.2131,31.7744,73.0447,43.5000,31.6185,61.3323,51.5528,36.8792,67.0335,55.0162,60.8900,74.5740,81.6504,88.0122,88.8339,99.0750,37.4213,75.5292,49.5455,86.2896,90.9344,94.8922,47.5378,74.8578,63.5041,41.0347,71.5542,57.3477,59.8767,81.6415,73.3410,51.9442,86.9763,59.7222,61.5036,87.9975,69.8925,34.5278,78.9207,43.7500,37.5439,72.3672,51.8797,37.8864,69.5949,54.4385
[10/13 15:28:46] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 15:28:46] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 15:28:46] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 15:28:46] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 15:28:46] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 15:28:46] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 15:28:49] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0046 s/iter. Inference: 0.1463 s/iter. Eval: 0.0725 s/iter. Total: 0.2234 s/iter. ETA=0:01:49
[10/13 15:28:54] d2.evaluation.evaluator INFO: Inference done 34/500. Dataloading: 0.0050 s/iter. Inference: 0.1422 s/iter. Eval: 0.0736 s/iter. Total: 0.2209 s/iter. ETA=0:01:42
[10/13 15:28:59] d2.evaluation.evaluator INFO: Inference done 57/500. Dataloading: 0.0051 s/iter. Inference: 0.1418 s/iter. Eval: 0.0739 s/iter. Total: 0.2209 s/iter. ETA=0:01:37
[10/13 15:29:04] d2.evaluation.evaluator INFO: Inference done 81/500. Dataloading: 0.0051 s/iter. Inference: 0.1418 s/iter. Eval: 0.0719 s/iter. Total: 0.2188 s/iter. ETA=0:01:31
[10/13 15:29:09] d2.evaluation.evaluator INFO: Inference done 105/500. Dataloading: 0.0050 s/iter. Inference: 0.1401 s/iter. Eval: 0.0718 s/iter. Total: 0.2170 s/iter. ETA=0:01:25
[10/13 15:29:14] d2.evaluation.evaluator INFO: Inference done 129/500. Dataloading: 0.0050 s/iter. Inference: 0.1386 s/iter. Eval: 0.0719 s/iter. Total: 0.2155 s/iter. ETA=0:01:19
[10/13 15:29:19] d2.evaluation.evaluator INFO: Inference done 153/500. Dataloading: 0.0049 s/iter. Inference: 0.1377 s/iter. Eval: 0.0718 s/iter. Total: 0.2144 s/iter. ETA=0:01:14
[10/13 15:29:24] d2.evaluation.evaluator INFO: Inference done 177/500. Dataloading: 0.0049 s/iter. Inference: 0.1371 s/iter. Eval: 0.0717 s/iter. Total: 0.2137 s/iter. ETA=0:01:09
[10/13 15:29:29] d2.evaluation.evaluator INFO: Inference done 201/500. Dataloading: 0.0049 s/iter. Inference: 0.1371 s/iter. Eval: 0.0715 s/iter. Total: 0.2135 s/iter. ETA=0:01:03
[10/13 15:29:34] d2.evaluation.evaluator INFO: Inference done 225/500. Dataloading: 0.0048 s/iter. Inference: 0.1371 s/iter. Eval: 0.0714 s/iter. Total: 0.2134 s/iter. ETA=0:00:58
[10/13 15:29:40] d2.evaluation.evaluator INFO: Inference done 249/500. Dataloading: 0.0048 s/iter. Inference: 0.1373 s/iter. Eval: 0.0715 s/iter. Total: 0.2137 s/iter. ETA=0:00:53
[10/13 15:29:45] d2.evaluation.evaluator INFO: Inference done 273/500. Dataloading: 0.0048 s/iter. Inference: 0.1369 s/iter. Eval: 0.0717 s/iter. Total: 0.2135 s/iter. ETA=0:00:48
[10/13 15:29:50] d2.evaluation.evaluator INFO: Inference done 298/500. Dataloading: 0.0048 s/iter. Inference: 0.1363 s/iter. Eval: 0.0718 s/iter. Total: 0.2130 s/iter. ETA=0:00:43
[10/13 15:29:55] d2.evaluation.evaluator INFO: Inference done 323/500. Dataloading: 0.0048 s/iter. Inference: 0.1360 s/iter. Eval: 0.0718 s/iter. Total: 0.2126 s/iter. ETA=0:00:37
[10/13 15:30:00] d2.evaluation.evaluator INFO: Inference done 347/500. Dataloading: 0.0048 s/iter. Inference: 0.1358 s/iter. Eval: 0.0718 s/iter. Total: 0.2125 s/iter. ETA=0:00:32
[10/13 15:30:05] d2.evaluation.evaluator INFO: Inference done 371/500. Dataloading: 0.0048 s/iter. Inference: 0.1357 s/iter. Eval: 0.0717 s/iter. Total: 0.2124 s/iter. ETA=0:00:27
[10/13 15:30:10] d2.evaluation.evaluator INFO: Inference done 395/500. Dataloading: 0.0048 s/iter. Inference: 0.1358 s/iter. Eval: 0.0716 s/iter. Total: 0.2123 s/iter. ETA=0:00:22
[10/13 15:30:15] d2.evaluation.evaluator INFO: Inference done 420/500. Dataloading: 0.0049 s/iter. Inference: 0.1358 s/iter. Eval: 0.0712 s/iter. Total: 0.2120 s/iter. ETA=0:00:16
[10/13 15:30:20] d2.evaluation.evaluator INFO: Inference done 444/500. Dataloading: 0.0049 s/iter. Inference: 0.1357 s/iter. Eval: 0.0712 s/iter. Total: 0.2119 s/iter. ETA=0:00:11
[10/13 15:30:25] d2.evaluation.evaluator INFO: Inference done 468/500. Dataloading: 0.0049 s/iter. Inference: 0.1357 s/iter. Eval: 0.0712 s/iter. Total: 0.2117 s/iter. ETA=0:00:06
[10/13 15:30:31] d2.evaluation.evaluator INFO: Inference done 492/500. Dataloading: 0.0049 s/iter. Inference: 0.1356 s/iter. Eval: 0.0712 s/iter. Total: 0.2117 s/iter. ETA=0:00:01
[10/13 15:30:32] d2.evaluation.evaluator INFO: Total inference time: 0:01:44.811436 (0.211740 s / iter per device, on 1 devices)
[10/13 15:30:32] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:07 (0.135478 s / iter per device, on 1 devices)
[10/13 15:30:32] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_eval3duhhh71 ...
[10/13 15:30:56] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 55.249 | 79.657 | 67.966 |      19       |
| Things | 47.580 | 79.409 | 59.755 |       8       |
| Stuff  | 60.827 | 79.837 | 73.937 |      11       |
[10/13 15:30:56] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.757 | 97.261 | 99.482 |     Stuff     |
| class_8  | 73.819 | 83.001 | 88.938 |     Stuff     |
| class_11 | 85.989 | 88.512 | 97.149 |     Stuff     |
| class_12 | 39.620 | 77.627 | 51.039 |     Stuff     |
| class_13 | 31.491 | 73.674 | 42.744 |     Stuff     |
| class_17 | 35.473 | 61.601 | 57.585 |     Stuff     |
| class_19 | 40.322 | 67.165 | 60.034 |     Stuff     |
| class_20 | 58.823 | 74.298 | 79.171 |     Stuff     |
| class_21 | 88.049 | 88.961 | 98.975 |     Stuff     |
| class_22 | 33.270 | 75.024 | 44.346 |     Stuff     |
| class_23 | 85.481 | 91.083 | 93.850 |     Stuff     |
| class_24 | 47.870 | 74.758 | 64.032 |    Things     |
| class_25 | 43.669 | 72.729 | 60.044 |    Things     |
| class_26 | 60.071 | 80.934 | 74.222 |    Things     |
| class_27 | 51.305 | 88.292 | 58.108 |    Things     |
| class_28 | 52.945 | 91.039 | 58.156 |    Things     |
| class_31 | 51.797 | 84.759 | 61.111 |    Things     |
| class_32 | 35.048 | 72.850 | 48.110 |    Things     |
| class_33 | 37.932 | 69.913 | 54.256 |    Things     |
[10/13 15:30:56] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:30:56] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:30:56] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:30:56] d2.evaluation.testing INFO: copypaste: 55.2490,79.6570,67.9659,47.5797,79.4094,59.7550,60.8267,79.8370,73.9375,96.7569,97.2609,99.4819,73.8192,83.0012,88.9376,85.9887,88.5124,97.1487,39.6196,77.6268,51.0386,31.4911,73.6737,42.7441,35.4732,61.6014,57.5851,40.3221,67.1650,60.0343,58.8228,74.2982,79.1712,88.0492,88.9607,98.9754,33.2699,75.0236,44.3459,85.4809,91.0828,93.8497,47.8696,74.7583,64.0325,43.6691,72.7289,60.0437,60.0713,80.9342,74.2225,51.3050,88.2922,58.1081,52.9447,91.0391,58.1560,51.7973,84.7592,61.1111,35.0482,72.8501,48.1100,37.9324,69.9134,54.2563
[10/13 15:32:43] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 15:32:43] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 15:32:43] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 15:32:43] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 15:32:43] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 15:32:43] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 15:32:45] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0034 s/iter. Inference: 0.1349 s/iter. Eval: 0.0736 s/iter. Total: 0.2119 s/iter. ETA=0:01:43
[10/13 15:32:51] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0047 s/iter. Inference: 0.1346 s/iter. Eval: 0.0730 s/iter. Total: 0.2123 s/iter. ETA=0:01:38
[10/13 15:32:56] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0046 s/iter. Inference: 0.1361 s/iter. Eval: 0.0721 s/iter. Total: 0.2129 s/iter. ETA=0:01:33
[10/13 15:33:01] d2.evaluation.evaluator INFO: Inference done 82/500. Dataloading: 0.0047 s/iter. Inference: 0.1377 s/iter. Eval: 0.0721 s/iter. Total: 0.2146 s/iter. ETA=0:01:29
[10/13 15:33:06] d2.evaluation.evaluator INFO: Inference done 106/500. Dataloading: 0.0048 s/iter. Inference: 0.1372 s/iter. Eval: 0.0712 s/iter. Total: 0.2132 s/iter. ETA=0:01:24
[10/13 15:33:11] d2.evaluation.evaluator INFO: Inference done 129/500. Dataloading: 0.0048 s/iter. Inference: 0.1377 s/iter. Eval: 0.0718 s/iter. Total: 0.2145 s/iter. ETA=0:01:19
[10/13 15:33:16] d2.evaluation.evaluator INFO: Inference done 153/500. Dataloading: 0.0049 s/iter. Inference: 0.1373 s/iter. Eval: 0.0718 s/iter. Total: 0.2140 s/iter. ETA=0:01:14
[10/13 15:33:21] d2.evaluation.evaluator INFO: Inference done 177/500. Dataloading: 0.0049 s/iter. Inference: 0.1371 s/iter. Eval: 0.0718 s/iter. Total: 0.2138 s/iter. ETA=0:01:09
[10/13 15:33:26] d2.evaluation.evaluator INFO: Inference done 201/500. Dataloading: 0.0049 s/iter. Inference: 0.1370 s/iter. Eval: 0.0716 s/iter. Total: 0.2135 s/iter. ETA=0:01:03
[10/13 15:33:31] d2.evaluation.evaluator INFO: Inference done 225/500. Dataloading: 0.0048 s/iter. Inference: 0.1367 s/iter. Eval: 0.0718 s/iter. Total: 0.2134 s/iter. ETA=0:00:58
[10/13 15:33:36] d2.evaluation.evaluator INFO: Inference done 249/500. Dataloading: 0.0048 s/iter. Inference: 0.1363 s/iter. Eval: 0.0718 s/iter. Total: 0.2130 s/iter. ETA=0:00:53
[10/13 15:33:41] d2.evaluation.evaluator INFO: Inference done 273/500. Dataloading: 0.0048 s/iter. Inference: 0.1359 s/iter. Eval: 0.0719 s/iter. Total: 0.2126 s/iter. ETA=0:00:48
[10/13 15:33:46] d2.evaluation.evaluator INFO: Inference done 298/500. Dataloading: 0.0048 s/iter. Inference: 0.1354 s/iter. Eval: 0.0720 s/iter. Total: 0.2122 s/iter. ETA=0:00:42
[10/13 15:33:52] d2.evaluation.evaluator INFO: Inference done 323/500. Dataloading: 0.0048 s/iter. Inference: 0.1349 s/iter. Eval: 0.0720 s/iter. Total: 0.2117 s/iter. ETA=0:00:37
[10/13 15:33:57] d2.evaluation.evaluator INFO: Inference done 347/500. Dataloading: 0.0048 s/iter. Inference: 0.1347 s/iter. Eval: 0.0720 s/iter. Total: 0.2115 s/iter. ETA=0:00:32
[10/13 15:34:02] d2.evaluation.evaluator INFO: Inference done 371/500. Dataloading: 0.0048 s/iter. Inference: 0.1346 s/iter. Eval: 0.0720 s/iter. Total: 0.2114 s/iter. ETA=0:00:27
[10/13 15:34:07] d2.evaluation.evaluator INFO: Inference done 395/500. Dataloading: 0.0048 s/iter. Inference: 0.1345 s/iter. Eval: 0.0721 s/iter. Total: 0.2114 s/iter. ETA=0:00:22
[10/13 15:34:12] d2.evaluation.evaluator INFO: Inference done 419/500. Dataloading: 0.0048 s/iter. Inference: 0.1344 s/iter. Eval: 0.0721 s/iter. Total: 0.2113 s/iter. ETA=0:00:17
[10/13 15:34:17] d2.evaluation.evaluator INFO: Inference done 444/500. Dataloading: 0.0047 s/iter. Inference: 0.1342 s/iter. Eval: 0.0721 s/iter. Total: 0.2111 s/iter. ETA=0:00:11
[10/13 15:34:22] d2.evaluation.evaluator INFO: Inference done 468/500. Dataloading: 0.0047 s/iter. Inference: 0.1341 s/iter. Eval: 0.0721 s/iter. Total: 0.2110 s/iter. ETA=0:00:06
[10/13 15:34:27] d2.evaluation.evaluator INFO: Inference done 492/500. Dataloading: 0.0047 s/iter. Inference: 0.1340 s/iter. Eval: 0.0722 s/iter. Total: 0.2109 s/iter. ETA=0:00:01
[10/13 15:34:29] d2.evaluation.evaluator INFO: Total inference time: 0:01:44.476507 (0.211064 s / iter per device, on 1 devices)
[10/13 15:34:29] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.133938 s / iter per device, on 1 devices)
[10/13 15:34:29] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_eval4fi32ks_ ...
[10/13 15:34:52] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 55.291 | 79.729 | 68.138 |      19       |
| Things | 46.663 | 79.254 | 58.922 |       8       |
| Stuff  | 61.565 | 80.074 | 74.841 |      11       |
[10/13 15:34:52] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.449 | 96.850 | 99.586 |     Stuff     |
| class_8  | 70.902 | 83.051 | 85.371 |     Stuff     |
| class_11 | 86.064 | 88.600 | 97.137 |     Stuff     |
| class_12 | 39.569 | 79.138 | 50.000 |     Stuff     |
| class_13 | 34.064 | 74.252 | 45.876 |     Stuff     |
| class_17 | 37.774 | 61.829 | 61.094 |     Stuff     |
| class_19 | 41.681 | 67.127 | 62.093 |     Stuff     |
| class_20 | 60.036 | 74.403 | 80.690 |     Stuff     |
| class_21 | 88.296 | 89.212 | 98.973 |     Stuff     |
| class_22 | 34.889 | 75.306 | 46.330 |     Stuff     |
| class_23 | 87.495 | 91.045 | 96.101 |     Stuff     |
| class_24 | 46.916 | 74.240 | 63.194 |    Things     |
| class_25 | 44.366 | 71.981 | 61.635 |    Things     |
| class_26 | 62.496 | 81.723 | 76.473 |    Things     |
| class_27 | 51.006 | 86.073 | 59.259 |    Things     |
| class_28 | 63.094 | 90.363 | 69.822 |    Things     |
| class_31 | 25.517 | 86.120 | 29.630 |    Things     |
| class_32 | 40.488 | 73.103 | 55.385 |    Things     |
| class_33 | 39.421 | 70.426 | 55.975 |    Things     |
[10/13 15:34:52] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:34:52] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:34:52] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:34:52] d2.evaluation.testing INFO: copypaste: 55.2907,79.7286,68.1382,46.6629,79.2537,58.9217,61.5654,80.0740,74.8411,96.4490,96.8500,99.5859,70.9020,83.0515,85.3712,86.0637,88.6003,97.1370,39.5691,79.1383,50.0000,34.0642,74.2523,45.8763,37.7735,61.8286,61.0939,41.6807,67.1267,62.0926,60.0362,74.4032,80.6904,88.2960,89.2119,98.9733,34.8894,75.3059,46.3303,87.4954,91.0454,96.1009,46.9155,74.2399,63.1944,44.3658,71.9813,61.6352,62.4955,81.7227,76.4726,51.0060,86.0726,59.2593,63.0937,90.3630,69.8225,25.5171,86.1203,29.6296,40.4880,73.1033,55.3846,39.4215,70.4263,55.9755
[10/13 15:36:38] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 15:36:38] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 15:36:38] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 15:36:38] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 15:36:38] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 15:36:38] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 15:36:41] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0039 s/iter. Inference: 0.1307 s/iter. Eval: 0.0726 s/iter. Total: 0.2072 s/iter. ETA=0:01:41
[10/13 15:36:46] d2.evaluation.evaluator INFO: Inference done 36/500. Dataloading: 0.0046 s/iter. Inference: 0.1316 s/iter. Eval: 0.0717 s/iter. Total: 0.2079 s/iter. ETA=0:01:36
[10/13 15:36:51] d2.evaluation.evaluator INFO: Inference done 60/500. Dataloading: 0.0046 s/iter. Inference: 0.1333 s/iter. Eval: 0.0708 s/iter. Total: 0.2088 s/iter. ETA=0:01:31
[10/13 15:36:56] d2.evaluation.evaluator INFO: Inference done 84/500. Dataloading: 0.0046 s/iter. Inference: 0.1334 s/iter. Eval: 0.0712 s/iter. Total: 0.2092 s/iter. ETA=0:01:27
[10/13 15:37:01] d2.evaluation.evaluator INFO: Inference done 108/500. Dataloading: 0.0046 s/iter. Inference: 0.1335 s/iter. Eval: 0.0713 s/iter. Total: 0.2095 s/iter. ETA=0:01:22
[10/13 15:37:06] d2.evaluation.evaluator INFO: Inference done 132/500. Dataloading: 0.0047 s/iter. Inference: 0.1337 s/iter. Eval: 0.0715 s/iter. Total: 0.2099 s/iter. ETA=0:01:17
[10/13 15:37:11] d2.evaluation.evaluator INFO: Inference done 157/500. Dataloading: 0.0047 s/iter. Inference: 0.1333 s/iter. Eval: 0.0716 s/iter. Total: 0.2096 s/iter. ETA=0:01:11
[10/13 15:37:16] d2.evaluation.evaluator INFO: Inference done 181/500. Dataloading: 0.0047 s/iter. Inference: 0.1333 s/iter. Eval: 0.0715 s/iter. Total: 0.2096 s/iter. ETA=0:01:06
[10/13 15:37:21] d2.evaluation.evaluator INFO: Inference done 205/500. Dataloading: 0.0047 s/iter. Inference: 0.1334 s/iter. Eval: 0.0715 s/iter. Total: 0.2097 s/iter. ETA=0:01:01
[10/13 15:37:26] d2.evaluation.evaluator INFO: Inference done 229/500. Dataloading: 0.0047 s/iter. Inference: 0.1333 s/iter. Eval: 0.0716 s/iter. Total: 0.2096 s/iter. ETA=0:00:56
[10/13 15:37:32] d2.evaluation.evaluator INFO: Inference done 253/500. Dataloading: 0.0047 s/iter. Inference: 0.1333 s/iter. Eval: 0.0716 s/iter. Total: 0.2097 s/iter. ETA=0:00:51
[10/13 15:37:37] d2.evaluation.evaluator INFO: Inference done 277/500. Dataloading: 0.0047 s/iter. Inference: 0.1334 s/iter. Eval: 0.0716 s/iter. Total: 0.2098 s/iter. ETA=0:00:46
[10/13 15:37:42] d2.evaluation.evaluator INFO: Inference done 302/500. Dataloading: 0.0047 s/iter. Inference: 0.1332 s/iter. Eval: 0.0716 s/iter. Total: 0.2096 s/iter. ETA=0:00:41
[10/13 15:37:47] d2.evaluation.evaluator INFO: Inference done 327/500. Dataloading: 0.0048 s/iter. Inference: 0.1330 s/iter. Eval: 0.0715 s/iter. Total: 0.2092 s/iter. ETA=0:00:36
[10/13 15:37:52] d2.evaluation.evaluator INFO: Inference done 351/500. Dataloading: 0.0048 s/iter. Inference: 0.1329 s/iter. Eval: 0.0715 s/iter. Total: 0.2092 s/iter. ETA=0:00:31
[10/13 15:37:57] d2.evaluation.evaluator INFO: Inference done 375/500. Dataloading: 0.0048 s/iter. Inference: 0.1328 s/iter. Eval: 0.0716 s/iter. Total: 0.2092 s/iter. ETA=0:00:26
[10/13 15:38:02] d2.evaluation.evaluator INFO: Inference done 399/500. Dataloading: 0.0048 s/iter. Inference: 0.1328 s/iter. Eval: 0.0715 s/iter. Total: 0.2092 s/iter. ETA=0:00:21
[10/13 15:38:07] d2.evaluation.evaluator INFO: Inference done 424/500. Dataloading: 0.0048 s/iter. Inference: 0.1328 s/iter. Eval: 0.0715 s/iter. Total: 0.2091 s/iter. ETA=0:00:15
[10/13 15:38:12] d2.evaluation.evaluator INFO: Inference done 448/500. Dataloading: 0.0048 s/iter. Inference: 0.1328 s/iter. Eval: 0.0715 s/iter. Total: 0.2091 s/iter. ETA=0:00:10
[10/13 15:38:17] d2.evaluation.evaluator INFO: Inference done 472/500. Dataloading: 0.0048 s/iter. Inference: 0.1328 s/iter. Eval: 0.0714 s/iter. Total: 0.2091 s/iter. ETA=0:00:05
[10/13 15:38:22] d2.evaluation.evaluator INFO: Inference done 496/500. Dataloading: 0.0048 s/iter. Inference: 0.1328 s/iter. Eval: 0.0715 s/iter. Total: 0.2091 s/iter. ETA=0:00:00
[10/13 15:38:23] d2.evaluation.evaluator INFO: Total inference time: 0:01:43.592974 (0.209279 s / iter per device, on 1 devices)
[10/13 15:38:23] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:05 (0.132783 s / iter per device, on 1 devices)
[10/13 15:38:23] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalxhtmrpc5 ...
[10/13 15:38:47] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 55.615 | 79.701 | 68.373 |      19       |
| Things | 48.549 | 79.225 | 61.261 |       8       |
| Stuff  | 60.754 | 80.046 | 73.546 |      11       |
[10/13 15:38:47] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 97.026 | 97.328 | 99.690 |     Stuff     |
| class_8  | 69.305 | 82.837 | 83.664 |     Stuff     |
| class_11 | 85.510 | 88.499 | 96.622 |     Stuff     |
| class_12 | 39.240 | 79.487 | 49.367 |     Stuff     |
| class_13 | 36.415 | 74.348 | 48.980 |     Stuff     |
| class_17 | 28.872 | 61.241 | 47.144 |     Stuff     |
| class_19 | 39.498 | 66.834 | 59.099 |     Stuff     |
| class_20 | 62.451 | 74.990 | 83.279 |     Stuff     |
| class_21 | 88.213 | 89.130 | 98.971 |     Stuff     |
| class_22 | 35.237 | 74.837 | 47.084 |     Stuff     |
| class_23 | 86.527 | 90.978 | 95.108 |     Stuff     |
| class_24 | 49.266 | 74.990 | 65.697 |    Things     |
| class_25 | 42.677 | 71.836 | 59.408 |    Things     |
| class_26 | 63.060 | 81.715 | 77.171 |    Things     |
| class_27 | 45.001 | 88.930 | 50.602 |    Things     |
| class_28 | 56.768 | 89.266 | 63.594 |    Things     |
| class_31 | 50.493 | 84.921 | 59.459 |    Things     |
| class_32 | 41.016 | 72.188 | 56.818 |    Things     |
| class_33 | 40.110 | 69.959 | 57.334 |    Things     |
[10/13 15:38:47] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:38:47] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:38:47] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:38:47] d2.evaluation.testing INFO: copypaste: 55.6149,79.7006,68.3733,48.5488,79.2254,61.2606,60.7539,80.0461,73.5463,97.0259,97.3278,99.6898,69.3049,82.8367,83.6645,85.5096,88.4988,96.6223,39.2402,79.4866,49.3671,36.4153,74.3478,48.9796,28.8717,61.2410,47.1443,39.4984,66.8342,59.0991,62.4506,74.9898,83.2787,88.2130,89.1300,98.9712,35.2365,74.8372,47.0842,86.5270,90.9776,95.1081,49.2657,74.9895,65.6969,42.6767,71.8363,59.4083,63.0603,81.7153,77.1708,45.0006,88.9297,50.6024,56.7683,89.2661,63.5945,50.4933,84.9206,59.4595,41.0157,72.1876,56.8182,40.1100,69.9585,57.3340
[10/13 15:40:32] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 15:40:32] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 15:40:32] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 15:40:32] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 15:40:32] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 15:40:32] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 15:40:34] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0038 s/iter. Inference: 0.1314 s/iter. Eval: 0.0724 s/iter. Total: 0.2075 s/iter. ETA=0:01:41
[10/13 15:40:39] d2.evaluation.evaluator INFO: Inference done 36/500. Dataloading: 0.0047 s/iter. Inference: 0.1319 s/iter. Eval: 0.0701 s/iter. Total: 0.2067 s/iter. ETA=0:01:35
[10/13 15:40:45] d2.evaluation.evaluator INFO: Inference done 61/500. Dataloading: 0.0050 s/iter. Inference: 0.1336 s/iter. Eval: 0.0673 s/iter. Total: 0.2059 s/iter. ETA=0:01:30
[10/13 15:40:50] d2.evaluation.evaluator INFO: Inference done 85/500. Dataloading: 0.0049 s/iter. Inference: 0.1338 s/iter. Eval: 0.0687 s/iter. Total: 0.2075 s/iter. ETA=0:01:26
[10/13 15:40:55] d2.evaluation.evaluator INFO: Inference done 109/500. Dataloading: 0.0049 s/iter. Inference: 0.1338 s/iter. Eval: 0.0694 s/iter. Total: 0.2082 s/iter. ETA=0:01:21
[10/13 15:41:00] d2.evaluation.evaluator INFO: Inference done 133/500. Dataloading: 0.0048 s/iter. Inference: 0.1336 s/iter. Eval: 0.0699 s/iter. Total: 0.2084 s/iter. ETA=0:01:16
[10/13 15:41:05] d2.evaluation.evaluator INFO: Inference done 157/500. Dataloading: 0.0048 s/iter. Inference: 0.1335 s/iter. Eval: 0.0703 s/iter. Total: 0.2087 s/iter. ETA=0:01:11
[10/13 15:41:10] d2.evaluation.evaluator INFO: Inference done 181/500. Dataloading: 0.0048 s/iter. Inference: 0.1335 s/iter. Eval: 0.0706 s/iter. Total: 0.2089 s/iter. ETA=0:01:06
[10/13 15:41:15] d2.evaluation.evaluator INFO: Inference done 205/500. Dataloading: 0.0048 s/iter. Inference: 0.1338 s/iter. Eval: 0.0707 s/iter. Total: 0.2094 s/iter. ETA=0:01:01
[10/13 15:41:20] d2.evaluation.evaluator INFO: Inference done 229/500. Dataloading: 0.0048 s/iter. Inference: 0.1337 s/iter. Eval: 0.0709 s/iter. Total: 0.2094 s/iter. ETA=0:00:56
[10/13 15:41:25] d2.evaluation.evaluator INFO: Inference done 253/500. Dataloading: 0.0048 s/iter. Inference: 0.1337 s/iter. Eval: 0.0710 s/iter. Total: 0.2096 s/iter. ETA=0:00:51
[10/13 15:41:30] d2.evaluation.evaluator INFO: Inference done 278/500. Dataloading: 0.0048 s/iter. Inference: 0.1334 s/iter. Eval: 0.0712 s/iter. Total: 0.2094 s/iter. ETA=0:00:46
[10/13 15:41:35] d2.evaluation.evaluator INFO: Inference done 303/500. Dataloading: 0.0048 s/iter. Inference: 0.1330 s/iter. Eval: 0.0714 s/iter. Total: 0.2092 s/iter. ETA=0:00:41
[10/13 15:41:41] d2.evaluation.evaluator INFO: Inference done 328/500. Dataloading: 0.0048 s/iter. Inference: 0.1326 s/iter. Eval: 0.0715 s/iter. Total: 0.2090 s/iter. ETA=0:00:35
[10/13 15:41:46] d2.evaluation.evaluator INFO: Inference done 352/500. Dataloading: 0.0048 s/iter. Inference: 0.1326 s/iter. Eval: 0.0715 s/iter. Total: 0.2090 s/iter. ETA=0:00:30
[10/13 15:41:51] d2.evaluation.evaluator INFO: Inference done 376/500. Dataloading: 0.0048 s/iter. Inference: 0.1326 s/iter. Eval: 0.0716 s/iter. Total: 0.2091 s/iter. ETA=0:00:25
[10/13 15:41:56] d2.evaluation.evaluator INFO: Inference done 400/500. Dataloading: 0.0048 s/iter. Inference: 0.1326 s/iter. Eval: 0.0716 s/iter. Total: 0.2091 s/iter. ETA=0:00:20
[10/13 15:42:01] d2.evaluation.evaluator INFO: Inference done 424/500. Dataloading: 0.0048 s/iter. Inference: 0.1326 s/iter. Eval: 0.0717 s/iter. Total: 0.2091 s/iter. ETA=0:00:15
[10/13 15:42:06] d2.evaluation.evaluator INFO: Inference done 449/500. Dataloading: 0.0048 s/iter. Inference: 0.1325 s/iter. Eval: 0.0717 s/iter. Total: 0.2091 s/iter. ETA=0:00:10
[10/13 15:42:11] d2.evaluation.evaluator INFO: Inference done 473/500. Dataloading: 0.0048 s/iter. Inference: 0.1325 s/iter. Eval: 0.0718 s/iter. Total: 0.2091 s/iter. ETA=0:00:05
[10/13 15:42:16] d2.evaluation.evaluator INFO: Inference done 497/500. Dataloading: 0.0048 s/iter. Inference: 0.1325 s/iter. Eval: 0.0718 s/iter. Total: 0.2091 s/iter. ETA=0:00:00
[10/13 15:42:17] d2.evaluation.evaluator INFO: Total inference time: 0:01:43.569748 (0.209232 s / iter per device, on 1 devices)
[10/13 15:42:17] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:05 (0.132485 s / iter per device, on 1 devices)
[10/13 15:42:17] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evaldro7fwuo ...
[10/13 15:42:40] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 55.366 | 79.339 | 68.477 |      19       |
| Things | 46.530 | 78.590 | 59.081 |       8       |
| Stuff  | 61.792 | 79.884 | 75.311 |      11       |
[10/13 15:42:40] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.908 | 97.311 | 99.586 |     Stuff     |
| class_8  | 72.067 | 82.923 | 86.909 |     Stuff     |
| class_11 | 85.871 | 88.301 | 97.248 |     Stuff     |
| class_12 | 41.582 | 78.313 | 53.097 |     Stuff     |
| class_13 | 33.368 | 74.698 | 44.670 |     Stuff     |
| class_17 | 36.965 | 62.291 | 59.343 |     Stuff     |
| class_19 | 43.733 | 67.128 | 65.149 |     Stuff     |
| class_20 | 61.786 | 74.206 | 83.262 |     Stuff     |
| class_21 | 87.812 | 88.632 | 99.075 |     Stuff     |
| class_22 | 33.775 | 74.058 | 45.607 |     Stuff     |
| class_23 | 85.839 | 90.858 | 94.476 |     Stuff     |
| class_24 | 47.840 | 74.773 | 63.981 |    Things     |
| class_25 | 42.918 | 71.286 | 60.205 |    Things     |
| class_26 | 60.569 | 81.070 | 74.712 |    Things     |
| class_27 | 46.664 | 86.795 | 53.763 |    Things     |
| class_28 | 60.162 | 89.715 | 67.059 |    Things     |
| class_31 | 37.325 | 82.648 | 45.161 |    Things     |
| class_32 | 39.359 | 72.471 | 54.310 |    Things     |
| class_33 | 37.400 | 69.959 | 53.460 |    Things     |
[10/13 15:42:40] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:42:40] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:42:40] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:42:40] d2.evaluation.testing INFO: copypaste: 55.3655,79.3389,68.4775,46.5296,78.5896,59.0814,61.7916,79.8838,75.3110,96.9084,97.3114,99.5859,72.0674,82.9231,86.9087,85.8712,88.3015,97.2477,41.5821,78.3130,53.0973,33.3677,74.6982,44.6701,36.9655,62.2913,59.3429,43.7333,67.1282,65.1489,61.7856,74.2064,83.2618,87.8124,88.6322,99.0750,33.7754,74.0580,45.6067,85.8392,90.8584,94.4758,47.8403,74.7731,63.9807,42.9179,71.2860,60.2052,60.5686,81.0699,74.7116,46.6641,86.7952,53.7634,60.1616,89.7146,67.0588,37.3251,82.6485,45.1613,39.3591,72.4706,54.3103,37.3999,69.9590,53.4597
[10/13 15:44:27] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 15:44:27] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 15:44:27] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 15:44:27] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 15:44:27] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 15:44:27] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 15:44:29] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0040 s/iter. Inference: 0.1307 s/iter. Eval: 0.0727 s/iter. Total: 0.2074 s/iter. ETA=0:01:41
[10/13 15:44:34] d2.evaluation.evaluator INFO: Inference done 34/500. Dataloading: 0.0049 s/iter. Inference: 0.1444 s/iter. Eval: 0.0693 s/iter. Total: 0.2187 s/iter. ETA=0:01:41
[10/13 15:44:40] d2.evaluation.evaluator INFO: Inference done 57/500. Dataloading: 0.0050 s/iter. Inference: 0.1485 s/iter. Eval: 0.0686 s/iter. Total: 0.2221 s/iter. ETA=0:01:38
[10/13 15:44:45] d2.evaluation.evaluator INFO: Inference done 80/500. Dataloading: 0.0050 s/iter. Inference: 0.1480 s/iter. Eval: 0.0698 s/iter. Total: 0.2228 s/iter. ETA=0:01:33
[10/13 15:44:50] d2.evaluation.evaluator INFO: Inference done 103/500. Dataloading: 0.0050 s/iter. Inference: 0.1485 s/iter. Eval: 0.0698 s/iter. Total: 0.2234 s/iter. ETA=0:01:28
[10/13 15:44:55] d2.evaluation.evaluator INFO: Inference done 126/500. Dataloading: 0.0050 s/iter. Inference: 0.1475 s/iter. Eval: 0.0704 s/iter. Total: 0.2229 s/iter. ETA=0:01:23
[10/13 15:45:00] d2.evaluation.evaluator INFO: Inference done 150/500. Dataloading: 0.0050 s/iter. Inference: 0.1449 s/iter. Eval: 0.0712 s/iter. Total: 0.2211 s/iter. ETA=0:01:17
[10/13 15:45:05] d2.evaluation.evaluator INFO: Inference done 174/500. Dataloading: 0.0050 s/iter. Inference: 0.1435 s/iter. Eval: 0.0716 s/iter. Total: 0.2202 s/iter. ETA=0:01:11
[10/13 15:45:10] d2.evaluation.evaluator INFO: Inference done 196/500. Dataloading: 0.0050 s/iter. Inference: 0.1449 s/iter. Eval: 0.0714 s/iter. Total: 0.2213 s/iter. ETA=0:01:07
[10/13 15:45:15] d2.evaluation.evaluator INFO: Inference done 219/500. Dataloading: 0.0050 s/iter. Inference: 0.1451 s/iter. Eval: 0.0716 s/iter. Total: 0.2217 s/iter. ETA=0:01:02
[10/13 15:45:21] d2.evaluation.evaluator INFO: Inference done 243/500. Dataloading: 0.0050 s/iter. Inference: 0.1440 s/iter. Eval: 0.0720 s/iter. Total: 0.2210 s/iter. ETA=0:00:56
[10/13 15:45:26] d2.evaluation.evaluator INFO: Inference done 267/500. Dataloading: 0.0050 s/iter. Inference: 0.1433 s/iter. Eval: 0.0722 s/iter. Total: 0.2205 s/iter. ETA=0:00:51
[10/13 15:45:31] d2.evaluation.evaluator INFO: Inference done 291/500. Dataloading: 0.0050 s/iter. Inference: 0.1420 s/iter. Eval: 0.0726 s/iter. Total: 0.2197 s/iter. ETA=0:00:45
[10/13 15:45:36] d2.evaluation.evaluator INFO: Inference done 314/500. Dataloading: 0.0050 s/iter. Inference: 0.1415 s/iter. Eval: 0.0732 s/iter. Total: 0.2198 s/iter. ETA=0:00:40
[10/13 15:45:41] d2.evaluation.evaluator INFO: Inference done 337/500. Dataloading: 0.0050 s/iter. Inference: 0.1416 s/iter. Eval: 0.0731 s/iter. Total: 0.2198 s/iter. ETA=0:00:35
[10/13 15:45:46] d2.evaluation.evaluator INFO: Inference done 360/500. Dataloading: 0.0050 s/iter. Inference: 0.1418 s/iter. Eval: 0.0733 s/iter. Total: 0.2201 s/iter. ETA=0:00:30
[10/13 15:45:51] d2.evaluation.evaluator INFO: Inference done 382/500. Dataloading: 0.0050 s/iter. Inference: 0.1422 s/iter. Eval: 0.0733 s/iter. Total: 0.2206 s/iter. ETA=0:00:26
[10/13 15:45:56] d2.evaluation.evaluator INFO: Inference done 405/500. Dataloading: 0.0050 s/iter. Inference: 0.1423 s/iter. Eval: 0.0731 s/iter. Total: 0.2206 s/iter. ETA=0:00:20
[10/13 15:46:01] d2.evaluation.evaluator INFO: Inference done 429/500. Dataloading: 0.0050 s/iter. Inference: 0.1419 s/iter. Eval: 0.0732 s/iter. Total: 0.2201 s/iter. ETA=0:00:15
[10/13 15:46:06] d2.evaluation.evaluator INFO: Inference done 453/500. Dataloading: 0.0050 s/iter. Inference: 0.1416 s/iter. Eval: 0.0731 s/iter. Total: 0.2198 s/iter. ETA=0:00:10
[10/13 15:46:12] d2.evaluation.evaluator INFO: Inference done 477/500. Dataloading: 0.0051 s/iter. Inference: 0.1415 s/iter. Eval: 0.0730 s/iter. Total: 0.2196 s/iter. ETA=0:00:05
[10/13 15:46:17] d2.evaluation.evaluator INFO: Inference done 499/500. Dataloading: 0.0051 s/iter. Inference: 0.1419 s/iter. Eval: 0.0732 s/iter. Total: 0.2201 s/iter. ETA=0:00:00
[10/13 15:46:17] d2.evaluation.evaluator INFO: Total inference time: 0:01:49.037849 (0.220278 s / iter per device, on 1 devices)
[10/13 15:46:17] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:10 (0.141865 s / iter per device, on 1 devices)
[10/13 15:46:17] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_eval5n4owy8n ...
[10/13 15:46:41] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 56.231 | 79.426 | 69.375 |      19       |
| Things | 48.658 | 78.753 | 61.522 |       8       |
| Stuff  | 61.739 | 79.916 | 75.085 |      11       |
[10/13 15:46:41] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.616 | 96.917 | 99.690 |     Stuff     |
| class_8  | 71.850 | 83.367 | 86.184 |     Stuff     |
| class_11 | 86.334 | 88.692 | 97.342 |     Stuff     |
| class_12 | 40.621 | 77.590 | 52.353 |     Stuff     |
| class_13 | 35.813 | 74.077 | 48.346 |     Stuff     |
| class_17 | 34.639 | 61.728 | 56.115 |     Stuff     |
| class_19 | 41.329 | 67.420 | 61.301 |     Stuff     |
| class_20 | 60.827 | 74.497 | 81.650 |     Stuff     |
| class_21 | 88.085 | 88.907 | 99.075 |     Stuff     |
| class_22 | 36.740 | 74.905 | 49.049 |     Stuff     |
| class_23 | 86.276 | 90.976 | 94.834 |     Stuff     |
| class_24 | 48.267 | 74.834 | 64.498 |    Things     |
| class_25 | 45.229 | 72.833 | 62.100 |    Things     |
| class_26 | 62.655 | 81.675 | 76.713 |    Things     |
| class_27 | 51.000 | 86.000 | 59.302 |    Things     |
| class_28 | 61.464 | 91.057 | 67.500 |    Things     |
| class_31 | 43.161 | 81.698 | 52.830 |    Things     |
| class_32 | 38.591 | 72.104 | 53.521 |    Things     |
| class_33 | 38.902 | 69.824 | 55.714 |    Things     |
[10/13 15:46:41] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:46:41] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:46:41] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:46:41] d2.evaluation.testing INFO: copypaste: 56.2315,79.4264,69.3746,48.6585,78.7529,61.5224,61.7391,79.9161,75.0853,96.6164,96.9171,99.6898,71.8496,83.3674,86.1842,86.3341,88.6919,97.3415,40.6205,77.5897,52.3529,35.8135,74.0773,48.3461,34.6390,61.7284,56.1151,41.3291,67.4195,61.3014,60.8274,74.4974,81.6504,88.0849,88.9073,99.0750,36.7400,74.9053,49.0486,86.2755,90.9758,94.8335,48.2667,74.8344,64.4980,45.2294,72.8326,62.1005,62.6550,81.6746,76.7130,50.9997,85.9995,59.3023,61.4636,91.0571,67.5000,43.1611,81.6978,52.8302,38.5907,72.1037,53.5211,38.9017,69.8236,55.7143
[10/13 15:48:27] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 15:48:27] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 15:48:27] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 15:48:27] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 15:48:27] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 15:48:27] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 15:48:30] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0049 s/iter. Inference: 0.1540 s/iter. Eval: 0.0696 s/iter. Total: 0.2284 s/iter. ETA=0:01:51
[10/13 15:48:35] d2.evaluation.evaluator INFO: Inference done 34/500. Dataloading: 0.0055 s/iter. Inference: 0.1466 s/iter. Eval: 0.0723 s/iter. Total: 0.2244 s/iter. ETA=0:01:44
[10/13 15:48:40] d2.evaluation.evaluator INFO: Inference done 57/500. Dataloading: 0.0054 s/iter. Inference: 0.1449 s/iter. Eval: 0.0723 s/iter. Total: 0.2227 s/iter. ETA=0:01:38
[10/13 15:48:45] d2.evaluation.evaluator INFO: Inference done 80/500. Dataloading: 0.0053 s/iter. Inference: 0.1444 s/iter. Eval: 0.0719 s/iter. Total: 0.2217 s/iter. ETA=0:01:33
[10/13 15:48:50] d2.evaluation.evaluator INFO: Inference done 104/500. Dataloading: 0.0054 s/iter. Inference: 0.1432 s/iter. Eval: 0.0718 s/iter. Total: 0.2205 s/iter. ETA=0:01:27
[10/13 15:48:55] d2.evaluation.evaluator INFO: Inference done 128/500. Dataloading: 0.0053 s/iter. Inference: 0.1419 s/iter. Eval: 0.0719 s/iter. Total: 0.2192 s/iter. ETA=0:01:21
[10/13 15:49:01] d2.evaluation.evaluator INFO: Inference done 152/500. Dataloading: 0.0052 s/iter. Inference: 0.1417 s/iter. Eval: 0.0716 s/iter. Total: 0.2186 s/iter. ETA=0:01:16
[10/13 15:49:06] d2.evaluation.evaluator INFO: Inference done 176/500. Dataloading: 0.0052 s/iter. Inference: 0.1408 s/iter. Eval: 0.0716 s/iter. Total: 0.2177 s/iter. ETA=0:01:10
[10/13 15:49:11] d2.evaluation.evaluator INFO: Inference done 200/500. Dataloading: 0.0051 s/iter. Inference: 0.1405 s/iter. Eval: 0.0715 s/iter. Total: 0.2173 s/iter. ETA=0:01:05
[10/13 15:49:16] d2.evaluation.evaluator INFO: Inference done 224/500. Dataloading: 0.0051 s/iter. Inference: 0.1400 s/iter. Eval: 0.0714 s/iter. Total: 0.2166 s/iter. ETA=0:00:59
[10/13 15:49:21] d2.evaluation.evaluator INFO: Inference done 248/500. Dataloading: 0.0051 s/iter. Inference: 0.1397 s/iter. Eval: 0.0714 s/iter. Total: 0.2162 s/iter. ETA=0:00:54
[10/13 15:49:26] d2.evaluation.evaluator INFO: Inference done 272/500. Dataloading: 0.0050 s/iter. Inference: 0.1390 s/iter. Eval: 0.0715 s/iter. Total: 0.2156 s/iter. ETA=0:00:49
[10/13 15:49:31] d2.evaluation.evaluator INFO: Inference done 297/500. Dataloading: 0.0050 s/iter. Inference: 0.1381 s/iter. Eval: 0.0716 s/iter. Total: 0.2148 s/iter. ETA=0:00:43
[10/13 15:49:36] d2.evaluation.evaluator INFO: Inference done 322/500. Dataloading: 0.0050 s/iter. Inference: 0.1373 s/iter. Eval: 0.0717 s/iter. Total: 0.2141 s/iter. ETA=0:00:38
[10/13 15:49:41] d2.evaluation.evaluator INFO: Inference done 346/500. Dataloading: 0.0050 s/iter. Inference: 0.1370 s/iter. Eval: 0.0718 s/iter. Total: 0.2138 s/iter. ETA=0:00:32
[10/13 15:49:46] d2.evaluation.evaluator INFO: Inference done 370/500. Dataloading: 0.0050 s/iter. Inference: 0.1369 s/iter. Eval: 0.0718 s/iter. Total: 0.2137 s/iter. ETA=0:00:27
[10/13 15:49:52] d2.evaluation.evaluator INFO: Inference done 394/500. Dataloading: 0.0050 s/iter. Inference: 0.1369 s/iter. Eval: 0.0717 s/iter. Total: 0.2136 s/iter. ETA=0:00:22
[10/13 15:49:57] d2.evaluation.evaluator INFO: Inference done 419/500. Dataloading: 0.0050 s/iter. Inference: 0.1366 s/iter. Eval: 0.0716 s/iter. Total: 0.2133 s/iter. ETA=0:00:17
[10/13 15:50:02] d2.evaluation.evaluator INFO: Inference done 443/500. Dataloading: 0.0050 s/iter. Inference: 0.1364 s/iter. Eval: 0.0716 s/iter. Total: 0.2131 s/iter. ETA=0:00:12
[10/13 15:50:07] d2.evaluation.evaluator INFO: Inference done 467/500. Dataloading: 0.0050 s/iter. Inference: 0.1362 s/iter. Eval: 0.0717 s/iter. Total: 0.2129 s/iter. ETA=0:00:07
[10/13 15:50:12] d2.evaluation.evaluator INFO: Inference done 491/500. Dataloading: 0.0050 s/iter. Inference: 0.1362 s/iter. Eval: 0.0717 s/iter. Total: 0.2129 s/iter. ETA=0:00:01
[10/13 15:50:14] d2.evaluation.evaluator INFO: Total inference time: 0:01:45.428677 (0.212987 s / iter per device, on 1 devices)
[10/13 15:50:14] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:07 (0.136093 s / iter per device, on 1 devices)
[10/13 15:50:14] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_eval1_h247q3 ...
[10/13 15:50:37] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 56.682 | 79.801 | 69.731 |      19       |
| Things | 49.970 | 79.023 | 62.968 |       8       |
| Stuff  | 61.563 | 80.367 | 74.650 |      11       |
[10/13 15:50:37] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.678 | 97.182 | 99.482 |     Stuff     |
| class_8  | 67.907 | 83.585 | 81.243 |     Stuff     |
| class_11 | 86.503 | 88.489 | 97.755 |     Stuff     |
| class_12 | 39.489 | 79.472 | 49.689 |     Stuff     |
| class_13 | 33.837 | 74.566 | 45.378 |     Stuff     |
| class_17 | 37.949 | 61.907 | 61.300 |     Stuff     |
| class_19 | 44.078 | 67.406 | 65.391 |     Stuff     |
| class_20 | 62.963 | 75.228 | 83.696 |     Stuff     |
| class_21 | 88.602 | 89.521 | 98.973 |     Stuff     |
| class_22 | 32.388 | 75.801 | 42.727 |     Stuff     |
| class_23 | 86.802 | 90.881 | 95.512 |     Stuff     |
| class_24 | 48.712 | 74.724 | 65.189 |    Things     |
| class_25 | 42.396 | 72.566 | 58.424 |    Things     |
| class_26 | 63.232 | 81.621 | 77.471 |    Things     |
| class_27 | 53.574 | 86.630 | 61.842 |    Things     |
| class_28 | 63.137 | 89.614 | 70.455 |    Things     |
| class_31 | 46.425 | 83.178 | 55.814 |    Things     |
| class_32 | 40.659 | 74.125 | 54.852 |    Things     |
| class_33 | 41.622 | 69.725 | 59.694 |    Things     |
[10/13 15:50:37] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:50:37] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:50:37] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:50:37] d2.evaluation.testing INFO: copypaste: 56.6817,79.8011,69.7310,49.9696,79.0228,62.9677,61.5632,80.3671,74.6498,96.6782,97.1817,99.4819,67.9069,83.5849,81.2431,86.5027,88.4892,97.7551,39.4892,79.4720,49.6894,33.8369,74.5664,45.3782,37.9492,61.9071,61.3003,44.0776,67.4059,65.3913,62.9628,75.2283,83.6957,88.6019,89.5210,98.9733,32.3879,75.8014,42.7273,86.8020,90.8807,95.5121,48.7120,74.7240,65.1892,42.3963,72.5663,58.4242,63.2318,81.6205,77.4705,53.5741,86.6304,61.8421,63.1369,89.6136,70.4545,46.4247,83.1776,55.8140,40.6592,74.1248,54.8523,41.6222,69.7254,59.6944
[10/13 15:52:23] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 15:52:23] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 15:52:23] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 15:52:23] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 15:52:23] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 15:52:23] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 15:52:26] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0041 s/iter. Inference: 0.1337 s/iter. Eval: 0.0744 s/iter. Total: 0.2122 s/iter. ETA=0:01:43
[10/13 15:52:31] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0048 s/iter. Inference: 0.1353 s/iter. Eval: 0.0740 s/iter. Total: 0.2142 s/iter. ETA=0:01:39
[10/13 15:52:36] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0049 s/iter. Inference: 0.1350 s/iter. Eval: 0.0748 s/iter. Total: 0.2147 s/iter. ETA=0:01:34
[10/13 15:52:41] d2.evaluation.evaluator INFO: Inference done 83/500. Dataloading: 0.0049 s/iter. Inference: 0.1355 s/iter. Eval: 0.0751 s/iter. Total: 0.2156 s/iter. ETA=0:01:29
[10/13 15:52:47] d2.evaluation.evaluator INFO: Inference done 106/500. Dataloading: 0.0051 s/iter. Inference: 0.1365 s/iter. Eval: 0.0750 s/iter. Total: 0.2166 s/iter. ETA=0:01:25
[10/13 15:52:52] d2.evaluation.evaluator INFO: Inference done 129/500. Dataloading: 0.0052 s/iter. Inference: 0.1373 s/iter. Eval: 0.0749 s/iter. Total: 0.2173 s/iter. ETA=0:01:20
[10/13 15:52:57] d2.evaluation.evaluator INFO: Inference done 152/500. Dataloading: 0.0053 s/iter. Inference: 0.1376 s/iter. Eval: 0.0748 s/iter. Total: 0.2178 s/iter. ETA=0:01:15
[10/13 15:53:02] d2.evaluation.evaluator INFO: Inference done 176/500. Dataloading: 0.0053 s/iter. Inference: 0.1379 s/iter. Eval: 0.0740 s/iter. Total: 0.2173 s/iter. ETA=0:01:10
[10/13 15:53:07] d2.evaluation.evaluator INFO: Inference done 203/500. Dataloading: 0.0054 s/iter. Inference: 0.1372 s/iter. Eval: 0.0712 s/iter. Total: 0.2138 s/iter. ETA=0:01:03
[10/13 15:53:12] d2.evaluation.evaluator INFO: Inference done 226/500. Dataloading: 0.0054 s/iter. Inference: 0.1385 s/iter. Eval: 0.0709 s/iter. Total: 0.2148 s/iter. ETA=0:00:58
[10/13 15:53:17] d2.evaluation.evaluator INFO: Inference done 248/500. Dataloading: 0.0054 s/iter. Inference: 0.1392 s/iter. Eval: 0.0714 s/iter. Total: 0.2160 s/iter. ETA=0:00:54
[10/13 15:53:22] d2.evaluation.evaluator INFO: Inference done 272/500. Dataloading: 0.0053 s/iter. Inference: 0.1387 s/iter. Eval: 0.0717 s/iter. Total: 0.2158 s/iter. ETA=0:00:49
[10/13 15:53:27] d2.evaluation.evaluator INFO: Inference done 296/500. Dataloading: 0.0053 s/iter. Inference: 0.1384 s/iter. Eval: 0.0719 s/iter. Total: 0.2157 s/iter. ETA=0:00:44
[10/13 15:53:32] d2.evaluation.evaluator INFO: Inference done 319/500. Dataloading: 0.0053 s/iter. Inference: 0.1384 s/iter. Eval: 0.0721 s/iter. Total: 0.2158 s/iter. ETA=0:00:39
[10/13 15:53:38] d2.evaluation.evaluator INFO: Inference done 343/500. Dataloading: 0.0053 s/iter. Inference: 0.1381 s/iter. Eval: 0.0723 s/iter. Total: 0.2157 s/iter. ETA=0:00:33
[10/13 15:53:43] d2.evaluation.evaluator INFO: Inference done 366/500. Dataloading: 0.0052 s/iter. Inference: 0.1383 s/iter. Eval: 0.0724 s/iter. Total: 0.2160 s/iter. ETA=0:00:28
[10/13 15:53:48] d2.evaluation.evaluator INFO: Inference done 389/500. Dataloading: 0.0052 s/iter. Inference: 0.1383 s/iter. Eval: 0.0725 s/iter. Total: 0.2161 s/iter. ETA=0:00:23
[10/13 15:53:53] d2.evaluation.evaluator INFO: Inference done 413/500. Dataloading: 0.0052 s/iter. Inference: 0.1383 s/iter. Eval: 0.0724 s/iter. Total: 0.2160 s/iter. ETA=0:00:18
[10/13 15:53:58] d2.evaluation.evaluator INFO: Inference done 439/500. Dataloading: 0.0053 s/iter. Inference: 0.1379 s/iter. Eval: 0.0715 s/iter. Total: 0.2147 s/iter. ETA=0:00:13
[10/13 15:54:03] d2.evaluation.evaluator INFO: Inference done 463/500. Dataloading: 0.0053 s/iter. Inference: 0.1377 s/iter. Eval: 0.0715 s/iter. Total: 0.2146 s/iter. ETA=0:00:07
[10/13 15:54:08] d2.evaluation.evaluator INFO: Inference done 487/500. Dataloading: 0.0053 s/iter. Inference: 0.1376 s/iter. Eval: 0.0716 s/iter. Total: 0.2145 s/iter. ETA=0:00:02
[10/13 15:54:11] d2.evaluation.evaluator INFO: Total inference time: 0:01:46.173113 (0.214491 s / iter per device, on 1 devices)
[10/13 15:54:11] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:08 (0.137410 s / iter per device, on 1 devices)
[10/13 15:54:11] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalz45qzokl ...
[10/13 15:54:34] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 56.587 | 79.794 | 69.755 |      19       |
| Things | 47.826 | 79.290 | 60.355 |       8       |
| Stuff  | 62.958 | 80.161 | 76.591 |      11       |
[10/13 15:54:34] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.908 | 97.412 | 99.482 |     Stuff     |
| class_8  | 70.663 | 83.269 | 84.862 |     Stuff     |
| class_11 | 86.929 | 88.737 | 97.963 |     Stuff     |
| class_12 | 43.533 | 77.770 | 55.977 |     Stuff     |
| class_13 | 36.217 | 73.961 | 48.968 |     Stuff     |
| class_17 | 40.298 | 62.578 | 64.396 |     Stuff     |
| class_19 | 44.573 | 67.784 | 65.758 |     Stuff     |
| class_20 | 63.098 | 75.390 | 83.696 |     Stuff     |
| class_21 | 88.387 | 89.304 | 98.973 |     Stuff     |
| class_22 | 34.911 | 74.521 | 46.847 |     Stuff     |
| class_23 | 87.024 | 91.045 | 95.583 |     Stuff     |
| class_24 | 49.656 | 74.784 | 66.399 |    Things     |
| class_25 | 45.732 | 73.963 | 61.831 |    Things     |
| class_26 | 63.372 | 81.643 | 77.620 |    Things     |
| class_27 | 48.331 | 86.798 | 55.682 |    Things     |
| class_28 | 54.261 | 90.641 | 59.864 |    Things     |
| class_31 | 40.568 | 82.585 | 49.123 |    Things     |
| class_32 | 37.727 | 73.328 | 51.449 |    Things     |
| class_33 | 42.962 | 70.575 | 60.874 |    Things     |
[10/13 15:54:34] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:54:34] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:54:34] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:54:34] d2.evaluation.testing INFO: copypaste: 56.5868,79.7941,69.7551,47.8260,79.2896,60.3553,62.9583,80.1610,76.5913,96.9077,97.4124,99.4819,70.6633,83.2686,84.8619,86.9294,88.7367,97.9633,43.5331,77.7701,55.9767,36.2168,73.9608,48.9676,40.2977,62.5777,64.3963,44.5734,67.7839,65.7581,63.0983,75.3901,83.6957,88.3871,89.3040,98.9733,34.9107,74.5210,46.8468,87.0241,91.0454,95.5832,49.6561,74.7839,66.3994,45.7320,73.9627,61.8312,63.3717,81.6434,77.6201,48.3307,86.7981,55.6818,54.2611,90.6407,59.8639,40.5678,82.5845,49.1228,37.7267,73.3280,51.4493,42.9618,70.5753,60.8737
[10/13 15:56:20] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 15:56:20] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 15:56:20] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 15:56:20] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 15:56:20] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 15:56:20] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 15:56:23] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0038 s/iter. Inference: 0.1312 s/iter. Eval: 0.0729 s/iter. Total: 0.2079 s/iter. ETA=0:01:41
[10/13 15:56:28] d2.evaluation.evaluator INFO: Inference done 34/500. Dataloading: 0.0047 s/iter. Inference: 0.1384 s/iter. Eval: 0.0725 s/iter. Total: 0.2156 s/iter. ETA=0:01:40
[10/13 15:56:33] d2.evaluation.evaluator INFO: Inference done 57/500. Dataloading: 0.0048 s/iter. Inference: 0.1399 s/iter. Eval: 0.0724 s/iter. Total: 0.2171 s/iter. ETA=0:01:36
[10/13 15:56:38] d2.evaluation.evaluator INFO: Inference done 80/500. Dataloading: 0.0048 s/iter. Inference: 0.1401 s/iter. Eval: 0.0725 s/iter. Total: 0.2174 s/iter. ETA=0:01:31
[10/13 15:56:43] d2.evaluation.evaluator INFO: Inference done 105/500. Dataloading: 0.0051 s/iter. Inference: 0.1394 s/iter. Eval: 0.0703 s/iter. Total: 0.2148 s/iter. ETA=0:01:24
[10/13 15:56:48] d2.evaluation.evaluator INFO: Inference done 129/500. Dataloading: 0.0053 s/iter. Inference: 0.1391 s/iter. Eval: 0.0698 s/iter. Total: 0.2142 s/iter. ETA=0:01:19
[10/13 15:56:53] d2.evaluation.evaluator INFO: Inference done 153/500. Dataloading: 0.0053 s/iter. Inference: 0.1384 s/iter. Eval: 0.0697 s/iter. Total: 0.2134 s/iter. ETA=0:01:14
[10/13 15:56:58] d2.evaluation.evaluator INFO: Inference done 178/500. Dataloading: 0.0054 s/iter. Inference: 0.1377 s/iter. Eval: 0.0691 s/iter. Total: 0.2122 s/iter. ETA=0:01:08
[10/13 15:57:03] d2.evaluation.evaluator INFO: Inference done 203/500. Dataloading: 0.0055 s/iter. Inference: 0.1375 s/iter. Eval: 0.0678 s/iter. Total: 0.2108 s/iter. ETA=0:01:02
[10/13 15:57:09] d2.evaluation.evaluator INFO: Inference done 228/500. Dataloading: 0.0056 s/iter. Inference: 0.1375 s/iter. Eval: 0.0672 s/iter. Total: 0.2104 s/iter. ETA=0:00:57
[10/13 15:57:14] d2.evaluation.evaluator INFO: Inference done 252/500. Dataloading: 0.0056 s/iter. Inference: 0.1375 s/iter. Eval: 0.0674 s/iter. Total: 0.2106 s/iter. ETA=0:00:52
[10/13 15:57:19] d2.evaluation.evaluator INFO: Inference done 277/500. Dataloading: 0.0055 s/iter. Inference: 0.1371 s/iter. Eval: 0.0676 s/iter. Total: 0.2103 s/iter. ETA=0:00:46
[10/13 15:57:24] d2.evaluation.evaluator INFO: Inference done 301/500. Dataloading: 0.0055 s/iter. Inference: 0.1369 s/iter. Eval: 0.0681 s/iter. Total: 0.2106 s/iter. ETA=0:00:41
[10/13 15:57:29] d2.evaluation.evaluator INFO: Inference done 325/500. Dataloading: 0.0055 s/iter. Inference: 0.1367 s/iter. Eval: 0.0687 s/iter. Total: 0.2110 s/iter. ETA=0:00:36
[10/13 15:57:34] d2.evaluation.evaluator INFO: Inference done 348/500. Dataloading: 0.0055 s/iter. Inference: 0.1374 s/iter. Eval: 0.0689 s/iter. Total: 0.2118 s/iter. ETA=0:00:32
[10/13 15:57:39] d2.evaluation.evaluator INFO: Inference done 371/500. Dataloading: 0.0055 s/iter. Inference: 0.1375 s/iter. Eval: 0.0692 s/iter. Total: 0.2122 s/iter. ETA=0:00:27
[10/13 15:57:44] d2.evaluation.evaluator INFO: Inference done 394/500. Dataloading: 0.0055 s/iter. Inference: 0.1379 s/iter. Eval: 0.0695 s/iter. Total: 0.2129 s/iter. ETA=0:00:22
[10/13 15:57:50] d2.evaluation.evaluator INFO: Inference done 417/500. Dataloading: 0.0055 s/iter. Inference: 0.1385 s/iter. Eval: 0.0696 s/iter. Total: 0.2137 s/iter. ETA=0:00:17
[10/13 15:57:55] d2.evaluation.evaluator INFO: Inference done 440/500. Dataloading: 0.0054 s/iter. Inference: 0.1387 s/iter. Eval: 0.0697 s/iter. Total: 0.2139 s/iter. ETA=0:00:12
[10/13 15:58:00] d2.evaluation.evaluator INFO: Inference done 464/500. Dataloading: 0.0054 s/iter. Inference: 0.1385 s/iter. Eval: 0.0699 s/iter. Total: 0.2139 s/iter. ETA=0:00:07
[10/13 15:58:05] d2.evaluation.evaluator INFO: Inference done 488/500. Dataloading: 0.0054 s/iter. Inference: 0.1383 s/iter. Eval: 0.0700 s/iter. Total: 0.2138 s/iter. ETA=0:00:02
[10/13 15:58:08] d2.evaluation.evaluator INFO: Total inference time: 0:01:45.930610 (0.214001 s / iter per device, on 1 devices)
[10/13 15:58:08] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:08 (0.138256 s / iter per device, on 1 devices)
[10/13 15:58:08] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_eval4ucnrx9a ...
[10/13 15:58:31] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 56.708 | 79.858 | 69.704 |      19       |
| Things | 49.226 | 79.571 | 61.683 |       8       |
| Stuff  | 62.150 | 80.067 | 75.538 |      11       |
[10/13 15:58:31] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 97.184 | 97.487 | 99.690 |     Stuff     |
| class_8  | 72.179 | 83.625 | 86.313 |     Stuff     |
| class_11 | 86.156 | 88.594 | 97.248 |     Stuff     |
| class_12 | 43.444 | 76.470 | 56.812 |     Stuff     |
| class_13 | 32.693 | 73.188 | 44.670 |     Stuff     |
| class_17 | 37.540 | 62.017 | 60.532 |     Stuff     |
| class_19 | 45.251 | 67.756 | 66.785 |     Stuff     |
| class_20 | 61.549 | 75.434 | 81.593 |     Stuff     |
| class_21 | 88.413 | 89.145 | 99.179 |     Stuff     |
| class_22 | 33.095 | 75.804 | 43.659 |     Stuff     |
| class_23 | 86.144 | 91.217 | 94.438 |     Stuff     |
| class_24 | 48.995 | 75.166 | 65.182 |    Things     |
| class_25 | 46.582 | 72.488 | 64.261 |    Things     |
| class_26 | 63.953 | 82.096 | 77.901 |    Things     |
| class_27 | 49.050 | 87.089 | 56.322 |    Things     |
| class_28 | 62.230 | 91.123 | 68.293 |    Things     |
| class_31 | 45.614 | 85.009 | 53.659 |    Things     |
| class_32 | 38.407 | 73.424 | 52.308 |    Things     |
| class_33 | 38.975 | 70.176 | 55.539 |    Things     |
[10/13 15:58:31] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 15:58:31] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 15:58:31] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 15:58:31] d2.evaluation.testing INFO: copypaste: 56.7081,79.8583,69.7043,49.2257,79.5714,61.6829,62.1498,80.0670,75.5380,97.1843,97.4868,99.6898,72.1794,83.6247,86.3135,86.1556,88.5940,97.2477,43.4441,76.4704,56.8116,32.6930,73.1878,44.6701,37.5398,62.0168,60.5317,45.2508,67.7559,66.7851,61.5493,75.4344,81.5931,88.4127,89.1449,99.1786,33.0955,75.8044,43.6590,86.1437,91.2171,94.4381,48.9949,75.1661,65.1821,46.5816,72.4883,64.2608,63.9531,82.0958,77.9006,49.0500,87.0888,56.3218,62.2302,91.1228,68.2927,45.6144,85.0086,53.6585,38.4066,73.4244,52.3077,38.9749,70.1761,55.5387
[10/13 16:00:18] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 16:00:18] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 16:00:18] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 16:00:18] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 16:00:18] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 16:00:18] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 16:00:21] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0037 s/iter. Inference: 0.1329 s/iter. Eval: 0.0719 s/iter. Total: 0.2085 s/iter. ETA=0:01:41
[10/13 16:00:26] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0047 s/iter. Inference: 0.1334 s/iter. Eval: 0.0715 s/iter. Total: 0.2097 s/iter. ETA=0:01:37
[10/13 16:00:31] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0047 s/iter. Inference: 0.1338 s/iter. Eval: 0.0716 s/iter. Total: 0.2102 s/iter. ETA=0:01:32
[10/13 16:00:36] d2.evaluation.evaluator INFO: Inference done 83/500. Dataloading: 0.0048 s/iter. Inference: 0.1348 s/iter. Eval: 0.0701 s/iter. Total: 0.2098 s/iter. ETA=0:01:27
[10/13 16:00:41] d2.evaluation.evaluator INFO: Inference done 107/500. Dataloading: 0.0048 s/iter. Inference: 0.1352 s/iter. Eval: 0.0703 s/iter. Total: 0.2103 s/iter. ETA=0:01:22
[10/13 16:00:46] d2.evaluation.evaluator INFO: Inference done 131/500. Dataloading: 0.0048 s/iter. Inference: 0.1347 s/iter. Eval: 0.0705 s/iter. Total: 0.2100 s/iter. ETA=0:01:17
[10/13 16:00:51] d2.evaluation.evaluator INFO: Inference done 155/500. Dataloading: 0.0048 s/iter. Inference: 0.1343 s/iter. Eval: 0.0708 s/iter. Total: 0.2099 s/iter. ETA=0:01:12
[10/13 16:00:56] d2.evaluation.evaluator INFO: Inference done 179/500. Dataloading: 0.0048 s/iter. Inference: 0.1341 s/iter. Eval: 0.0709 s/iter. Total: 0.2099 s/iter. ETA=0:01:07
[10/13 16:01:01] d2.evaluation.evaluator INFO: Inference done 203/500. Dataloading: 0.0048 s/iter. Inference: 0.1342 s/iter. Eval: 0.0709 s/iter. Total: 0.2100 s/iter. ETA=0:01:02
[10/13 16:01:06] d2.evaluation.evaluator INFO: Inference done 227/500. Dataloading: 0.0048 s/iter. Inference: 0.1340 s/iter. Eval: 0.0710 s/iter. Total: 0.2099 s/iter. ETA=0:00:57
[10/13 16:01:11] d2.evaluation.evaluator INFO: Inference done 251/500. Dataloading: 0.0048 s/iter. Inference: 0.1339 s/iter. Eval: 0.0711 s/iter. Total: 0.2099 s/iter. ETA=0:00:52
[10/13 16:01:16] d2.evaluation.evaluator INFO: Inference done 275/500. Dataloading: 0.0048 s/iter. Inference: 0.1338 s/iter. Eval: 0.0712 s/iter. Total: 0.2098 s/iter. ETA=0:00:47
[10/13 16:01:21] d2.evaluation.evaluator INFO: Inference done 298/500. Dataloading: 0.0048 s/iter. Inference: 0.1334 s/iter. Eval: 0.0723 s/iter. Total: 0.2105 s/iter. ETA=0:00:42
[10/13 16:01:26] d2.evaluation.evaluator INFO: Inference done 323/500. Dataloading: 0.0048 s/iter. Inference: 0.1330 s/iter. Eval: 0.0724 s/iter. Total: 0.2102 s/iter. ETA=0:00:37
[10/13 16:01:31] d2.evaluation.evaluator INFO: Inference done 347/500. Dataloading: 0.0048 s/iter. Inference: 0.1330 s/iter. Eval: 0.0724 s/iter. Total: 0.2102 s/iter. ETA=0:00:32
[10/13 16:01:36] d2.evaluation.evaluator INFO: Inference done 371/500. Dataloading: 0.0048 s/iter. Inference: 0.1330 s/iter. Eval: 0.0724 s/iter. Total: 0.2102 s/iter. ETA=0:00:27
[10/13 16:01:41] d2.evaluation.evaluator INFO: Inference done 395/500. Dataloading: 0.0048 s/iter. Inference: 0.1332 s/iter. Eval: 0.0724 s/iter. Total: 0.2104 s/iter. ETA=0:00:22
[10/13 16:01:47] d2.evaluation.evaluator INFO: Inference done 419/500. Dataloading: 0.0048 s/iter. Inference: 0.1332 s/iter. Eval: 0.0724 s/iter. Total: 0.2104 s/iter. ETA=0:00:17
[10/13 16:01:52] d2.evaluation.evaluator INFO: Inference done 443/500. Dataloading: 0.0048 s/iter. Inference: 0.1331 s/iter. Eval: 0.0724 s/iter. Total: 0.2103 s/iter. ETA=0:00:11
[10/13 16:01:57] d2.evaluation.evaluator INFO: Inference done 467/500. Dataloading: 0.0048 s/iter. Inference: 0.1331 s/iter. Eval: 0.0724 s/iter. Total: 0.2103 s/iter. ETA=0:00:06
[10/13 16:02:02] d2.evaluation.evaluator INFO: Inference done 491/500. Dataloading: 0.0048 s/iter. Inference: 0.1331 s/iter. Eval: 0.0724 s/iter. Total: 0.2103 s/iter. ETA=0:00:01
[10/13 16:02:04] d2.evaluation.evaluator INFO: Total inference time: 0:01:44.157308 (0.210419 s / iter per device, on 1 devices)
[10/13 16:02:04] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:05 (0.133071 s / iter per device, on 1 devices)
[10/13 16:02:04] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalu__8s8uw ...
[10/13 16:02:27] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 56.681 | 80.066 | 69.591 |      19       |
| Things | 48.659 | 79.563 | 61.023 |       8       |
| Stuff  | 62.516 | 80.432 | 75.823 |      11       |
[10/13 16:02:27] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.906 | 97.207 | 99.690 |     Stuff     |
| class_8  | 71.120 | 83.372 | 85.304 |     Stuff     |
| class_11 | 86.118 | 88.747 | 97.038 |     Stuff     |
| class_12 | 40.442 | 78.447 | 51.553 |     Stuff     |
| class_13 | 36.152 | 75.279 | 48.024 |     Stuff     |
| class_17 | 37.889 | 62.356 | 60.762 |     Stuff     |
| class_19 | 43.271 | 67.082 | 64.505 |     Stuff     |
| class_20 | 63.573 | 75.667 | 84.017 |     Stuff     |
| class_21 | 88.333 | 89.249 | 98.973 |     Stuff     |
| class_22 | 38.045 | 76.438 | 49.772 |     Stuff     |
| class_23 | 85.825 | 90.904 | 94.413 |     Stuff     |
| class_24 | 47.877 | 74.330 | 64.412 |    Things     |
| class_25 | 41.222 | 73.386 | 56.171 |    Things     |
| class_26 | 64.298 | 82.102 | 78.315 |    Things     |
| class_27 | 45.373 | 88.773 | 51.111 |    Things     |
| class_28 | 61.515 | 90.223 | 68.182 |    Things     |
| class_31 | 47.725 | 84.603 | 56.410 |    Things     |
| class_32 | 41.555 | 73.200 | 56.769 |    Things     |
| class_33 | 39.705 | 69.886 | 56.814 |    Things     |
[10/13 16:02:27] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 16:02:27] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 16:02:27] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 16:02:27] d2.evaluation.testing INFO: copypaste: 56.6812,80.0658,69.5913,48.6587,79.5629,61.0229,62.5157,80.4316,75.8228,96.9058,97.2074,99.6898,71.1197,83.3722,85.3039,86.1178,88.7466,97.0378,40.4417,78.4472,51.5528,36.1521,75.2786,48.0243,37.8885,62.3555,60.7621,43.2715,67.0822,64.5051,63.5730,75.6666,84.0173,88.3327,89.2490,98.9733,38.0446,76.4382,49.7717,85.8255,90.9045,94.4128,47.8775,74.3303,64.4118,41.2216,73.3856,56.1713,64.2976,82.1017,78.3147,45.3727,88.7727,51.1111,61.5153,90.2225,68.1818,47.7250,84.6035,56.4103,41.5549,73.2005,56.7686,39.7049,69.8862,56.8136
[10/13 16:04:13] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 16:04:13] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 16:04:13] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 16:04:13] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 16:04:13] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 16:04:13] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 16:04:16] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0044 s/iter. Inference: 0.1508 s/iter. Eval: 0.0663 s/iter. Total: 0.2215 s/iter. ETA=0:01:48
[10/13 16:04:21] d2.evaluation.evaluator INFO: Inference done 37/500. Dataloading: 0.0054 s/iter. Inference: 0.1367 s/iter. Eval: 0.0610 s/iter. Total: 0.2032 s/iter. ETA=0:01:34
[10/13 16:04:26] d2.evaluation.evaluator INFO: Inference done 61/500. Dataloading: 0.0052 s/iter. Inference: 0.1380 s/iter. Eval: 0.0657 s/iter. Total: 0.2090 s/iter. ETA=0:01:31
[10/13 16:04:32] d2.evaluation.evaluator INFO: Inference done 84/500. Dataloading: 0.0051 s/iter. Inference: 0.1393 s/iter. Eval: 0.0683 s/iter. Total: 0.2128 s/iter. ETA=0:01:28
[10/13 16:04:37] d2.evaluation.evaluator INFO: Inference done 107/500. Dataloading: 0.0051 s/iter. Inference: 0.1412 s/iter. Eval: 0.0691 s/iter. Total: 0.2155 s/iter. ETA=0:01:24
[10/13 16:04:42] d2.evaluation.evaluator INFO: Inference done 131/500. Dataloading: 0.0050 s/iter. Inference: 0.1397 s/iter. Eval: 0.0699 s/iter. Total: 0.2147 s/iter. ETA=0:01:19
[10/13 16:04:47] d2.evaluation.evaluator INFO: Inference done 155/500. Dataloading: 0.0050 s/iter. Inference: 0.1386 s/iter. Eval: 0.0701 s/iter. Total: 0.2138 s/iter. ETA=0:01:13
[10/13 16:04:52] d2.evaluation.evaluator INFO: Inference done 180/500. Dataloading: 0.0051 s/iter. Inference: 0.1378 s/iter. Eval: 0.0693 s/iter. Total: 0.2122 s/iter. ETA=0:01:07
[10/13 16:04:57] d2.evaluation.evaluator INFO: Inference done 204/500. Dataloading: 0.0050 s/iter. Inference: 0.1377 s/iter. Eval: 0.0694 s/iter. Total: 0.2123 s/iter. ETA=0:01:02
[10/13 16:05:02] d2.evaluation.evaluator INFO: Inference done 228/500. Dataloading: 0.0050 s/iter. Inference: 0.1374 s/iter. Eval: 0.0696 s/iter. Total: 0.2121 s/iter. ETA=0:00:57
[10/13 16:05:07] d2.evaluation.evaluator INFO: Inference done 252/500. Dataloading: 0.0050 s/iter. Inference: 0.1371 s/iter. Eval: 0.0700 s/iter. Total: 0.2121 s/iter. ETA=0:00:52
[10/13 16:05:12] d2.evaluation.evaluator INFO: Inference done 276/500. Dataloading: 0.0050 s/iter. Inference: 0.1368 s/iter. Eval: 0.0700 s/iter. Total: 0.2119 s/iter. ETA=0:00:47
[10/13 16:05:17] d2.evaluation.evaluator INFO: Inference done 301/500. Dataloading: 0.0051 s/iter. Inference: 0.1363 s/iter. Eval: 0.0695 s/iter. Total: 0.2109 s/iter. ETA=0:00:41
[10/13 16:05:22] d2.evaluation.evaluator INFO: Inference done 326/500. Dataloading: 0.0051 s/iter. Inference: 0.1357 s/iter. Eval: 0.0695 s/iter. Total: 0.2103 s/iter. ETA=0:00:36
[10/13 16:05:27] d2.evaluation.evaluator INFO: Inference done 350/500. Dataloading: 0.0051 s/iter. Inference: 0.1356 s/iter. Eval: 0.0697 s/iter. Total: 0.2104 s/iter. ETA=0:00:31
[10/13 16:05:33] d2.evaluation.evaluator INFO: Inference done 375/500. Dataloading: 0.0051 s/iter. Inference: 0.1355 s/iter. Eval: 0.0696 s/iter. Total: 0.2103 s/iter. ETA=0:00:26
[10/13 16:05:38] d2.evaluation.evaluator INFO: Inference done 399/500. Dataloading: 0.0051 s/iter. Inference: 0.1355 s/iter. Eval: 0.0697 s/iter. Total: 0.2104 s/iter. ETA=0:00:21
[10/13 16:05:43] d2.evaluation.evaluator INFO: Inference done 423/500. Dataloading: 0.0051 s/iter. Inference: 0.1354 s/iter. Eval: 0.0697 s/iter. Total: 0.2103 s/iter. ETA=0:00:16
[10/13 16:05:48] d2.evaluation.evaluator INFO: Inference done 448/500. Dataloading: 0.0051 s/iter. Inference: 0.1353 s/iter. Eval: 0.0697 s/iter. Total: 0.2101 s/iter. ETA=0:00:10
[10/13 16:05:53] d2.evaluation.evaluator INFO: Inference done 472/500. Dataloading: 0.0051 s/iter. Inference: 0.1353 s/iter. Eval: 0.0697 s/iter. Total: 0.2101 s/iter. ETA=0:00:05
[10/13 16:05:58] d2.evaluation.evaluator INFO: Inference done 496/500. Dataloading: 0.0051 s/iter. Inference: 0.1352 s/iter. Eval: 0.0698 s/iter. Total: 0.2102 s/iter. ETA=0:00:00
[10/13 16:05:59] d2.evaluation.evaluator INFO: Total inference time: 0:01:44.097430 (0.210298 s / iter per device, on 1 devices)
[10/13 16:05:59] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.135123 s / iter per device, on 1 devices)
[10/13 16:05:59] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalnvu_u15l ...
[10/13 16:06:23] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 57.148 | 79.875 | 70.363 |      19       |
| Things | 48.422 | 79.215 | 61.046 |       8       |
| Stuff  | 63.495 | 80.355 | 77.140 |      11       |
[10/13 16:06:23] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 97.323 | 97.626 | 99.690 |     Stuff     |
| class_8  | 72.062 | 83.552 | 86.249 |     Stuff     |
| class_11 | 85.703 | 88.615 | 96.715 |     Stuff     |
| class_12 | 43.668 | 77.608 | 56.267 |     Stuff     |
| class_13 | 37.732 | 75.464 | 50.000 |     Stuff     |
| class_17 | 40.794 | 62.345 | 65.432 |     Stuff     |
| class_19 | 45.224 | 67.483 | 67.016 |     Stuff     |
| class_20 | 63.120 | 75.990 | 83.064 |     Stuff     |
| class_21 | 88.999 | 89.736 | 99.179 |     Stuff     |
| class_22 | 36.899 | 74.160 | 49.756 |     Stuff     |
| class_23 | 86.920 | 91.329 | 95.172 |     Stuff     |
| class_24 | 48.895 | 74.645 | 65.503 |    Things     |
| class_25 | 44.462 | 72.850 | 61.033 |    Things     |
| class_26 | 63.277 | 82.086 | 77.086 |    Things     |
| class_27 | 46.136 | 86.391 | 53.403 |    Things     |
| class_28 | 58.774 | 89.794 | 65.455 |    Things     |
| class_31 | 45.225 | 83.990 | 53.846 |    Things     |
| class_32 | 40.280 | 73.647 | 54.694 |    Things     |
| class_33 | 40.324 | 70.316 | 57.347 |    Things     |
[10/13 16:06:23] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 16:06:23] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 16:06:23] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 16:06:23] d2.evaluation.testing INFO: copypaste: 57.1484,79.8752,70.3635,48.4217,79.2149,61.0458,63.4951,80.3554,77.1399,97.3234,97.6263,99.6898,72.0625,83.5520,86.2486,85.7034,88.6148,96.7146,43.6683,77.6084,56.2674,37.7319,75.4637,50.0000,40.7937,62.3451,65.4321,45.2243,67.4831,67.0157,63.1199,75.9898,83.0636,88.9992,89.7363,99.1786,36.8992,74.1603,49.7561,86.9203,91.3293,95.1724,48.8953,74.6455,65.5034,44.4623,72.8498,61.0329,63.2769,82.0864,77.0858,46.1356,86.3911,53.4031,58.7744,89.7942,65.4545,45.2252,83.9897,53.8462,40.2803,73.6468,54.6939,40.3239,70.3156,57.3469
[10/13 16:08:09] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 16:08:09] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 16:08:09] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 16:08:09] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 16:08:09] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 16:08:09] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 16:08:12] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0037 s/iter. Inference: 0.1308 s/iter. Eval: 0.0726 s/iter. Total: 0.2071 s/iter. ETA=0:01:41
[10/13 16:08:17] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0045 s/iter. Inference: 0.1325 s/iter. Eval: 0.0721 s/iter. Total: 0.2092 s/iter. ETA=0:01:37
[10/13 16:08:22] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0046 s/iter. Inference: 0.1335 s/iter. Eval: 0.0718 s/iter. Total: 0.2099 s/iter. ETA=0:01:32
[10/13 16:08:27] d2.evaluation.evaluator INFO: Inference done 83/500. Dataloading: 0.0048 s/iter. Inference: 0.1338 s/iter. Eval: 0.0709 s/iter. Total: 0.2095 s/iter. ETA=0:01:27
[10/13 16:08:32] d2.evaluation.evaluator INFO: Inference done 107/500. Dataloading: 0.0048 s/iter. Inference: 0.1342 s/iter. Eval: 0.0709 s/iter. Total: 0.2100 s/iter. ETA=0:01:22
[10/13 16:08:37] d2.evaluation.evaluator INFO: Inference done 131/500. Dataloading: 0.0048 s/iter. Inference: 0.1338 s/iter. Eval: 0.0711 s/iter. Total: 0.2098 s/iter. ETA=0:01:17
[10/13 16:08:42] d2.evaluation.evaluator INFO: Inference done 155/500. Dataloading: 0.0048 s/iter. Inference: 0.1335 s/iter. Eval: 0.0713 s/iter. Total: 0.2097 s/iter. ETA=0:01:12
[10/13 16:08:47] d2.evaluation.evaluator INFO: Inference done 179/500. Dataloading: 0.0048 s/iter. Inference: 0.1334 s/iter. Eval: 0.0714 s/iter. Total: 0.2097 s/iter. ETA=0:01:07
[10/13 16:08:52] d2.evaluation.evaluator INFO: Inference done 203/500. Dataloading: 0.0048 s/iter. Inference: 0.1336 s/iter. Eval: 0.0714 s/iter. Total: 0.2099 s/iter. ETA=0:01:02
[10/13 16:08:57] d2.evaluation.evaluator INFO: Inference done 229/500. Dataloading: 0.0049 s/iter. Inference: 0.1335 s/iter. Eval: 0.0695 s/iter. Total: 0.2080 s/iter. ETA=0:00:56
[10/13 16:09:02] d2.evaluation.evaluator INFO: Inference done 254/500. Dataloading: 0.0050 s/iter. Inference: 0.1335 s/iter. Eval: 0.0691 s/iter. Total: 0.2076 s/iter. ETA=0:00:51
[10/13 16:09:07] d2.evaluation.evaluator INFO: Inference done 279/500. Dataloading: 0.0050 s/iter. Inference: 0.1333 s/iter. Eval: 0.0688 s/iter. Total: 0.2072 s/iter. ETA=0:00:45
[10/13 16:09:12] d2.evaluation.evaluator INFO: Inference done 303/500. Dataloading: 0.0050 s/iter. Inference: 0.1332 s/iter. Eval: 0.0691 s/iter. Total: 0.2074 s/iter. ETA=0:00:40
[10/13 16:09:17] d2.evaluation.evaluator INFO: Inference done 329/500. Dataloading: 0.0051 s/iter. Inference: 0.1329 s/iter. Eval: 0.0682 s/iter. Total: 0.2063 s/iter. ETA=0:00:35
[10/13 16:09:22] d2.evaluation.evaluator INFO: Inference done 353/500. Dataloading: 0.0052 s/iter. Inference: 0.1331 s/iter. Eval: 0.0681 s/iter. Total: 0.2064 s/iter. ETA=0:00:30
[10/13 16:09:27] d2.evaluation.evaluator INFO: Inference done 377/500. Dataloading: 0.0052 s/iter. Inference: 0.1333 s/iter. Eval: 0.0684 s/iter. Total: 0.2069 s/iter. ETA=0:00:25
[10/13 16:09:32] d2.evaluation.evaluator INFO: Inference done 401/500. Dataloading: 0.0051 s/iter. Inference: 0.1333 s/iter. Eval: 0.0686 s/iter. Total: 0.2072 s/iter. ETA=0:00:20
[10/13 16:09:37] d2.evaluation.evaluator INFO: Inference done 425/500. Dataloading: 0.0051 s/iter. Inference: 0.1332 s/iter. Eval: 0.0689 s/iter. Total: 0.2073 s/iter. ETA=0:00:15
[10/13 16:09:42] d2.evaluation.evaluator INFO: Inference done 449/500. Dataloading: 0.0051 s/iter. Inference: 0.1331 s/iter. Eval: 0.0691 s/iter. Total: 0.2074 s/iter. ETA=0:00:10
[10/13 16:09:47] d2.evaluation.evaluator INFO: Inference done 473/500. Dataloading: 0.0051 s/iter. Inference: 0.1333 s/iter. Eval: 0.0691 s/iter. Total: 0.2076 s/iter. ETA=0:00:05
[10/13 16:09:52] d2.evaluation.evaluator INFO: Inference done 497/500. Dataloading: 0.0051 s/iter. Inference: 0.1333 s/iter. Eval: 0.0693 s/iter. Total: 0.2077 s/iter. ETA=0:00:00
[10/13 16:09:53] d2.evaluation.evaluator INFO: Total inference time: 0:01:42.871834 (0.207822 s / iter per device, on 1 devices)
[10/13 16:09:53] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:05 (0.133231 s / iter per device, on 1 devices)
[10/13 16:09:53] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_eval3q1m0tj9 ...
[10/13 16:10:17] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 57.032 | 79.655 | 70.253 |      19       |
| Things | 50.191 | 79.198 | 63.120 |       8       |
| Stuff  | 62.007 | 79.987 | 75.440 |      11       |
[10/13 16:10:17] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.490 | 96.891 | 99.586 |     Stuff     |
| class_8  | 71.500 | 83.266 | 85.870 |     Stuff     |
| class_11 | 85.989 | 88.710 | 96.933 |     Stuff     |
| class_12 | 41.660 | 76.753 | 54.277 |     Stuff     |
| class_13 | 36.505 | 74.463 | 49.025 |     Stuff     |
| class_17 | 38.170 | 61.756 | 61.807 |     Stuff     |
| class_19 | 42.450 | 67.057 | 63.304 |     Stuff     |
| class_20 | 60.019 | 75.390 | 79.612 |     Stuff     |
| class_21 | 88.533 | 89.824 | 98.563 |     Stuff     |
| class_22 | 33.910 | 74.871 | 45.291 |     Stuff     |
| class_23 | 86.853 | 90.876 | 95.573 |     Stuff     |
| class_24 | 49.508 | 74.827 | 66.163 |    Things     |
| class_25 | 45.213 | 72.842 | 62.069 |    Things     |
| class_26 | 62.807 | 81.245 | 77.306 |    Things     |
| class_27 | 52.101 | 86.835 | 60.000 |    Things     |
| class_28 | 58.667 | 90.257 | 65.000 |    Things     |
| class_31 | 55.320 | 85.494 | 64.706 |    Things     |
| class_32 | 38.637 | 72.160 | 53.543 |    Things     |
| class_33 | 39.279 | 69.925 | 56.172 |    Things     |
[10/13 16:10:17] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 16:10:17] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 16:10:17] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 16:10:17] d2.evaluation.testing INFO: copypaste: 57.0321,79.6550,70.2526,50.1914,79.1984,63.1199,62.0072,79.9870,75.4401,96.4895,96.8907,99.5859,71.5004,83.2662,85.8696,85.9893,88.7105,96.9325,41.6596,76.7532,54.2773,36.5054,74.4628,49.0251,38.1696,61.7561,61.8070,42.4498,67.0566,63.3043,60.0191,75.3898,79.6117,88.5330,89.8241,98.5626,33.9102,74.8711,45.2915,86.8533,90.8762,95.5732,49.5079,74.8272,66.1630,45.2125,72.8424,62.0690,62.8071,81.2451,77.3057,52.1008,86.8347,60.0000,58.6673,90.2575,65.0000,55.3198,85.4942,64.7059,38.6371,72.1605,53.5433,39.2786,69.9253,56.1722
[10/13 16:12:02] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 16:12:02] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 16:12:02] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 16:12:02] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 16:12:02] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 16:12:02] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 16:12:05] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0040 s/iter. Inference: 0.1363 s/iter. Eval: 0.0731 s/iter. Total: 0.2134 s/iter. ETA=0:01:44
[10/13 16:12:10] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0046 s/iter. Inference: 0.1336 s/iter. Eval: 0.0714 s/iter. Total: 0.2096 s/iter. ETA=0:01:37
[10/13 16:12:15] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0046 s/iter. Inference: 0.1343 s/iter. Eval: 0.0714 s/iter. Total: 0.2103 s/iter. ETA=0:01:32
[10/13 16:12:20] d2.evaluation.evaluator INFO: Inference done 84/500. Dataloading: 0.0049 s/iter. Inference: 0.1342 s/iter. Eval: 0.0701 s/iter. Total: 0.2093 s/iter. ETA=0:01:27
[10/13 16:12:25] d2.evaluation.evaluator INFO: Inference done 108/500. Dataloading: 0.0049 s/iter. Inference: 0.1341 s/iter. Eval: 0.0707 s/iter. Total: 0.2098 s/iter. ETA=0:01:22
[10/13 16:12:31] d2.evaluation.evaluator INFO: Inference done 132/500. Dataloading: 0.0049 s/iter. Inference: 0.1339 s/iter. Eval: 0.0707 s/iter. Total: 0.2096 s/iter. ETA=0:01:17
[10/13 16:12:36] d2.evaluation.evaluator INFO: Inference done 156/500. Dataloading: 0.0051 s/iter. Inference: 0.1342 s/iter. Eval: 0.0705 s/iter. Total: 0.2098 s/iter. ETA=0:01:12
[10/13 16:12:41] d2.evaluation.evaluator INFO: Inference done 180/500. Dataloading: 0.0050 s/iter. Inference: 0.1339 s/iter. Eval: 0.0708 s/iter. Total: 0.2098 s/iter. ETA=0:01:07
[10/13 16:12:46] d2.evaluation.evaluator INFO: Inference done 204/500. Dataloading: 0.0050 s/iter. Inference: 0.1339 s/iter. Eval: 0.0709 s/iter. Total: 0.2099 s/iter. ETA=0:01:02
[10/13 16:12:51] d2.evaluation.evaluator INFO: Inference done 229/500. Dataloading: 0.0050 s/iter. Inference: 0.1341 s/iter. Eval: 0.0705 s/iter. Total: 0.2097 s/iter. ETA=0:00:56
[10/13 16:12:56] d2.evaluation.evaluator INFO: Inference done 254/500. Dataloading: 0.0051 s/iter. Inference: 0.1340 s/iter. Eval: 0.0701 s/iter. Total: 0.2092 s/iter. ETA=0:00:51
[10/13 16:13:01] d2.evaluation.evaluator INFO: Inference done 279/500. Dataloading: 0.0050 s/iter. Inference: 0.1337 s/iter. Eval: 0.0703 s/iter. Total: 0.2091 s/iter. ETA=0:00:46
[10/13 16:13:06] d2.evaluation.evaluator INFO: Inference done 304/500. Dataloading: 0.0051 s/iter. Inference: 0.1336 s/iter. Eval: 0.0699 s/iter. Total: 0.2086 s/iter. ETA=0:00:40
[10/13 16:13:11] d2.evaluation.evaluator INFO: Inference done 328/500. Dataloading: 0.0051 s/iter. Inference: 0.1335 s/iter. Eval: 0.0700 s/iter. Total: 0.2087 s/iter. ETA=0:00:35
[10/13 16:13:16] d2.evaluation.evaluator INFO: Inference done 353/500. Dataloading: 0.0052 s/iter. Inference: 0.1334 s/iter. Eval: 0.0698 s/iter. Total: 0.2084 s/iter. ETA=0:00:30
[10/13 16:13:21] d2.evaluation.evaluator INFO: Inference done 377/500. Dataloading: 0.0051 s/iter. Inference: 0.1334 s/iter. Eval: 0.0699 s/iter. Total: 0.2086 s/iter. ETA=0:00:25
[10/13 16:13:27] d2.evaluation.evaluator INFO: Inference done 401/500. Dataloading: 0.0051 s/iter. Inference: 0.1335 s/iter. Eval: 0.0700 s/iter. Total: 0.2087 s/iter. ETA=0:00:20
[10/13 16:13:32] d2.evaluation.evaluator INFO: Inference done 426/500. Dataloading: 0.0051 s/iter. Inference: 0.1334 s/iter. Eval: 0.0702 s/iter. Total: 0.2087 s/iter. ETA=0:00:15
[10/13 16:13:37] d2.evaluation.evaluator INFO: Inference done 450/500. Dataloading: 0.0051 s/iter. Inference: 0.1335 s/iter. Eval: 0.0703 s/iter. Total: 0.2089 s/iter. ETA=0:00:10
[10/13 16:13:42] d2.evaluation.evaluator INFO: Inference done 474/500. Dataloading: 0.0050 s/iter. Inference: 0.1336 s/iter. Eval: 0.0703 s/iter. Total: 0.2090 s/iter. ETA=0:00:05
[10/13 16:13:47] d2.evaluation.evaluator INFO: Inference done 498/500. Dataloading: 0.0050 s/iter. Inference: 0.1336 s/iter. Eval: 0.0704 s/iter. Total: 0.2091 s/iter. ETA=0:00:00
[10/13 16:13:47] d2.evaluation.evaluator INFO: Total inference time: 0:01:43.601624 (0.209296 s / iter per device, on 1 devices)
[10/13 16:13:47] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.133583 s / iter per device, on 1 devices)
[10/13 16:13:47] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalfcl_325s ...
[10/13 16:14:11] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 56.298 | 79.589 | 69.399 |      19       |
| Things | 48.935 | 78.834 | 61.872 |       8       |
| Stuff  | 61.654 | 80.139 | 74.872 |      11       |
[10/13 16:14:11] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 97.232 | 97.534 | 99.690 |     Stuff     |
| class_8  | 71.088 | 83.854 | 84.775 |     Stuff     |
| class_11 | 86.331 | 88.598 | 97.441 |     Stuff     |
| class_12 | 39.718 | 77.358 | 51.343 |     Stuff     |
| class_13 | 35.341 | 74.652 | 47.340 |     Stuff     |
| class_17 | 37.668 | 62.208 | 60.550 |     Stuff     |
| class_19 | 43.305 | 67.709 | 63.958 |     Stuff     |
| class_20 | 57.950 | 74.439 | 77.849 |     Stuff     |
| class_21 | 88.185 | 89.285 | 98.768 |     Stuff     |
| class_22 | 35.632 | 75.094 | 47.450 |     Stuff     |
| class_23 | 85.742 | 90.798 | 94.432 |     Stuff     |
| class_24 | 47.036 | 74.226 | 63.368 |    Things     |
| class_25 | 45.580 | 72.430 | 62.929 |    Things     |
| class_26 | 63.366 | 81.585 | 77.669 |    Things     |
| class_27 | 48.071 | 87.402 | 55.000 |    Things     |
| class_28 | 60.899 | 89.173 | 68.293 |    Things     |
| class_31 | 48.858 | 83.465 | 58.537 |    Things     |
| class_32 | 37.721 | 72.463 | 52.055 |    Things     |
| class_33 | 39.947 | 69.924 | 57.129 |    Things     |
[10/13 16:14:11] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 16:14:11] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 16:14:11] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 16:14:11] d2.evaluation.testing INFO: copypaste: 56.2983,79.5894,69.3988,48.9345,78.8336,61.8724,61.6538,80.1391,74.8725,97.2319,97.5345,99.6898,71.0878,83.8542,84.7755,86.3310,88.5981,97.4411,39.7180,77.3576,51.3433,35.3407,74.6524,47.3404,37.6675,62.2085,60.5505,43.3048,67.7086,63.9576,57.9504,74.4391,77.8495,88.1852,89.2852,98.7680,35.6323,75.0943,47.4501,85.7420,90.7980,94.4316,47.0358,74.2263,63.3681,45.5797,72.4303,62.9291,63.3659,81.5846,77.6690,48.0711,87.4020,55.0000,60.8988,89.1733,68.2927,48.8575,83.4649,58.5366,37.7206,72.4633,52.0548,39.9468,69.9237,57.1291
[10/13 16:15:57] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 16:15:57] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 16:15:57] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 16:15:57] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 16:15:57] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 16:15:57] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 16:16:00] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0038 s/iter. Inference: 0.1317 s/iter. Eval: 0.0742 s/iter. Total: 0.2097 s/iter. ETA=0:01:42
[10/13 16:16:05] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0045 s/iter. Inference: 0.1319 s/iter. Eval: 0.0728 s/iter. Total: 0.2093 s/iter. ETA=0:01:37
[10/13 16:16:10] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0046 s/iter. Inference: 0.1330 s/iter. Eval: 0.0722 s/iter. Total: 0.2099 s/iter. ETA=0:01:32
[10/13 16:16:15] d2.evaluation.evaluator INFO: Inference done 83/500. Dataloading: 0.0046 s/iter. Inference: 0.1339 s/iter. Eval: 0.0718 s/iter. Total: 0.2104 s/iter. ETA=0:01:27
[10/13 16:16:20] d2.evaluation.evaluator INFO: Inference done 107/500. Dataloading: 0.0047 s/iter. Inference: 0.1339 s/iter. Eval: 0.0719 s/iter. Total: 0.2105 s/iter. ETA=0:01:22
[10/13 16:16:25] d2.evaluation.evaluator INFO: Inference done 132/500. Dataloading: 0.0047 s/iter. Inference: 0.1333 s/iter. Eval: 0.0721 s/iter. Total: 0.2100 s/iter. ETA=0:01:17
[10/13 16:16:31] d2.evaluation.evaluator INFO: Inference done 157/500. Dataloading: 0.0047 s/iter. Inference: 0.1329 s/iter. Eval: 0.0721 s/iter. Total: 0.2097 s/iter. ETA=0:01:11
[10/13 16:16:36] d2.evaluation.evaluator INFO: Inference done 181/500. Dataloading: 0.0046 s/iter. Inference: 0.1328 s/iter. Eval: 0.0721 s/iter. Total: 0.2097 s/iter. ETA=0:01:06
[10/13 16:16:41] d2.evaluation.evaluator INFO: Inference done 205/500. Dataloading: 0.0047 s/iter. Inference: 0.1331 s/iter. Eval: 0.0721 s/iter. Total: 0.2099 s/iter. ETA=0:01:01
[10/13 16:16:46] d2.evaluation.evaluator INFO: Inference done 229/500. Dataloading: 0.0047 s/iter. Inference: 0.1332 s/iter. Eval: 0.0721 s/iter. Total: 0.2101 s/iter. ETA=0:00:56
[10/13 16:16:51] d2.evaluation.evaluator INFO: Inference done 253/500. Dataloading: 0.0047 s/iter. Inference: 0.1332 s/iter. Eval: 0.0721 s/iter. Total: 0.2100 s/iter. ETA=0:00:51
[10/13 16:16:56] d2.evaluation.evaluator INFO: Inference done 277/500. Dataloading: 0.0047 s/iter. Inference: 0.1332 s/iter. Eval: 0.0721 s/iter. Total: 0.2100 s/iter. ETA=0:00:46
[10/13 16:17:01] d2.evaluation.evaluator INFO: Inference done 302/500. Dataloading: 0.0047 s/iter. Inference: 0.1329 s/iter. Eval: 0.0720 s/iter. Total: 0.2097 s/iter. ETA=0:00:41
[10/13 16:17:06] d2.evaluation.evaluator INFO: Inference done 327/500. Dataloading: 0.0047 s/iter. Inference: 0.1326 s/iter. Eval: 0.0721 s/iter. Total: 0.2095 s/iter. ETA=0:00:36
[10/13 16:17:11] d2.evaluation.evaluator INFO: Inference done 351/500. Dataloading: 0.0047 s/iter. Inference: 0.1327 s/iter. Eval: 0.0721 s/iter. Total: 0.2095 s/iter. ETA=0:00:31
[10/13 16:17:16] d2.evaluation.evaluator INFO: Inference done 375/500. Dataloading: 0.0047 s/iter. Inference: 0.1326 s/iter. Eval: 0.0721 s/iter. Total: 0.2095 s/iter. ETA=0:00:26
[10/13 16:17:21] d2.evaluation.evaluator INFO: Inference done 399/500. Dataloading: 0.0047 s/iter. Inference: 0.1328 s/iter. Eval: 0.0721 s/iter. Total: 0.2097 s/iter. ETA=0:00:21
[10/13 16:17:27] d2.evaluation.evaluator INFO: Inference done 425/500. Dataloading: 0.0047 s/iter. Inference: 0.1328 s/iter. Eval: 0.0714 s/iter. Total: 0.2090 s/iter. ETA=0:00:15
[10/13 16:17:32] d2.evaluation.evaluator INFO: Inference done 450/500. Dataloading: 0.0048 s/iter. Inference: 0.1328 s/iter. Eval: 0.0713 s/iter. Total: 0.2089 s/iter. ETA=0:00:10
[10/13 16:17:37] d2.evaluation.evaluator INFO: Inference done 474/500. Dataloading: 0.0048 s/iter. Inference: 0.1329 s/iter. Eval: 0.0713 s/iter. Total: 0.2090 s/iter. ETA=0:00:05
[10/13 16:17:42] d2.evaluation.evaluator INFO: Inference done 498/500. Dataloading: 0.0048 s/iter. Inference: 0.1328 s/iter. Eval: 0.0714 s/iter. Total: 0.2090 s/iter. ETA=0:00:00
[10/13 16:17:42] d2.evaluation.evaluator INFO: Total inference time: 0:01:43.531873 (0.209155 s / iter per device, on 1 devices)
[10/13 16:17:42] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:05 (0.132783 s / iter per device, on 1 devices)
[10/13 16:17:42] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalhghzz525 ...
[10/13 16:18:05] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 56.879 | 79.859 | 70.015 |      19       |
| Things | 48.411 | 79.043 | 61.042 |       8       |
| Stuff  | 63.038 | 80.452 | 76.541 |      11       |
[10/13 16:18:05] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 97.078 | 97.380 | 99.690 |     Stuff     |
| class_8  | 70.956 | 82.183 | 86.339 |     Stuff     |
| class_11 | 87.070 | 88.979 | 97.855 |     Stuff     |
| class_12 | 40.299 | 78.228 | 51.515 |     Stuff     |
| class_13 | 36.530 | 76.104 | 48.000 |     Stuff     |
| class_17 | 40.391 | 62.446 | 64.682 |     Stuff     |
| class_19 | 46.192 | 68.067 | 67.864 |     Stuff     |
| class_20 | 61.611 | 75.412 | 81.699 |     Stuff     |
| class_21 | 88.624 | 89.732 | 98.765 |     Stuff     |
| class_22 | 37.526 | 75.538 | 49.679 |     Stuff     |
| class_23 | 87.140 | 90.901 | 95.862 |     Stuff     |
| class_24 | 49.584 | 75.067 | 66.052 |    Things     |
| class_25 | 38.747 | 73.445 | 52.756 |    Things     |
| class_26 | 61.965 | 81.626 | 75.913 |    Things     |
| class_27 | 48.088 | 87.760 | 54.795 |    Things     |
| class_28 | 59.655 | 90.067 | 66.234 |    Things     |
| class_31 | 48.465 | 81.509 | 59.459 |    Things     |
| class_32 | 39.630 | 72.229 | 54.867 |    Things     |
| class_33 | 41.157 | 70.641 | 58.263 |    Things     |
[10/13 16:18:05] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 16:18:05] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 16:18:05] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 16:18:05] d2.evaluation.testing INFO: copypaste: 56.8793,79.8585,70.0152,48.4112,79.0430,61.0424,63.0379,80.4517,76.5409,97.0783,97.3804,99.6898,70.9555,82.1827,86.3388,87.0699,88.9786,97.8550,40.2993,78.2280,51.5152,36.5298,76.1038,48.0000,40.3910,62.4457,64.6817,46.1924,68.0666,67.8636,61.6111,75.4119,81.6993,88.6237,89.7315,98.7654,37.5264,75.5380,49.6788,87.1397,90.9011,95.8621,49.5835,75.0674,66.0520,38.7466,73.4451,52.7559,61.9646,81.6257,75.9131,48.0875,87.7597,54.7945,59.6551,90.0675,66.2338,48.4646,81.5087,59.4595,39.6301,72.2290,54.8673,41.1575,70.6408,58.2630
[10/13 16:19:52] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 16:19:52] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 16:19:52] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 16:19:52] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 16:19:52] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 16:19:52] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 16:19:55] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0040 s/iter. Inference: 0.1304 s/iter. Eval: 0.0727 s/iter. Total: 0.2071 s/iter. ETA=0:01:41
[10/13 16:20:00] d2.evaluation.evaluator INFO: Inference done 36/500. Dataloading: 0.0058 s/iter. Inference: 0.1334 s/iter. Eval: 0.0640 s/iter. Total: 0.2032 s/iter. ETA=0:01:34
[10/13 16:20:05] d2.evaluation.evaluator INFO: Inference done 61/500. Dataloading: 0.0058 s/iter. Inference: 0.1346 s/iter. Eval: 0.0636 s/iter. Total: 0.2041 s/iter. ETA=0:01:29
[10/13 16:20:10] d2.evaluation.evaluator INFO: Inference done 85/500. Dataloading: 0.0055 s/iter. Inference: 0.1347 s/iter. Eval: 0.0660 s/iter. Total: 0.2063 s/iter. ETA=0:01:25
[10/13 16:20:15] d2.evaluation.evaluator INFO: Inference done 109/500. Dataloading: 0.0054 s/iter. Inference: 0.1344 s/iter. Eval: 0.0674 s/iter. Total: 0.2072 s/iter. ETA=0:01:21
[10/13 16:20:20] d2.evaluation.evaluator INFO: Inference done 133/500. Dataloading: 0.0053 s/iter. Inference: 0.1339 s/iter. Eval: 0.0684 s/iter. Total: 0.2075 s/iter. ETA=0:01:16
[10/13 16:20:25] d2.evaluation.evaluator INFO: Inference done 160/500. Dataloading: 0.0055 s/iter. Inference: 0.1334 s/iter. Eval: 0.0659 s/iter. Total: 0.2048 s/iter. ETA=0:01:09
[10/13 16:20:31] d2.evaluation.evaluator INFO: Inference done 186/500. Dataloading: 0.0056 s/iter. Inference: 0.1332 s/iter. Eval: 0.0650 s/iter. Total: 0.2038 s/iter. ETA=0:01:04
[10/13 16:20:36] d2.evaluation.evaluator INFO: Inference done 210/500. Dataloading: 0.0055 s/iter. Inference: 0.1337 s/iter. Eval: 0.0656 s/iter. Total: 0.2049 s/iter. ETA=0:00:59
[10/13 16:20:41] d2.evaluation.evaluator INFO: Inference done 234/500. Dataloading: 0.0054 s/iter. Inference: 0.1335 s/iter. Eval: 0.0663 s/iter. Total: 0.2053 s/iter. ETA=0:00:54
[10/13 16:20:46] d2.evaluation.evaluator INFO: Inference done 259/500. Dataloading: 0.0054 s/iter. Inference: 0.1334 s/iter. Eval: 0.0665 s/iter. Total: 0.2053 s/iter. ETA=0:00:49
[10/13 16:20:51] d2.evaluation.evaluator INFO: Inference done 284/500. Dataloading: 0.0053 s/iter. Inference: 0.1332 s/iter. Eval: 0.0671 s/iter. Total: 0.2056 s/iter. ETA=0:00:44
[10/13 16:20:56] d2.evaluation.evaluator INFO: Inference done 309/500. Dataloading: 0.0052 s/iter. Inference: 0.1328 s/iter. Eval: 0.0676 s/iter. Total: 0.2057 s/iter. ETA=0:00:39
[10/13 16:21:01] d2.evaluation.evaluator INFO: Inference done 334/500. Dataloading: 0.0052 s/iter. Inference: 0.1326 s/iter. Eval: 0.0680 s/iter. Total: 0.2059 s/iter. ETA=0:00:34
[10/13 16:21:07] d2.evaluation.evaluator INFO: Inference done 358/500. Dataloading: 0.0052 s/iter. Inference: 0.1326 s/iter. Eval: 0.0684 s/iter. Total: 0.2062 s/iter. ETA=0:00:29
[10/13 16:21:12] d2.evaluation.evaluator INFO: Inference done 382/500. Dataloading: 0.0051 s/iter. Inference: 0.1328 s/iter. Eval: 0.0686 s/iter. Total: 0.2065 s/iter. ETA=0:00:24
[10/13 16:21:17] d2.evaluation.evaluator INFO: Inference done 406/500. Dataloading: 0.0051 s/iter. Inference: 0.1330 s/iter. Eval: 0.0687 s/iter. Total: 0.2068 s/iter. ETA=0:00:19
[10/13 16:21:22] d2.evaluation.evaluator INFO: Inference done 430/500. Dataloading: 0.0051 s/iter. Inference: 0.1333 s/iter. Eval: 0.0687 s/iter. Total: 0.2072 s/iter. ETA=0:00:14
[10/13 16:21:27] d2.evaluation.evaluator INFO: Inference done 454/500. Dataloading: 0.0051 s/iter. Inference: 0.1334 s/iter. Eval: 0.0687 s/iter. Total: 0.2072 s/iter. ETA=0:00:09
[10/13 16:21:32] d2.evaluation.evaluator INFO: Inference done 479/500. Dataloading: 0.0051 s/iter. Inference: 0.1335 s/iter. Eval: 0.0686 s/iter. Total: 0.2073 s/iter. ETA=0:00:04
[10/13 16:21:36] d2.evaluation.evaluator INFO: Total inference time: 0:01:42.684089 (0.207443 s / iter per device, on 1 devices)
[10/13 16:21:36] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.133363 s / iter per device, on 1 devices)
[10/13 16:21:36] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalmzfewxdh ...
[10/13 16:22:00] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 57.649 | 79.676 | 71.055 |      19       |
| Things | 49.724 | 78.755 | 62.873 |       8       |
| Stuff  | 63.412 | 80.346 | 77.006 |      11       |
[10/13 16:22:00] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.986 | 97.390 | 99.586 |     Stuff     |
| class_8  | 72.443 | 83.803 | 86.444 |     Stuff     |
| class_11 | 86.657 | 89.018 | 97.347 |     Stuff     |
| class_12 | 41.039 | 78.698 | 52.147 |     Stuff     |
| class_13 | 38.143 | 74.380 | 51.282 |     Stuff     |
| class_17 | 39.396 | 62.018 | 63.525 |     Stuff     |
| class_19 | 46.148 | 67.830 | 68.034 |     Stuff     |
| class_20 | 65.343 | 75.712 | 86.304 |     Stuff     |
| class_21 | 88.710 | 89.446 | 99.177 |     Stuff     |
| class_22 | 35.274 | 74.108 | 47.598 |     Stuff     |
| class_23 | 87.397 | 91.398 | 95.622 |     Stuff     |
| class_24 | 49.625 | 75.134 | 66.048 |    Things     |
| class_25 | 46.587 | 72.226 | 64.502 |    Things     |
| class_26 | 62.196 | 81.538 | 76.280 |    Things     |
| class_27 | 52.398 | 86.958 | 60.256 |    Things     |
| class_28 | 62.003 | 89.388 | 69.364 |    Things     |
| class_31 | 47.705 | 82.399 | 57.895 |    Things     |
| class_32 | 36.972 | 72.360 | 51.095 |    Things     |
| class_33 | 40.303 | 70.039 | 57.543 |    Things     |
[10/13 16:22:00] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 16:22:00] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 16:22:00] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 16:22:00] d2.evaluation.testing INFO: copypaste: 57.6487,79.6759,71.0553,49.7236,78.7553,62.8728,63.4124,80.3455,77.0061,96.9864,97.3896,99.5859,72.4435,83.8035,86.4444,86.6568,89.0185,97.3469,41.0389,78.6981,52.1472,38.1435,74.3798,51.2821,39.3964,62.0176,63.5246,46.1475,67.8299,68.0342,65.3426,75.7118,86.3043,88.7102,89.4463,99.1770,35.2740,74.1077,47.5983,87.3967,91.3980,95.6221,49.6249,75.1344,66.0482,46.5873,72.2265,64.5017,62.1964,81.5375,76.2795,52.3976,86.9577,60.2564,62.0033,89.3881,69.3642,47.7046,82.3988,57.8947,36.9720,72.3595,51.0949,40.3030,70.0395,57.5432
[10/13 16:23:46] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 16:23:46] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 16:23:46] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 16:23:46] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 16:23:46] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 16:23:46] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 16:23:49] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0037 s/iter. Inference: 0.1333 s/iter. Eval: 0.0715 s/iter. Total: 0.2085 s/iter. ETA=0:01:41
[10/13 16:23:54] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0045 s/iter. Inference: 0.1324 s/iter. Eval: 0.0720 s/iter. Total: 0.2090 s/iter. ETA=0:01:37
[10/13 16:23:59] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0046 s/iter. Inference: 0.1338 s/iter. Eval: 0.0714 s/iter. Total: 0.2098 s/iter. ETA=0:01:32
[10/13 16:24:04] d2.evaluation.evaluator INFO: Inference done 83/500. Dataloading: 0.0047 s/iter. Inference: 0.1343 s/iter. Eval: 0.0713 s/iter. Total: 0.2103 s/iter. ETA=0:01:27
[10/13 16:24:09] d2.evaluation.evaluator INFO: Inference done 107/500. Dataloading: 0.0047 s/iter. Inference: 0.1341 s/iter. Eval: 0.0715 s/iter. Total: 0.2104 s/iter. ETA=0:01:22
[10/13 16:24:14] d2.evaluation.evaluator INFO: Inference done 131/500. Dataloading: 0.0047 s/iter. Inference: 0.1340 s/iter. Eval: 0.0716 s/iter. Total: 0.2103 s/iter. ETA=0:01:17
[10/13 16:24:19] d2.evaluation.evaluator INFO: Inference done 155/500. Dataloading: 0.0047 s/iter. Inference: 0.1338 s/iter. Eval: 0.0717 s/iter. Total: 0.2102 s/iter. ETA=0:01:12
[10/13 16:24:24] d2.evaluation.evaluator INFO: Inference done 179/500. Dataloading: 0.0047 s/iter. Inference: 0.1337 s/iter. Eval: 0.0717 s/iter. Total: 0.2101 s/iter. ETA=0:01:07
[10/13 16:24:30] d2.evaluation.evaluator INFO: Inference done 203/500. Dataloading: 0.0047 s/iter. Inference: 0.1341 s/iter. Eval: 0.0716 s/iter. Total: 0.2104 s/iter. ETA=0:01:02
[10/13 16:24:35] d2.evaluation.evaluator INFO: Inference done 227/500. Dataloading: 0.0047 s/iter. Inference: 0.1341 s/iter. Eval: 0.0715 s/iter. Total: 0.2104 s/iter. ETA=0:00:57
[10/13 16:24:40] d2.evaluation.evaluator INFO: Inference done 251/500. Dataloading: 0.0047 s/iter. Inference: 0.1341 s/iter. Eval: 0.0716 s/iter. Total: 0.2104 s/iter. ETA=0:00:52
[10/13 16:24:45] d2.evaluation.evaluator INFO: Inference done 276/500. Dataloading: 0.0047 s/iter. Inference: 0.1339 s/iter. Eval: 0.0713 s/iter. Total: 0.2100 s/iter. ETA=0:00:47
[10/13 16:24:50] d2.evaluation.evaluator INFO: Inference done 301/500. Dataloading: 0.0047 s/iter. Inference: 0.1335 s/iter. Eval: 0.0715 s/iter. Total: 0.2098 s/iter. ETA=0:00:41
[10/13 16:24:55] d2.evaluation.evaluator INFO: Inference done 326/500. Dataloading: 0.0047 s/iter. Inference: 0.1332 s/iter. Eval: 0.0716 s/iter. Total: 0.2096 s/iter. ETA=0:00:36
[10/13 16:25:00] d2.evaluation.evaluator INFO: Inference done 350/500. Dataloading: 0.0047 s/iter. Inference: 0.1333 s/iter. Eval: 0.0716 s/iter. Total: 0.2097 s/iter. ETA=0:00:31
[10/13 16:25:05] d2.evaluation.evaluator INFO: Inference done 374/500. Dataloading: 0.0047 s/iter. Inference: 0.1333 s/iter. Eval: 0.0716 s/iter. Total: 0.2097 s/iter. ETA=0:00:26
[10/13 16:25:10] d2.evaluation.evaluator INFO: Inference done 398/500. Dataloading: 0.0047 s/iter. Inference: 0.1335 s/iter. Eval: 0.0716 s/iter. Total: 0.2098 s/iter. ETA=0:00:21
[10/13 16:25:15] d2.evaluation.evaluator INFO: Inference done 422/500. Dataloading: 0.0047 s/iter. Inference: 0.1335 s/iter. Eval: 0.0716 s/iter. Total: 0.2099 s/iter. ETA=0:00:16
[10/13 16:25:20] d2.evaluation.evaluator INFO: Inference done 446/500. Dataloading: 0.0047 s/iter. Inference: 0.1334 s/iter. Eval: 0.0716 s/iter. Total: 0.2098 s/iter. ETA=0:00:11
[10/13 16:25:25] d2.evaluation.evaluator INFO: Inference done 470/500. Dataloading: 0.0047 s/iter. Inference: 0.1334 s/iter. Eval: 0.0716 s/iter. Total: 0.2098 s/iter. ETA=0:00:06
[10/13 16:25:31] d2.evaluation.evaluator INFO: Inference done 494/500. Dataloading: 0.0047 s/iter. Inference: 0.1336 s/iter. Eval: 0.0716 s/iter. Total: 0.2100 s/iter. ETA=0:00:01
[10/13 16:25:32] d2.evaluation.evaluator INFO: Total inference time: 0:01:44.035087 (0.210172 s / iter per device, on 1 devices)
[10/13 16:25:32] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.133538 s / iter per device, on 1 devices)
[10/13 16:25:32] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalt_fmalto ...
[10/13 16:25:56] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 57.158 | 79.934 | 70.291 |      19       |
| Things | 48.533 | 79.238 | 61.167 |       8       |
| Stuff  | 63.431 | 80.440 | 76.926 |      11       |
[10/13 16:25:56] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.861 | 97.162 | 99.690 |     Stuff     |
| class_8  | 72.526 | 83.606 | 86.747 |     Stuff     |
| class_11 | 86.016 | 89.023 | 96.622 |     Stuff     |
| class_12 | 41.964 | 78.454 | 53.488 |     Stuff     |
| class_13 | 37.831 | 75.439 | 50.147 |     Stuff     |
| class_17 | 36.881 | 62.236 | 59.259 |     Stuff     |
| class_19 | 46.319 | 67.289 | 68.836 |     Stuff     |
| class_20 | 64.217 | 76.185 | 84.290 |     Stuff     |
| class_21 | 88.809 | 89.638 | 99.075 |     Stuff     |
| class_22 | 38.902 | 74.699 | 52.079 |     Stuff     |
| class_23 | 87.419 | 91.105 | 95.954 |     Stuff     |
| class_24 | 47.487 | 74.773 | 63.509 |    Things     |
| class_25 | 45.369 | 73.094 | 62.069 |    Things     |
| class_26 | 64.539 | 82.039 | 78.670 |    Things     |
| class_27 | 49.172 | 86.804 | 56.647 |    Things     |
| class_28 | 58.375 | 90.911 | 64.211 |    Things     |
| class_31 | 41.354 | 82.709 | 50.000 |    Things     |
| class_32 | 40.912 | 73.226 | 55.870 |    Things     |
| class_33 | 41.054 | 70.347 | 58.360 |    Things     |
[10/13 16:25:56] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 16:25:56] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 16:25:56] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 16:25:56] d2.evaluation.testing INFO: copypaste: 57.1582,79.9336,70.2907,48.5328,79.2378,61.1670,63.4312,80.4397,76.9262,96.8606,97.1621,99.6898,72.5260,83.6063,86.7470,86.0160,89.0229,96.6223,41.9638,78.4541,53.4884,37.8305,75.4385,50.1475,36.8808,62.2364,59.2593,46.3191,67.2895,68.8356,64.2168,76.1852,84.2904,88.8090,89.6382,99.0750,38.9021,74.6985,52.0788,87.4187,91.1050,95.9538,47.4873,74.7727,63.5089,45.3688,73.0942,62.0690,64.5395,82.0385,78.6697,49.1720,86.8036,56.6474,58.3746,90.9113,64.2105,41.3545,82.7090,50.0000,40.9117,73.2261,55.8704,41.0542,70.3468,58.3598
[10/13 16:27:42] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 16:27:42] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 16:27:42] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 16:27:42] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 16:27:42] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 16:27:42] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 16:27:45] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0037 s/iter. Inference: 0.1343 s/iter. Eval: 0.0714 s/iter. Total: 0.2094 s/iter. ETA=0:01:42
[10/13 16:27:50] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0047 s/iter. Inference: 0.1346 s/iter. Eval: 0.0744 s/iter. Total: 0.2137 s/iter. ETA=0:01:39
[10/13 16:27:56] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0048 s/iter. Inference: 0.1362 s/iter. Eval: 0.0735 s/iter. Total: 0.2145 s/iter. ETA=0:01:34
[10/13 16:28:01] d2.evaluation.evaluator INFO: Inference done 83/500. Dataloading: 0.0048 s/iter. Inference: 0.1352 s/iter. Eval: 0.0730 s/iter. Total: 0.2131 s/iter. ETA=0:01:28
[10/13 16:28:06] d2.evaluation.evaluator INFO: Inference done 106/500. Dataloading: 0.0048 s/iter. Inference: 0.1376 s/iter. Eval: 0.0732 s/iter. Total: 0.2157 s/iter. ETA=0:01:24
[10/13 16:28:11] d2.evaluation.evaluator INFO: Inference done 128/500. Dataloading: 0.0049 s/iter. Inference: 0.1397 s/iter. Eval: 0.0738 s/iter. Total: 0.2184 s/iter. ETA=0:01:21
[10/13 16:28:16] d2.evaluation.evaluator INFO: Inference done 151/500. Dataloading: 0.0049 s/iter. Inference: 0.1396 s/iter. Eval: 0.0742 s/iter. Total: 0.2188 s/iter. ETA=0:01:16
[10/13 16:28:21] d2.evaluation.evaluator INFO: Inference done 174/500. Dataloading: 0.0049 s/iter. Inference: 0.1409 s/iter. Eval: 0.0737 s/iter. Total: 0.2196 s/iter. ETA=0:01:11
[10/13 16:28:26] d2.evaluation.evaluator INFO: Inference done 197/500. Dataloading: 0.0050 s/iter. Inference: 0.1421 s/iter. Eval: 0.0731 s/iter. Total: 0.2202 s/iter. ETA=0:01:06
[10/13 16:28:31] d2.evaluation.evaluator INFO: Inference done 221/500. Dataloading: 0.0050 s/iter. Inference: 0.1416 s/iter. Eval: 0.0731 s/iter. Total: 0.2198 s/iter. ETA=0:01:01
[10/13 16:28:36] d2.evaluation.evaluator INFO: Inference done 245/500. Dataloading: 0.0049 s/iter. Inference: 0.1407 s/iter. Eval: 0.0731 s/iter. Total: 0.2187 s/iter. ETA=0:00:55
[10/13 16:28:42] d2.evaluation.evaluator INFO: Inference done 269/500. Dataloading: 0.0049 s/iter. Inference: 0.1403 s/iter. Eval: 0.0730 s/iter. Total: 0.2183 s/iter. ETA=0:00:50
[10/13 16:28:47] d2.evaluation.evaluator INFO: Inference done 292/500. Dataloading: 0.0049 s/iter. Inference: 0.1402 s/iter. Eval: 0.0731 s/iter. Total: 0.2183 s/iter. ETA=0:00:45
[10/13 16:28:52] d2.evaluation.evaluator INFO: Inference done 316/500. Dataloading: 0.0050 s/iter. Inference: 0.1399 s/iter. Eval: 0.0732 s/iter. Total: 0.2181 s/iter. ETA=0:00:40
[10/13 16:28:57] d2.evaluation.evaluator INFO: Inference done 339/500. Dataloading: 0.0050 s/iter. Inference: 0.1399 s/iter. Eval: 0.0732 s/iter. Total: 0.2181 s/iter. ETA=0:00:35
[10/13 16:29:02] d2.evaluation.evaluator INFO: Inference done 363/500. Dataloading: 0.0050 s/iter. Inference: 0.1393 s/iter. Eval: 0.0732 s/iter. Total: 0.2176 s/iter. ETA=0:00:29
[10/13 16:29:07] d2.evaluation.evaluator INFO: Inference done 387/500. Dataloading: 0.0050 s/iter. Inference: 0.1390 s/iter. Eval: 0.0732 s/iter. Total: 0.2172 s/iter. ETA=0:00:24
[10/13 16:29:12] d2.evaluation.evaluator INFO: Inference done 411/500. Dataloading: 0.0050 s/iter. Inference: 0.1387 s/iter. Eval: 0.0733 s/iter. Total: 0.2170 s/iter. ETA=0:00:19
[10/13 16:29:17] d2.evaluation.evaluator INFO: Inference done 433/500. Dataloading: 0.0050 s/iter. Inference: 0.1399 s/iter. Eval: 0.0731 s/iter. Total: 0.2180 s/iter. ETA=0:00:14
[10/13 16:29:22] d2.evaluation.evaluator INFO: Inference done 457/500. Dataloading: 0.0049 s/iter. Inference: 0.1393 s/iter. Eval: 0.0732 s/iter. Total: 0.2175 s/iter. ETA=0:00:09
[10/13 16:29:27] d2.evaluation.evaluator INFO: Inference done 481/500. Dataloading: 0.0049 s/iter. Inference: 0.1390 s/iter. Eval: 0.0731 s/iter. Total: 0.2171 s/iter. ETA=0:00:04
[10/13 16:29:31] d2.evaluation.evaluator INFO: Total inference time: 0:01:47.409717 (0.216989 s / iter per device, on 1 devices)
[10/13 16:29:31] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:08 (0.138692 s / iter per device, on 1 devices)
[10/13 16:29:31] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalq2b5iccg ...
[10/13 16:29:55] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 57.610 | 79.803 | 70.892 |      19       |
| Things | 49.856 | 78.854 | 63.015 |       8       |
| Stuff  | 63.250 | 80.493 | 76.620 |      11       |
[10/13 16:29:55] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 97.309 | 97.612 | 99.690 |     Stuff     |
| class_8  | 72.985 | 83.794 | 87.100 |     Stuff     |
| class_11 | 86.736 | 89.110 | 97.336 |     Stuff     |
| class_12 | 41.901 | 78.395 | 53.448 |     Stuff     |
| class_13 | 37.494 | 74.988 | 50.000 |     Stuff     |
| class_17 | 39.642 | 62.616 | 63.309 |     Stuff     |
| class_19 | 42.618 | 67.554 | 63.087 |     Stuff     |
| class_20 | 64.074 | 75.843 | 84.483 |     Stuff     |
| class_21 | 88.615 | 89.813 | 98.667 |     Stuff     |
| class_22 | 37.417 | 74.834 | 50.000 |     Stuff     |
| class_23 | 86.956 | 90.861 | 95.703 |     Stuff     |
| class_24 | 50.281 | 75.078 | 66.971 |    Things     |
| class_25 | 45.346 | 72.039 | 62.946 |    Things     |
| class_26 | 64.811 | 82.033 | 79.006 |    Things     |
| class_27 | 48.549 | 87.033 | 55.782 |    Things     |
| class_28 | 61.988 | 90.728 | 68.323 |    Things     |
| class_31 | 48.303 | 80.504 | 60.000 |    Things     |
| class_32 | 38.627 | 73.340 | 52.669 |    Things     |
| class_33 | 40.940 | 70.077 | 58.422 |    Things     |
[10/13 16:29:55] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 16:29:55] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 16:29:55] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 16:29:55] d2.evaluation.testing INFO: copypaste: 57.6102,79.8028,70.8917,49.8557,78.8542,63.0150,63.2498,80.4927,76.6203,97.3094,97.6123,99.6898,72.9847,83.7939,87.1003,86.7363,89.1102,97.3361,41.9006,78.3947,53.4483,37.4941,74.9883,50.0000,39.6420,62.6163,63.3094,42.6180,67.5540,63.0872,64.0740,75.8427,84.4828,88.6151,89.8126,98.6667,37.4170,74.8341,50.0000,86.9560,90.8606,95.7027,50.2807,75.0781,66.9712,45.3459,72.0389,62.9464,64.8112,82.0332,79.0061,48.5491,87.0331,55.7823,61.9883,90.7284,68.3230,48.3027,80.5045,60.0000,38.6274,73.3399,52.6690,40.9405,70.0774,58.4218
[10/13 16:31:42] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 16:31:42] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 16:31:42] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 16:31:42] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 16:31:42] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 16:31:42] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 16:31:45] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0041 s/iter. Inference: 0.1367 s/iter. Eval: 0.0736 s/iter. Total: 0.2144 s/iter. ETA=0:01:44
[10/13 16:31:50] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0050 s/iter. Inference: 0.1384 s/iter. Eval: 0.0739 s/iter. Total: 0.2173 s/iter. ETA=0:01:41
[10/13 16:31:55] d2.evaluation.evaluator INFO: Inference done 58/500. Dataloading: 0.0051 s/iter. Inference: 0.1400 s/iter. Eval: 0.0735 s/iter. Total: 0.2187 s/iter. ETA=0:01:36
[10/13 16:32:00] d2.evaluation.evaluator INFO: Inference done 82/500. Dataloading: 0.0052 s/iter. Inference: 0.1397 s/iter. Eval: 0.0714 s/iter. Total: 0.2164 s/iter. ETA=0:01:30
[10/13 16:32:05] d2.evaluation.evaluator INFO: Inference done 107/500. Dataloading: 0.0053 s/iter. Inference: 0.1382 s/iter. Eval: 0.0689 s/iter. Total: 0.2125 s/iter. ETA=0:01:23
[10/13 16:32:10] d2.evaluation.evaluator INFO: Inference done 130/500. Dataloading: 0.0053 s/iter. Inference: 0.1387 s/iter. Eval: 0.0700 s/iter. Total: 0.2141 s/iter. ETA=0:01:19
[10/13 16:32:15] d2.evaluation.evaluator INFO: Inference done 154/500. Dataloading: 0.0052 s/iter. Inference: 0.1380 s/iter. Eval: 0.0703 s/iter. Total: 0.2135 s/iter. ETA=0:01:13
[10/13 16:32:21] d2.evaluation.evaluator INFO: Inference done 178/500. Dataloading: 0.0052 s/iter. Inference: 0.1379 s/iter. Eval: 0.0705 s/iter. Total: 0.2136 s/iter. ETA=0:01:08
[10/13 16:32:26] d2.evaluation.evaluator INFO: Inference done 202/500. Dataloading: 0.0052 s/iter. Inference: 0.1376 s/iter. Eval: 0.0706 s/iter. Total: 0.2134 s/iter. ETA=0:01:03
[10/13 16:32:31] d2.evaluation.evaluator INFO: Inference done 226/500. Dataloading: 0.0051 s/iter. Inference: 0.1373 s/iter. Eval: 0.0707 s/iter. Total: 0.2131 s/iter. ETA=0:00:58
[10/13 16:32:36] d2.evaluation.evaluator INFO: Inference done 250/500. Dataloading: 0.0051 s/iter. Inference: 0.1369 s/iter. Eval: 0.0709 s/iter. Total: 0.2129 s/iter. ETA=0:00:53
[10/13 16:32:41] d2.evaluation.evaluator INFO: Inference done 275/500. Dataloading: 0.0051 s/iter. Inference: 0.1366 s/iter. Eval: 0.0708 s/iter. Total: 0.2125 s/iter. ETA=0:00:47
[10/13 16:32:46] d2.evaluation.evaluator INFO: Inference done 300/500. Dataloading: 0.0051 s/iter. Inference: 0.1361 s/iter. Eval: 0.0707 s/iter. Total: 0.2119 s/iter. ETA=0:00:42
[10/13 16:32:51] d2.evaluation.evaluator INFO: Inference done 325/500. Dataloading: 0.0051 s/iter. Inference: 0.1357 s/iter. Eval: 0.0705 s/iter. Total: 0.2114 s/iter. ETA=0:00:36
[10/13 16:32:56] d2.evaluation.evaluator INFO: Inference done 349/500. Dataloading: 0.0051 s/iter. Inference: 0.1356 s/iter. Eval: 0.0706 s/iter. Total: 0.2113 s/iter. ETA=0:00:31
[10/13 16:33:01] d2.evaluation.evaluator INFO: Inference done 373/500. Dataloading: 0.0051 s/iter. Inference: 0.1354 s/iter. Eval: 0.0707 s/iter. Total: 0.2113 s/iter. ETA=0:00:26
[10/13 16:33:06] d2.evaluation.evaluator INFO: Inference done 397/500. Dataloading: 0.0051 s/iter. Inference: 0.1354 s/iter. Eval: 0.0708 s/iter. Total: 0.2113 s/iter. ETA=0:00:21
[10/13 16:33:11] d2.evaluation.evaluator INFO: Inference done 422/500. Dataloading: 0.0051 s/iter. Inference: 0.1351 s/iter. Eval: 0.0707 s/iter. Total: 0.2109 s/iter. ETA=0:00:16
[10/13 16:33:16] d2.evaluation.evaluator INFO: Inference done 446/500. Dataloading: 0.0051 s/iter. Inference: 0.1349 s/iter. Eval: 0.0707 s/iter. Total: 0.2107 s/iter. ETA=0:00:11
[10/13 16:33:22] d2.evaluation.evaluator INFO: Inference done 470/500. Dataloading: 0.0051 s/iter. Inference: 0.1348 s/iter. Eval: 0.0707 s/iter. Total: 0.2107 s/iter. ETA=0:00:06
[10/13 16:33:27] d2.evaluation.evaluator INFO: Inference done 494/500. Dataloading: 0.0051 s/iter. Inference: 0.1348 s/iter. Eval: 0.0708 s/iter. Total: 0.2107 s/iter. ETA=0:00:01
[10/13 16:33:28] d2.evaluation.evaluator INFO: Total inference time: 0:01:44.213593 (0.210533 s / iter per device, on 1 devices)
[10/13 16:33:28] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.134719 s / iter per device, on 1 devices)
[10/13 16:33:28] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_eval02lr30r_ ...
[10/13 16:33:51] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 54.527 | 79.341 | 67.371 |      19       |
| Things | 44.752 | 78.218 | 57.011 |       8       |
| Stuff  | 61.636 | 80.158 | 74.905 |      11       |
[10/13 16:33:51] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 97.192 | 97.597 | 99.586 |     Stuff     |
| class_8  | 70.818 | 83.652 | 84.657 |     Stuff     |
| class_11 | 85.767 | 88.385 | 97.038 |     Stuff     |
| class_12 | 37.440 | 80.152 | 46.711 |     Stuff     |
| class_13 | 29.397 | 73.073 | 40.230 |     Stuff     |
| class_17 | 40.851 | 63.022 | 64.821 |     Stuff     |
| class_19 | 46.574 | 67.429 | 69.072 |     Stuff     |
| class_20 | 62.777 | 75.105 | 83.585 |     Stuff     |
| class_21 | 88.059 | 89.343 | 98.563 |     Stuff     |
| class_22 | 32.256 | 73.060 | 44.150 |     Stuff     |
| class_23 | 86.863 | 90.916 | 95.543 |     Stuff     |
| class_24 | 48.521 | 74.491 | 65.137 |    Things     |
| class_25 | 39.083 | 72.181 | 54.146 |    Things     |
| class_26 | 63.704 | 81.596 | 78.073 |    Things     |
| class_27 | 48.583 | 87.864 | 55.294 |    Things     |
| class_28 | 58.297 | 89.240 | 65.327 |    Things     |
| class_31 | 21.870 | 79.280 | 27.586 |    Things     |
| class_32 | 39.320 | 71.999 | 54.613 |    Things     |
| class_33 | 38.633 | 69.098 | 55.910 |    Things     |
[10/13 16:33:51] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 16:33:51] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 16:33:51] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 16:33:51] d2.evaluation.testing INFO: copypaste: 54.5267,79.3411,67.3705,44.7516,78.2184,57.0106,61.6359,80.1576,74.9050,97.1924,97.5965,99.5859,70.8179,83.6525,84.6572,85.7673,88.3854,97.0378,37.4396,80.1523,46.7105,29.3970,73.0727,40.2299,40.8509,63.0216,64.8205,46.5743,67.4285,69.0722,62.7767,75.1049,83.5853,88.0593,89.3435,98.5626,32.2560,73.0597,44.1501,86.8634,90.9156,95.5429,48.5211,74.4912,65.1366,39.0833,72.1809,54.1463,63.7043,81.5959,78.0729,48.5834,87.8636,55.2941,58.2973,89.2397,65.3266,21.8702,79.2796,27.5862,39.3203,71.9987,54.6125,38.6325,69.0980,55.9098
[10/13 16:35:37] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 16:35:37] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 16:35:37] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 16:35:37] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 16:35:37] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 16:35:37] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 16:35:40] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0040 s/iter. Inference: 0.1457 s/iter. Eval: 0.0728 s/iter. Total: 0.2226 s/iter. ETA=0:01:48
[10/13 16:35:45] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0046 s/iter. Inference: 0.1345 s/iter. Eval: 0.0726 s/iter. Total: 0.2117 s/iter. ETA=0:01:38
[10/13 16:35:50] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0047 s/iter. Inference: 0.1356 s/iter. Eval: 0.0724 s/iter. Total: 0.2128 s/iter. ETA=0:01:33
[10/13 16:35:55] d2.evaluation.evaluator INFO: Inference done 83/500. Dataloading: 0.0048 s/iter. Inference: 0.1356 s/iter. Eval: 0.0722 s/iter. Total: 0.2127 s/iter. ETA=0:01:28
[10/13 16:36:00] d2.evaluation.evaluator INFO: Inference done 109/500. Dataloading: 0.0051 s/iter. Inference: 0.1349 s/iter. Eval: 0.0688 s/iter. Total: 0.2088 s/iter. ETA=0:01:21
[10/13 16:36:05] d2.evaluation.evaluator INFO: Inference done 134/500. Dataloading: 0.0052 s/iter. Inference: 0.1344 s/iter. Eval: 0.0680 s/iter. Total: 0.2076 s/iter. ETA=0:01:15
[10/13 16:36:10] d2.evaluation.evaluator INFO: Inference done 159/500. Dataloading: 0.0052 s/iter. Inference: 0.1346 s/iter. Eval: 0.0676 s/iter. Total: 0.2074 s/iter. ETA=0:01:10
[10/13 16:36:15] d2.evaluation.evaluator INFO: Inference done 184/500. Dataloading: 0.0052 s/iter. Inference: 0.1344 s/iter. Eval: 0.0673 s/iter. Total: 0.2070 s/iter. ETA=0:01:05
[10/13 16:36:20] d2.evaluation.evaluator INFO: Inference done 208/500. Dataloading: 0.0052 s/iter. Inference: 0.1348 s/iter. Eval: 0.0674 s/iter. Total: 0.2075 s/iter. ETA=0:01:00
[10/13 16:36:26] d2.evaluation.evaluator INFO: Inference done 235/500. Dataloading: 0.0053 s/iter. Inference: 0.1344 s/iter. Eval: 0.0659 s/iter. Total: 0.2056 s/iter. ETA=0:00:54
[10/13 16:36:31] d2.evaluation.evaluator INFO: Inference done 261/500. Dataloading: 0.0054 s/iter. Inference: 0.1341 s/iter. Eval: 0.0653 s/iter. Total: 0.2048 s/iter. ETA=0:00:48
[10/13 16:36:36] d2.evaluation.evaluator INFO: Inference done 286/500. Dataloading: 0.0053 s/iter. Inference: 0.1337 s/iter. Eval: 0.0657 s/iter. Total: 0.2048 s/iter. ETA=0:00:43
[10/13 16:36:41] d2.evaluation.evaluator INFO: Inference done 311/500. Dataloading: 0.0053 s/iter. Inference: 0.1334 s/iter. Eval: 0.0663 s/iter. Total: 0.2051 s/iter. ETA=0:00:38
[10/13 16:36:46] d2.evaluation.evaluator INFO: Inference done 335/500. Dataloading: 0.0053 s/iter. Inference: 0.1335 s/iter. Eval: 0.0667 s/iter. Total: 0.2055 s/iter. ETA=0:00:33
[10/13 16:36:51] d2.evaluation.evaluator INFO: Inference done 359/500. Dataloading: 0.0053 s/iter. Inference: 0.1336 s/iter. Eval: 0.0668 s/iter. Total: 0.2057 s/iter. ETA=0:00:29
[10/13 16:36:56] d2.evaluation.evaluator INFO: Inference done 383/500. Dataloading: 0.0053 s/iter. Inference: 0.1336 s/iter. Eval: 0.0671 s/iter. Total: 0.2061 s/iter. ETA=0:00:24
[10/13 16:37:01] d2.evaluation.evaluator INFO: Inference done 407/500. Dataloading: 0.0052 s/iter. Inference: 0.1336 s/iter. Eval: 0.0674 s/iter. Total: 0.2063 s/iter. ETA=0:00:19
[10/13 16:37:06] d2.evaluation.evaluator INFO: Inference done 431/500. Dataloading: 0.0052 s/iter. Inference: 0.1336 s/iter. Eval: 0.0676 s/iter. Total: 0.2064 s/iter. ETA=0:00:14
[10/13 16:37:11] d2.evaluation.evaluator INFO: Inference done 455/500. Dataloading: 0.0052 s/iter. Inference: 0.1337 s/iter. Eval: 0.0678 s/iter. Total: 0.2067 s/iter. ETA=0:00:09
[10/13 16:37:16] d2.evaluation.evaluator INFO: Inference done 479/500. Dataloading: 0.0051 s/iter. Inference: 0.1337 s/iter. Eval: 0.0680 s/iter. Total: 0.2068 s/iter. ETA=0:00:04
[10/13 16:37:21] d2.evaluation.evaluator INFO: Total inference time: 0:01:42.467987 (0.207006 s / iter per device, on 1 devices)
[10/13 16:37:21] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.133517 s / iter per device, on 1 devices)
[10/13 16:37:21] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_eval5y8v13_m ...
[10/13 16:37:44] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 57.595 | 80.194 | 70.643 |      19       |
| Things | 49.019 | 79.581 | 61.462 |       8       |
| Stuff  | 63.832 | 80.640 | 77.320 |      11       |
[10/13 16:37:44] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 97.272 | 97.575 | 99.690 |     Stuff     |
| class_8  | 73.602 | 83.354 | 88.300 |     Stuff     |
| class_11 | 86.603 | 88.973 | 97.336 |     Stuff     |
| class_12 | 44.776 | 78.032 | 57.382 |     Stuff     |
| class_13 | 36.357 | 75.848 | 47.934 |     Stuff     |
| class_17 | 41.790 | 62.943 | 66.394 |     Stuff     |
| class_19 | 42.560 | 67.272 | 63.265 |     Stuff     |
| class_20 | 64.573 | 76.210 | 84.731 |     Stuff     |
| class_21 | 88.804 | 89.725 | 98.973 |     Stuff     |
| class_22 | 38.531 | 76.039 | 50.673 |     Stuff     |
| class_23 | 87.283 | 91.068 | 95.843 |     Stuff     |
| class_24 | 50.096 | 75.109 | 66.697 |    Things     |
| class_25 | 42.244 | 72.167 | 58.537 |    Things     |
| class_26 | 63.981 | 81.945 | 78.078 |    Things     |
| class_27 | 48.422 | 88.591 | 54.658 |    Things     |
| class_28 | 62.563 | 89.673 | 69.767 |    Things     |
| class_31 | 43.170 | 84.182 | 51.282 |    Things     |
| class_32 | 42.032 | 74.724 | 56.250 |    Things     |
| class_33 | 39.647 | 70.261 | 56.428 |    Things     |
[10/13 16:37:44] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 16:37:44] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 16:37:44] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 16:37:44] d2.evaluation.testing INFO: copypaste: 57.5950,80.1942,70.6431,49.0193,79.5813,61.4622,63.8319,80.6399,77.3201,97.2721,97.5748,99.6898,73.6020,83.3542,88.3002,86.6031,88.9733,97.3361,44.7759,78.0318,57.3816,36.3570,75.8483,47.9339,41.7905,62.9429,66.3943,42.5596,67.2717,63.2653,64.5733,76.2096,84.7312,88.8039,89.7252,98.9733,38.5311,76.0392,50.6726,87.2827,91.0685,95.8430,50.0956,75.1091,66.6971,42.2438,72.1665,58.5366,63.9810,81.9447,78.0783,48.4221,88.5905,54.6584,62.5626,89.6731,69.7674,43.1700,84.1815,51.2821,42.0323,74.7242,56.2500,39.6466,70.2607,56.4279
[10/13 16:39:31] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 16:39:31] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 16:39:31] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 16:39:31] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 16:39:31] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 16:39:31] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 16:39:34] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0039 s/iter. Inference: 0.1309 s/iter. Eval: 0.0735 s/iter. Total: 0.2083 s/iter. ETA=0:01:41
[10/13 16:39:39] d2.evaluation.evaluator INFO: Inference done 36/500. Dataloading: 0.0050 s/iter. Inference: 0.1316 s/iter. Eval: 0.0674 s/iter. Total: 0.2041 s/iter. ETA=0:01:34
[10/13 16:39:44] d2.evaluation.evaluator INFO: Inference done 60/500. Dataloading: 0.0049 s/iter. Inference: 0.1337 s/iter. Eval: 0.0684 s/iter. Total: 0.2071 s/iter. ETA=0:01:31
[10/13 16:39:49] d2.evaluation.evaluator INFO: Inference done 84/500. Dataloading: 0.0049 s/iter. Inference: 0.1343 s/iter. Eval: 0.0683 s/iter. Total: 0.2075 s/iter. ETA=0:01:26
[10/13 16:39:54] d2.evaluation.evaluator INFO: Inference done 108/500. Dataloading: 0.0049 s/iter. Inference: 0.1340 s/iter. Eval: 0.0692 s/iter. Total: 0.2081 s/iter. ETA=0:01:21
[10/13 16:39:59] d2.evaluation.evaluator INFO: Inference done 132/500. Dataloading: 0.0049 s/iter. Inference: 0.1336 s/iter. Eval: 0.0698 s/iter. Total: 0.2083 s/iter. ETA=0:01:16
[10/13 16:40:04] d2.evaluation.evaluator INFO: Inference done 157/500. Dataloading: 0.0049 s/iter. Inference: 0.1332 s/iter. Eval: 0.0697 s/iter. Total: 0.2078 s/iter. ETA=0:01:11
[10/13 16:40:09] d2.evaluation.evaluator INFO: Inference done 181/500. Dataloading: 0.0048 s/iter. Inference: 0.1330 s/iter. Eval: 0.0700 s/iter. Total: 0.2079 s/iter. ETA=0:01:06
[10/13 16:40:15] d2.evaluation.evaluator INFO: Inference done 205/500. Dataloading: 0.0048 s/iter. Inference: 0.1334 s/iter. Eval: 0.0701 s/iter. Total: 0.2084 s/iter. ETA=0:01:01
[10/13 16:40:20] d2.evaluation.evaluator INFO: Inference done 229/500. Dataloading: 0.0048 s/iter. Inference: 0.1333 s/iter. Eval: 0.0703 s/iter. Total: 0.2084 s/iter. ETA=0:00:56
[10/13 16:40:25] d2.evaluation.evaluator INFO: Inference done 254/500. Dataloading: 0.0048 s/iter. Inference: 0.1332 s/iter. Eval: 0.0703 s/iter. Total: 0.2084 s/iter. ETA=0:00:51
[10/13 16:40:30] d2.evaluation.evaluator INFO: Inference done 279/500. Dataloading: 0.0048 s/iter. Inference: 0.1329 s/iter. Eval: 0.0706 s/iter. Total: 0.2083 s/iter. ETA=0:00:46
[10/13 16:40:35] d2.evaluation.evaluator INFO: Inference done 304/500. Dataloading: 0.0049 s/iter. Inference: 0.1326 s/iter. Eval: 0.0702 s/iter. Total: 0.2077 s/iter. ETA=0:00:40
[10/13 16:40:40] d2.evaluation.evaluator INFO: Inference done 330/500. Dataloading: 0.0049 s/iter. Inference: 0.1322 s/iter. Eval: 0.0699 s/iter. Total: 0.2071 s/iter. ETA=0:00:35
[10/13 16:40:45] d2.evaluation.evaluator INFO: Inference done 354/500. Dataloading: 0.0049 s/iter. Inference: 0.1325 s/iter. Eval: 0.0699 s/iter. Total: 0.2073 s/iter. ETA=0:00:30
[10/13 16:40:50] d2.evaluation.evaluator INFO: Inference done 379/500. Dataloading: 0.0049 s/iter. Inference: 0.1326 s/iter. Eval: 0.0697 s/iter. Total: 0.2073 s/iter. ETA=0:00:25
[10/13 16:40:55] d2.evaluation.evaluator INFO: Inference done 403/500. Dataloading: 0.0049 s/iter. Inference: 0.1326 s/iter. Eval: 0.0699 s/iter. Total: 0.2075 s/iter. ETA=0:00:20
[10/13 16:41:00] d2.evaluation.evaluator INFO: Inference done 428/500. Dataloading: 0.0049 s/iter. Inference: 0.1327 s/iter. Eval: 0.0696 s/iter. Total: 0.2073 s/iter. ETA=0:00:14
[10/13 16:41:06] d2.evaluation.evaluator INFO: Inference done 453/500. Dataloading: 0.0049 s/iter. Inference: 0.1326 s/iter. Eval: 0.0697 s/iter. Total: 0.2073 s/iter. ETA=0:00:09
[10/13 16:41:11] d2.evaluation.evaluator INFO: Inference done 477/500. Dataloading: 0.0049 s/iter. Inference: 0.1327 s/iter. Eval: 0.0698 s/iter. Total: 0.2075 s/iter. ETA=0:00:04
[10/13 16:41:16] d2.evaluation.evaluator INFO: Total inference time: 0:01:42.799240 (0.207675 s / iter per device, on 1 devices)
[10/13 16:41:16] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:05 (0.132587 s / iter per device, on 1 devices)
[10/13 16:41:16] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evaloqqwceon ...
[10/13 16:41:39] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 58.297 | 80.247 | 71.483 |      19       |
| Things | 50.744 | 79.822 | 63.372 |       8       |
| Stuff  | 63.789 | 80.555 | 77.382 |      11       |
[10/13 16:41:39] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.880 | 97.487 | 99.378 |     Stuff     |
| class_8  | 74.502 | 84.188 | 88.496 |     Stuff     |
| class_11 | 86.946 | 88.947 | 97.751 |     Stuff     |
| class_12 | 42.762 | 77.589 | 55.114 |     Stuff     |
| class_13 | 37.093 | 75.695 | 49.003 |     Stuff     |
| class_17 | 43.300 | 63.270 | 68.437 |     Stuff     |
| class_19 | 44.255 | 67.304 | 65.753 |     Stuff     |
| class_20 | 64.296 | 75.474 | 85.189 |     Stuff     |
| class_21 | 88.677 | 89.595 | 98.975 |     Stuff     |
| class_22 | 35.522 | 75.566 | 47.009 |     Stuff     |
| class_23 | 87.444 | 90.992 | 96.101 |     Stuff     |
| class_24 | 51.260 | 75.319 | 68.057 |    Things     |
| class_25 | 43.144 | 72.883 | 59.196 |    Things     |
| class_26 | 64.219 | 81.932 | 78.382 |    Things     |
| class_27 | 50.366 | 88.713 | 56.774 |    Things     |
| class_28 | 63.812 | 89.736 | 71.111 |    Things     |
| class_31 | 50.789 | 85.418 | 59.459 |    Things     |
| class_32 | 40.950 | 73.710 | 55.556 |    Things     |
| class_33 | 41.416 | 70.868 | 58.440 |    Things     |
[10/13 16:41:39] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 16:41:39] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 16:41:39] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 16:41:39] d2.evaluation.testing INFO: copypaste: 58.2966,80.2466,71.4832,50.7445,79.8223,63.3719,63.7890,80.5552,77.3823,96.8801,97.4868,99.3776,74.5025,84.1878,88.4956,86.9461,88.9470,97.7505,42.7622,77.5891,55.1136,37.0928,75.6953,49.0028,43.3002,63.2700,68.4372,44.2548,67.3042,65.7534,64.2958,75.4741,85.1892,88.6773,89.5953,98.9754,35.5225,75.5659,47.0085,87.4444,90.9923,96.1009,51.2598,75.3186,68.0572,43.1437,72.8827,59.1961,64.2192,81.9316,78.3815,50.3660,88.7128,56.7742,63.8122,89.7359,71.1111,50.7892,85.4183,59.4595,40.9502,73.7103,55.5556,41.4156,70.8683,58.4403
[10/13 16:43:25] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 16:43:25] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 16:43:25] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 16:43:25] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 16:43:25] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 16:43:25] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 16:43:28] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0039 s/iter. Inference: 0.1404 s/iter. Eval: 0.0729 s/iter. Total: 0.2172 s/iter. ETA=0:01:46
[10/13 16:43:33] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0046 s/iter. Inference: 0.1347 s/iter. Eval: 0.0719 s/iter. Total: 0.2112 s/iter. ETA=0:01:38
[10/13 16:43:38] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0047 s/iter. Inference: 0.1343 s/iter. Eval: 0.0723 s/iter. Total: 0.2114 s/iter. ETA=0:01:33
[10/13 16:43:43] d2.evaluation.evaluator INFO: Inference done 83/500. Dataloading: 0.0046 s/iter. Inference: 0.1342 s/iter. Eval: 0.0722 s/iter. Total: 0.2111 s/iter. ETA=0:01:28
[10/13 16:43:48] d2.evaluation.evaluator INFO: Inference done 107/500. Dataloading: 0.0047 s/iter. Inference: 0.1346 s/iter. Eval: 0.0721 s/iter. Total: 0.2115 s/iter. ETA=0:01:23
[10/13 16:43:54] d2.evaluation.evaluator INFO: Inference done 132/500. Dataloading: 0.0048 s/iter. Inference: 0.1339 s/iter. Eval: 0.0717 s/iter. Total: 0.2105 s/iter. ETA=0:01:17
[10/13 16:43:59] d2.evaluation.evaluator INFO: Inference done 156/500. Dataloading: 0.0048 s/iter. Inference: 0.1336 s/iter. Eval: 0.0718 s/iter. Total: 0.2103 s/iter. ETA=0:01:12
[10/13 16:44:04] d2.evaluation.evaluator INFO: Inference done 180/500. Dataloading: 0.0048 s/iter. Inference: 0.1334 s/iter. Eval: 0.0719 s/iter. Total: 0.2101 s/iter. ETA=0:01:07
[10/13 16:44:09] d2.evaluation.evaluator INFO: Inference done 204/500. Dataloading: 0.0047 s/iter. Inference: 0.1335 s/iter. Eval: 0.0718 s/iter. Total: 0.2102 s/iter. ETA=0:01:02
[10/13 16:44:14] d2.evaluation.evaluator INFO: Inference done 228/500. Dataloading: 0.0047 s/iter. Inference: 0.1334 s/iter. Eval: 0.0719 s/iter. Total: 0.2101 s/iter. ETA=0:00:57
[10/13 16:44:19] d2.evaluation.evaluator INFO: Inference done 253/500. Dataloading: 0.0047 s/iter. Inference: 0.1331 s/iter. Eval: 0.0720 s/iter. Total: 0.2099 s/iter. ETA=0:00:51
[10/13 16:44:24] d2.evaluation.evaluator INFO: Inference done 278/500. Dataloading: 0.0047 s/iter. Inference: 0.1328 s/iter. Eval: 0.0721 s/iter. Total: 0.2097 s/iter. ETA=0:00:46
[10/13 16:44:29] d2.evaluation.evaluator INFO: Inference done 303/500. Dataloading: 0.0047 s/iter. Inference: 0.1323 s/iter. Eval: 0.0722 s/iter. Total: 0.2093 s/iter. ETA=0:00:41
[10/13 16:44:34] d2.evaluation.evaluator INFO: Inference done 328/500. Dataloading: 0.0047 s/iter. Inference: 0.1321 s/iter. Eval: 0.0722 s/iter. Total: 0.2091 s/iter. ETA=0:00:35
[10/13 16:44:39] d2.evaluation.evaluator INFO: Inference done 352/500. Dataloading: 0.0047 s/iter. Inference: 0.1321 s/iter. Eval: 0.0722 s/iter. Total: 0.2091 s/iter. ETA=0:00:30
[10/13 16:44:44] d2.evaluation.evaluator INFO: Inference done 376/500. Dataloading: 0.0047 s/iter. Inference: 0.1321 s/iter. Eval: 0.0723 s/iter. Total: 0.2091 s/iter. ETA=0:00:25
[10/13 16:44:49] d2.evaluation.evaluator INFO: Inference done 400/500. Dataloading: 0.0047 s/iter. Inference: 0.1322 s/iter. Eval: 0.0723 s/iter. Total: 0.2092 s/iter. ETA=0:00:20
[10/13 16:44:55] d2.evaluation.evaluator INFO: Inference done 425/500. Dataloading: 0.0047 s/iter. Inference: 0.1321 s/iter. Eval: 0.0723 s/iter. Total: 0.2092 s/iter. ETA=0:00:15
[10/13 16:45:00] d2.evaluation.evaluator INFO: Inference done 450/500. Dataloading: 0.0047 s/iter. Inference: 0.1321 s/iter. Eval: 0.0722 s/iter. Total: 0.2091 s/iter. ETA=0:00:10
[10/13 16:45:05] d2.evaluation.evaluator INFO: Inference done 474/500. Dataloading: 0.0047 s/iter. Inference: 0.1322 s/iter. Eval: 0.0722 s/iter. Total: 0.2092 s/iter. ETA=0:00:05
[10/13 16:45:10] d2.evaluation.evaluator INFO: Inference done 498/500. Dataloading: 0.0047 s/iter. Inference: 0.1324 s/iter. Eval: 0.0722 s/iter. Total: 0.2093 s/iter. ETA=0:00:00
[10/13 16:45:10] d2.evaluation.evaluator INFO: Total inference time: 0:01:43.685235 (0.209465 s / iter per device, on 1 devices)
[10/13 16:45:10] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:05 (0.132346 s / iter per device, on 1 devices)
[10/13 16:45:10] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evaly19rxivn ...
[10/13 16:45:34] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 54.834 | 79.792 | 67.690 |      19       |
| Things | 43.410 | 78.996 | 55.328 |       8       |
| Stuff  | 63.141 | 80.371 | 76.681 |      11       |
[10/13 16:45:34] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 97.409 | 97.712 | 99.690 |     Stuff     |
| class_8  | 71.419 | 83.353 | 85.683 |     Stuff     |
| class_11 | 87.328 | 88.962 | 98.163 |     Stuff     |
| class_12 | 43.340 | 78.200 | 55.422 |     Stuff     |
| class_13 | 36.716 | 74.994 | 48.958 |     Stuff     |
| class_17 | 40.337 | 62.228 | 64.821 |     Stuff     |
| class_19 | 46.244 | 67.274 | 68.739 |     Stuff     |
| class_20 | 62.138 | 75.361 | 82.454 |     Stuff     |
| class_21 | 88.938 | 89.674 | 99.179 |     Stuff     |
| class_22 | 33.824 | 75.363 | 44.882 |     Stuff     |
| class_23 | 86.864 | 90.956 | 95.502 |     Stuff     |
| class_24 | 48.251 | 74.200 | 65.028 |    Things     |
| class_25 | 43.071 | 72.123 | 59.719 |    Things     |
| class_26 | 62.846 | 81.581 | 77.036 |    Things     |
| class_27 | 47.473 | 87.034 | 54.545 |    Things     |
| class_28 | 41.030 | 87.847 | 46.707 |    Things     |
| class_31 | 25.724 | 84.520 | 30.435 |    Things     |
| class_32 | 39.307 | 74.278 | 52.918 |    Things     |
| class_33 | 39.580 | 70.384 | 56.235 |    Things     |
[10/13 16:45:34] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 16:45:34] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 16:45:34] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 16:45:34] d2.evaluation.testing INFO: copypaste: 54.8336,79.7918,67.6902,43.4103,78.9960,55.3278,63.1414,80.3706,76.6811,97.4091,97.7122,99.6898,71.4188,83.3525,85.6828,87.3275,88.9615,98.1633,43.3400,78.2004,55.4217,36.7160,74.9943,48.9583,40.3366,62.2282,64.8205,46.2436,67.2740,68.7392,62.1380,75.3605,82.4543,88.9375,89.6741,99.1786,33.8244,75.3631,44.8819,86.8644,90.9559,95.5017,48.2510,74.2003,65.0280,43.0712,72.1231,59.7190,62.8463,81.5806,77.0358,47.4733,87.0343,54.5455,41.0304,87.8471,46.7066,25.7235,84.5202,30.4348,39.3067,74.2782,52.9183,39.5803,70.3840,56.2347
[10/13 16:47:20] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 16:47:20] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 16:47:20] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 16:47:20] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 16:47:20] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 16:47:20] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 16:47:22] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0037 s/iter. Inference: 0.1326 s/iter. Eval: 0.0726 s/iter. Total: 0.2089 s/iter. ETA=0:01:42
[10/13 16:47:27] d2.evaluation.evaluator INFO: Inference done 36/500. Dataloading: 0.0050 s/iter. Inference: 0.1330 s/iter. Eval: 0.0650 s/iter. Total: 0.2030 s/iter. ETA=0:01:34
[10/13 16:47:32] d2.evaluation.evaluator INFO: Inference done 60/500. Dataloading: 0.0050 s/iter. Inference: 0.1344 s/iter. Eval: 0.0668 s/iter. Total: 0.2062 s/iter. ETA=0:01:30
[10/13 16:47:38] d2.evaluation.evaluator INFO: Inference done 85/500. Dataloading: 0.0050 s/iter. Inference: 0.1340 s/iter. Eval: 0.0676 s/iter. Total: 0.2067 s/iter. ETA=0:01:25
[10/13 16:47:43] d2.evaluation.evaluator INFO: Inference done 109/500. Dataloading: 0.0050 s/iter. Inference: 0.1341 s/iter. Eval: 0.0683 s/iter. Total: 0.2074 s/iter. ETA=0:01:21
[10/13 16:47:48] d2.evaluation.evaluator INFO: Inference done 133/500. Dataloading: 0.0050 s/iter. Inference: 0.1337 s/iter. Eval: 0.0690 s/iter. Total: 0.2078 s/iter. ETA=0:01:16
[10/13 16:47:53] d2.evaluation.evaluator INFO: Inference done 157/500. Dataloading: 0.0049 s/iter. Inference: 0.1335 s/iter. Eval: 0.0695 s/iter. Total: 0.2080 s/iter. ETA=0:01:11
[10/13 16:47:58] d2.evaluation.evaluator INFO: Inference done 181/500. Dataloading: 0.0049 s/iter. Inference: 0.1334 s/iter. Eval: 0.0699 s/iter. Total: 0.2083 s/iter. ETA=0:01:06
[10/13 16:48:03] d2.evaluation.evaluator INFO: Inference done 205/500. Dataloading: 0.0049 s/iter. Inference: 0.1337 s/iter. Eval: 0.0700 s/iter. Total: 0.2087 s/iter. ETA=0:01:01
[10/13 16:48:08] d2.evaluation.evaluator INFO: Inference done 229/500. Dataloading: 0.0049 s/iter. Inference: 0.1336 s/iter. Eval: 0.0703 s/iter. Total: 0.2089 s/iter. ETA=0:00:56
[10/13 16:48:13] d2.evaluation.evaluator INFO: Inference done 253/500. Dataloading: 0.0049 s/iter. Inference: 0.1336 s/iter. Eval: 0.0704 s/iter. Total: 0.2089 s/iter. ETA=0:00:51
[10/13 16:48:18] d2.evaluation.evaluator INFO: Inference done 277/500. Dataloading: 0.0049 s/iter. Inference: 0.1333 s/iter. Eval: 0.0706 s/iter. Total: 0.2089 s/iter. ETA=0:00:46
[10/13 16:48:23] d2.evaluation.evaluator INFO: Inference done 302/500. Dataloading: 0.0049 s/iter. Inference: 0.1330 s/iter. Eval: 0.0709 s/iter. Total: 0.2088 s/iter. ETA=0:00:41
[10/13 16:48:28] d2.evaluation.evaluator INFO: Inference done 327/500. Dataloading: 0.0048 s/iter. Inference: 0.1327 s/iter. Eval: 0.0710 s/iter. Total: 0.2086 s/iter. ETA=0:00:36
[10/13 16:48:33] d2.evaluation.evaluator INFO: Inference done 351/500. Dataloading: 0.0048 s/iter. Inference: 0.1326 s/iter. Eval: 0.0711 s/iter. Total: 0.2086 s/iter. ETA=0:00:31
[10/13 16:48:38] d2.evaluation.evaluator INFO: Inference done 375/500. Dataloading: 0.0048 s/iter. Inference: 0.1325 s/iter. Eval: 0.0712 s/iter. Total: 0.2086 s/iter. ETA=0:00:26
[10/13 16:48:43] d2.evaluation.evaluator INFO: Inference done 399/500. Dataloading: 0.0048 s/iter. Inference: 0.1326 s/iter. Eval: 0.0713 s/iter. Total: 0.2087 s/iter. ETA=0:00:21
[10/13 16:48:48] d2.evaluation.evaluator INFO: Inference done 423/500. Dataloading: 0.0047 s/iter. Inference: 0.1325 s/iter. Eval: 0.0714 s/iter. Total: 0.2087 s/iter. ETA=0:00:16
[10/13 16:48:54] d2.evaluation.evaluator INFO: Inference done 448/500. Dataloading: 0.0047 s/iter. Inference: 0.1324 s/iter. Eval: 0.0715 s/iter. Total: 0.2087 s/iter. ETA=0:00:10
[10/13 16:48:59] d2.evaluation.evaluator INFO: Inference done 472/500. Dataloading: 0.0047 s/iter. Inference: 0.1324 s/iter. Eval: 0.0715 s/iter. Total: 0.2087 s/iter. ETA=0:00:05
[10/13 16:49:04] d2.evaluation.evaluator INFO: Inference done 496/500. Dataloading: 0.0047 s/iter. Inference: 0.1324 s/iter. Eval: 0.0715 s/iter. Total: 0.2087 s/iter. ETA=0:00:00
[10/13 16:49:04] d2.evaluation.evaluator INFO: Total inference time: 0:01:43.362316 (0.208813 s / iter per device, on 1 devices)
[10/13 16:49:04] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:05 (0.132350 s / iter per device, on 1 devices)
[10/13 16:49:04] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalc6s1gg0n ...
[10/13 16:49:28] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 57.223 | 80.103 | 70.161 |      19       |
| Things | 49.686 | 79.735 | 62.116 |       8       |
| Stuff  | 62.705 | 80.371 | 76.012 |      11       |
[10/13 16:49:28] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 96.979 | 97.280 | 99.690 |     Stuff     |
| class_8  | 73.133 | 83.620 | 87.459 |     Stuff     |
| class_11 | 87.073 | 88.890 | 97.955 |     Stuff     |
| class_12 | 44.825 | 77.910 | 57.534 |     Stuff     |
| class_13 | 34.579 | 75.982 | 45.509 |     Stuff     |
| class_17 | 38.904 | 62.310 | 62.436 |     Stuff     |
| class_19 | 42.069 | 66.981 | 62.807 |     Stuff     |
| class_20 | 62.080 | 75.406 | 82.328 |     Stuff     |
| class_21 | 88.966 | 89.799 | 99.073 |     Stuff     |
| class_22 | 35.058 | 74.738 | 46.908 |     Stuff     |
| class_23 | 86.090 | 91.166 | 94.432 |     Stuff     |
| class_24 | 50.114 | 74.766 | 67.028 |    Things     |
| class_25 | 46.546 | 73.323 | 63.481 |    Things     |
| class_26 | 64.622 | 81.605 | 79.189 |    Things     |
| class_27 | 49.669 | 88.852 | 55.901 |    Things     |
| class_28 | 63.385 | 90.780 | 69.822 |    Things     |
| class_31 | 47.538 | 85.568 | 55.556 |    Things     |
| class_32 | 36.314 | 73.407 | 49.470 |    Things     |
| class_33 | 39.298 | 69.581 | 56.478 |    Things     |
[10/13 16:49:28] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 16:49:28] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 16:49:28] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 16:49:28] d2.evaluation.testing INFO: copypaste: 57.2233,80.1034,70.1608,49.6859,79.7353,62.1156,62.7050,80.3711,76.0119,96.9786,97.2804,99.6898,73.1330,83.6196,87.4591,87.0726,88.8904,97.9550,44.8251,77.9103,57.5342,34.5788,75.9823,45.5090,38.9038,62.3099,62.4360,42.0688,66.9811,62.8070,62.0795,75.4055,82.3276,88.9662,89.7985,99.0731,35.0584,74.7382,46.9083,86.0898,91.1664,94.4316,50.1138,74.7657,67.0278,46.5464,73.3231,63.4812,64.6222,81.6050,79.1891,49.6690,88.8524,55.9006,63.3850,90.7802,69.8225,47.5377,85.5678,55.5556,36.3145,73.4071,49.4700,39.2985,69.5814,56.4784
[10/13 16:51:14] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 16:51:14] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 16:51:14] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 16:51:14] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 16:51:14] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 16:51:14] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 16:51:17] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0046 s/iter. Inference: 0.1309 s/iter. Eval: 0.0691 s/iter. Total: 0.2046 s/iter. ETA=0:01:40
[10/13 16:51:22] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0048 s/iter. Inference: 0.1322 s/iter. Eval: 0.0720 s/iter. Total: 0.2090 s/iter. ETA=0:01:37
[10/13 16:51:27] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0048 s/iter. Inference: 0.1333 s/iter. Eval: 0.0719 s/iter. Total: 0.2101 s/iter. ETA=0:01:32
[10/13 16:51:32] d2.evaluation.evaluator INFO: Inference done 84/500. Dataloading: 0.0049 s/iter. Inference: 0.1336 s/iter. Eval: 0.0704 s/iter. Total: 0.2091 s/iter. ETA=0:01:26
[10/13 16:51:37] d2.evaluation.evaluator INFO: Inference done 108/500. Dataloading: 0.0050 s/iter. Inference: 0.1341 s/iter. Eval: 0.0707 s/iter. Total: 0.2098 s/iter. ETA=0:01:22
[10/13 16:51:42] d2.evaluation.evaluator INFO: Inference done 133/500. Dataloading: 0.0050 s/iter. Inference: 0.1339 s/iter. Eval: 0.0705 s/iter. Total: 0.2094 s/iter. ETA=0:01:16
[10/13 16:51:47] d2.evaluation.evaluator INFO: Inference done 157/500. Dataloading: 0.0049 s/iter. Inference: 0.1338 s/iter. Eval: 0.0707 s/iter. Total: 0.2095 s/iter. ETA=0:01:11
[10/13 16:51:52] d2.evaluation.evaluator INFO: Inference done 181/500. Dataloading: 0.0049 s/iter. Inference: 0.1336 s/iter. Eval: 0.0709 s/iter. Total: 0.2095 s/iter. ETA=0:01:06
[10/13 16:51:57] d2.evaluation.evaluator INFO: Inference done 205/500. Dataloading: 0.0049 s/iter. Inference: 0.1341 s/iter. Eval: 0.0708 s/iter. Total: 0.2098 s/iter. ETA=0:01:01
[10/13 16:52:03] d2.evaluation.evaluator INFO: Inference done 230/500. Dataloading: 0.0049 s/iter. Inference: 0.1340 s/iter. Eval: 0.0707 s/iter. Total: 0.2096 s/iter. ETA=0:00:56
[10/13 16:52:08] d2.evaluation.evaluator INFO: Inference done 254/500. Dataloading: 0.0048 s/iter. Inference: 0.1339 s/iter. Eval: 0.0708 s/iter. Total: 0.2096 s/iter. ETA=0:00:51
[10/13 16:52:13] d2.evaluation.evaluator INFO: Inference done 278/500. Dataloading: 0.0048 s/iter. Inference: 0.1339 s/iter. Eval: 0.0709 s/iter. Total: 0.2097 s/iter. ETA=0:00:46
[10/13 16:52:18] d2.evaluation.evaluator INFO: Inference done 303/500. Dataloading: 0.0048 s/iter. Inference: 0.1335 s/iter. Eval: 0.0711 s/iter. Total: 0.2095 s/iter. ETA=0:00:41
[10/13 16:52:23] d2.evaluation.evaluator INFO: Inference done 328/500. Dataloading: 0.0048 s/iter. Inference: 0.1332 s/iter. Eval: 0.0712 s/iter. Total: 0.2093 s/iter. ETA=0:00:35
[10/13 16:52:28] d2.evaluation.evaluator INFO: Inference done 352/500. Dataloading: 0.0048 s/iter. Inference: 0.1332 s/iter. Eval: 0.0713 s/iter. Total: 0.2094 s/iter. ETA=0:00:30
[10/13 16:52:33] d2.evaluation.evaluator INFO: Inference done 376/500. Dataloading: 0.0048 s/iter. Inference: 0.1332 s/iter. Eval: 0.0714 s/iter. Total: 0.2095 s/iter. ETA=0:00:25
[10/13 16:52:38] d2.evaluation.evaluator INFO: Inference done 400/500. Dataloading: 0.0048 s/iter. Inference: 0.1333 s/iter. Eval: 0.0714 s/iter. Total: 0.2096 s/iter. ETA=0:00:20
[10/13 16:52:43] d2.evaluation.evaluator INFO: Inference done 424/500. Dataloading: 0.0048 s/iter. Inference: 0.1333 s/iter. Eval: 0.0715 s/iter. Total: 0.2096 s/iter. ETA=0:00:15
[10/13 16:52:48] d2.evaluation.evaluator INFO: Inference done 448/500. Dataloading: 0.0048 s/iter. Inference: 0.1333 s/iter. Eval: 0.0715 s/iter. Total: 0.2096 s/iter. ETA=0:00:10
[10/13 16:52:53] d2.evaluation.evaluator INFO: Inference done 472/500. Dataloading: 0.0048 s/iter. Inference: 0.1332 s/iter. Eval: 0.0716 s/iter. Total: 0.2096 s/iter. ETA=0:00:05
[10/13 16:52:58] d2.evaluation.evaluator INFO: Inference done 496/500. Dataloading: 0.0048 s/iter. Inference: 0.1331 s/iter. Eval: 0.0716 s/iter. Total: 0.2095 s/iter. ETA=0:00:00
[10/13 16:52:59] d2.evaluation.evaluator INFO: Total inference time: 0:01:43.797584 (0.209692 s / iter per device, on 1 devices)
[10/13 16:52:59] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:05 (0.133100 s / iter per device, on 1 devices)
[10/13 16:52:59] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evaltuyuk2ev ...
[10/13 16:53:22] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 57.748 | 80.073 | 70.961 |      19       |
| Things | 49.455 | 79.331 | 62.076 |       8       |
| Stuff  | 63.779 | 80.613 | 77.423 |      11       |
[10/13 16:53:22] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 97.410 | 97.713 | 99.690 |     Stuff     |
| class_8  | 71.605 | 83.817 | 85.430 |     Stuff     |
| class_11 | 86.729 | 88.631 | 97.855 |     Stuff     |
| class_12 | 41.502 | 78.146 | 53.107 |     Stuff     |
| class_13 | 38.197 | 75.322 | 50.712 |     Stuff     |
| class_17 | 42.954 | 62.887 | 68.303 |     Stuff     |
| class_19 | 46.475 | 67.527 | 68.825 |     Stuff     |
| class_20 | 65.834 | 75.930 | 86.703 |     Stuff     |
| class_21 | 88.346 | 89.451 | 98.765 |     Stuff     |
| class_22 | 36.122 | 76.312 | 47.335 |     Stuff     |
| class_23 | 86.390 | 91.003 | 94.931 |     Stuff     |
| class_24 | 48.321 | 74.717 | 64.672 |    Things     |
| class_25 | 43.888 | 73.402 | 59.791 |    Things     |
| class_26 | 63.709 | 81.777 | 77.906 |    Things     |
| class_27 | 52.042 | 87.280 | 59.627 |    Things     |
| class_28 | 61.819 | 89.239 | 69.274 |    Things     |
| class_31 | 46.787 | 82.777 | 56.522 |    Things     |
| class_32 | 39.338 | 74.618 | 52.720 |    Things     |
| class_33 | 39.739 | 70.841 | 56.095 |    Things     |
[10/13 16:53:22] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 16:53:22] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 16:53:22] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 16:53:22] d2.evaluation.testing INFO: copypaste: 57.7478,80.0731,70.9612,49.4554,79.3312,62.0759,63.7786,80.6126,77.4232,97.4099,97.7130,99.6898,71.6054,83.8171,85.4305,86.7294,88.6306,97.8550,41.5015,78.1465,53.1073,38.1972,75.3215,50.7123,42.9536,62.8871,68.3027,46.4750,67.5268,68.8245,65.8335,75.9302,86.7027,88.3464,89.4508,98.7654,36.1221,76.3119,47.3348,86.3903,91.0033,94.9309,48.3207,74.7165,64.6721,43.8881,73.4020,59.7914,63.7092,81.7766,77.9064,52.0424,87.2795,59.6273,61.8190,89.2387,69.2737,46.7872,82.7774,56.5217,39.3382,74.6176,52.7197,39.7386,70.8414,56.0951
[10/13 16:55:09] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 16:55:09] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 16:55:09] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 16:55:09] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 16:55:09] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 16:55:09] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 16:55:12] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0040 s/iter. Inference: 0.1332 s/iter. Eval: 0.0680 s/iter. Total: 0.2052 s/iter. ETA=0:01:40
[10/13 16:55:17] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0048 s/iter. Inference: 0.1344 s/iter. Eval: 0.0730 s/iter. Total: 0.2123 s/iter. ETA=0:01:38
[10/13 16:55:22] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0049 s/iter. Inference: 0.1363 s/iter. Eval: 0.0727 s/iter. Total: 0.2140 s/iter. ETA=0:01:34
[10/13 16:55:27] d2.evaluation.evaluator INFO: Inference done 83/500. Dataloading: 0.0050 s/iter. Inference: 0.1372 s/iter. Eval: 0.0715 s/iter. Total: 0.2138 s/iter. ETA=0:01:29
[10/13 16:55:32] d2.evaluation.evaluator INFO: Inference done 107/500. Dataloading: 0.0050 s/iter. Inference: 0.1372 s/iter. Eval: 0.0714 s/iter. Total: 0.2136 s/iter. ETA=0:01:23
[10/13 16:55:37] d2.evaluation.evaluator INFO: Inference done 132/500. Dataloading: 0.0050 s/iter. Inference: 0.1360 s/iter. Eval: 0.0710 s/iter. Total: 0.2120 s/iter. ETA=0:01:18
[10/13 16:55:43] d2.evaluation.evaluator INFO: Inference done 157/500. Dataloading: 0.0051 s/iter. Inference: 0.1359 s/iter. Eval: 0.0692 s/iter. Total: 0.2102 s/iter. ETA=0:01:12
[10/13 16:55:48] d2.evaluation.evaluator INFO: Inference done 182/500. Dataloading: 0.0051 s/iter. Inference: 0.1356 s/iter. Eval: 0.0692 s/iter. Total: 0.2099 s/iter. ETA=0:01:06
[10/13 16:55:53] d2.evaluation.evaluator INFO: Inference done 206/500. Dataloading: 0.0051 s/iter. Inference: 0.1358 s/iter. Eval: 0.0694 s/iter. Total: 0.2103 s/iter. ETA=0:01:01
[10/13 16:55:58] d2.evaluation.evaluator INFO: Inference done 230/500. Dataloading: 0.0050 s/iter. Inference: 0.1357 s/iter. Eval: 0.0697 s/iter. Total: 0.2105 s/iter. ETA=0:00:56
[10/13 16:56:03] d2.evaluation.evaluator INFO: Inference done 254/500. Dataloading: 0.0050 s/iter. Inference: 0.1357 s/iter. Eval: 0.0699 s/iter. Total: 0.2107 s/iter. ETA=0:00:51
[10/13 16:56:08] d2.evaluation.evaluator INFO: Inference done 278/500. Dataloading: 0.0050 s/iter. Inference: 0.1355 s/iter. Eval: 0.0702 s/iter. Total: 0.2107 s/iter. ETA=0:00:46
[10/13 16:56:13] d2.evaluation.evaluator INFO: Inference done 303/500. Dataloading: 0.0049 s/iter. Inference: 0.1350 s/iter. Eval: 0.0704 s/iter. Total: 0.2104 s/iter. ETA=0:00:41
[10/13 16:56:18] d2.evaluation.evaluator INFO: Inference done 327/500. Dataloading: 0.0049 s/iter. Inference: 0.1348 s/iter. Eval: 0.0705 s/iter. Total: 0.2103 s/iter. ETA=0:00:36
[10/13 16:56:23] d2.evaluation.evaluator INFO: Inference done 351/500. Dataloading: 0.0049 s/iter. Inference: 0.1349 s/iter. Eval: 0.0706 s/iter. Total: 0.2104 s/iter. ETA=0:00:31
[10/13 16:56:29] d2.evaluation.evaluator INFO: Inference done 375/500. Dataloading: 0.0049 s/iter. Inference: 0.1352 s/iter. Eval: 0.0706 s/iter. Total: 0.2107 s/iter. ETA=0:00:26
[10/13 16:56:34] d2.evaluation.evaluator INFO: Inference done 399/500. Dataloading: 0.0049 s/iter. Inference: 0.1353 s/iter. Eval: 0.0707 s/iter. Total: 0.2110 s/iter. ETA=0:00:21
[10/13 16:56:39] d2.evaluation.evaluator INFO: Inference done 423/500. Dataloading: 0.0048 s/iter. Inference: 0.1354 s/iter. Eval: 0.0708 s/iter. Total: 0.2112 s/iter. ETA=0:00:16
[10/13 16:56:44] d2.evaluation.evaluator INFO: Inference done 447/500. Dataloading: 0.0048 s/iter. Inference: 0.1353 s/iter. Eval: 0.0709 s/iter. Total: 0.2110 s/iter. ETA=0:00:11
[10/13 16:56:49] d2.evaluation.evaluator INFO: Inference done 471/500. Dataloading: 0.0048 s/iter. Inference: 0.1352 s/iter. Eval: 0.0710 s/iter. Total: 0.2110 s/iter. ETA=0:00:06
[10/13 16:56:54] d2.evaluation.evaluator INFO: Inference done 495/500. Dataloading: 0.0048 s/iter. Inference: 0.1352 s/iter. Eval: 0.0709 s/iter. Total: 0.2110 s/iter. ETA=0:00:01
[10/13 16:56:55] d2.evaluation.evaluator INFO: Total inference time: 0:01:44.515991 (0.211143 s / iter per device, on 1 devices)
[10/13 16:56:55] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.135155 s / iter per device, on 1 devices)
[10/13 16:56:55] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evala93849s_ ...
[10/13 16:57:18] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 56.458 | 79.661 | 69.618 |      19       |
| Things | 47.623 | 78.352 | 60.591 |       8       |
| Stuff  | 62.884 | 80.613 | 76.183 |      11       |
[10/13 16:57:18] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 97.282 | 97.687 | 99.586 |     Stuff     |
| class_8  | 72.130 | 83.605 | 86.275 |     Stuff     |
| class_11 | 86.621 | 89.174 | 97.137 |     Stuff     |
| class_12 | 41.810 | 77.898 | 53.672 |     Stuff     |
| class_13 | 34.727 | 75.583 | 45.946 |     Stuff     |
| class_17 | 42.093 | 63.010 | 66.803 |     Stuff     |
| class_19 | 44.535 | 67.365 | 66.110 |     Stuff     |
| class_20 | 62.043 | 75.223 | 82.479 |     Stuff     |
| class_21 | 88.920 | 89.751 | 99.075 |     Stuff     |
| class_22 | 35.096 | 76.459 | 45.902 |     Stuff     |
| class_23 | 86.464 | 90.987 | 95.029 |     Stuff     |
| class_24 | 47.565 | 74.323 | 63.998 |    Things     |
| class_25 | 43.892 | 72.108 | 60.870 |    Things     |
| class_26 | 62.643 | 81.397 | 76.959 |    Things     |
| class_27 | 53.713 | 86.478 | 62.112 |    Things     |
| class_28 | 59.873 | 87.382 | 68.519 |    Things     |
| class_31 | 35.073 | 82.672 | 42.424 |    Things     |
| class_32 | 39.077 | 72.242 | 54.093 |    Things     |
| class_33 | 39.151 | 70.216 | 55.758 |    Things     |
[10/13 16:57:18] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 16:57:18] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 16:57:18] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 16:57:18] d2.evaluation.testing INFO: copypaste: 56.4583,79.6611,69.6181,47.6234,78.3524,60.5914,62.8837,80.6128,76.1830,97.2824,97.6869,99.5859,72.1296,83.6048,86.2745,86.6213,89.1743,97.1370,41.8096,77.8979,53.6723,34.7274,75.5831,45.9459,42.0926,63.0098,66.8033,44.5353,67.3653,66.1102,62.0425,75.2225,82.4786,88.9205,89.7507,99.0750,35.0958,76.4588,45.9016,86.4641,90.9871,95.0289,47.5649,74.3227,63.9977,43.8921,72.1085,60.8696,62.6430,81.3975,76.9594,53.7133,86.4784,62.1118,59.8727,87.3818,68.5185,35.0732,82.6725,42.4242,39.0774,72.2417,54.0925,39.1506,70.2158,55.7576
[10/13 16:59:04] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 16:59:05] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 16:59:05] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 16:59:05] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 16:59:05] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 16:59:05] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 16:59:07] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0037 s/iter. Inference: 0.1312 s/iter. Eval: 0.0724 s/iter. Total: 0.2074 s/iter. ETA=0:01:41
[10/13 16:59:12] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0049 s/iter. Inference: 0.1337 s/iter. Eval: 0.0698 s/iter. Total: 0.2085 s/iter. ETA=0:01:36
[10/13 16:59:17] d2.evaluation.evaluator INFO: Inference done 59/500. Dataloading: 0.0050 s/iter. Inference: 0.1348 s/iter. Eval: 0.0686 s/iter. Total: 0.2085 s/iter. ETA=0:01:31
[10/13 16:59:22] d2.evaluation.evaluator INFO: Inference done 84/500. Dataloading: 0.0050 s/iter. Inference: 0.1342 s/iter. Eval: 0.0682 s/iter. Total: 0.2074 s/iter. ETA=0:01:26
[10/13 16:59:27] d2.evaluation.evaluator INFO: Inference done 108/500. Dataloading: 0.0049 s/iter. Inference: 0.1342 s/iter. Eval: 0.0692 s/iter. Total: 0.2083 s/iter. ETA=0:01:21
[10/13 16:59:33] d2.evaluation.evaluator INFO: Inference done 133/500. Dataloading: 0.0049 s/iter. Inference: 0.1339 s/iter. Eval: 0.0692 s/iter. Total: 0.2081 s/iter. ETA=0:01:16
[10/13 16:59:38] d2.evaluation.evaluator INFO: Inference done 157/500. Dataloading: 0.0049 s/iter. Inference: 0.1336 s/iter. Eval: 0.0696 s/iter. Total: 0.2081 s/iter. ETA=0:01:11
[10/13 16:59:43] d2.evaluation.evaluator INFO: Inference done 182/500. Dataloading: 0.0049 s/iter. Inference: 0.1336 s/iter. Eval: 0.0692 s/iter. Total: 0.2078 s/iter. ETA=0:01:06
[10/13 16:59:48] d2.evaluation.evaluator INFO: Inference done 206/500. Dataloading: 0.0049 s/iter. Inference: 0.1337 s/iter. Eval: 0.0695 s/iter. Total: 0.2081 s/iter. ETA=0:01:01
[10/13 16:59:53] d2.evaluation.evaluator INFO: Inference done 230/500. Dataloading: 0.0049 s/iter. Inference: 0.1336 s/iter. Eval: 0.0698 s/iter. Total: 0.2083 s/iter. ETA=0:00:56
[10/13 16:59:58] d2.evaluation.evaluator INFO: Inference done 255/500. Dataloading: 0.0049 s/iter. Inference: 0.1335 s/iter. Eval: 0.0698 s/iter. Total: 0.2083 s/iter. ETA=0:00:51
[10/13 17:00:03] d2.evaluation.evaluator INFO: Inference done 280/500. Dataloading: 0.0049 s/iter. Inference: 0.1334 s/iter. Eval: 0.0694 s/iter. Total: 0.2078 s/iter. ETA=0:00:45
[10/13 17:00:08] d2.evaluation.evaluator INFO: Inference done 305/500. Dataloading: 0.0049 s/iter. Inference: 0.1332 s/iter. Eval: 0.0693 s/iter. Total: 0.2075 s/iter. ETA=0:00:40
[10/13 17:00:13] d2.evaluation.evaluator INFO: Inference done 330/500. Dataloading: 0.0050 s/iter. Inference: 0.1334 s/iter. Eval: 0.0691 s/iter. Total: 0.2075 s/iter. ETA=0:00:35
[10/13 17:00:18] d2.evaluation.evaluator INFO: Inference done 354/500. Dataloading: 0.0050 s/iter. Inference: 0.1335 s/iter. Eval: 0.0691 s/iter. Total: 0.2077 s/iter. ETA=0:00:30
[10/13 17:00:24] d2.evaluation.evaluator INFO: Inference done 378/500. Dataloading: 0.0050 s/iter. Inference: 0.1335 s/iter. Eval: 0.0693 s/iter. Total: 0.2078 s/iter. ETA=0:00:25
[10/13 17:00:29] d2.evaluation.evaluator INFO: Inference done 402/500. Dataloading: 0.0050 s/iter. Inference: 0.1336 s/iter. Eval: 0.0693 s/iter. Total: 0.2079 s/iter. ETA=0:00:20
[10/13 17:00:34] d2.evaluation.evaluator INFO: Inference done 427/500. Dataloading: 0.0050 s/iter. Inference: 0.1335 s/iter. Eval: 0.0694 s/iter. Total: 0.2079 s/iter. ETA=0:00:15
[10/13 17:00:39] d2.evaluation.evaluator INFO: Inference done 451/500. Dataloading: 0.0050 s/iter. Inference: 0.1335 s/iter. Eval: 0.0695 s/iter. Total: 0.2080 s/iter. ETA=0:00:10
[10/13 17:00:44] d2.evaluation.evaluator INFO: Inference done 475/500. Dataloading: 0.0050 s/iter. Inference: 0.1336 s/iter. Eval: 0.0695 s/iter. Total: 0.2082 s/iter. ETA=0:00:05
[10/13 17:00:49] d2.evaluation.evaluator INFO: Inference done 499/500. Dataloading: 0.0049 s/iter. Inference: 0.1335 s/iter. Eval: 0.0697 s/iter. Total: 0.2082 s/iter. ETA=0:00:00
[10/13 17:00:49] d2.evaluation.evaluator INFO: Total inference time: 0:01:43.146360 (0.208376 s / iter per device, on 1 devices)
[10/13 17:00:49] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:06 (0.133502 s / iter per device, on 1 devices)
[10/13 17:00:49] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evals82c5iem ...
[10/13 17:01:13] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 57.252 | 80.294 | 70.316 |      19       |
| Things | 49.069 | 79.846 | 61.675 |       8       |
| Stuff  | 63.202 | 80.620 | 76.600 |      11       |
[10/13 17:01:13] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 97.340 | 97.745 | 99.586 |     Stuff     |
| class_8  | 73.601 | 83.839 | 87.789 |     Stuff     |
| class_11 | 86.813 | 89.088 | 97.446 |     Stuff     |
| class_12 | 40.372 | 78.357 | 51.524 |     Stuff     |
| class_13 | 38.632 | 75.272 | 51.323 |     Stuff     |
| class_17 | 42.509 | 62.985 | 67.490 |     Stuff     |
| class_19 | 46.076 | 67.271 | 68.493 |     Stuff     |
| class_20 | 60.681 | 75.689 | 80.171 |     Stuff     |
| class_21 | 88.493 | 89.595 | 98.770 |     Stuff     |
| class_22 | 34.187 | 75.834 | 45.082 |     Stuff     |
| class_23 | 86.519 | 91.139 | 94.931 |     Stuff     |
| class_24 | 52.346 | 75.516 | 69.318 |    Things     |
| class_25 | 47.303 | 72.859 | 64.924 |    Things     |
| class_26 | 64.332 | 81.927 | 78.523 |    Things     |
| class_27 | 42.480 | 88.263 | 48.128 |    Things     |
| class_28 | 50.062 | 91.560 | 54.676 |    Things     |
| class_31 | 53.801 | 84.839 | 63.415 |    Things     |
| class_32 | 40.712 | 73.059 | 55.725 |    Things     |
| class_33 | 41.520 | 70.742 | 58.693 |    Things     |
[10/13 17:01:13] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 17:01:13] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 17:01:13] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 17:01:13] d2.evaluation.testing INFO: copypaste: 57.2516,80.2937,70.3162,49.0694,79.8458,61.6753,63.2022,80.6195,76.6005,97.3400,97.7447,99.5859,73.6011,83.8388,87.7888,86.8133,89.0883,97.4464,40.3721,78.3567,51.5235,38.6318,75.2723,51.3228,42.5087,62.9854,67.4897,46.0763,67.2714,68.4932,60.6813,75.6894,80.1715,88.4931,89.5947,98.7705,34.1872,75.8335,45.0820,86.5194,91.1394,94.9309,52.3461,75.5161,69.3178,47.3030,72.8593,64.9237,64.3318,81.9268,78.5235,42.4796,88.2632,48.1283,50.0618,91.5604,54.6763,53.8006,84.8395,63.4146,40.7125,73.0594,55.7252,41.5201,70.7416,58.6926
[10/13 17:02:58] fcclip.data.datasets.register_cityscapes_panoptic INFO: 3 cities found in 'datasets/cityscapes/leftImg8bit/val'.
[10/13 17:02:58] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2560, sample_style='choice')]
[10/13 17:02:58] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/13 17:02:58] d2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/13 17:02:58] d2.data.common INFO: Serialized dataset takes 0.74 MiB
[10/13 17:02:58] d2.evaluation.evaluator INFO: Start inference on 500 batches
[10/13 17:03:01] d2.evaluation.evaluator INFO: Inference done 11/500. Dataloading: 0.0039 s/iter. Inference: 0.1365 s/iter. Eval: 0.0743 s/iter. Total: 0.2147 s/iter. ETA=0:01:44
[10/13 17:03:06] d2.evaluation.evaluator INFO: Inference done 35/500. Dataloading: 0.0049 s/iter. Inference: 0.1362 s/iter. Eval: 0.0688 s/iter. Total: 0.2099 s/iter. ETA=0:01:37
[10/13 17:03:11] d2.evaluation.evaluator INFO: Inference done 60/500. Dataloading: 0.0050 s/iter. Inference: 0.1343 s/iter. Eval: 0.0687 s/iter. Total: 0.2080 s/iter. ETA=0:01:31
[10/13 17:03:16] d2.evaluation.evaluator INFO: Inference done 85/500. Dataloading: 0.0050 s/iter. Inference: 0.1335 s/iter. Eval: 0.0682 s/iter. Total: 0.2068 s/iter. ETA=0:01:25
[10/13 17:03:21] d2.evaluation.evaluator INFO: Inference done 109/500. Dataloading: 0.0050 s/iter. Inference: 0.1337 s/iter. Eval: 0.0690 s/iter. Total: 0.2077 s/iter. ETA=0:01:21
[10/13 17:03:26] d2.evaluation.evaluator INFO: Inference done 134/500. Dataloading: 0.0051 s/iter. Inference: 0.1335 s/iter. Eval: 0.0679 s/iter. Total: 0.2066 s/iter. ETA=0:01:15
[10/13 17:03:31] d2.evaluation.evaluator INFO: Inference done 159/500. Dataloading: 0.0051 s/iter. Inference: 0.1337 s/iter. Eval: 0.0677 s/iter. Total: 0.2066 s/iter. ETA=0:01:10
[10/13 17:03:37] d2.evaluation.evaluator INFO: Inference done 183/500. Dataloading: 0.0051 s/iter. Inference: 0.1337 s/iter. Eval: 0.0683 s/iter. Total: 0.2071 s/iter. ETA=0:01:05
[10/13 17:03:42] d2.evaluation.evaluator INFO: Inference done 207/500. Dataloading: 0.0051 s/iter. Inference: 0.1337 s/iter. Eval: 0.0687 s/iter. Total: 0.2075 s/iter. ETA=0:01:00
[10/13 17:03:47] d2.evaluation.evaluator INFO: Inference done 231/500. Dataloading: 0.0051 s/iter. Inference: 0.1335 s/iter. Eval: 0.0691 s/iter. Total: 0.2078 s/iter. ETA=0:00:55
[10/13 17:03:52] d2.evaluation.evaluator INFO: Inference done 255/500. Dataloading: 0.0050 s/iter. Inference: 0.1335 s/iter. Eval: 0.0694 s/iter. Total: 0.2080 s/iter. ETA=0:00:50
[10/13 17:03:57] d2.evaluation.evaluator INFO: Inference done 279/500. Dataloading: 0.0050 s/iter. Inference: 0.1332 s/iter. Eval: 0.0698 s/iter. Total: 0.2080 s/iter. ETA=0:00:45
[10/13 17:04:02] d2.evaluation.evaluator INFO: Inference done 304/500. Dataloading: 0.0050 s/iter. Inference: 0.1329 s/iter. Eval: 0.0701 s/iter. Total: 0.2080 s/iter. ETA=0:00:40
[10/13 17:04:07] d2.evaluation.evaluator INFO: Inference done 329/500. Dataloading: 0.0050 s/iter. Inference: 0.1326 s/iter. Eval: 0.0703 s/iter. Total: 0.2079 s/iter. ETA=0:00:35
[10/13 17:04:12] d2.evaluation.evaluator INFO: Inference done 354/500. Dataloading: 0.0050 s/iter. Inference: 0.1326 s/iter. Eval: 0.0703 s/iter. Total: 0.2079 s/iter. ETA=0:00:30
[10/13 17:04:17] d2.evaluation.evaluator INFO: Inference done 378/500. Dataloading: 0.0050 s/iter. Inference: 0.1327 s/iter. Eval: 0.0704 s/iter. Total: 0.2082 s/iter. ETA=0:00:25
[10/13 17:04:22] d2.evaluation.evaluator INFO: Inference done 403/500. Dataloading: 0.0050 s/iter. Inference: 0.1328 s/iter. Eval: 0.0700 s/iter. Total: 0.2079 s/iter. ETA=0:00:20
[10/13 17:04:27] d2.evaluation.evaluator INFO: Inference done 427/500. Dataloading: 0.0050 s/iter. Inference: 0.1327 s/iter. Eval: 0.0702 s/iter. Total: 0.2080 s/iter. ETA=0:00:15
[10/13 17:04:32] d2.evaluation.evaluator INFO: Inference done 451/500. Dataloading: 0.0050 s/iter. Inference: 0.1327 s/iter. Eval: 0.0703 s/iter. Total: 0.2081 s/iter. ETA=0:00:10
[10/13 17:04:37] d2.evaluation.evaluator INFO: Inference done 475/500. Dataloading: 0.0050 s/iter. Inference: 0.1327 s/iter. Eval: 0.0704 s/iter. Total: 0.2082 s/iter. ETA=0:00:05
[10/13 17:04:43] d2.evaluation.evaluator INFO: Inference done 500/500. Dataloading: 0.0050 s/iter. Inference: 0.1327 s/iter. Eval: 0.0702 s/iter. Total: 0.2080 s/iter. ETA=0:00:00
[10/13 17:04:43] d2.evaluation.evaluator INFO: Total inference time: 0:01:43.011270 (0.208104 s / iter per device, on 1 devices)
[10/13 17:04:43] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:05 (0.132676 s / iter per device, on 1 devices)
[10/13 17:04:43] d2.evaluation.panoptic_evaluation INFO: Writing all panoptic predictions to /tmp/panoptic_evalgsy_djm0 ...
[10/13 17:05:06] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 58.101 | 80.021 | 71.486 |      19       |
| Things | 50.493 | 79.296 | 63.523 |       8       |
| Stuff  | 63.633 | 80.548 | 77.277 |      11       |
[10/13 17:05:06] d2.evaluation.panoptic_evaluation INFO: Panoptic Evaluation Results:
|          |   PQ   |   SQ   |   RQ   |  #categories  |
|:--------:|:------:|:------:|:------:|:-------------:|
| class_7  | 97.180 | 97.584 | 99.586 |     Stuff     |
| class_8  | 72.848 | 83.437 | 87.309 |     Stuff     |
| class_11 | 86.863 | 88.953 | 97.651 |     Stuff     |
| class_12 | 42.234 | 77.500 | 54.496 |     Stuff     |
| class_13 | 37.146 | 75.545 | 49.171 |     Stuff     |
| class_17 | 43.007 | 62.718 | 68.571 |     Stuff     |
| class_19 | 46.503 | 67.876 | 68.512 |     Stuff     |
| class_20 | 63.261 | 75.427 | 83.871 |     Stuff     |
| class_21 | 88.571 | 89.676 | 98.768 |     Stuff     |
| class_22 | 35.551 | 76.618 | 46.400 |     Stuff     |
| class_23 | 86.801 | 90.689 | 95.713 |     Stuff     |
| class_24 | 51.844 | 75.443 | 68.719 |    Things     |
| class_25 | 46.602 | 72.754 | 64.054 |    Things     |
| class_26 | 64.648 | 82.037 | 78.803 |    Things     |
| class_27 | 50.674 | 87.871 | 57.669 |    Things     |
| class_28 | 61.418 | 89.800 | 68.394 |    Things     |
| class_31 | 47.239 | 82.669 | 57.143 |    Things     |
| class_32 | 41.410 | 73.617 | 56.250 |    Things     |
| class_33 | 40.112 | 70.179 | 57.156 |    Things     |
[10/13 17:05:06] d2.engine.defaults INFO: Evaluation results for openvocab_cityscapes_fine_panoptic_val in csv format:
[10/13 17:05:06] d2.evaluation.testing INFO: copypaste: Task: panoptic_seg
[10/13 17:05:06] d2.evaluation.testing INFO: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st,PQ_7,SQ_7,RQ_7,PQ_8,SQ_8,RQ_8,PQ_11,SQ_11,RQ_11,PQ_12,SQ_12,RQ_12,PQ_13,SQ_13,RQ_13,PQ_17,SQ_17,RQ_17,PQ_19,SQ_19,RQ_19,PQ_20,SQ_20,RQ_20,PQ_21,SQ_21,RQ_21,PQ_22,SQ_22,RQ_22,PQ_23,SQ_23,RQ_23,PQ_24,SQ_24,RQ_24,PQ_25,SQ_25,RQ_25,PQ_26,SQ_26,RQ_26,PQ_27,SQ_27,RQ_27,PQ_28,SQ_28,RQ_28,PQ_31,SQ_31,RQ_31,PQ_32,SQ_32,RQ_32,PQ_33,SQ_33,RQ_33
[10/13 17:05:06] d2.evaluation.testing INFO: copypaste: 58.1006,80.0207,71.4861,50.4933,79.2964,63.5235,63.6332,80.5475,77.2770,97.1803,97.5844,99.5859,72.8477,83.4371,87.3085,86.8634,88.9532,97.6507,42.2343,77.4999,54.4959,37.1463,75.5448,49.1713,43.0069,62.7184,68.5714,46.5030,67.8756,68.5121,63.2612,75.4269,83.8710,88.5714,89.6763,98.7680,35.5505,76.6175,46.4000,86.8007,90.6888,95.7126,51.8439,75.4433,68.7191,46.6017,72.7540,64.0538,64.6480,82.0371,78.8034,50.6743,87.8714,57.6687,61.4177,89.8001,68.3938,47.2395,82.6691,57.1429,41.4098,73.6174,56.2500,40.1116,70.1787,57.1564
