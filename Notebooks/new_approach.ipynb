{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read the initial json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/ids/gbrison/FC/fc-clip/datasets/cityscapes/gtFine/cityscapes_panoptic_train.json\"\n",
    "with open(path, 'r') as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the ids that can be changed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_id_class=[]\n",
    "for i in data['annotations']:\n",
    "    for k in i['segments_info']:\n",
    "        if k['category_id'] < 50:\n",
    "            if k['category_id'] not in lis_id_class:\n",
    "                lis_id_class.append(k['category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 8, 11, 17, 20, 21, 22, 23, 24, 25, 26, 33, 12, 13, 19, 32, 28, 27, 31]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis_id_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the output json after the inference \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_results=\"/tsi/hi-paris/FCCLIP_results/inference_results/fcclip_cocopan_train/inference/predictions.json\"\n",
    "with open(path_results, 'r') as file:\n",
    "    outputs = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are objects that are not classified with the model \n",
    "Proof: For the first image, we have 21 objects in the input annotation and the model detects 12 objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 12)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['annotations'][0]['segments_info']),len(outputs['annotations'][0]['segments_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get  classes that represent isthing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "isthing_classes=[]\n",
    "for i in data[\"categories\"]: \n",
    "    if i['isthing']==1:\n",
    "        isthing_classes.append(i['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 25, 26, 27, 28, 31, 32, 33]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isthing_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Read data for intermediate results to find correspondences between labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tsi/hi-paris/FCCLIP_results/inference_results/train/aal\", \"rb\") as fp:   # Unpickling\n",
    "     gt_pred_map = pickle.load(fp)\n",
    "with open(\"/tsi/hi-paris/FCCLIP_results/inference_results/train/all1\", \"rb\") as fp:   # Unpickling\n",
    "     gt_ann = pickle.load(fp)\n",
    "with open(\"/tsi/hi-paris/FCCLIP_results/inference_results/train/all2\", \"rb\") as fp:   # Unpickling\n",
    "     pred_ann = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tsi/hi-paris/FCCLIP_results/inference_results/train/pred_segms_list\", \"rb\") as fp:   # Unpickling\n",
    "     pred_segms_list = pickle.load(fp)\n",
    "with open(\"/tsi/hi-paris/FCCLIP_results/inference_results/train/gt_segms_list\", \"rb\") as fp:   # Unpickling\n",
    "     gt_segms_list = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Found the matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_(data, id, val):\n",
    "    for i in data:\n",
    "        if i[0]==id[0]:\n",
    "            return True, i\n",
    "    return False, None\n",
    "\n",
    "def get_matchin(pred_segms_list,gt_segms_list,matchin_list):\n",
    "    matchin_ids_data=[]\n",
    "    for pred_segms, gt_segms, matchin in zip(pred_segms_list, gt_segms_list, matchin_list):\n",
    "        \n",
    "        lis={}\n",
    "        for label_tuple, intersection in matchin.items():\n",
    "            gt_label, pred_label = label_tuple\n",
    "            if gt_label not in gt_segms:\n",
    "                continue\n",
    "            if pred_label not in pred_segms:\n",
    "                continue\n",
    "            if gt_segms[gt_label]['iscrowd'] == 1:\n",
    "                continue\n",
    "            if gt_segms[gt_label]['category_id'] != pred_segms[pred_label]['category_id']:\n",
    "                continue\n",
    "            if label_tuple in lis:\n",
    "                if lis[label_tuple] < intersection :\n",
    "                    lis[label_tuple]=intersection\n",
    "            elif label_tuple not in lis:\n",
    "                test,id=test_(lis, label_tuple, intersection)\n",
    "                if test:\n",
    "                    if lis[id] < intersection:\n",
    "                        lis[id]=intersection   \n",
    "                else:\n",
    "                    lis[label_tuple]=intersection\n",
    "\n",
    "        matchin_ids_data.append(lis)\n",
    "    return matchin_ids_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchin_ids_data=get_matchin(pred_segms_list,gt_segms_list,gt_pred_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exemple of the matching for the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert data matching\n",
    "new_data_matchin=[]\n",
    "for i in matchin_ids_data:\n",
    "    lis={}\n",
    "    for j in i:\n",
    "        lis[j[0]]=j[1]\n",
    "    new_data_matchin.append(lis) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparate jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_json(input_json, data_matchin,pred_segms_list, conf):\n",
    "    path=\"/home/ids/gbrison/FC/fc-clip/datasets/cityscapes/gtFine/cityscapes_panoptic_train.json\"\n",
    "    with open(path, 'r') as file:\n",
    "        new_json = json.load(file)\n",
    "\n",
    "    list_of_labels= [7, 8, 11, 17, 20, 21, 22, 23, 24, 25, 26, 33, 12, 13, 19, 32, 28, 27, 31]\n",
    "    in_vocab_labels=list_of_labels[:-conf]\n",
    "    out_vocab_labels=list_of_labels[-conf:]\n",
    "    for annot_new, outputs, matching in zip(new_json[\"annotations\"],pred_segms_list, data_matchin):\n",
    "        for segment in annot_new[\"segments_info\"]:\n",
    "            if segment['category_id'] in out_vocab_labels:\n",
    "                if segment['id'] in matching:\n",
    "                    segment['category_id']=outputs[matching[segment['id']]][\"category_id\"] \n",
    "    return new_json\n",
    "\n",
    "    \n",
    "\n",
    "new_json=prepare_json(data, new_data_matchin,pred_segms_list, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json=\"/home/ids/gbrison/FC/fc-clip/datasets/cityscapes/gtFine/cityscapes_panoptic_train5.json\"\n",
    "with open(save_json, 'w') as f:\n",
    "    json.dump(new_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "la=0\n",
    "for k in range(len(new_json[\"annotations\"])):\n",
    "    for i,j in zip(new_json[\"annotations\"][k][\"segments_info\"],data[\"annotations\"][k][\"segments_info\"]):\n",
    "        if i['category_id']!=j['category_id']:\n",
    "            la+=1\n",
    "la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000, 0.0000, 0.0000, 0.0000, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Exemple de tenseur\n",
    "input_tensor = torch.tensor([0.5, 0.2, 0.1, 0.0, 0.2])\n",
    "\n",
    "# Appliquer le seuil\n",
    "threshold_value = .2\n",
    "thresholded_tensor = F.threshold(input_tensor, threshold_value, 0)\n",
    "\n",
    "print(thresholded_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
