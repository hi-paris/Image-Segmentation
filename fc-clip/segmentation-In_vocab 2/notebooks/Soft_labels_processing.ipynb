{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path='/tsi/hi-paris/FCCLIP_results/All_results/INvocab/fcclip_cocopan_soft_label_cls_reslt'\n",
    "image_id='frankfurt_000000_003025'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(results_path, image_id, iter):\n",
    "    path_cls=os.path.join(results_path, \"Softlabels\", \"iter_\"+str(iter), \"mask_cls_\"+image_id)\n",
    "    path_pred=os.path.join(results_path, \"Softlabels\", \"iter_\"+str(iter), \"mask_pred_\"+image_id)\n",
    "    path_cls_results=os.path.join(results_path, \"Softlabels\", \"iter_\"+str(iter), \"cls_results_\"+image_id) \n",
    "    with open(path_cls, 'rb') as file:\n",
    "        mask_cls_results=pickle.load(file)\n",
    "    with open(path_pred, 'rb') as file:\n",
    "        mask_pred_results=pickle.load(file)\n",
    "    with open(path_cls_results, 'rb') as file:\n",
    "        cls_results=pickle.load(file)\n",
    "    return mask_cls_results, mask_pred_results, cls_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_cls, mask_pred, cls_results=read_data(results_path,image_id, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_cls shape :  torch.Size([250, 20])\n",
      "mask_pred shape :  torch.Size([250, 1024, 2048])\n",
      "cls_results shape :  torch.Size([250, 19])\n"
     ]
    }
   ],
   "source": [
    "print(\"mask_cls shape : \",mask_cls.shape)\n",
    "print(\"mask_pred shape : \",mask_pred.shape)\n",
    "print(\"cls_results shape : \",cls_results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.5868,  -6.1712,  -5.3217,  ...,  -6.6361,  -5.7529,  -6.2488],\n",
       "        [ -3.1796,  -0.5827,  -7.1274,  ...,  -7.4282,  -8.3347,  -7.3614],\n",
       "        [ -4.6267,  -3.4722,  -4.5846,  ...,  -6.4773,  -2.5643,  -1.1388],\n",
       "        ...,\n",
       "        [ -4.7889,  -0.2774,  -7.3556,  ..., -10.5080, -10.2403,  -8.1663],\n",
       "        [ -6.3979,  -7.4855,  -4.6816,  ...,  -6.1244,  -7.6204,  -6.7934],\n",
       "        [ -7.1083,  -7.3084,  -0.5636,  ...,  -6.0019,  -8.5052,  -6.5708]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.1133e+00, -9.6976e+00, -8.8482e+00,  ..., -9.2793e+00,\n",
       "         -9.7752e+00, -2.5161e-02],\n",
       "        [-3.7035e+00, -1.1066e+00, -7.6513e+00,  ..., -8.8586e+00,\n",
       "         -7.8853e+00, -4.7646e-01],\n",
       "        [-8.5122e+00, -7.3577e+00, -8.4701e+00,  ..., -6.4498e+00,\n",
       "         -5.0243e+00, -2.0750e-02],\n",
       "        ...,\n",
       "        [-6.7635e+00, -2.2520e+00, -9.3300e+00,  ..., -1.2213e+01,\n",
       "         -1.0141e+01, -1.4946e-01],\n",
       "        [-9.3261e+00, -1.0413e+01, -7.6098e+00,  ..., -1.0548e+01,\n",
       "         -9.7215e+00, -5.1666e-02],\n",
       "        [-1.2587e+01, -1.2786e+01, -6.0452e+00,  ..., -1.3975e+01,\n",
       "         -1.2051e+01, -2.8985e-03]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-40.6938, -40.6938, -41.2296,  ..., -49.4048, -50.0707, -50.0707],\n",
       "         [-40.6938, -40.6938, -41.2296,  ..., -49.4048, -50.0707, -50.0707],\n",
       "         [-41.3912, -41.3912, -41.8377,  ..., -49.0957, -49.7322, -49.7322],\n",
       "         ...,\n",
       "         [-35.2304, -35.2304, -34.6074,  ..., -26.0899, -26.1625, -26.1625],\n",
       "         [-35.6348, -35.6348, -34.9745,  ..., -26.5478, -26.6025, -26.6025],\n",
       "         [-35.6348, -35.6348, -34.9745,  ..., -26.5478, -26.6025, -26.6025]],\n",
       "\n",
       "        [[-12.5402, -12.5402, -12.6221,  ..., -11.9848, -11.9099, -11.9099],\n",
       "         [-12.5402, -12.5402, -12.6221,  ..., -11.9848, -11.9099, -11.9099],\n",
       "         [-12.6390, -12.6390, -12.6980,  ..., -11.8489, -11.7799, -11.7799],\n",
       "         ...,\n",
       "         [ -8.4243,  -8.4243,  -7.9612,  ...,  -4.9468,  -5.0400,  -5.0400],\n",
       "         [ -8.7508,  -8.7508,  -8.2640,  ...,  -5.0188,  -5.1018,  -5.1018],\n",
       "         [ -8.7508,  -8.7508,  -8.2640,  ...,  -5.0188,  -5.1018,  -5.1018]],\n",
       "\n",
       "        [[-70.2140, -70.2140, -71.5643,  ..., -89.5870, -90.5260, -90.5260],\n",
       "         [-70.2140, -70.2140, -71.5643,  ..., -89.5870, -90.5260, -90.5260],\n",
       "         [-71.4504, -71.4504, -72.6197,  ..., -88.9698, -89.9667, -89.9667],\n",
       "         ...,\n",
       "         [-91.9999, -91.9999, -91.6913,  ..., -89.9380, -90.0798, -90.0798],\n",
       "         [-92.2806, -92.2806, -91.9985,  ..., -90.5254, -90.6074, -90.6074],\n",
       "         [-92.2806, -92.2806, -91.9985,  ..., -90.5254, -90.6074, -90.6074]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-30.1200, -30.1200, -30.1037,  ..., -33.1380, -33.4056, -33.4056],\n",
       "         [-30.1200, -30.1200, -30.1037,  ..., -33.1380, -33.4056, -33.4056],\n",
       "         [-29.7709, -29.7709, -29.6896,  ..., -32.4720, -32.7987, -32.7987],\n",
       "         ...,\n",
       "         [-35.8751, -35.8751, -35.4712,  ..., -29.8406, -30.1800, -30.1800],\n",
       "         [-36.1667, -36.1667, -35.7599,  ..., -30.0818, -30.3766, -30.3766],\n",
       "         [-36.1667, -36.1667, -35.7599,  ..., -30.0818, -30.3766, -30.3766]],\n",
       "\n",
       "        [[-11.1832, -11.1832, -11.4484,  ..., -20.5740, -21.0526, -21.0526],\n",
       "         [-11.1832, -11.1832, -11.4484,  ..., -20.5740, -21.0526, -21.0526],\n",
       "         [-11.1511, -11.1511, -11.4016,  ..., -20.4239, -20.8843, -20.8843],\n",
       "         ...,\n",
       "         [-30.7002, -30.7002, -30.7240,  ..., -28.1307, -28.1186, -28.1186],\n",
       "         [-31.0567, -31.0567, -31.0910,  ..., -28.2385, -28.1704, -28.1704],\n",
       "         [-31.0567, -31.0567, -31.0910,  ..., -28.2385, -28.1704, -28.1704]],\n",
       "\n",
       "        [[ -5.3018,  -5.3018,  -5.3915,  ..., -13.0256, -13.3356, -13.3356],\n",
       "         [ -5.3018,  -5.3018,  -5.3915,  ..., -13.0256, -13.3356, -13.3356],\n",
       "         [ -5.3414,  -5.3414,  -5.4145,  ..., -12.9951, -13.2847, -13.2847],\n",
       "         ...,\n",
       "         [-13.3745, -13.3745, -13.2164,  ..., -12.0207, -11.9719, -11.9719],\n",
       "         [-13.6370, -13.6370, -13.4683,  ..., -12.0762, -12.0041, -12.0041],\n",
       "         [-13.6370, -13.6370, -13.4683,  ..., -12.0762, -12.0041, -12.0041]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(mask_cls, mask_pred): \n",
    "    mask_pred_view = mask_pred.view(250, -1)   \n",
    "  \n",
    "    result = torch.matmul(mask_pred_view.T,mask_cls)\n",
    " \n",
    "    result_reshaped = result.view(19, 1024, 2048)\n",
    " \n",
    "    softmax_result = F.softmax(result_reshaped.T, dim=-1)\n",
    "    return softmax_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4136620/1249224819.py:8: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3675.)\n",
      "  softmax_result = F.softmax(result_reshaped.T, dim=-1)\n"
     ]
    }
   ],
   "source": [
    "results=get_results(mask_cls, mask_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possibility_of_erreur(results, seuil):\n",
    " \n",
    "    greater_than_seuil = results > seuil\n",
    "\n",
    "    count_greater_than_suil = greater_than_seuil.sum(dim=-1)\n",
    " \n",
    "    conflict_mask = count_greater_than_suil > 1\n",
    " \n",
    "    sum_of_conflict = conflict_mask.sum().item()\n",
    "\n",
    "    print(\"Number of conflicts:\", sum_of_conflict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conflicts: 145\n"
     ]
    }
   ],
   "source": [
    "get_possibility_of_erreur(results, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# approach  1 \n",
    "### The criterions\n",
    "To detect cases were probabilities of labels are similar\n",
    "\n",
    "Case were there is a risk of change in final label prediction\n",
    "\n",
    "We are looking at a pixel level per image an array of 19 labels with probabilities\n",
    "\n",
    "Examples: Standard Deviation between values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possibility_of_erreur_std(results):\n",
    " \n",
    "    std_deviation = results.std(dim=-1)\n",
    "    \n",
    "    conflict_mask = std_deviation > 1\n",
    " \n",
    "    sum_of_conflict = conflict_mask.sum().item()\n",
    "\n",
    "    print(\"Number of conflicts:\", sum_of_conflict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2294, 0.2294, 0.2294,  ..., 0.2294, 0.2294, 0.2294],\n",
      "        [0.2294, 0.2294, 0.2294,  ..., 0.2294, 0.2294, 0.2294],\n",
      "        [0.2294, 0.2294, 0.2294,  ..., 0.2294, 0.2294, 0.2294],\n",
      "        ...,\n",
      "        [0.2294, 0.2294, 0.2294,  ..., 0.2294, 0.2294, 0.2294],\n",
      "        [0.2294, 0.2294, 0.2294,  ..., 0.2294, 0.2294, 0.2294],\n",
      "        [0.2294, 0.2294, 0.2294,  ..., 0.2294, 0.2294, 0.2294]])\n",
      "Number of conflicts: 0\n"
     ]
    }
   ],
   "source": [
    "get_possibility_of_erreur_std(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
